{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Wanita-8943/Project_2023/blob/main/2e-5_32_0.2_Male18_500.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#เรียกใช้ CSV"
      ],
      "metadata": {
        "id": "ow7eWoNw6U-c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import shutil"
      ],
      "metadata": {
        "id": "DlQ2oT7cIR6o"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1_2Fe8u81d5r",
        "outputId": "0fd982f0-bbb0-4f6b-ed99-c13697f8909c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Imports"
      ],
      "metadata": {
        "id": "5qxePnnn7TGW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import models\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import optimizers\n",
        "import os\n",
        "import glob\n",
        "import shutil\n",
        "import sys\n",
        "import numpy as np\n",
        "from skimage.io import imread\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import Image\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "D-hCRloc3t39"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras import backend as K"
      ],
      "metadata": {
        "id": "YZWXwjXeGxZP"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#กำหนดค่าพารามิเตอร์\n"
      ],
      "metadata": {
        "id": "RooqSdBc7QHC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 32\n",
        "width = 150\n",
        "height = 150\n",
        "epochs = 500\n",
        "NUM_TRAIN = 1425\n",
        "NUM_TEST = 475\n",
        "dropout_rate = 0.2\n",
        "input_shape = (height, width, 3)"
      ],
      "metadata": {
        "id": "thDb7U9B3xOo"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Clone efficientnet repo\n"
      ],
      "metadata": {
        "id": "pumGmy6f3eSW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#ดึงข้อมูลใน Github มาใช้\n",
        "import os\n",
        "%cd /content\n",
        "if not os.path.isdir(\"efficientnet_keras_transfer_learning\"):\n",
        " !git clone https://github.com/Wanita-8943/efficientnet_keras_transfer_learning\n",
        "%cd efficientnet_keras_transfer_learning/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P7iy2f8n16p0",
        "outputId": "99bbb597-93c0-48f3-e4ff-61154272c659"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "Cloning into 'efficientnet_keras_transfer_learning'...\n",
            "remote: Enumerating objects: 831, done.\u001b[K\n",
            "remote: Counting objects: 100% (353/353), done.\u001b[K\n",
            "remote: Compressing objects: 100% (166/166), done.\u001b[K\n",
            "remote: Total 831 (delta 249), reused 248 (delta 187), pack-reused 478\u001b[K\n",
            "Receiving objects: 100% (831/831), 13.73 MiB | 26.33 MiB/s, done.\n",
            "Resolving deltas: 100% (489/489), done.\n",
            "/content/efficientnet_keras_transfer_learning\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import keras"
      ],
      "metadata": {
        "id": "Vbdblwbv89fe"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ],
      "metadata": {
        "id": "vnLrobY_-GCx",
        "outputId": "e812271c-1486-4a04-a979-6d7de30129a8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.11.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Options: EfficientNetB0, EfficientNetB1, EfficientNetB2, EfficientNetB3\n",
        "# Higher the number, the more complex the model is.\n",
        "from efficientnet import EfficientNetB0 as Net\n",
        "from efficientnet import center_crop_and_resize, preprocess_input"
      ],
      "metadata": {
        "id": "tjZBRnfo3bN0"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# loading pretrained conv base model\n",
        "# โหลดโมเดล มาโดยตัด output ของโมเดลออก เเต่ยังใช้ input อันเดิม\n",
        "# เเละโหลด weight ของโมเดล มาด้วยที่ชื่อว่า imagenet\n",
        "conv_base = Net(weights='imagenet', include_top=False, input_shape=input_shape)"
      ],
      "metadata": {
        "id": "hNZAzbDp3lgA",
        "outputId": "8772baca-9a8b-4f18-cc69-27f938ae683a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
            "Instructions for updating:\n",
            "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://github.com/qubvel/efficientnet/releases/download/v0.0.1/efficientnet-b0_imagenet_1000_notop.h5\n",
            "16717576/16717576 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = models.Sequential()\n",
        "model.add(conv_base)\n",
        "model.add(layers.GlobalMaxPooling2D(name=\"gap\"))\n",
        "# model.add(layers.Flatten(name=\"flatten\"))\n",
        "if dropout_rate > 0:\n",
        "    model.add(layers.Dropout(dropout_rate, name=\"dropout_out\"))\n",
        "# model.add(layers.Dense(256, activation='relu', name=\"fc1\"))\n",
        "model.add(layers.Dense(19, activation='softmax', name=\"fc_out\"))\n",
        "model.add(layers.Dense(1))"
      ],
      "metadata": {
        "id": "yWNKfQUt5rga"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "NadBB12251jh",
        "outputId": "a21833da-97cf-4020-84cf-3d96676d9655",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " efficientnet-b0 (Functional  (None, 5, 5, 1280)       4049564   \n",
            " )                                                               \n",
            "                                                                 \n",
            " gap (GlobalMaxPooling2D)    (None, 1280)              0         \n",
            "                                                                 \n",
            " dropout_out (Dropout)       (None, 1280)              0         \n",
            "                                                                 \n",
            " fc_out (Dense)              (None, 19)                24339     \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1)                 20        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4,073,923\n",
            "Trainable params: 4,031,907\n",
            "Non-trainable params: 42,016\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('This is the number of trainable layers '\n",
        "      'before freezing the conv base:', len(model.trainable_weights))\n",
        "\n",
        "conv_base.trainable = False\n",
        "\n",
        "print('This is the number of trainable layers '\n",
        "      'after freezing the conv base:', len(model.trainable_weights))"
      ],
      "metadata": {
        "id": "GepWq3yy53t5",
        "outputId": "5de2710e-43f6-4ad8-f4c8-095d8d709410",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This is the number of trainable layers before freezing the conv base: 215\n",
            "This is the number of trainable layers after freezing the conv base: 4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "conv_base.summary() #ดู Summary"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iD76D6c_79py",
        "outputId": "b4c1523c-d712-461c-adbb-be29fdc17be8"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"efficientnet-b0\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 150, 150, 3  0           []                               \n",
            "                                )]                                                                \n",
            "                                                                                                  \n",
            " conv2d (Conv2D)                (None, 75, 75, 32)   864         ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " batch_normalization (BatchNorm  (None, 75, 75, 32)  128         ['conv2d[0][0]']                 \n",
            " alization)                                                                                       \n",
            "                                                                                                  \n",
            " swish (Swish)                  (None, 75, 75, 32)   0           ['batch_normalization[0][0]']    \n",
            "                                                                                                  \n",
            " depthwise_conv2d (DepthwiseCon  (None, 75, 75, 32)  288         ['swish[0][0]']                  \n",
            " v2D)                                                                                             \n",
            "                                                                                                  \n",
            " batch_normalization_1 (BatchNo  (None, 75, 75, 32)  128         ['depthwise_conv2d[0][0]']       \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " swish_1 (Swish)                (None, 75, 75, 32)   0           ['batch_normalization_1[0][0]']  \n",
            "                                                                                                  \n",
            " lambda (Lambda)                (None, 1, 1, 32)     0           ['swish_1[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d_1 (Conv2D)              (None, 1, 1, 8)      264         ['lambda[0][0]']                 \n",
            "                                                                                                  \n",
            " swish_2 (Swish)                (None, 1, 1, 8)      0           ['conv2d_1[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_2 (Conv2D)              (None, 1, 1, 32)     288         ['swish_2[0][0]']                \n",
            "                                                                                                  \n",
            " activation (Activation)        (None, 1, 1, 32)     0           ['conv2d_2[0][0]']               \n",
            "                                                                                                  \n",
            " multiply (Multiply)            (None, 75, 75, 32)   0           ['activation[0][0]',             \n",
            "                                                                  'swish_1[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d_3 (Conv2D)              (None, 75, 75, 16)   512         ['multiply[0][0]']               \n",
            "                                                                                                  \n",
            " batch_normalization_2 (BatchNo  (None, 75, 75, 16)  64          ['conv2d_3[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv2d_4 (Conv2D)              (None, 75, 75, 96)   1536        ['batch_normalization_2[0][0]']  \n",
            "                                                                                                  \n",
            " batch_normalization_3 (BatchNo  (None, 75, 75, 96)  384         ['conv2d_4[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " swish_3 (Swish)                (None, 75, 75, 96)   0           ['batch_normalization_3[0][0]']  \n",
            "                                                                                                  \n",
            " depthwise_conv2d_1 (DepthwiseC  (None, 38, 38, 96)  864         ['swish_3[0][0]']                \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_4 (BatchNo  (None, 38, 38, 96)  384         ['depthwise_conv2d_1[0][0]']     \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " swish_4 (Swish)                (None, 38, 38, 96)   0           ['batch_normalization_4[0][0]']  \n",
            "                                                                                                  \n",
            " lambda_1 (Lambda)              (None, 1, 1, 96)     0           ['swish_4[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d_5 (Conv2D)              (None, 1, 1, 4)      388         ['lambda_1[0][0]']               \n",
            "                                                                                                  \n",
            " swish_5 (Swish)                (None, 1, 1, 4)      0           ['conv2d_5[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_6 (Conv2D)              (None, 1, 1, 96)     480         ['swish_5[0][0]']                \n",
            "                                                                                                  \n",
            " activation_1 (Activation)      (None, 1, 1, 96)     0           ['conv2d_6[0][0]']               \n",
            "                                                                                                  \n",
            " multiply_1 (Multiply)          (None, 38, 38, 96)   0           ['activation_1[0][0]',           \n",
            "                                                                  'swish_4[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d_7 (Conv2D)              (None, 38, 38, 24)   2304        ['multiply_1[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_5 (BatchNo  (None, 38, 38, 24)  96          ['conv2d_7[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv2d_8 (Conv2D)              (None, 38, 38, 144)  3456        ['batch_normalization_5[0][0]']  \n",
            "                                                                                                  \n",
            " batch_normalization_6 (BatchNo  (None, 38, 38, 144)  576        ['conv2d_8[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " swish_6 (Swish)                (None, 38, 38, 144)  0           ['batch_normalization_6[0][0]']  \n",
            "                                                                                                  \n",
            " depthwise_conv2d_2 (DepthwiseC  (None, 38, 38, 144)  1296       ['swish_6[0][0]']                \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_7 (BatchNo  (None, 38, 38, 144)  576        ['depthwise_conv2d_2[0][0]']     \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " swish_7 (Swish)                (None, 38, 38, 144)  0           ['batch_normalization_7[0][0]']  \n",
            "                                                                                                  \n",
            " lambda_2 (Lambda)              (None, 1, 1, 144)    0           ['swish_7[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d_9 (Conv2D)              (None, 1, 1, 6)      870         ['lambda_2[0][0]']               \n",
            "                                                                                                  \n",
            " swish_8 (Swish)                (None, 1, 1, 6)      0           ['conv2d_9[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_10 (Conv2D)             (None, 1, 1, 144)    1008        ['swish_8[0][0]']                \n",
            "                                                                                                  \n",
            " activation_2 (Activation)      (None, 1, 1, 144)    0           ['conv2d_10[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_2 (Multiply)          (None, 38, 38, 144)  0           ['activation_2[0][0]',           \n",
            "                                                                  'swish_7[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d_11 (Conv2D)             (None, 38, 38, 24)   3456        ['multiply_2[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_8 (BatchNo  (None, 38, 38, 24)  96          ['conv2d_11[0][0]']              \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " drop_connect (DropConnect)     (None, 38, 38, 24)   0           ['batch_normalization_8[0][0]']  \n",
            "                                                                                                  \n",
            " add (Add)                      (None, 38, 38, 24)   0           ['drop_connect[0][0]',           \n",
            "                                                                  'batch_normalization_5[0][0]']  \n",
            "                                                                                                  \n",
            " conv2d_12 (Conv2D)             (None, 38, 38, 144)  3456        ['add[0][0]']                    \n",
            "                                                                                                  \n",
            " batch_normalization_9 (BatchNo  (None, 38, 38, 144)  576        ['conv2d_12[0][0]']              \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " swish_9 (Swish)                (None, 38, 38, 144)  0           ['batch_normalization_9[0][0]']  \n",
            "                                                                                                  \n",
            " depthwise_conv2d_3 (DepthwiseC  (None, 19, 19, 144)  3600       ['swish_9[0][0]']                \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_10 (BatchN  (None, 19, 19, 144)  576        ['depthwise_conv2d_3[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_10 (Swish)               (None, 19, 19, 144)  0           ['batch_normalization_10[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_3 (Lambda)              (None, 1, 1, 144)    0           ['swish_10[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_13 (Conv2D)             (None, 1, 1, 6)      870         ['lambda_3[0][0]']               \n",
            "                                                                                                  \n",
            " swish_11 (Swish)               (None, 1, 1, 6)      0           ['conv2d_13[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_14 (Conv2D)             (None, 1, 1, 144)    1008        ['swish_11[0][0]']               \n",
            "                                                                                                  \n",
            " activation_3 (Activation)      (None, 1, 1, 144)    0           ['conv2d_14[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_3 (Multiply)          (None, 19, 19, 144)  0           ['activation_3[0][0]',           \n",
            "                                                                  'swish_10[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_15 (Conv2D)             (None, 19, 19, 40)   5760        ['multiply_3[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_11 (BatchN  (None, 19, 19, 40)  160         ['conv2d_15[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_16 (Conv2D)             (None, 19, 19, 240)  9600        ['batch_normalization_11[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_12 (BatchN  (None, 19, 19, 240)  960        ['conv2d_16[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_12 (Swish)               (None, 19, 19, 240)  0           ['batch_normalization_12[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_4 (DepthwiseC  (None, 19, 19, 240)  6000       ['swish_12[0][0]']               \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_13 (BatchN  (None, 19, 19, 240)  960        ['depthwise_conv2d_4[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_13 (Swish)               (None, 19, 19, 240)  0           ['batch_normalization_13[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_4 (Lambda)              (None, 1, 1, 240)    0           ['swish_13[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_17 (Conv2D)             (None, 1, 1, 10)     2410        ['lambda_4[0][0]']               \n",
            "                                                                                                  \n",
            " swish_14 (Swish)               (None, 1, 1, 10)     0           ['conv2d_17[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_18 (Conv2D)             (None, 1, 1, 240)    2640        ['swish_14[0][0]']               \n",
            "                                                                                                  \n",
            " activation_4 (Activation)      (None, 1, 1, 240)    0           ['conv2d_18[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_4 (Multiply)          (None, 19, 19, 240)  0           ['activation_4[0][0]',           \n",
            "                                                                  'swish_13[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_19 (Conv2D)             (None, 19, 19, 40)   9600        ['multiply_4[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_14 (BatchN  (None, 19, 19, 40)  160         ['conv2d_19[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_1 (DropConnect)   (None, 19, 19, 40)   0           ['batch_normalization_14[0][0]'] \n",
            "                                                                                                  \n",
            " add_1 (Add)                    (None, 19, 19, 40)   0           ['drop_connect_1[0][0]',         \n",
            "                                                                  'batch_normalization_11[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_20 (Conv2D)             (None, 19, 19, 240)  9600        ['add_1[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_15 (BatchN  (None, 19, 19, 240)  960        ['conv2d_20[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_15 (Swish)               (None, 19, 19, 240)  0           ['batch_normalization_15[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_5 (DepthwiseC  (None, 10, 10, 240)  2160       ['swish_15[0][0]']               \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_16 (BatchN  (None, 10, 10, 240)  960        ['depthwise_conv2d_5[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_16 (Swish)               (None, 10, 10, 240)  0           ['batch_normalization_16[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_5 (Lambda)              (None, 1, 1, 240)    0           ['swish_16[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_21 (Conv2D)             (None, 1, 1, 10)     2410        ['lambda_5[0][0]']               \n",
            "                                                                                                  \n",
            " swish_17 (Swish)               (None, 1, 1, 10)     0           ['conv2d_21[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_22 (Conv2D)             (None, 1, 1, 240)    2640        ['swish_17[0][0]']               \n",
            "                                                                                                  \n",
            " activation_5 (Activation)      (None, 1, 1, 240)    0           ['conv2d_22[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_5 (Multiply)          (None, 10, 10, 240)  0           ['activation_5[0][0]',           \n",
            "                                                                  'swish_16[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_23 (Conv2D)             (None, 10, 10, 80)   19200       ['multiply_5[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_17 (BatchN  (None, 10, 10, 80)  320         ['conv2d_23[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_24 (Conv2D)             (None, 10, 10, 480)  38400       ['batch_normalization_17[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_18 (BatchN  (None, 10, 10, 480)  1920       ['conv2d_24[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_18 (Swish)               (None, 10, 10, 480)  0           ['batch_normalization_18[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_6 (DepthwiseC  (None, 10, 10, 480)  4320       ['swish_18[0][0]']               \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_19 (BatchN  (None, 10, 10, 480)  1920       ['depthwise_conv2d_6[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_19 (Swish)               (None, 10, 10, 480)  0           ['batch_normalization_19[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_6 (Lambda)              (None, 1, 1, 480)    0           ['swish_19[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_25 (Conv2D)             (None, 1, 1, 20)     9620        ['lambda_6[0][0]']               \n",
            "                                                                                                  \n",
            " swish_20 (Swish)               (None, 1, 1, 20)     0           ['conv2d_25[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_26 (Conv2D)             (None, 1, 1, 480)    10080       ['swish_20[0][0]']               \n",
            "                                                                                                  \n",
            " activation_6 (Activation)      (None, 1, 1, 480)    0           ['conv2d_26[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_6 (Multiply)          (None, 10, 10, 480)  0           ['activation_6[0][0]',           \n",
            "                                                                  'swish_19[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_27 (Conv2D)             (None, 10, 10, 80)   38400       ['multiply_6[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_20 (BatchN  (None, 10, 10, 80)  320         ['conv2d_27[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_2 (DropConnect)   (None, 10, 10, 80)   0           ['batch_normalization_20[0][0]'] \n",
            "                                                                                                  \n",
            " add_2 (Add)                    (None, 10, 10, 80)   0           ['drop_connect_2[0][0]',         \n",
            "                                                                  'batch_normalization_17[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_28 (Conv2D)             (None, 10, 10, 480)  38400       ['add_2[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_21 (BatchN  (None, 10, 10, 480)  1920       ['conv2d_28[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_21 (Swish)               (None, 10, 10, 480)  0           ['batch_normalization_21[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_7 (DepthwiseC  (None, 10, 10, 480)  4320       ['swish_21[0][0]']               \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_22 (BatchN  (None, 10, 10, 480)  1920       ['depthwise_conv2d_7[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_22 (Swish)               (None, 10, 10, 480)  0           ['batch_normalization_22[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_7 (Lambda)              (None, 1, 1, 480)    0           ['swish_22[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_29 (Conv2D)             (None, 1, 1, 20)     9620        ['lambda_7[0][0]']               \n",
            "                                                                                                  \n",
            " swish_23 (Swish)               (None, 1, 1, 20)     0           ['conv2d_29[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_30 (Conv2D)             (None, 1, 1, 480)    10080       ['swish_23[0][0]']               \n",
            "                                                                                                  \n",
            " activation_7 (Activation)      (None, 1, 1, 480)    0           ['conv2d_30[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_7 (Multiply)          (None, 10, 10, 480)  0           ['activation_7[0][0]',           \n",
            "                                                                  'swish_22[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_31 (Conv2D)             (None, 10, 10, 80)   38400       ['multiply_7[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_23 (BatchN  (None, 10, 10, 80)  320         ['conv2d_31[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_3 (DropConnect)   (None, 10, 10, 80)   0           ['batch_normalization_23[0][0]'] \n",
            "                                                                                                  \n",
            " add_3 (Add)                    (None, 10, 10, 80)   0           ['drop_connect_3[0][0]',         \n",
            "                                                                  'add_2[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_32 (Conv2D)             (None, 10, 10, 480)  38400       ['add_3[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_24 (BatchN  (None, 10, 10, 480)  1920       ['conv2d_32[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_24 (Swish)               (None, 10, 10, 480)  0           ['batch_normalization_24[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_8 (DepthwiseC  (None, 10, 10, 480)  12000      ['swish_24[0][0]']               \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_25 (BatchN  (None, 10, 10, 480)  1920       ['depthwise_conv2d_8[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_25 (Swish)               (None, 10, 10, 480)  0           ['batch_normalization_25[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_8 (Lambda)              (None, 1, 1, 480)    0           ['swish_25[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_33 (Conv2D)             (None, 1, 1, 20)     9620        ['lambda_8[0][0]']               \n",
            "                                                                                                  \n",
            " swish_26 (Swish)               (None, 1, 1, 20)     0           ['conv2d_33[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_34 (Conv2D)             (None, 1, 1, 480)    10080       ['swish_26[0][0]']               \n",
            "                                                                                                  \n",
            " activation_8 (Activation)      (None, 1, 1, 480)    0           ['conv2d_34[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_8 (Multiply)          (None, 10, 10, 480)  0           ['activation_8[0][0]',           \n",
            "                                                                  'swish_25[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_35 (Conv2D)             (None, 10, 10, 112)  53760       ['multiply_8[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_26 (BatchN  (None, 10, 10, 112)  448        ['conv2d_35[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_36 (Conv2D)             (None, 10, 10, 672)  75264       ['batch_normalization_26[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_27 (BatchN  (None, 10, 10, 672)  2688       ['conv2d_36[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_27 (Swish)               (None, 10, 10, 672)  0           ['batch_normalization_27[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_9 (DepthwiseC  (None, 10, 10, 672)  16800      ['swish_27[0][0]']               \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_28 (BatchN  (None, 10, 10, 672)  2688       ['depthwise_conv2d_9[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_28 (Swish)               (None, 10, 10, 672)  0           ['batch_normalization_28[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_9 (Lambda)              (None, 1, 1, 672)    0           ['swish_28[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_37 (Conv2D)             (None, 1, 1, 28)     18844       ['lambda_9[0][0]']               \n",
            "                                                                                                  \n",
            " swish_29 (Swish)               (None, 1, 1, 28)     0           ['conv2d_37[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_38 (Conv2D)             (None, 1, 1, 672)    19488       ['swish_29[0][0]']               \n",
            "                                                                                                  \n",
            " activation_9 (Activation)      (None, 1, 1, 672)    0           ['conv2d_38[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_9 (Multiply)          (None, 10, 10, 672)  0           ['activation_9[0][0]',           \n",
            "                                                                  'swish_28[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_39 (Conv2D)             (None, 10, 10, 112)  75264       ['multiply_9[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_29 (BatchN  (None, 10, 10, 112)  448        ['conv2d_39[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_4 (DropConnect)   (None, 10, 10, 112)  0           ['batch_normalization_29[0][0]'] \n",
            "                                                                                                  \n",
            " add_4 (Add)                    (None, 10, 10, 112)  0           ['drop_connect_4[0][0]',         \n",
            "                                                                  'batch_normalization_26[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_40 (Conv2D)             (None, 10, 10, 672)  75264       ['add_4[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_30 (BatchN  (None, 10, 10, 672)  2688       ['conv2d_40[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_30 (Swish)               (None, 10, 10, 672)  0           ['batch_normalization_30[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_10 (Depthwise  (None, 10, 10, 672)  16800      ['swish_30[0][0]']               \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_31 (BatchN  (None, 10, 10, 672)  2688       ['depthwise_conv2d_10[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_31 (Swish)               (None, 10, 10, 672)  0           ['batch_normalization_31[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_10 (Lambda)             (None, 1, 1, 672)    0           ['swish_31[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_41 (Conv2D)             (None, 1, 1, 28)     18844       ['lambda_10[0][0]']              \n",
            "                                                                                                  \n",
            " swish_32 (Swish)               (None, 1, 1, 28)     0           ['conv2d_41[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_42 (Conv2D)             (None, 1, 1, 672)    19488       ['swish_32[0][0]']               \n",
            "                                                                                                  \n",
            " activation_10 (Activation)     (None, 1, 1, 672)    0           ['conv2d_42[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_10 (Multiply)         (None, 10, 10, 672)  0           ['activation_10[0][0]',          \n",
            "                                                                  'swish_31[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_43 (Conv2D)             (None, 10, 10, 112)  75264       ['multiply_10[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_32 (BatchN  (None, 10, 10, 112)  448        ['conv2d_43[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_5 (DropConnect)   (None, 10, 10, 112)  0           ['batch_normalization_32[0][0]'] \n",
            "                                                                                                  \n",
            " add_5 (Add)                    (None, 10, 10, 112)  0           ['drop_connect_5[0][0]',         \n",
            "                                                                  'add_4[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_44 (Conv2D)             (None, 10, 10, 672)  75264       ['add_5[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_33 (BatchN  (None, 10, 10, 672)  2688       ['conv2d_44[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_33 (Swish)               (None, 10, 10, 672)  0           ['batch_normalization_33[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_11 (Depthwise  (None, 5, 5, 672)   16800       ['swish_33[0][0]']               \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_34 (BatchN  (None, 5, 5, 672)   2688        ['depthwise_conv2d_11[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_34 (Swish)               (None, 5, 5, 672)    0           ['batch_normalization_34[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_11 (Lambda)             (None, 1, 1, 672)    0           ['swish_34[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_45 (Conv2D)             (None, 1, 1, 28)     18844       ['lambda_11[0][0]']              \n",
            "                                                                                                  \n",
            " swish_35 (Swish)               (None, 1, 1, 28)     0           ['conv2d_45[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_46 (Conv2D)             (None, 1, 1, 672)    19488       ['swish_35[0][0]']               \n",
            "                                                                                                  \n",
            " activation_11 (Activation)     (None, 1, 1, 672)    0           ['conv2d_46[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_11 (Multiply)         (None, 5, 5, 672)    0           ['activation_11[0][0]',          \n",
            "                                                                  'swish_34[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_47 (Conv2D)             (None, 5, 5, 192)    129024      ['multiply_11[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_35 (BatchN  (None, 5, 5, 192)   768         ['conv2d_47[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_48 (Conv2D)             (None, 5, 5, 1152)   221184      ['batch_normalization_35[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_36 (BatchN  (None, 5, 5, 1152)  4608        ['conv2d_48[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_36 (Swish)               (None, 5, 5, 1152)   0           ['batch_normalization_36[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_12 (Depthwise  (None, 5, 5, 1152)  28800       ['swish_36[0][0]']               \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_37 (BatchN  (None, 5, 5, 1152)  4608        ['depthwise_conv2d_12[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_37 (Swish)               (None, 5, 5, 1152)   0           ['batch_normalization_37[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_12 (Lambda)             (None, 1, 1, 1152)   0           ['swish_37[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_49 (Conv2D)             (None, 1, 1, 48)     55344       ['lambda_12[0][0]']              \n",
            "                                                                                                  \n",
            " swish_38 (Swish)               (None, 1, 1, 48)     0           ['conv2d_49[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_50 (Conv2D)             (None, 1, 1, 1152)   56448       ['swish_38[0][0]']               \n",
            "                                                                                                  \n",
            " activation_12 (Activation)     (None, 1, 1, 1152)   0           ['conv2d_50[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_12 (Multiply)         (None, 5, 5, 1152)   0           ['activation_12[0][0]',          \n",
            "                                                                  'swish_37[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_51 (Conv2D)             (None, 5, 5, 192)    221184      ['multiply_12[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_38 (BatchN  (None, 5, 5, 192)   768         ['conv2d_51[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_6 (DropConnect)   (None, 5, 5, 192)    0           ['batch_normalization_38[0][0]'] \n",
            "                                                                                                  \n",
            " add_6 (Add)                    (None, 5, 5, 192)    0           ['drop_connect_6[0][0]',         \n",
            "                                                                  'batch_normalization_35[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_52 (Conv2D)             (None, 5, 5, 1152)   221184      ['add_6[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_39 (BatchN  (None, 5, 5, 1152)  4608        ['conv2d_52[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_39 (Swish)               (None, 5, 5, 1152)   0           ['batch_normalization_39[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_13 (Depthwise  (None, 5, 5, 1152)  28800       ['swish_39[0][0]']               \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_40 (BatchN  (None, 5, 5, 1152)  4608        ['depthwise_conv2d_13[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_40 (Swish)               (None, 5, 5, 1152)   0           ['batch_normalization_40[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_13 (Lambda)             (None, 1, 1, 1152)   0           ['swish_40[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_53 (Conv2D)             (None, 1, 1, 48)     55344       ['lambda_13[0][0]']              \n",
            "                                                                                                  \n",
            " swish_41 (Swish)               (None, 1, 1, 48)     0           ['conv2d_53[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_54 (Conv2D)             (None, 1, 1, 1152)   56448       ['swish_41[0][0]']               \n",
            "                                                                                                  \n",
            " activation_13 (Activation)     (None, 1, 1, 1152)   0           ['conv2d_54[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_13 (Multiply)         (None, 5, 5, 1152)   0           ['activation_13[0][0]',          \n",
            "                                                                  'swish_40[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_55 (Conv2D)             (None, 5, 5, 192)    221184      ['multiply_13[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_41 (BatchN  (None, 5, 5, 192)   768         ['conv2d_55[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_7 (DropConnect)   (None, 5, 5, 192)    0           ['batch_normalization_41[0][0]'] \n",
            "                                                                                                  \n",
            " add_7 (Add)                    (None, 5, 5, 192)    0           ['drop_connect_7[0][0]',         \n",
            "                                                                  'add_6[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_56 (Conv2D)             (None, 5, 5, 1152)   221184      ['add_7[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_42 (BatchN  (None, 5, 5, 1152)  4608        ['conv2d_56[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_42 (Swish)               (None, 5, 5, 1152)   0           ['batch_normalization_42[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_14 (Depthwise  (None, 5, 5, 1152)  28800       ['swish_42[0][0]']               \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_43 (BatchN  (None, 5, 5, 1152)  4608        ['depthwise_conv2d_14[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_43 (Swish)               (None, 5, 5, 1152)   0           ['batch_normalization_43[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_14 (Lambda)             (None, 1, 1, 1152)   0           ['swish_43[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_57 (Conv2D)             (None, 1, 1, 48)     55344       ['lambda_14[0][0]']              \n",
            "                                                                                                  \n",
            " swish_44 (Swish)               (None, 1, 1, 48)     0           ['conv2d_57[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_58 (Conv2D)             (None, 1, 1, 1152)   56448       ['swish_44[0][0]']               \n",
            "                                                                                                  \n",
            " activation_14 (Activation)     (None, 1, 1, 1152)   0           ['conv2d_58[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_14 (Multiply)         (None, 5, 5, 1152)   0           ['activation_14[0][0]',          \n",
            "                                                                  'swish_43[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_59 (Conv2D)             (None, 5, 5, 192)    221184      ['multiply_14[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_44 (BatchN  (None, 5, 5, 192)   768         ['conv2d_59[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_8 (DropConnect)   (None, 5, 5, 192)    0           ['batch_normalization_44[0][0]'] \n",
            "                                                                                                  \n",
            " add_8 (Add)                    (None, 5, 5, 192)    0           ['drop_connect_8[0][0]',         \n",
            "                                                                  'add_7[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_60 (Conv2D)             (None, 5, 5, 1152)   221184      ['add_8[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_45 (BatchN  (None, 5, 5, 1152)  4608        ['conv2d_60[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_45 (Swish)               (None, 5, 5, 1152)   0           ['batch_normalization_45[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_15 (Depthwise  (None, 5, 5, 1152)  10368       ['swish_45[0][0]']               \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_46 (BatchN  (None, 5, 5, 1152)  4608        ['depthwise_conv2d_15[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_46 (Swish)               (None, 5, 5, 1152)   0           ['batch_normalization_46[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_15 (Lambda)             (None, 1, 1, 1152)   0           ['swish_46[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_61 (Conv2D)             (None, 1, 1, 48)     55344       ['lambda_15[0][0]']              \n",
            "                                                                                                  \n",
            " swish_47 (Swish)               (None, 1, 1, 48)     0           ['conv2d_61[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_62 (Conv2D)             (None, 1, 1, 1152)   56448       ['swish_47[0][0]']               \n",
            "                                                                                                  \n",
            " activation_15 (Activation)     (None, 1, 1, 1152)   0           ['conv2d_62[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_15 (Multiply)         (None, 5, 5, 1152)   0           ['activation_15[0][0]',          \n",
            "                                                                  'swish_46[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_63 (Conv2D)             (None, 5, 5, 320)    368640      ['multiply_15[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_47 (BatchN  (None, 5, 5, 320)   1280        ['conv2d_63[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_64 (Conv2D)             (None, 5, 5, 1280)   409600      ['batch_normalization_47[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_48 (BatchN  (None, 5, 5, 1280)  5120        ['conv2d_64[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_48 (Swish)               (None, 5, 5, 1280)   0           ['batch_normalization_48[0][0]'] \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 4,049,564\n",
            "Trainable params: 0\n",
            "Non-trainable params: 4,049,564\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#สร้างโฟลเดอร์ Train Valodation และ Test"
      ],
      "metadata": {
        "id": "J36J9EAE7qSB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv (r'/content/drive/MyDrive/cut_panoramic/Data/New_Data_Male125.csv')\n",
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "skoKhKJDngAZ",
        "outputId": "dc9bf5ee-e64b-4c61-fb28-439c71ea0330"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      Fig_Age  Fig_Person_Sex  Age(year) Class  Class_Re       Filename  \\\n",
              "0           1               1          7  Y07M         0       VV03.jpg   \n",
              "1           2               1          7  Y07M         0  Flip_VV03.jpg   \n",
              "2           3               2          7  Y07M         0       VV04.jpg   \n",
              "3           4               2          7  Y07M         0  Flip_VV04.jpg   \n",
              "4           5               3          7  Y07M         0       VV05.jpg   \n",
              "...       ...             ...        ...   ...       ...            ...   \n",
              "2370      121              77         25  Y25M        18  Flip_J463.jpg   \n",
              "2371      122              78         25  Y25M        18       J464.jpg   \n",
              "2372      123              78         25  Y25M        18  Flip_J464.jpg   \n",
              "2373      124              79         25  Y25M        18       J465.jpg   \n",
              "2374      125              79         25  Y25M        18  Flip_J465.jpg   \n",
              "\n",
              "                                          Path_filename     Sex Floder  \n",
              "0     /content/drive/My Drive/TVT_Male125/train/Y07M...  เพศชาย   Both  \n",
              "1     /content/drive/My Drive/TVT_Male125/train/Y07M...  เพศชาย   Both  \n",
              "2     /content/drive/My Drive/TVT_Male125/train/Y07M...  เพศชาย   Both  \n",
              "3     /content/drive/My Drive/TVT_Male125/train/Y07M...  เพศชาย   Both  \n",
              "4     /content/drive/My Drive/TVT_Male125/train/Y07M...  เพศชาย   Both  \n",
              "...                                                 ...     ...    ...  \n",
              "2370  /content/drive/My Drive/TVT_Male125/test/Y25M/...  เพศชาย   Both  \n",
              "2371  /content/drive/My Drive/TVT_Male125/test/Y25M/...  เพศชาย   Both  \n",
              "2372  /content/drive/My Drive/TVT_Male125/test/Y25M/...  เพศชาย   Both  \n",
              "2373  /content/drive/My Drive/TVT_Male125/test/Y25M/...  เพศชาย   Both  \n",
              "2374  /content/drive/My Drive/TVT_Male125/test/Y25M/...  เพศชาย   Both  \n",
              "\n",
              "[2375 rows x 9 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-fd48806f-7547-4d55-8b5f-204418bb9a78\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Fig_Age</th>\n",
              "      <th>Fig_Person_Sex</th>\n",
              "      <th>Age(year)</th>\n",
              "      <th>Class</th>\n",
              "      <th>Class_Re</th>\n",
              "      <th>Filename</th>\n",
              "      <th>Path_filename</th>\n",
              "      <th>Sex</th>\n",
              "      <th>Floder</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>Y07M</td>\n",
              "      <td>0</td>\n",
              "      <td>VV03.jpg</td>\n",
              "      <td>/content/drive/My Drive/TVT_Male125/train/Y07M...</td>\n",
              "      <td>เพศชาย</td>\n",
              "      <td>Both</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>Y07M</td>\n",
              "      <td>0</td>\n",
              "      <td>Flip_VV03.jpg</td>\n",
              "      <td>/content/drive/My Drive/TVT_Male125/train/Y07M...</td>\n",
              "      <td>เพศชาย</td>\n",
              "      <td>Both</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>7</td>\n",
              "      <td>Y07M</td>\n",
              "      <td>0</td>\n",
              "      <td>VV04.jpg</td>\n",
              "      <td>/content/drive/My Drive/TVT_Male125/train/Y07M...</td>\n",
              "      <td>เพศชาย</td>\n",
              "      <td>Both</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>7</td>\n",
              "      <td>Y07M</td>\n",
              "      <td>0</td>\n",
              "      <td>Flip_VV04.jpg</td>\n",
              "      <td>/content/drive/My Drive/TVT_Male125/train/Y07M...</td>\n",
              "      <td>เพศชาย</td>\n",
              "      <td>Both</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>7</td>\n",
              "      <td>Y07M</td>\n",
              "      <td>0</td>\n",
              "      <td>VV05.jpg</td>\n",
              "      <td>/content/drive/My Drive/TVT_Male125/train/Y07M...</td>\n",
              "      <td>เพศชาย</td>\n",
              "      <td>Both</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2370</th>\n",
              "      <td>121</td>\n",
              "      <td>77</td>\n",
              "      <td>25</td>\n",
              "      <td>Y25M</td>\n",
              "      <td>18</td>\n",
              "      <td>Flip_J463.jpg</td>\n",
              "      <td>/content/drive/My Drive/TVT_Male125/test/Y25M/...</td>\n",
              "      <td>เพศชาย</td>\n",
              "      <td>Both</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2371</th>\n",
              "      <td>122</td>\n",
              "      <td>78</td>\n",
              "      <td>25</td>\n",
              "      <td>Y25M</td>\n",
              "      <td>18</td>\n",
              "      <td>J464.jpg</td>\n",
              "      <td>/content/drive/My Drive/TVT_Male125/test/Y25M/...</td>\n",
              "      <td>เพศชาย</td>\n",
              "      <td>Both</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2372</th>\n",
              "      <td>123</td>\n",
              "      <td>78</td>\n",
              "      <td>25</td>\n",
              "      <td>Y25M</td>\n",
              "      <td>18</td>\n",
              "      <td>Flip_J464.jpg</td>\n",
              "      <td>/content/drive/My Drive/TVT_Male125/test/Y25M/...</td>\n",
              "      <td>เพศชาย</td>\n",
              "      <td>Both</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2373</th>\n",
              "      <td>124</td>\n",
              "      <td>79</td>\n",
              "      <td>25</td>\n",
              "      <td>Y25M</td>\n",
              "      <td>18</td>\n",
              "      <td>J465.jpg</td>\n",
              "      <td>/content/drive/My Drive/TVT_Male125/test/Y25M/...</td>\n",
              "      <td>เพศชาย</td>\n",
              "      <td>Both</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2374</th>\n",
              "      <td>125</td>\n",
              "      <td>79</td>\n",
              "      <td>25</td>\n",
              "      <td>Y25M</td>\n",
              "      <td>18</td>\n",
              "      <td>Flip_J465.jpg</td>\n",
              "      <td>/content/drive/My Drive/TVT_Male125/test/Y25M/...</td>\n",
              "      <td>เพศชาย</td>\n",
              "      <td>Both</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2375 rows × 9 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fd48806f-7547-4d55-8b5f-204418bb9a78')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-fd48806f-7547-4d55-8b5f-204418bb9a78 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-fd48806f-7547-4d55-8b5f-204418bb9a78');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train = df[df['Fig_Age'].between(1,75)]\n",
        "val = df[df['Fig_Age'].between(76,100)]"
      ],
      "metadata": {
        "id": "Z1zBw01Gl8Ac"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DATA_PATH = \"/content/drive/My Drive/TVT_Male125\"\n",
        "os.chdir(DATA_PATH)\n",
        "train_dir = os.path.join(DATA_PATH, 'train')\n",
        "print(train_dir)\n",
        "validation_dir = os.path.join(DATA_PATH, 'validation')\n",
        "print(validation_dir)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QL0g-8iOnMC4",
        "outputId": "34b692ca-ca80-4b4f-9580-9a08fd8e9981"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/My Drive/TVT_Male125/train\n",
            "/content/drive/My Drive/TVT_Male125/validation\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "#Train"
      ],
      "metadata": {
        "id": "bWEnlTSwazL5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train ด้วย ImageDataGenerator ของ Keras ซึ่งจะเพิ่มข้อมูลเสริมระหว่างการฝึกเพื่อลดโอกาสเกิด overfitting\n",
        "#overfitting เกิดจากข้อมูลที่ซับซ้อนกันเกินไป\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "train_datagen = ImageDataGenerator(\n",
        "      rescale=1./255, #โมเดลส่วนใหญ่ต้องใช้ RGB ในช่วง 0–1\n",
        "      rotation_range=40,\n",
        "      width_shift_range=0.2,\n",
        "      height_shift_range=0.2,\n",
        "      shear_range=0.2,\n",
        "      zoom_range=0.2,\n",
        "      horizontal_flip=True,\n",
        "      fill_mode='nearest')\n",
        "\n",
        "# Note that the validation data should not be augmented!\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)"
      ],
      "metadata": {
        "id": "xGPrsn9no_pa"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_generator = train_datagen.flow_from_dataframe(\n",
        "        dataframe = train,\n",
        "        directory = train_dir,\n",
        "        x_col = 'Path_filename',\n",
        "        y_col = 'Class_Re',\n",
        "        class_mode = 'other',\n",
        "        target_size=(height, width),\n",
        "        batch_size=batch_size)\n",
        "\n",
        "validation_generator = test_datagen.flow_from_dataframe(\n",
        "        dataframe = val,\n",
        "        directory = validation_dir,\n",
        "        x_col = 'Path_filename',\n",
        "        y_col = 'Class_Re',\n",
        "        class_mode = 'other',\n",
        "        target_size=(height, width),\n",
        "        batch_size=batch_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8nVlmAszntK_",
        "outputId": "3d2b19f4-bd31-4a73-df2f-295c791ed1e7"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1425 validated image filenames.\n",
            "Found 475 validated image filenames.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='mse',\n",
        "          optimizer=Adam(learning_rate=2e-6),\n",
        "          metrics=['mae'])\n",
        "history = model.fit_generator(\n",
        "      train_generator,\n",
        "      steps_per_epoch= NUM_TRAIN //batch_size,\n",
        "      epochs=epochs,\n",
        "      validation_data=validation_generator,\n",
        "      validation_steps= NUM_TEST //batch_size,\n",
        "      verbose=1,\n",
        "      use_multiprocessing=True,\n",
        "      workers=4)"
      ],
      "metadata": {
        "id": "N6qUmmF856ZE",
        "outputId": "6b5c2533-132d-4ae7-b153-b45e83070bf3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-20-e769003e5d08>:4: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  history = model.fit_generator(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "44/44 [==============================] - 106s 2s/step - loss: 110.0872 - mae: 8.9594 - val_loss: 110.8589 - val_mae: 8.9608\n",
            "Epoch 2/500\n",
            "44/44 [==============================] - 27s 573ms/step - loss: 109.8425 - mae: 8.9495 - val_loss: 109.8794 - val_mae: 8.9501\n",
            "Epoch 3/500\n",
            "44/44 [==============================] - 25s 530ms/step - loss: 108.9692 - mae: 8.9006 - val_loss: 108.1248 - val_mae: 8.8499\n",
            "Epoch 4/500\n",
            "44/44 [==============================] - 25s 532ms/step - loss: 108.9868 - mae: 8.8972 - val_loss: 112.2758 - val_mae: 9.0793\n",
            "Epoch 5/500\n",
            "44/44 [==============================] - 26s 560ms/step - loss: 109.3750 - mae: 8.9214 - val_loss: 109.7850 - val_mae: 8.9262\n",
            "Epoch 6/500\n",
            "44/44 [==============================] - 26s 569ms/step - loss: 107.6537 - mae: 8.8381 - val_loss: 110.4115 - val_mae: 8.9863\n",
            "Epoch 7/500\n",
            "44/44 [==============================] - 25s 553ms/step - loss: 108.4050 - mae: 8.8732 - val_loss: 108.7512 - val_mae: 8.8827\n",
            "Epoch 8/500\n",
            "44/44 [==============================] - 25s 539ms/step - loss: 107.9897 - mae: 8.8503 - val_loss: 108.9820 - val_mae: 8.8787\n",
            "Epoch 9/500\n",
            "44/44 [==============================] - 25s 548ms/step - loss: 107.4498 - mae: 8.8297 - val_loss: 109.3738 - val_mae: 8.9181\n",
            "Epoch 10/500\n",
            "44/44 [==============================] - 25s 547ms/step - loss: 107.3897 - mae: 8.8302 - val_loss: 106.6194 - val_mae: 8.7838\n",
            "Epoch 11/500\n",
            "44/44 [==============================] - 25s 561ms/step - loss: 106.6827 - mae: 8.7789 - val_loss: 107.4728 - val_mae: 8.8002\n",
            "Epoch 12/500\n",
            "44/44 [==============================] - 25s 547ms/step - loss: 106.8385 - mae: 8.7895 - val_loss: 106.5747 - val_mae: 8.7806\n",
            "Epoch 13/500\n",
            "44/44 [==============================] - 25s 538ms/step - loss: 107.0251 - mae: 8.7964 - val_loss: 107.8978 - val_mae: 8.8376\n",
            "Epoch 14/500\n",
            "44/44 [==============================] - 24s 521ms/step - loss: 106.7570 - mae: 8.7867 - val_loss: 108.8387 - val_mae: 8.8552\n",
            "Epoch 15/500\n",
            "44/44 [==============================] - 25s 540ms/step - loss: 106.4004 - mae: 8.7616 - val_loss: 107.3451 - val_mae: 8.8073\n",
            "Epoch 16/500\n",
            "44/44 [==============================] - 19s 410ms/step - loss: 105.9929 - mae: 8.7487 - val_loss: 103.3456 - val_mae: 8.6117\n",
            "Epoch 17/500\n",
            "44/44 [==============================] - 26s 549ms/step - loss: 105.9529 - mae: 8.7414 - val_loss: 105.2189 - val_mae: 8.6826\n",
            "Epoch 18/500\n",
            "44/44 [==============================] - 25s 549ms/step - loss: 105.3850 - mae: 8.7074 - val_loss: 106.1136 - val_mae: 8.7732\n",
            "Epoch 19/500\n",
            "44/44 [==============================] - 20s 425ms/step - loss: 106.1237 - mae: 8.7512 - val_loss: 104.4743 - val_mae: 8.6700\n",
            "Epoch 20/500\n",
            "44/44 [==============================] - 26s 572ms/step - loss: 104.9981 - mae: 8.7002 - val_loss: 105.9407 - val_mae: 8.7238\n",
            "Epoch 21/500\n",
            "44/44 [==============================] - 26s 559ms/step - loss: 105.5933 - mae: 8.7242 - val_loss: 106.6575 - val_mae: 8.7789\n",
            "Epoch 22/500\n",
            "44/44 [==============================] - 20s 432ms/step - loss: 105.4416 - mae: 8.7308 - val_loss: 105.7929 - val_mae: 8.7551\n",
            "Epoch 23/500\n",
            "44/44 [==============================] - 26s 528ms/step - loss: 105.4124 - mae: 8.7316 - val_loss: 106.3317 - val_mae: 8.7665\n",
            "Epoch 24/500\n",
            "44/44 [==============================] - 26s 571ms/step - loss: 105.8929 - mae: 8.7359 - val_loss: 104.7830 - val_mae: 8.6819\n",
            "Epoch 25/500\n",
            "44/44 [==============================] - 27s 585ms/step - loss: 104.9687 - mae: 8.6960 - val_loss: 105.7073 - val_mae: 8.7294\n",
            "Epoch 26/500\n",
            "44/44 [==============================] - 21s 451ms/step - loss: 105.3014 - mae: 8.7111 - val_loss: 105.4800 - val_mae: 8.7197\n",
            "Epoch 27/500\n",
            "44/44 [==============================] - 25s 542ms/step - loss: 104.8443 - mae: 8.6827 - val_loss: 106.3378 - val_mae: 8.7499\n",
            "Epoch 28/500\n",
            "44/44 [==============================] - 27s 592ms/step - loss: 104.9996 - mae: 8.6999 - val_loss: 102.7504 - val_mae: 8.5754\n",
            "Epoch 29/500\n",
            "44/44 [==============================] - 26s 584ms/step - loss: 103.9754 - mae: 8.6478 - val_loss: 103.6539 - val_mae: 8.6536\n",
            "Epoch 30/500\n",
            "44/44 [==============================] - 27s 587ms/step - loss: 104.1539 - mae: 8.6553 - val_loss: 105.3910 - val_mae: 8.7136\n",
            "Epoch 31/500\n",
            "44/44 [==============================] - 19s 420ms/step - loss: 104.6001 - mae: 8.6804 - val_loss: 105.2337 - val_mae: 8.7081\n",
            "Epoch 32/500\n",
            "44/44 [==============================] - 28s 545ms/step - loss: 104.2815 - mae: 8.6554 - val_loss: 105.4696 - val_mae: 8.7323\n",
            "Epoch 33/500\n",
            "44/44 [==============================] - 26s 566ms/step - loss: 104.3472 - mae: 8.6544 - val_loss: 104.0607 - val_mae: 8.6423\n",
            "Epoch 34/500\n",
            "44/44 [==============================] - 27s 587ms/step - loss: 104.3767 - mae: 8.6568 - val_loss: 105.5832 - val_mae: 8.7294\n",
            "Epoch 35/500\n",
            "44/44 [==============================] - 25s 548ms/step - loss: 104.8155 - mae: 8.6957 - val_loss: 105.2495 - val_mae: 8.7057\n",
            "Epoch 36/500\n",
            "44/44 [==============================] - 25s 553ms/step - loss: 104.4251 - mae: 8.6608 - val_loss: 102.6113 - val_mae: 8.5577\n",
            "Epoch 37/500\n",
            "44/44 [==============================] - 25s 548ms/step - loss: 104.0735 - mae: 8.6497 - val_loss: 104.5697 - val_mae: 8.6975\n",
            "Epoch 38/500\n",
            "44/44 [==============================] - 25s 538ms/step - loss: 104.1191 - mae: 8.6426 - val_loss: 105.2831 - val_mae: 8.6915\n",
            "Epoch 39/500\n",
            "44/44 [==============================] - 25s 551ms/step - loss: 104.0995 - mae: 8.6433 - val_loss: 103.0889 - val_mae: 8.5957\n",
            "Epoch 40/500\n",
            "44/44 [==============================] - 24s 522ms/step - loss: 104.2401 - mae: 8.6503 - val_loss: 104.0096 - val_mae: 8.6458\n",
            "Epoch 41/500\n",
            "44/44 [==============================] - 25s 541ms/step - loss: 103.6820 - mae: 8.6365 - val_loss: 104.6245 - val_mae: 8.6309\n",
            "Epoch 42/500\n",
            "44/44 [==============================] - 24s 532ms/step - loss: 103.7283 - mae: 8.6374 - val_loss: 103.6811 - val_mae: 8.6166\n",
            "Epoch 43/500\n",
            "44/44 [==============================] - 25s 543ms/step - loss: 103.7937 - mae: 8.6276 - val_loss: 103.3611 - val_mae: 8.5919\n",
            "Epoch 44/500\n",
            "44/44 [==============================] - 26s 563ms/step - loss: 103.7543 - mae: 8.6230 - val_loss: 102.3516 - val_mae: 8.5267\n",
            "Epoch 45/500\n",
            "44/44 [==============================] - 25s 538ms/step - loss: 103.1231 - mae: 8.5919 - val_loss: 103.5199 - val_mae: 8.6247\n",
            "Epoch 46/500\n",
            "44/44 [==============================] - 25s 541ms/step - loss: 102.9205 - mae: 8.5773 - val_loss: 103.7549 - val_mae: 8.6332\n",
            "Epoch 47/500\n",
            "44/44 [==============================] - 24s 531ms/step - loss: 103.5561 - mae: 8.6197 - val_loss: 102.9450 - val_mae: 8.6023\n",
            "Epoch 48/500\n",
            "44/44 [==============================] - 19s 416ms/step - loss: 102.9433 - mae: 8.5785 - val_loss: 103.5982 - val_mae: 8.6038\n",
            "Epoch 49/500\n",
            "44/44 [==============================] - 25s 548ms/step - loss: 102.4314 - mae: 8.5716 - val_loss: 100.7497 - val_mae: 8.4901\n",
            "Epoch 50/500\n",
            "44/44 [==============================] - 25s 545ms/step - loss: 103.0567 - mae: 8.5873 - val_loss: 103.7611 - val_mae: 8.6087\n",
            "Epoch 51/500\n",
            "44/44 [==============================] - 25s 557ms/step - loss: 103.1007 - mae: 8.5897 - val_loss: 104.3947 - val_mae: 8.6592\n",
            "Epoch 52/500\n",
            "44/44 [==============================] - 26s 572ms/step - loss: 102.9547 - mae: 8.5910 - val_loss: 102.8305 - val_mae: 8.5730\n",
            "Epoch 53/500\n",
            "44/44 [==============================] - 26s 569ms/step - loss: 102.6689 - mae: 8.5714 - val_loss: 103.1648 - val_mae: 8.6057\n",
            "Epoch 54/500\n",
            "44/44 [==============================] - 25s 538ms/step - loss: 103.3077 - mae: 8.6082 - val_loss: 103.2045 - val_mae: 8.6165\n",
            "Epoch 55/500\n",
            "44/44 [==============================] - 24s 520ms/step - loss: 102.8771 - mae: 8.5834 - val_loss: 103.0278 - val_mae: 8.6101\n",
            "Epoch 56/500\n",
            "44/44 [==============================] - 20s 433ms/step - loss: 102.7837 - mae: 8.5772 - val_loss: 103.3349 - val_mae: 8.6073\n",
            "Epoch 57/500\n",
            "44/44 [==============================] - 26s 534ms/step - loss: 102.4591 - mae: 8.5567 - val_loss: 104.5343 - val_mae: 8.6836\n",
            "Epoch 58/500\n",
            "44/44 [==============================] - 24s 526ms/step - loss: 102.9250 - mae: 8.5782 - val_loss: 103.1101 - val_mae: 8.6010\n",
            "Epoch 59/500\n",
            "44/44 [==============================] - 26s 561ms/step - loss: 103.4108 - mae: 8.6202 - val_loss: 101.2551 - val_mae: 8.4720\n",
            "Epoch 60/500\n",
            "44/44 [==============================] - 25s 547ms/step - loss: 102.3108 - mae: 8.5565 - val_loss: 103.9782 - val_mae: 8.6402\n",
            "Epoch 61/500\n",
            "44/44 [==============================] - 26s 559ms/step - loss: 102.7560 - mae: 8.5739 - val_loss: 100.8376 - val_mae: 8.4826\n",
            "Epoch 62/500\n",
            "44/44 [==============================] - 25s 539ms/step - loss: 102.4829 - mae: 8.5691 - val_loss: 102.8494 - val_mae: 8.5933\n",
            "Epoch 63/500\n",
            "44/44 [==============================] - 25s 539ms/step - loss: 102.2425 - mae: 8.5505 - val_loss: 99.8715 - val_mae: 8.4020\n",
            "Epoch 64/500\n",
            "44/44 [==============================] - 24s 538ms/step - loss: 103.2215 - mae: 8.6015 - val_loss: 104.0385 - val_mae: 8.6734\n",
            "Epoch 65/500\n",
            "44/44 [==============================] - 19s 427ms/step - loss: 101.5156 - mae: 8.5051 - val_loss: 102.4746 - val_mae: 8.5495\n",
            "Epoch 66/500\n",
            "44/44 [==============================] - 28s 545ms/step - loss: 102.2700 - mae: 8.5637 - val_loss: 100.4188 - val_mae: 8.4393\n",
            "Epoch 67/500\n",
            "44/44 [==============================] - 25s 523ms/step - loss: 102.0182 - mae: 8.5308 - val_loss: 101.5206 - val_mae: 8.4963\n",
            "Epoch 68/500\n",
            "44/44 [==============================] - 19s 431ms/step - loss: 102.2930 - mae: 8.5529 - val_loss: 102.5926 - val_mae: 8.5516\n",
            "Epoch 69/500\n",
            "44/44 [==============================] - 22s 449ms/step - loss: 102.6217 - mae: 8.5687 - val_loss: 103.6768 - val_mae: 8.6245\n",
            "Epoch 70/500\n",
            "44/44 [==============================] - 21s 424ms/step - loss: 102.6410 - mae: 8.5684 - val_loss: 100.2795 - val_mae: 8.4542\n",
            "Epoch 71/500\n",
            "44/44 [==============================] - 27s 568ms/step - loss: 102.1731 - mae: 8.5525 - val_loss: 103.0681 - val_mae: 8.5985\n",
            "Epoch 72/500\n",
            "44/44 [==============================] - 25s 538ms/step - loss: 102.2098 - mae: 8.5531 - val_loss: 103.7822 - val_mae: 8.6336\n",
            "Epoch 73/500\n",
            "44/44 [==============================] - 26s 573ms/step - loss: 102.1270 - mae: 8.5508 - val_loss: 102.2086 - val_mae: 8.5304\n",
            "Epoch 74/500\n",
            "44/44 [==============================] - 26s 559ms/step - loss: 102.7009 - mae: 8.5736 - val_loss: 103.1389 - val_mae: 8.5855\n",
            "Epoch 75/500\n",
            "44/44 [==============================] - 24s 531ms/step - loss: 102.2948 - mae: 8.5653 - val_loss: 102.5275 - val_mae: 8.5938\n",
            "Epoch 76/500\n",
            "44/44 [==============================] - 25s 548ms/step - loss: 102.3888 - mae: 8.5531 - val_loss: 102.1487 - val_mae: 8.5375\n",
            "Epoch 77/500\n",
            "44/44 [==============================] - 19s 417ms/step - loss: 102.5720 - mae: 8.5708 - val_loss: 103.8208 - val_mae: 8.6285\n",
            "Epoch 78/500\n",
            "44/44 [==============================] - 28s 581ms/step - loss: 102.3724 - mae: 8.5511 - val_loss: 101.4005 - val_mae: 8.5074\n",
            "Epoch 79/500\n",
            "44/44 [==============================] - 25s 547ms/step - loss: 102.7977 - mae: 8.5770 - val_loss: 102.1047 - val_mae: 8.5560\n",
            "Epoch 80/500\n",
            "44/44 [==============================] - 26s 572ms/step - loss: 102.5092 - mae: 8.5704 - val_loss: 104.0498 - val_mae: 8.6403\n",
            "Epoch 81/500\n",
            "44/44 [==============================] - 20s 443ms/step - loss: 101.9727 - mae: 8.5386 - val_loss: 101.7912 - val_mae: 8.5305\n",
            "Epoch 82/500\n",
            "44/44 [==============================] - 26s 527ms/step - loss: 101.9217 - mae: 8.5323 - val_loss: 101.0178 - val_mae: 8.4987\n",
            "Epoch 83/500\n",
            "44/44 [==============================] - 26s 540ms/step - loss: 101.5178 - mae: 8.5087 - val_loss: 99.7267 - val_mae: 8.4046\n",
            "Epoch 84/500\n",
            "44/44 [==============================] - 26s 580ms/step - loss: 102.1091 - mae: 8.5375 - val_loss: 103.7939 - val_mae: 8.6451\n",
            "Epoch 85/500\n",
            "44/44 [==============================] - 26s 569ms/step - loss: 102.4876 - mae: 8.5723 - val_loss: 103.5168 - val_mae: 8.5933\n",
            "Epoch 86/500\n",
            "44/44 [==============================] - 25s 540ms/step - loss: 102.0336 - mae: 8.5339 - val_loss: 102.4545 - val_mae: 8.5459\n",
            "Epoch 87/500\n",
            "44/44 [==============================] - 24s 534ms/step - loss: 103.1844 - mae: 8.6070 - val_loss: 103.2661 - val_mae: 8.5924\n",
            "Epoch 88/500\n",
            "44/44 [==============================] - 25s 543ms/step - loss: 102.0632 - mae: 8.5362 - val_loss: 100.1815 - val_mae: 8.4336\n",
            "Epoch 89/500\n",
            "44/44 [==============================] - 21s 457ms/step - loss: 102.0619 - mae: 8.5386 - val_loss: 100.5394 - val_mae: 8.4889\n",
            "Epoch 90/500\n",
            "44/44 [==============================] - 26s 544ms/step - loss: 101.7301 - mae: 8.5243 - val_loss: 100.0851 - val_mae: 8.4506\n",
            "Epoch 91/500\n",
            "44/44 [==============================] - 27s 562ms/step - loss: 101.3868 - mae: 8.5075 - val_loss: 101.8185 - val_mae: 8.5507\n",
            "Epoch 92/500\n",
            "44/44 [==============================] - 27s 567ms/step - loss: 102.4212 - mae: 8.5682 - val_loss: 104.1565 - val_mae: 8.6796\n",
            "Epoch 93/500\n",
            "44/44 [==============================] - 26s 583ms/step - loss: 102.4808 - mae: 8.5566 - val_loss: 102.0257 - val_mae: 8.5499\n",
            "Epoch 94/500\n",
            "44/44 [==============================] - 25s 549ms/step - loss: 101.9948 - mae: 8.5443 - val_loss: 104.4494 - val_mae: 8.6544\n",
            "Epoch 95/500\n",
            "44/44 [==============================] - 25s 555ms/step - loss: 102.1164 - mae: 8.5477 - val_loss: 101.2845 - val_mae: 8.4866\n",
            "Epoch 96/500\n",
            "44/44 [==============================] - 25s 551ms/step - loss: 102.2123 - mae: 8.5476 - val_loss: 101.9999 - val_mae: 8.5465\n",
            "Epoch 97/500\n",
            "44/44 [==============================] - 25s 535ms/step - loss: 102.7415 - mae: 8.5884 - val_loss: 101.9258 - val_mae: 8.5506\n",
            "Epoch 98/500\n",
            "44/44 [==============================] - 26s 555ms/step - loss: 102.1022 - mae: 8.5403 - val_loss: 101.9293 - val_mae: 8.5369\n",
            "Epoch 99/500\n",
            "44/44 [==============================] - 26s 580ms/step - loss: 102.6166 - mae: 8.5719 - val_loss: 103.4016 - val_mae: 8.6303\n",
            "Epoch 100/500\n",
            "44/44 [==============================] - 25s 549ms/step - loss: 102.0776 - mae: 8.5371 - val_loss: 101.8536 - val_mae: 8.5229\n",
            "Epoch 101/500\n",
            "44/44 [==============================] - 26s 582ms/step - loss: 102.5781 - mae: 8.5692 - val_loss: 99.8040 - val_mae: 8.4265\n",
            "Epoch 102/500\n",
            "44/44 [==============================] - 24s 532ms/step - loss: 101.8625 - mae: 8.5309 - val_loss: 102.4382 - val_mae: 8.5579\n",
            "Epoch 103/500\n",
            "44/44 [==============================] - 26s 578ms/step - loss: 102.0433 - mae: 8.5424 - val_loss: 100.9556 - val_mae: 8.4995\n",
            "Epoch 104/500\n",
            "44/44 [==============================] - 25s 554ms/step - loss: 101.3547 - mae: 8.4979 - val_loss: 100.9861 - val_mae: 8.4724\n",
            "Epoch 105/500\n",
            "44/44 [==============================] - 25s 552ms/step - loss: 101.8436 - mae: 8.5300 - val_loss: 102.1439 - val_mae: 8.5391\n",
            "Epoch 106/500\n",
            "44/44 [==============================] - 23s 506ms/step - loss: 103.0588 - mae: 8.6049 - val_loss: 100.1085 - val_mae: 8.4429\n",
            "Epoch 107/500\n",
            "44/44 [==============================] - 26s 540ms/step - loss: 101.9702 - mae: 8.5330 - val_loss: 99.7472 - val_mae: 8.4225\n",
            "Epoch 108/500\n",
            "44/44 [==============================] - 25s 550ms/step - loss: 101.3939 - mae: 8.5175 - val_loss: 101.6899 - val_mae: 8.5338\n",
            "Epoch 109/500\n",
            "44/44 [==============================] - 21s 459ms/step - loss: 101.9531 - mae: 8.5358 - val_loss: 100.1741 - val_mae: 8.4398\n",
            "Epoch 110/500\n",
            "44/44 [==============================] - 25s 549ms/step - loss: 102.3684 - mae: 8.5603 - val_loss: 103.1268 - val_mae: 8.6201\n",
            "Epoch 111/500\n",
            "44/44 [==============================] - 26s 559ms/step - loss: 102.6903 - mae: 8.5729 - val_loss: 103.0033 - val_mae: 8.5889\n",
            "Epoch 112/500\n",
            "44/44 [==============================] - 25s 557ms/step - loss: 101.9372 - mae: 8.5300 - val_loss: 102.9360 - val_mae: 8.5863\n",
            "Epoch 113/500\n",
            "44/44 [==============================] - 25s 545ms/step - loss: 101.9452 - mae: 8.5396 - val_loss: 102.7660 - val_mae: 8.5593\n",
            "Epoch 114/500\n",
            "44/44 [==============================] - 20s 429ms/step - loss: 102.0684 - mae: 8.5432 - val_loss: 102.3020 - val_mae: 8.5457\n",
            "Epoch 115/500\n",
            "44/44 [==============================] - 28s 624ms/step - loss: 102.5388 - mae: 8.5643 - val_loss: 104.0267 - val_mae: 8.6347\n",
            "Epoch 116/500\n",
            "44/44 [==============================] - 26s 568ms/step - loss: 101.6779 - mae: 8.5296 - val_loss: 101.8601 - val_mae: 8.5341\n",
            "Epoch 117/500\n",
            "44/44 [==============================] - 27s 585ms/step - loss: 101.7664 - mae: 8.5328 - val_loss: 102.9514 - val_mae: 8.5985\n",
            "Epoch 118/500\n",
            "44/44 [==============================] - 26s 578ms/step - loss: 101.8590 - mae: 8.5398 - val_loss: 102.6526 - val_mae: 8.6027\n",
            "Epoch 119/500\n",
            "44/44 [==============================] - 27s 593ms/step - loss: 101.6821 - mae: 8.5218 - val_loss: 103.8826 - val_mae: 8.6337\n",
            "Epoch 120/500\n",
            "44/44 [==============================] - 26s 580ms/step - loss: 102.1559 - mae: 8.5477 - val_loss: 102.7961 - val_mae: 8.5889\n",
            "Epoch 121/500\n",
            "44/44 [==============================] - 21s 461ms/step - loss: 101.0765 - mae: 8.4946 - val_loss: 101.4961 - val_mae: 8.4994\n",
            "Epoch 122/500\n",
            "44/44 [==============================] - 26s 579ms/step - loss: 102.4256 - mae: 8.5674 - val_loss: 99.9096 - val_mae: 8.4301\n",
            "Epoch 123/500\n",
            "44/44 [==============================] - 25s 559ms/step - loss: 102.1018 - mae: 8.5478 - val_loss: 101.2425 - val_mae: 8.4901\n",
            "Epoch 124/500\n",
            "44/44 [==============================] - 20s 442ms/step - loss: 101.2097 - mae: 8.5009 - val_loss: 103.0659 - val_mae: 8.5791\n",
            "Epoch 125/500\n",
            "44/44 [==============================] - 24s 533ms/step - loss: 101.3268 - mae: 8.5010 - val_loss: 102.9370 - val_mae: 8.5767\n",
            "Epoch 126/500\n",
            "44/44 [==============================] - 24s 531ms/step - loss: 101.1760 - mae: 8.4947 - val_loss: 103.2477 - val_mae: 8.6367\n",
            "Epoch 127/500\n",
            "44/44 [==============================] - 24s 535ms/step - loss: 101.7088 - mae: 8.5233 - val_loss: 100.2830 - val_mae: 8.4380\n",
            "Epoch 128/500\n",
            "44/44 [==============================] - 24s 535ms/step - loss: 102.0365 - mae: 8.5379 - val_loss: 101.6916 - val_mae: 8.5182\n",
            "Epoch 129/500\n",
            "44/44 [==============================] - 26s 573ms/step - loss: 101.8493 - mae: 8.5270 - val_loss: 101.0310 - val_mae: 8.5201\n",
            "Epoch 130/500\n",
            "44/44 [==============================] - 25s 546ms/step - loss: 102.4276 - mae: 8.5658 - val_loss: 103.1899 - val_mae: 8.5891\n",
            "Epoch 131/500\n",
            "44/44 [==============================] - 21s 446ms/step - loss: 102.5116 - mae: 8.5710 - val_loss: 102.5532 - val_mae: 8.5598\n",
            "Epoch 132/500\n",
            "44/44 [==============================] - 24s 537ms/step - loss: 101.9639 - mae: 8.5379 - val_loss: 101.4042 - val_mae: 8.5151\n",
            "Epoch 133/500\n",
            "44/44 [==============================] - 25s 544ms/step - loss: 101.8652 - mae: 8.5307 - val_loss: 100.8878 - val_mae: 8.5015\n",
            "Epoch 134/500\n",
            "44/44 [==============================] - 24s 528ms/step - loss: 101.9003 - mae: 8.5347 - val_loss: 102.1623 - val_mae: 8.5725\n",
            "Epoch 135/500\n",
            "44/44 [==============================] - 26s 562ms/step - loss: 101.4354 - mae: 8.5034 - val_loss: 101.6693 - val_mae: 8.5391\n",
            "Epoch 136/500\n",
            "44/44 [==============================] - 21s 461ms/step - loss: 102.3201 - mae: 8.5499 - val_loss: 100.6295 - val_mae: 8.4541\n",
            "Epoch 137/500\n",
            "44/44 [==============================] - 25s 553ms/step - loss: 101.7043 - mae: 8.5283 - val_loss: 101.2094 - val_mae: 8.4852\n",
            "Epoch 138/500\n",
            "44/44 [==============================] - 26s 563ms/step - loss: 101.8005 - mae: 8.5202 - val_loss: 101.9816 - val_mae: 8.5163\n",
            "Epoch 139/500\n",
            "44/44 [==============================] - 25s 535ms/step - loss: 101.9633 - mae: 8.5354 - val_loss: 101.7014 - val_mae: 8.5117\n",
            "Epoch 140/500\n",
            "44/44 [==============================] - 25s 550ms/step - loss: 102.4970 - mae: 8.5669 - val_loss: 102.8162 - val_mae: 8.5650\n",
            "Epoch 141/500\n",
            "44/44 [==============================] - 26s 553ms/step - loss: 102.3817 - mae: 8.5558 - val_loss: 101.3951 - val_mae: 8.5224\n",
            "Epoch 142/500\n",
            "44/44 [==============================] - 26s 564ms/step - loss: 101.8625 - mae: 8.5293 - val_loss: 101.7442 - val_mae: 8.5312\n",
            "Epoch 143/500\n",
            "44/44 [==============================] - 26s 561ms/step - loss: 102.1609 - mae: 8.5465 - val_loss: 100.6582 - val_mae: 8.4819\n",
            "Epoch 144/500\n",
            "44/44 [==============================] - 26s 576ms/step - loss: 101.9922 - mae: 8.5331 - val_loss: 102.7436 - val_mae: 8.5887\n",
            "Epoch 145/500\n",
            "44/44 [==============================] - 25s 546ms/step - loss: 102.0452 - mae: 8.5295 - val_loss: 103.4457 - val_mae: 8.5932\n",
            "Epoch 146/500\n",
            "44/44 [==============================] - 24s 528ms/step - loss: 101.7086 - mae: 8.5250 - val_loss: 100.0841 - val_mae: 8.4234\n",
            "Epoch 147/500\n",
            "44/44 [==============================] - 25s 542ms/step - loss: 102.0886 - mae: 8.5470 - val_loss: 102.2454 - val_mae: 8.5371\n",
            "Epoch 148/500\n",
            "44/44 [==============================] - 27s 577ms/step - loss: 102.1207 - mae: 8.5517 - val_loss: 101.4984 - val_mae: 8.4944\n",
            "Epoch 149/500\n",
            "44/44 [==============================] - 26s 580ms/step - loss: 101.8741 - mae: 8.5335 - val_loss: 101.4012 - val_mae: 8.5033\n",
            "Epoch 150/500\n",
            "44/44 [==============================] - 27s 589ms/step - loss: 101.7534 - mae: 8.5249 - val_loss: 102.8127 - val_mae: 8.6012\n",
            "Epoch 151/500\n",
            "44/44 [==============================] - 25s 541ms/step - loss: 102.0560 - mae: 8.5461 - val_loss: 103.3403 - val_mae: 8.6145\n",
            "Epoch 152/500\n",
            "44/44 [==============================] - 20s 437ms/step - loss: 101.6880 - mae: 8.5224 - val_loss: 102.0501 - val_mae: 8.5497\n",
            "Epoch 153/500\n",
            "44/44 [==============================] - 28s 588ms/step - loss: 101.6743 - mae: 8.5206 - val_loss: 100.6799 - val_mae: 8.4758\n",
            "Epoch 154/500\n",
            "44/44 [==============================] - 22s 477ms/step - loss: 101.7176 - mae: 8.5247 - val_loss: 100.7266 - val_mae: 8.4623\n",
            "Epoch 155/500\n",
            "44/44 [==============================] - 26s 537ms/step - loss: 101.7586 - mae: 8.5188 - val_loss: 99.7829 - val_mae: 8.4308\n",
            "Epoch 156/500\n",
            "44/44 [==============================] - 24s 532ms/step - loss: 101.9889 - mae: 8.5411 - val_loss: 100.4264 - val_mae: 8.4486\n",
            "Epoch 157/500\n",
            "44/44 [==============================] - 24s 531ms/step - loss: 102.3677 - mae: 8.5594 - val_loss: 101.4331 - val_mae: 8.5153\n",
            "Epoch 158/500\n",
            "44/44 [==============================] - 25s 543ms/step - loss: 101.7181 - mae: 8.5256 - val_loss: 102.1698 - val_mae: 8.5419\n",
            "Epoch 159/500\n",
            "44/44 [==============================] - 26s 568ms/step - loss: 101.8542 - mae: 8.5359 - val_loss: 101.7448 - val_mae: 8.4995\n",
            "Epoch 160/500\n",
            "44/44 [==============================] - 24s 527ms/step - loss: 101.3347 - mae: 8.5026 - val_loss: 102.6001 - val_mae: 8.5595\n",
            "Epoch 161/500\n",
            "44/44 [==============================] - 25s 547ms/step - loss: 101.7336 - mae: 8.5161 - val_loss: 102.6707 - val_mae: 8.5947\n",
            "Epoch 162/500\n",
            "44/44 [==============================] - 27s 586ms/step - loss: 101.6439 - mae: 8.5205 - val_loss: 101.6756 - val_mae: 8.5300\n",
            "Epoch 163/500\n",
            "44/44 [==============================] - 26s 564ms/step - loss: 101.9830 - mae: 8.5389 - val_loss: 101.7370 - val_mae: 8.4966\n",
            "Epoch 164/500\n",
            "44/44 [==============================] - 26s 574ms/step - loss: 101.6289 - mae: 8.5264 - val_loss: 102.7974 - val_mae: 8.5611\n",
            "Epoch 165/500\n",
            "44/44 [==============================] - 24s 523ms/step - loss: 101.7358 - mae: 8.5305 - val_loss: 103.1219 - val_mae: 8.6124\n",
            "Epoch 166/500\n",
            "44/44 [==============================] - 24s 532ms/step - loss: 101.8607 - mae: 8.5312 - val_loss: 99.9766 - val_mae: 8.4359\n",
            "Epoch 167/500\n",
            "44/44 [==============================] - 20s 429ms/step - loss: 102.1203 - mae: 8.5439 - val_loss: 102.1858 - val_mae: 8.5515\n",
            "Epoch 168/500\n",
            "44/44 [==============================] - 28s 606ms/step - loss: 102.1853 - mae: 8.5559 - val_loss: 101.1947 - val_mae: 8.4957\n",
            "Epoch 169/500\n",
            "44/44 [==============================] - 27s 588ms/step - loss: 101.7242 - mae: 8.5305 - val_loss: 103.0077 - val_mae: 8.5936\n",
            "Epoch 170/500\n",
            "44/44 [==============================] - 27s 591ms/step - loss: 101.8127 - mae: 8.5240 - val_loss: 101.7362 - val_mae: 8.5244\n",
            "Epoch 171/500\n",
            "44/44 [==============================] - 25s 558ms/step - loss: 102.3088 - mae: 8.5559 - val_loss: 101.3805 - val_mae: 8.5220\n",
            "Epoch 172/500\n",
            "44/44 [==============================] - 25s 543ms/step - loss: 101.7786 - mae: 8.5265 - val_loss: 101.1250 - val_mae: 8.4861\n",
            "Epoch 173/500\n",
            "44/44 [==============================] - 25s 543ms/step - loss: 101.7727 - mae: 8.5227 - val_loss: 102.6447 - val_mae: 8.5574\n",
            "Epoch 174/500\n",
            "44/44 [==============================] - 25s 554ms/step - loss: 101.8050 - mae: 8.5362 - val_loss: 102.9294 - val_mae: 8.5926\n",
            "Epoch 175/500\n",
            "44/44 [==============================] - 24s 518ms/step - loss: 101.9522 - mae: 8.5431 - val_loss: 104.4178 - val_mae: 8.6709\n",
            "Epoch 176/500\n",
            "44/44 [==============================] - 25s 522ms/step - loss: 102.0500 - mae: 8.5536 - val_loss: 101.8782 - val_mae: 8.5279\n",
            "Epoch 177/500\n",
            "44/44 [==============================] - 24s 535ms/step - loss: 101.2299 - mae: 8.5085 - val_loss: 100.6569 - val_mae: 8.4429\n",
            "Epoch 178/500\n",
            "44/44 [==============================] - 20s 424ms/step - loss: 102.0220 - mae: 8.5268 - val_loss: 104.1909 - val_mae: 8.6433\n",
            "Epoch 179/500\n",
            "44/44 [==============================] - 28s 568ms/step - loss: 101.4964 - mae: 8.5080 - val_loss: 101.0854 - val_mae: 8.4892\n",
            "Epoch 180/500\n",
            "44/44 [==============================] - 26s 571ms/step - loss: 101.9226 - mae: 8.5330 - val_loss: 101.7864 - val_mae: 8.5138\n",
            "Epoch 181/500\n",
            "44/44 [==============================] - 24s 520ms/step - loss: 101.5649 - mae: 8.5241 - val_loss: 100.9905 - val_mae: 8.4824\n",
            "Epoch 182/500\n",
            "44/44 [==============================] - 25s 555ms/step - loss: 101.6553 - mae: 8.5224 - val_loss: 100.5200 - val_mae: 8.4552\n",
            "Epoch 183/500\n",
            "44/44 [==============================] - 19s 413ms/step - loss: 102.1683 - mae: 8.5495 - val_loss: 101.0511 - val_mae: 8.4843\n",
            "Epoch 184/500\n",
            "44/44 [==============================] - 26s 557ms/step - loss: 102.1146 - mae: 8.5429 - val_loss: 100.2651 - val_mae: 8.4397\n",
            "Epoch 185/500\n",
            "44/44 [==============================] - 26s 579ms/step - loss: 101.5455 - mae: 8.5174 - val_loss: 104.0221 - val_mae: 8.6380\n",
            "Epoch 186/500\n",
            "44/44 [==============================] - 26s 560ms/step - loss: 101.6210 - mae: 8.5244 - val_loss: 99.9103 - val_mae: 8.4437\n",
            "Epoch 187/500\n",
            "44/44 [==============================] - 26s 574ms/step - loss: 101.5143 - mae: 8.5157 - val_loss: 101.5684 - val_mae: 8.5014\n",
            "Epoch 188/500\n",
            "44/44 [==============================] - 25s 552ms/step - loss: 101.4949 - mae: 8.5097 - val_loss: 99.6734 - val_mae: 8.4145\n",
            "Epoch 189/500\n",
            "44/44 [==============================] - 24s 532ms/step - loss: 101.4652 - mae: 8.5003 - val_loss: 102.3149 - val_mae: 8.5281\n",
            "Epoch 190/500\n",
            "44/44 [==============================] - 25s 542ms/step - loss: 102.0331 - mae: 8.5358 - val_loss: 102.9461 - val_mae: 8.5814\n",
            "Epoch 191/500\n",
            "44/44 [==============================] - 25s 555ms/step - loss: 102.1509 - mae: 8.5414 - val_loss: 99.7803 - val_mae: 8.3938\n",
            "Epoch 192/500\n",
            "44/44 [==============================] - 25s 556ms/step - loss: 101.6719 - mae: 8.5204 - val_loss: 102.3211 - val_mae: 8.5341\n",
            "Epoch 193/500\n",
            "44/44 [==============================] - 25s 541ms/step - loss: 102.0004 - mae: 8.5353 - val_loss: 102.5249 - val_mae: 8.5628\n",
            "Epoch 194/500\n",
            "44/44 [==============================] - 26s 564ms/step - loss: 101.8819 - mae: 8.5326 - val_loss: 102.0405 - val_mae: 8.5313\n",
            "Epoch 195/500\n",
            "44/44 [==============================] - 24s 535ms/step - loss: 101.7291 - mae: 8.5168 - val_loss: 102.5032 - val_mae: 8.5491\n",
            "Epoch 196/500\n",
            "44/44 [==============================] - 25s 546ms/step - loss: 102.1358 - mae: 8.5452 - val_loss: 102.6682 - val_mae: 8.5445\n",
            "Epoch 197/500\n",
            "44/44 [==============================] - 25s 555ms/step - loss: 102.1808 - mae: 8.5513 - val_loss: 99.7182 - val_mae: 8.4277\n",
            "Epoch 198/500\n",
            "44/44 [==============================] - 27s 588ms/step - loss: 102.2261 - mae: 8.5636 - val_loss: 101.5622 - val_mae: 8.5236\n",
            "Epoch 199/500\n",
            "44/44 [==============================] - 26s 560ms/step - loss: 100.9152 - mae: 8.4819 - val_loss: 101.2926 - val_mae: 8.5100\n",
            "Epoch 200/500\n",
            "44/44 [==============================] - 24s 536ms/step - loss: 100.7919 - mae: 8.4693 - val_loss: 103.3515 - val_mae: 8.6230\n",
            "Epoch 201/500\n",
            "44/44 [==============================] - 25s 549ms/step - loss: 101.7966 - mae: 8.5300 - val_loss: 102.7821 - val_mae: 8.5716\n",
            "Epoch 202/500\n",
            "44/44 [==============================] - 25s 545ms/step - loss: 101.4378 - mae: 8.5114 - val_loss: 101.6719 - val_mae: 8.5596\n",
            "Epoch 203/500\n",
            "44/44 [==============================] - 25s 547ms/step - loss: 100.8071 - mae: 8.4736 - val_loss: 101.0063 - val_mae: 8.4854\n",
            "Epoch 204/500\n",
            "44/44 [==============================] - 25s 555ms/step - loss: 101.1734 - mae: 8.5077 - val_loss: 101.9401 - val_mae: 8.5357\n",
            "Epoch 205/500\n",
            "44/44 [==============================] - 25s 548ms/step - loss: 101.5005 - mae: 8.5115 - val_loss: 102.4598 - val_mae: 8.5567\n",
            "Epoch 206/500\n",
            "44/44 [==============================] - 26s 570ms/step - loss: 101.5707 - mae: 8.5139 - val_loss: 101.5580 - val_mae: 8.5070\n",
            "Epoch 207/500\n",
            "44/44 [==============================] - 25s 541ms/step - loss: 101.3737 - mae: 8.5055 - val_loss: 103.6049 - val_mae: 8.6437\n",
            "Epoch 208/500\n",
            "44/44 [==============================] - 25s 552ms/step - loss: 101.8686 - mae: 8.5335 - val_loss: 101.3003 - val_mae: 8.4957\n",
            "Epoch 209/500\n",
            "44/44 [==============================] - 25s 557ms/step - loss: 102.1303 - mae: 8.5425 - val_loss: 103.0318 - val_mae: 8.5702\n",
            "Epoch 210/500\n",
            "44/44 [==============================] - 21s 456ms/step - loss: 101.9462 - mae: 8.5319 - val_loss: 100.4016 - val_mae: 8.4508\n",
            "Epoch 211/500\n",
            "44/44 [==============================] - 25s 560ms/step - loss: 101.0014 - mae: 8.4779 - val_loss: 101.2184 - val_mae: 8.4902\n",
            "Epoch 212/500\n",
            "44/44 [==============================] - 25s 548ms/step - loss: 101.5871 - mae: 8.5183 - val_loss: 100.6642 - val_mae: 8.4647\n",
            "Epoch 213/500\n",
            "44/44 [==============================] - 25s 546ms/step - loss: 101.3507 - mae: 8.4997 - val_loss: 102.2263 - val_mae: 8.5550\n",
            "Epoch 214/500\n",
            "44/44 [==============================] - 21s 442ms/step - loss: 101.1258 - mae: 8.4965 - val_loss: 104.1121 - val_mae: 8.6351\n",
            "Epoch 215/500\n",
            "44/44 [==============================] - 25s 547ms/step - loss: 100.7453 - mae: 8.4782 - val_loss: 102.6346 - val_mae: 8.5671\n",
            "Epoch 216/500\n",
            "44/44 [==============================] - 25s 553ms/step - loss: 101.4402 - mae: 8.4998 - val_loss: 100.0513 - val_mae: 8.4176\n",
            "Epoch 217/500\n",
            "44/44 [==============================] - 24s 533ms/step - loss: 101.8912 - mae: 8.5329 - val_loss: 99.6597 - val_mae: 8.4125\n",
            "Epoch 218/500\n",
            "44/44 [==============================] - 26s 561ms/step - loss: 101.5938 - mae: 8.5276 - val_loss: 102.6552 - val_mae: 8.5637\n",
            "Epoch 219/500\n",
            "44/44 [==============================] - 25s 550ms/step - loss: 101.3768 - mae: 8.5095 - val_loss: 101.6419 - val_mae: 8.5008\n",
            "Epoch 220/500\n",
            "44/44 [==============================] - 25s 543ms/step - loss: 101.8659 - mae: 8.5278 - val_loss: 101.3236 - val_mae: 8.5404\n",
            "Epoch 221/500\n",
            "44/44 [==============================] - 25s 543ms/step - loss: 101.2389 - mae: 8.4919 - val_loss: 101.6656 - val_mae: 8.5140\n",
            "Epoch 222/500\n",
            "44/44 [==============================] - 25s 560ms/step - loss: 101.2772 - mae: 8.4986 - val_loss: 101.7831 - val_mae: 8.5287\n",
            "Epoch 223/500\n",
            "44/44 [==============================] - 26s 561ms/step - loss: 100.9789 - mae: 8.4947 - val_loss: 100.0849 - val_mae: 8.4218\n",
            "Epoch 224/500\n",
            "44/44 [==============================] - 24s 535ms/step - loss: 101.6680 - mae: 8.5222 - val_loss: 102.0991 - val_mae: 8.5398\n",
            "Epoch 225/500\n",
            "44/44 [==============================] - 26s 572ms/step - loss: 101.9689 - mae: 8.5401 - val_loss: 100.9854 - val_mae: 8.4748\n",
            "Epoch 226/500\n",
            "44/44 [==============================] - 25s 549ms/step - loss: 102.0599 - mae: 8.5479 - val_loss: 101.2287 - val_mae: 8.4967\n",
            "Epoch 227/500\n",
            "44/44 [==============================] - 25s 565ms/step - loss: 100.6638 - mae: 8.4659 - val_loss: 100.3068 - val_mae: 8.4409\n",
            "Epoch 228/500\n",
            "44/44 [==============================] - 26s 563ms/step - loss: 101.5499 - mae: 8.5313 - val_loss: 102.6787 - val_mae: 8.5543\n",
            "Epoch 229/500\n",
            "44/44 [==============================] - 26s 562ms/step - loss: 101.1674 - mae: 8.4960 - val_loss: 101.5673 - val_mae: 8.5186\n",
            "Epoch 230/500\n",
            "44/44 [==============================] - 25s 539ms/step - loss: 101.4043 - mae: 8.4993 - val_loss: 102.2115 - val_mae: 8.5869\n",
            "Epoch 231/500\n",
            "44/44 [==============================] - 20s 421ms/step - loss: 101.4626 - mae: 8.5074 - val_loss: 101.7167 - val_mae: 8.5090\n",
            "Epoch 232/500\n",
            "44/44 [==============================] - 27s 547ms/step - loss: 101.8564 - mae: 8.5229 - val_loss: 100.3692 - val_mae: 8.4334\n",
            "Epoch 233/500\n",
            "44/44 [==============================] - 26s 537ms/step - loss: 101.7124 - mae: 8.5223 - val_loss: 99.6324 - val_mae: 8.4020\n",
            "Epoch 234/500\n",
            "44/44 [==============================] - 27s 566ms/step - loss: 101.5195 - mae: 8.5194 - val_loss: 101.4233 - val_mae: 8.5246\n",
            "Epoch 235/500\n",
            "44/44 [==============================] - 27s 585ms/step - loss: 101.3454 - mae: 8.5072 - val_loss: 104.1395 - val_mae: 8.6687\n",
            "Epoch 236/500\n",
            "44/44 [==============================] - 26s 550ms/step - loss: 102.0358 - mae: 8.5390 - val_loss: 100.8934 - val_mae: 8.4885\n",
            "Epoch 237/500\n",
            "44/44 [==============================] - 25s 544ms/step - loss: 101.8872 - mae: 8.5279 - val_loss: 100.0983 - val_mae: 8.4213\n",
            "Epoch 238/500\n",
            "44/44 [==============================] - 24s 530ms/step - loss: 101.4226 - mae: 8.5055 - val_loss: 102.5535 - val_mae: 8.5883\n",
            "Epoch 239/500\n",
            "44/44 [==============================] - 25s 542ms/step - loss: 101.0374 - mae: 8.4853 - val_loss: 101.8559 - val_mae: 8.5279\n",
            "Epoch 240/500\n",
            "44/44 [==============================] - 24s 533ms/step - loss: 101.9164 - mae: 8.5402 - val_loss: 103.4587 - val_mae: 8.6147\n",
            "Epoch 241/500\n",
            "44/44 [==============================] - 20s 421ms/step - loss: 100.9449 - mae: 8.4840 - val_loss: 101.3522 - val_mae: 8.5007\n",
            "Epoch 242/500\n",
            "44/44 [==============================] - 27s 552ms/step - loss: 100.7426 - mae: 8.4738 - val_loss: 101.2801 - val_mae: 8.5112\n",
            "Epoch 243/500\n",
            "44/44 [==============================] - 25s 548ms/step - loss: 100.3127 - mae: 8.4534 - val_loss: 102.3925 - val_mae: 8.5584\n",
            "Epoch 244/500\n",
            "44/44 [==============================] - 24s 527ms/step - loss: 101.3751 - mae: 8.5029 - val_loss: 99.6002 - val_mae: 8.4335\n",
            "Epoch 245/500\n",
            "44/44 [==============================] - 20s 431ms/step - loss: 101.5286 - mae: 8.5248 - val_loss: 101.2591 - val_mae: 8.4956\n",
            "Epoch 246/500\n",
            "44/44 [==============================] - 28s 556ms/step - loss: 100.8406 - mae: 8.4795 - val_loss: 102.0212 - val_mae: 8.5557\n",
            "Epoch 247/500\n",
            "44/44 [==============================] - 25s 544ms/step - loss: 100.6635 - mae: 8.4748 - val_loss: 101.3492 - val_mae: 8.5086\n",
            "Epoch 248/500\n",
            "44/44 [==============================] - 25s 556ms/step - loss: 101.4011 - mae: 8.5048 - val_loss: 101.0676 - val_mae: 8.5193\n",
            "Epoch 249/500\n",
            "44/44 [==============================] - 21s 457ms/step - loss: 101.4349 - mae: 8.5174 - val_loss: 99.5411 - val_mae: 8.4145\n",
            "Epoch 250/500\n",
            "44/44 [==============================] - 26s 529ms/step - loss: 100.7746 - mae: 8.4750 - val_loss: 97.8982 - val_mae: 8.3142\n",
            "Epoch 251/500\n",
            "44/44 [==============================] - 26s 560ms/step - loss: 101.6819 - mae: 8.5257 - val_loss: 101.3668 - val_mae: 8.5096\n",
            "Epoch 252/500\n",
            "44/44 [==============================] - 26s 572ms/step - loss: 101.0470 - mae: 8.4917 - val_loss: 102.5592 - val_mae: 8.5920\n",
            "Epoch 253/500\n",
            "44/44 [==============================] - 21s 465ms/step - loss: 101.1147 - mae: 8.4923 - val_loss: 100.7934 - val_mae: 8.4738\n",
            "Epoch 254/500\n",
            "44/44 [==============================] - 27s 563ms/step - loss: 101.2527 - mae: 8.4971 - val_loss: 101.1319 - val_mae: 8.4940\n",
            "Epoch 255/500\n",
            "44/44 [==============================] - 25s 561ms/step - loss: 101.7469 - mae: 8.5229 - val_loss: 102.9773 - val_mae: 8.6032\n",
            "Epoch 256/500\n",
            "44/44 [==============================] - 25s 536ms/step - loss: 101.2972 - mae: 8.4962 - val_loss: 101.0164 - val_mae: 8.4736\n",
            "Epoch 257/500\n",
            "44/44 [==============================] - 25s 548ms/step - loss: 101.2111 - mae: 8.4980 - val_loss: 103.6879 - val_mae: 8.6210\n",
            "Epoch 258/500\n",
            "44/44 [==============================] - 26s 550ms/step - loss: 101.7992 - mae: 8.5379 - val_loss: 101.4787 - val_mae: 8.5392\n",
            "Epoch 259/500\n",
            "44/44 [==============================] - 26s 530ms/step - loss: 101.5485 - mae: 8.5127 - val_loss: 100.7160 - val_mae: 8.4773\n",
            "Epoch 260/500\n",
            "44/44 [==============================] - 25s 540ms/step - loss: 100.9009 - mae: 8.4788 - val_loss: 101.6230 - val_mae: 8.4866\n",
            "Epoch 261/500\n",
            "44/44 [==============================] - 19s 405ms/step - loss: 101.4368 - mae: 8.5179 - val_loss: 101.9908 - val_mae: 8.5174\n",
            "Epoch 262/500\n",
            "44/44 [==============================] - 28s 588ms/step - loss: 101.3851 - mae: 8.5101 - val_loss: 100.8648 - val_mae: 8.4637\n",
            "Epoch 263/500\n",
            "44/44 [==============================] - 25s 549ms/step - loss: 101.0282 - mae: 8.4804 - val_loss: 102.6304 - val_mae: 8.5637\n",
            "Epoch 264/500\n",
            "44/44 [==============================] - 26s 576ms/step - loss: 101.7905 - mae: 8.5319 - val_loss: 101.6685 - val_mae: 8.5189\n",
            "Epoch 265/500\n",
            "44/44 [==============================] - 27s 602ms/step - loss: 101.1736 - mae: 8.4859 - val_loss: 100.7338 - val_mae: 8.4721\n",
            "Epoch 266/500\n",
            "44/44 [==============================] - 20s 440ms/step - loss: 100.6505 - mae: 8.4749 - val_loss: 99.7413 - val_mae: 8.4228\n",
            "Epoch 267/500\n",
            "44/44 [==============================] - 27s 530ms/step - loss: 101.2853 - mae: 8.4943 - val_loss: 100.2656 - val_mae: 8.4489\n",
            "Epoch 268/500\n",
            "44/44 [==============================] - 24s 526ms/step - loss: 101.2625 - mae: 8.5010 - val_loss: 99.5817 - val_mae: 8.4002\n",
            "Epoch 269/500\n",
            "44/44 [==============================] - 25s 526ms/step - loss: 101.1689 - mae: 8.4958 - val_loss: 102.8055 - val_mae: 8.5875\n",
            "Epoch 270/500\n",
            "44/44 [==============================] - 26s 554ms/step - loss: 101.4214 - mae: 8.5077 - val_loss: 100.5860 - val_mae: 8.4269\n",
            "Epoch 271/500\n",
            "44/44 [==============================] - 26s 575ms/step - loss: 101.9272 - mae: 8.5406 - val_loss: 100.2501 - val_mae: 8.4750\n",
            "Epoch 272/500\n",
            "44/44 [==============================] - 27s 590ms/step - loss: 101.6858 - mae: 8.5105 - val_loss: 102.6785 - val_mae: 8.5672\n",
            "Epoch 273/500\n",
            "44/44 [==============================] - 26s 575ms/step - loss: 101.0652 - mae: 8.4951 - val_loss: 100.9187 - val_mae: 8.4728\n",
            "Epoch 274/500\n",
            "44/44 [==============================] - 28s 601ms/step - loss: 101.4450 - mae: 8.5128 - val_loss: 102.9586 - val_mae: 8.5957\n",
            "Epoch 275/500\n",
            "44/44 [==============================] - 27s 585ms/step - loss: 101.5677 - mae: 8.5105 - val_loss: 100.8513 - val_mae: 8.4992\n",
            "Epoch 276/500\n",
            "44/44 [==============================] - 27s 582ms/step - loss: 101.5016 - mae: 8.5182 - val_loss: 102.9016 - val_mae: 8.6062\n",
            "Epoch 277/500\n",
            "44/44 [==============================] - 26s 568ms/step - loss: 101.4977 - mae: 8.5104 - val_loss: 101.6230 - val_mae: 8.5232\n",
            "Epoch 278/500\n",
            "44/44 [==============================] - 25s 553ms/step - loss: 101.0061 - mae: 8.4842 - val_loss: 101.4827 - val_mae: 8.5141\n",
            "Epoch 279/500\n",
            "44/44 [==============================] - 25s 541ms/step - loss: 101.3569 - mae: 8.5034 - val_loss: 102.7851 - val_mae: 8.5722\n",
            "Epoch 280/500\n",
            "44/44 [==============================] - 25s 536ms/step - loss: 101.7262 - mae: 8.5191 - val_loss: 103.2753 - val_mae: 8.5950\n",
            "Epoch 281/500\n",
            "44/44 [==============================] - 25s 549ms/step - loss: 101.4120 - mae: 8.5061 - val_loss: 102.0550 - val_mae: 8.5429\n",
            "Epoch 282/500\n",
            "44/44 [==============================] - 22s 476ms/step - loss: 100.7992 - mae: 8.4881 - val_loss: 101.1463 - val_mae: 8.4716\n",
            "Epoch 283/500\n",
            "44/44 [==============================] - 27s 540ms/step - loss: 101.0640 - mae: 8.4786 - val_loss: 101.5223 - val_mae: 8.5119\n",
            "Epoch 284/500\n",
            "44/44 [==============================] - 27s 593ms/step - loss: 101.2162 - mae: 8.4899 - val_loss: 102.7219 - val_mae: 8.5650\n",
            "Epoch 285/500\n",
            "44/44 [==============================] - 26s 569ms/step - loss: 101.9936 - mae: 8.5406 - val_loss: 102.1155 - val_mae: 8.5333\n",
            "Epoch 286/500\n",
            "44/44 [==============================] - 26s 563ms/step - loss: 101.1697 - mae: 8.5101 - val_loss: 101.2028 - val_mae: 8.4882\n",
            "Epoch 287/500\n",
            "44/44 [==============================] - 20s 448ms/step - loss: 100.9361 - mae: 8.4751 - val_loss: 99.6296 - val_mae: 8.4150\n",
            "Epoch 288/500\n",
            "44/44 [==============================] - 28s 555ms/step - loss: 101.3459 - mae: 8.5007 - val_loss: 100.6971 - val_mae: 8.4882\n",
            "Epoch 289/500\n",
            "44/44 [==============================] - 24s 523ms/step - loss: 102.0328 - mae: 8.5425 - val_loss: 99.9865 - val_mae: 8.4342\n",
            "Epoch 290/500\n",
            "44/44 [==============================] - 25s 526ms/step - loss: 100.6930 - mae: 8.4646 - val_loss: 101.5117 - val_mae: 8.5306\n",
            "Epoch 291/500\n",
            "44/44 [==============================] - 25s 545ms/step - loss: 101.6753 - mae: 8.5153 - val_loss: 100.1321 - val_mae: 8.4412\n",
            "Epoch 292/500\n",
            "44/44 [==============================] - 26s 560ms/step - loss: 101.4920 - mae: 8.4994 - val_loss: 100.0250 - val_mae: 8.4496\n",
            "Epoch 293/500\n",
            "44/44 [==============================] - 26s 546ms/step - loss: 101.8918 - mae: 8.5371 - val_loss: 101.2842 - val_mae: 8.5228\n",
            "Epoch 294/500\n",
            "44/44 [==============================] - 25s 552ms/step - loss: 100.7978 - mae: 8.4766 - val_loss: 102.2649 - val_mae: 8.5475\n",
            "Epoch 295/500\n",
            "44/44 [==============================] - 25s 540ms/step - loss: 101.3805 - mae: 8.4988 - val_loss: 97.3824 - val_mae: 8.2820\n",
            "Epoch 296/500\n",
            "44/44 [==============================] - 24s 530ms/step - loss: 100.9820 - mae: 8.4855 - val_loss: 101.2333 - val_mae: 8.5023\n",
            "Epoch 297/500\n",
            "44/44 [==============================] - 25s 555ms/step - loss: 101.5335 - mae: 8.5212 - val_loss: 100.4779 - val_mae: 8.4581\n",
            "Epoch 298/500\n",
            "44/44 [==============================] - 25s 545ms/step - loss: 101.5182 - mae: 8.5166 - val_loss: 100.8785 - val_mae: 8.4780\n",
            "Epoch 299/500\n",
            "44/44 [==============================] - 25s 545ms/step - loss: 100.4239 - mae: 8.4614 - val_loss: 100.9205 - val_mae: 8.4781\n",
            "Epoch 300/500\n",
            "44/44 [==============================] - 24s 529ms/step - loss: 100.7773 - mae: 8.4705 - val_loss: 100.4860 - val_mae: 8.4643\n",
            "Epoch 301/500\n",
            "44/44 [==============================] - 25s 556ms/step - loss: 100.8397 - mae: 8.4877 - val_loss: 101.7993 - val_mae: 8.5305\n",
            "Epoch 302/500\n",
            "44/44 [==============================] - 19s 411ms/step - loss: 100.8536 - mae: 8.4768 - val_loss: 100.6104 - val_mae: 8.4547\n",
            "Epoch 303/500\n",
            "44/44 [==============================] - 29s 594ms/step - loss: 101.4167 - mae: 8.5084 - val_loss: 100.8318 - val_mae: 8.4791\n",
            "Epoch 304/500\n",
            "44/44 [==============================] - 20s 429ms/step - loss: 100.3695 - mae: 8.4579 - val_loss: 103.0404 - val_mae: 8.5973\n",
            "Epoch 305/500\n",
            "44/44 [==============================] - 28s 553ms/step - loss: 101.0070 - mae: 8.4829 - val_loss: 100.3968 - val_mae: 8.4498\n",
            "Epoch 306/500\n",
            "44/44 [==============================] - 25s 529ms/step - loss: 100.8804 - mae: 8.4762 - val_loss: 99.2941 - val_mae: 8.3961\n",
            "Epoch 307/500\n",
            "44/44 [==============================] - 23s 514ms/step - loss: 101.2594 - mae: 8.4991 - val_loss: 102.4116 - val_mae: 8.5589\n",
            "Epoch 308/500\n",
            "44/44 [==============================] - 27s 600ms/step - loss: 100.8123 - mae: 8.4817 - val_loss: 100.5822 - val_mae: 8.4650\n",
            "Epoch 309/500\n",
            "44/44 [==============================] - 27s 581ms/step - loss: 100.7595 - mae: 8.4822 - val_loss: 100.9598 - val_mae: 8.4893\n",
            "Epoch 310/500\n",
            "44/44 [==============================] - 26s 578ms/step - loss: 100.7878 - mae: 8.4684 - val_loss: 101.5161 - val_mae: 8.4853\n",
            "Epoch 311/500\n",
            "44/44 [==============================] - 27s 584ms/step - loss: 101.9941 - mae: 8.5448 - val_loss: 101.5761 - val_mae: 8.5117\n",
            "Epoch 312/500\n",
            "44/44 [==============================] - 27s 588ms/step - loss: 101.1179 - mae: 8.4902 - val_loss: 99.5591 - val_mae: 8.4200\n",
            "Epoch 313/500\n",
            "44/44 [==============================] - 26s 560ms/step - loss: 100.4232 - mae: 8.4537 - val_loss: 101.2694 - val_mae: 8.4887\n",
            "Epoch 314/500\n",
            "44/44 [==============================] - 21s 463ms/step - loss: 101.3264 - mae: 8.5013 - val_loss: 101.0544 - val_mae: 8.5042\n",
            "Epoch 315/500\n",
            "44/44 [==============================] - 27s 532ms/step - loss: 100.8157 - mae: 8.4804 - val_loss: 100.2397 - val_mae: 8.4348\n",
            "Epoch 316/500\n",
            "44/44 [==============================] - 23s 461ms/step - loss: 100.6555 - mae: 8.4738 - val_loss: 100.8552 - val_mae: 8.4866\n",
            "Epoch 317/500\n",
            "44/44 [==============================] - 25s 529ms/step - loss: 100.9560 - mae: 8.4817 - val_loss: 101.4275 - val_mae: 8.5171\n",
            "Epoch 318/500\n",
            "44/44 [==============================] - 24s 532ms/step - loss: 100.7028 - mae: 8.4742 - val_loss: 102.7506 - val_mae: 8.5769\n",
            "Epoch 319/500\n",
            "44/44 [==============================] - 26s 548ms/step - loss: 100.9159 - mae: 8.4861 - val_loss: 102.8200 - val_mae: 8.6038\n",
            "Epoch 320/500\n",
            "44/44 [==============================] - 26s 577ms/step - loss: 101.1449 - mae: 8.4926 - val_loss: 101.8137 - val_mae: 8.5374\n",
            "Epoch 321/500\n",
            "44/44 [==============================] - 28s 606ms/step - loss: 101.3541 - mae: 8.5081 - val_loss: 99.7683 - val_mae: 8.4253\n",
            "Epoch 322/500\n",
            "44/44 [==============================] - 26s 565ms/step - loss: 101.1002 - mae: 8.4908 - val_loss: 101.7803 - val_mae: 8.5026\n",
            "Epoch 323/500\n",
            "44/44 [==============================] - 25s 554ms/step - loss: 101.8508 - mae: 8.5401 - val_loss: 100.3893 - val_mae: 8.4664\n",
            "Epoch 324/500\n",
            "44/44 [==============================] - 24s 527ms/step - loss: 101.3000 - mae: 8.5162 - val_loss: 103.3304 - val_mae: 8.6407\n",
            "Epoch 325/500\n",
            "44/44 [==============================] - 25s 549ms/step - loss: 100.9764 - mae: 8.4798 - val_loss: 100.3100 - val_mae: 8.4559\n",
            "Epoch 326/500\n",
            "44/44 [==============================] - 25s 547ms/step - loss: 100.9736 - mae: 8.4956 - val_loss: 99.8471 - val_mae: 8.3955\n",
            "Epoch 327/500\n",
            "44/44 [==============================] - 26s 559ms/step - loss: 100.8263 - mae: 8.4730 - val_loss: 101.7658 - val_mae: 8.5072\n",
            "Epoch 328/500\n",
            "44/44 [==============================] - 20s 424ms/step - loss: 100.7625 - mae: 8.4700 - val_loss: 98.5853 - val_mae: 8.3464\n",
            "Epoch 329/500\n",
            "44/44 [==============================] - 28s 559ms/step - loss: 101.2718 - mae: 8.5112 - val_loss: 101.1094 - val_mae: 8.5139\n",
            "Epoch 330/500\n",
            "44/44 [==============================] - 26s 560ms/step - loss: 101.2167 - mae: 8.5026 - val_loss: 101.7773 - val_mae: 8.5176\n",
            "Epoch 331/500\n",
            "44/44 [==============================] - 27s 575ms/step - loss: 101.3610 - mae: 8.5065 - val_loss: 101.2887 - val_mae: 8.5108\n",
            "Epoch 332/500\n",
            "44/44 [==============================] - 26s 557ms/step - loss: 101.4744 - mae: 8.5044 - val_loss: 98.9242 - val_mae: 8.3878\n",
            "Epoch 333/500\n",
            "44/44 [==============================] - 22s 473ms/step - loss: 101.1539 - mae: 8.4971 - val_loss: 101.7237 - val_mae: 8.5146\n",
            "Epoch 334/500\n",
            "44/44 [==============================] - 26s 563ms/step - loss: 100.9846 - mae: 8.4955 - val_loss: 102.0848 - val_mae: 8.5565\n",
            "Epoch 335/500\n",
            "44/44 [==============================] - 24s 523ms/step - loss: 100.7796 - mae: 8.4814 - val_loss: 101.6961 - val_mae: 8.5124\n",
            "Epoch 336/500\n",
            "44/44 [==============================] - 25s 539ms/step - loss: 101.8931 - mae: 8.5331 - val_loss: 99.9209 - val_mae: 8.4207\n",
            "Epoch 337/500\n",
            "44/44 [==============================] - 28s 598ms/step - loss: 100.1003 - mae: 8.4341 - val_loss: 100.3686 - val_mae: 8.4253\n",
            "Epoch 338/500\n",
            "44/44 [==============================] - 24s 484ms/step - loss: 101.5801 - mae: 8.5220 - val_loss: 100.4009 - val_mae: 8.4535\n",
            "Epoch 339/500\n",
            "44/44 [==============================] - 26s 541ms/step - loss: 101.1933 - mae: 8.4882 - val_loss: 100.5244 - val_mae: 8.4709\n",
            "Epoch 340/500\n",
            "44/44 [==============================] - 25s 548ms/step - loss: 100.8811 - mae: 8.4792 - val_loss: 101.9916 - val_mae: 8.5537\n",
            "Epoch 341/500\n",
            "44/44 [==============================] - 28s 616ms/step - loss: 101.0297 - mae: 8.4863 - val_loss: 101.6018 - val_mae: 8.5133\n",
            "Epoch 342/500\n",
            "44/44 [==============================] - 26s 557ms/step - loss: 100.8267 - mae: 8.4863 - val_loss: 99.7362 - val_mae: 8.4306\n",
            "Epoch 343/500\n",
            "44/44 [==============================] - 25s 544ms/step - loss: 100.6972 - mae: 8.4725 - val_loss: 99.5034 - val_mae: 8.3909\n",
            "Epoch 344/500\n",
            "44/44 [==============================] - 24s 533ms/step - loss: 101.4305 - mae: 8.5089 - val_loss: 101.1097 - val_mae: 8.4957\n",
            "Epoch 345/500\n",
            "44/44 [==============================] - 26s 572ms/step - loss: 100.6238 - mae: 8.4709 - val_loss: 103.3496 - val_mae: 8.6240\n",
            "Epoch 346/500\n",
            "44/44 [==============================] - 24s 530ms/step - loss: 100.4722 - mae: 8.4578 - val_loss: 98.9035 - val_mae: 8.3436\n",
            "Epoch 347/500\n",
            "44/44 [==============================] - 26s 544ms/step - loss: 101.5429 - mae: 8.5127 - val_loss: 100.8336 - val_mae: 8.4591\n",
            "Epoch 348/500\n",
            "44/44 [==============================] - 27s 600ms/step - loss: 100.8419 - mae: 8.4797 - val_loss: 101.2129 - val_mae: 8.5017\n",
            "Epoch 349/500\n",
            "44/44 [==============================] - 28s 610ms/step - loss: 101.2465 - mae: 8.4973 - val_loss: 100.9077 - val_mae: 8.4611\n",
            "Epoch 350/500\n",
            "44/44 [==============================] - 26s 578ms/step - loss: 100.9108 - mae: 8.4787 - val_loss: 101.8733 - val_mae: 8.5238\n",
            "Epoch 351/500\n",
            "44/44 [==============================] - 27s 585ms/step - loss: 100.8027 - mae: 8.4777 - val_loss: 102.5644 - val_mae: 8.5631\n",
            "Epoch 352/500\n",
            "44/44 [==============================] - 25s 533ms/step - loss: 101.5291 - mae: 8.5063 - val_loss: 101.8505 - val_mae: 8.5142\n",
            "Epoch 353/500\n",
            "44/44 [==============================] - 27s 591ms/step - loss: 101.1110 - mae: 8.4895 - val_loss: 98.9224 - val_mae: 8.4021\n",
            "Epoch 354/500\n",
            "44/44 [==============================] - 25s 550ms/step - loss: 100.7259 - mae: 8.4792 - val_loss: 101.8216 - val_mae: 8.5183\n",
            "Epoch 355/500\n",
            "44/44 [==============================] - 25s 546ms/step - loss: 100.8553 - mae: 8.4699 - val_loss: 101.4982 - val_mae: 8.5063\n",
            "Epoch 356/500\n",
            "44/44 [==============================] - 24s 529ms/step - loss: 100.6248 - mae: 8.4655 - val_loss: 98.2032 - val_mae: 8.3532\n",
            "Epoch 357/500\n",
            "44/44 [==============================] - 25s 531ms/step - loss: 101.0425 - mae: 8.4840 - val_loss: 98.8637 - val_mae: 8.3616\n",
            "Epoch 358/500\n",
            "44/44 [==============================] - 21s 445ms/step - loss: 100.9350 - mae: 8.4730 - val_loss: 102.4096 - val_mae: 8.5620\n",
            "Epoch 359/500\n",
            "44/44 [==============================] - 23s 461ms/step - loss: 100.7677 - mae: 8.4826 - val_loss: 101.4747 - val_mae: 8.5235\n",
            "Epoch 360/500\n",
            "44/44 [==============================] - 27s 554ms/step - loss: 100.6874 - mae: 8.4725 - val_loss: 101.5096 - val_mae: 8.4861\n",
            "Epoch 361/500\n",
            "44/44 [==============================] - 25s 535ms/step - loss: 100.2346 - mae: 8.4526 - val_loss: 101.6831 - val_mae: 8.4994\n",
            "Epoch 362/500\n",
            "44/44 [==============================] - 27s 584ms/step - loss: 100.8512 - mae: 8.4801 - val_loss: 101.4903 - val_mae: 8.4884\n",
            "Epoch 363/500\n",
            "44/44 [==============================] - 25s 542ms/step - loss: 101.1472 - mae: 8.4871 - val_loss: 99.2490 - val_mae: 8.3856\n",
            "Epoch 364/500\n",
            "44/44 [==============================] - 25s 548ms/step - loss: 100.9597 - mae: 8.4920 - val_loss: 101.8956 - val_mae: 8.5339\n",
            "Epoch 365/500\n",
            "44/44 [==============================] - 26s 576ms/step - loss: 100.6705 - mae: 8.4699 - val_loss: 103.1246 - val_mae: 8.5970\n",
            "Epoch 366/500\n",
            "44/44 [==============================] - 25s 557ms/step - loss: 101.0979 - mae: 8.4919 - val_loss: 101.6875 - val_mae: 8.5135\n",
            "Epoch 367/500\n",
            "44/44 [==============================] - 20s 429ms/step - loss: 100.6339 - mae: 8.4723 - val_loss: 101.0236 - val_mae: 8.4892\n",
            "Epoch 368/500\n",
            "44/44 [==============================] - 28s 586ms/step - loss: 101.0746 - mae: 8.4979 - val_loss: 99.5922 - val_mae: 8.4068\n",
            "Epoch 369/500\n",
            "44/44 [==============================] - 29s 633ms/step - loss: 100.6852 - mae: 8.4750 - val_loss: 100.4972 - val_mae: 8.4777\n",
            "Epoch 370/500\n",
            "44/44 [==============================] - 25s 551ms/step - loss: 100.6410 - mae: 8.4712 - val_loss: 101.5992 - val_mae: 8.4935\n",
            "Epoch 371/500\n",
            "44/44 [==============================] - 20s 436ms/step - loss: 100.6851 - mae: 8.4630 - val_loss: 100.4020 - val_mae: 8.4800\n",
            "Epoch 372/500\n",
            "44/44 [==============================] - 29s 577ms/step - loss: 100.9513 - mae: 8.4787 - val_loss: 101.6787 - val_mae: 8.5177\n",
            "Epoch 373/500\n",
            "44/44 [==============================] - 25s 533ms/step - loss: 100.8621 - mae: 8.4700 - val_loss: 99.9735 - val_mae: 8.4149\n",
            "Epoch 374/500\n",
            "44/44 [==============================] - 26s 562ms/step - loss: 101.6108 - mae: 8.5180 - val_loss: 101.5935 - val_mae: 8.5081\n",
            "Epoch 375/500\n",
            "44/44 [==============================] - 25s 553ms/step - loss: 100.8449 - mae: 8.4690 - val_loss: 100.8847 - val_mae: 8.4860\n",
            "Epoch 376/500\n",
            "44/44 [==============================] - 27s 590ms/step - loss: 101.2664 - mae: 8.5053 - val_loss: 99.5540 - val_mae: 8.4144\n",
            "Epoch 377/500\n",
            "44/44 [==============================] - 25s 551ms/step - loss: 99.7805 - mae: 8.4178 - val_loss: 99.8360 - val_mae: 8.4162\n",
            "Epoch 378/500\n",
            "44/44 [==============================] - 24s 533ms/step - loss: 101.6316 - mae: 8.5264 - val_loss: 101.3554 - val_mae: 8.4960\n",
            "Epoch 379/500\n",
            "44/44 [==============================] - 24s 536ms/step - loss: 101.1810 - mae: 8.4975 - val_loss: 100.9013 - val_mae: 8.4474\n",
            "Epoch 380/500\n",
            "44/44 [==============================] - 25s 525ms/step - loss: 100.2974 - mae: 8.4510 - val_loss: 99.1947 - val_mae: 8.3852\n",
            "Epoch 381/500\n",
            "44/44 [==============================] - 26s 575ms/step - loss: 100.7011 - mae: 8.4737 - val_loss: 100.3814 - val_mae: 8.4516\n",
            "Epoch 382/500\n",
            "44/44 [==============================] - 25s 556ms/step - loss: 101.8096 - mae: 8.5244 - val_loss: 101.9445 - val_mae: 8.5143\n",
            "Epoch 383/500\n",
            "44/44 [==============================] - 25s 559ms/step - loss: 100.6634 - mae: 8.4740 - val_loss: 99.3627 - val_mae: 8.3933\n",
            "Epoch 384/500\n",
            "44/44 [==============================] - 21s 444ms/step - loss: 101.0951 - mae: 8.4862 - val_loss: 101.1036 - val_mae: 8.4820\n",
            "Epoch 385/500\n",
            "44/44 [==============================] - 20s 427ms/step - loss: 100.2723 - mae: 8.4421 - val_loss: 101.8221 - val_mae: 8.5224\n",
            "Epoch 386/500\n",
            "44/44 [==============================] - 29s 559ms/step - loss: 101.1464 - mae: 8.4935 - val_loss: 99.6025 - val_mae: 8.4017\n",
            "Epoch 387/500\n",
            "44/44 [==============================] - 26s 559ms/step - loss: 100.9418 - mae: 8.4822 - val_loss: 101.3170 - val_mae: 8.4934\n",
            "Epoch 388/500\n",
            "44/44 [==============================] - 26s 545ms/step - loss: 101.1379 - mae: 8.4943 - val_loss: 102.0477 - val_mae: 8.5569\n",
            "Epoch 389/500\n",
            "44/44 [==============================] - 27s 590ms/step - loss: 101.1997 - mae: 8.4919 - val_loss: 101.5503 - val_mae: 8.5501\n",
            "Epoch 390/500\n",
            "44/44 [==============================] - 23s 501ms/step - loss: 100.4765 - mae: 8.4567 - val_loss: 100.9900 - val_mae: 8.4971\n",
            "Epoch 391/500\n",
            "44/44 [==============================] - 25s 545ms/step - loss: 100.3627 - mae: 8.4493 - val_loss: 100.7241 - val_mae: 8.4653\n",
            "Epoch 392/500\n",
            "44/44 [==============================] - 25s 522ms/step - loss: 100.4062 - mae: 8.4620 - val_loss: 102.2356 - val_mae: 8.5388\n",
            "Epoch 393/500\n",
            "44/44 [==============================] - 24s 518ms/step - loss: 101.2887 - mae: 8.5085 - val_loss: 102.2828 - val_mae: 8.5345\n",
            "Epoch 394/500\n",
            "44/44 [==============================] - 25s 550ms/step - loss: 100.5622 - mae: 8.4621 - val_loss: 100.0203 - val_mae: 8.4343\n",
            "Epoch 395/500\n",
            "44/44 [==============================] - 24s 526ms/step - loss: 101.0194 - mae: 8.4835 - val_loss: 102.6906 - val_mae: 8.5406\n",
            "Epoch 396/500\n",
            "44/44 [==============================] - 25s 535ms/step - loss: 101.2000 - mae: 8.4942 - val_loss: 99.6744 - val_mae: 8.4359\n",
            "Epoch 397/500\n",
            "44/44 [==============================] - 25s 548ms/step - loss: 100.7842 - mae: 8.4717 - val_loss: 102.2364 - val_mae: 8.5246\n",
            "Epoch 398/500\n",
            "44/44 [==============================] - 25s 544ms/step - loss: 101.0190 - mae: 8.4854 - val_loss: 99.9845 - val_mae: 8.4129\n",
            "Epoch 399/500\n",
            "44/44 [==============================] - 22s 469ms/step - loss: 100.7500 - mae: 8.4718 - val_loss: 100.8887 - val_mae: 8.4837\n",
            "Epoch 400/500\n",
            "44/44 [==============================] - 29s 628ms/step - loss: 100.8144 - mae: 8.4715 - val_loss: 101.4942 - val_mae: 8.5282\n",
            "Epoch 401/500\n",
            "44/44 [==============================] - 26s 535ms/step - loss: 100.5673 - mae: 8.4704 - val_loss: 101.4753 - val_mae: 8.5195\n",
            "Epoch 402/500\n",
            "44/44 [==============================] - 26s 573ms/step - loss: 100.7328 - mae: 8.4768 - val_loss: 101.0446 - val_mae: 8.4855\n",
            "Epoch 403/500\n",
            "44/44 [==============================] - 21s 463ms/step - loss: 100.6472 - mae: 8.4660 - val_loss: 99.4155 - val_mae: 8.4191\n",
            "Epoch 404/500\n",
            "44/44 [==============================] - 25s 542ms/step - loss: 101.0118 - mae: 8.4893 - val_loss: 101.3643 - val_mae: 8.4927\n",
            "Epoch 405/500\n",
            "44/44 [==============================] - 26s 562ms/step - loss: 100.8190 - mae: 8.4750 - val_loss: 101.4419 - val_mae: 8.5144\n",
            "Epoch 406/500\n",
            "44/44 [==============================] - 25s 557ms/step - loss: 100.4778 - mae: 8.4695 - val_loss: 101.4807 - val_mae: 8.5080\n",
            "Epoch 407/500\n",
            "44/44 [==============================] - 26s 567ms/step - loss: 101.1230 - mae: 8.4978 - val_loss: 100.7721 - val_mae: 8.4833\n",
            "Epoch 408/500\n",
            "44/44 [==============================] - 24s 526ms/step - loss: 101.0500 - mae: 8.4823 - val_loss: 103.1136 - val_mae: 8.6002\n",
            "Epoch 409/500\n",
            "44/44 [==============================] - 28s 620ms/step - loss: 101.0050 - mae: 8.4774 - val_loss: 101.2233 - val_mae: 8.4986\n",
            "Epoch 410/500\n",
            "44/44 [==============================] - 24s 520ms/step - loss: 101.3360 - mae: 8.5051 - val_loss: 100.3718 - val_mae: 8.4493\n",
            "Epoch 411/500\n",
            "44/44 [==============================] - 24s 526ms/step - loss: 100.3420 - mae: 8.4551 - val_loss: 99.9300 - val_mae: 8.4287\n",
            "Epoch 412/500\n",
            "44/44 [==============================] - 25s 533ms/step - loss: 100.4533 - mae: 8.4524 - val_loss: 102.1951 - val_mae: 8.5505\n",
            "Epoch 413/500\n",
            "44/44 [==============================] - 26s 568ms/step - loss: 100.7154 - mae: 8.4736 - val_loss: 98.8580 - val_mae: 8.3726\n",
            "Epoch 414/500\n",
            "44/44 [==============================] - 28s 598ms/step - loss: 100.7126 - mae: 8.4637 - val_loss: 99.4558 - val_mae: 8.3888\n",
            "Epoch 415/500\n",
            "44/44 [==============================] - 25s 520ms/step - loss: 100.8575 - mae: 8.4791 - val_loss: 101.2899 - val_mae: 8.4779\n",
            "Epoch 416/500\n",
            "44/44 [==============================] - 26s 577ms/step - loss: 100.6605 - mae: 8.4569 - val_loss: 103.9598 - val_mae: 8.6552\n",
            "Epoch 417/500\n",
            "44/44 [==============================] - 19s 418ms/step - loss: 99.9228 - mae: 8.4380 - val_loss: 101.1089 - val_mae: 8.5063\n",
            "Epoch 418/500\n",
            "44/44 [==============================] - 28s 534ms/step - loss: 100.8771 - mae: 8.4799 - val_loss: 102.3473 - val_mae: 8.5526\n",
            "Epoch 419/500\n",
            "44/44 [==============================] - 26s 567ms/step - loss: 100.5667 - mae: 8.4579 - val_loss: 97.5147 - val_mae: 8.2957\n",
            "Epoch 420/500\n",
            "44/44 [==============================] - 27s 593ms/step - loss: 100.4988 - mae: 8.4599 - val_loss: 102.8617 - val_mae: 8.6314\n",
            "Epoch 421/500\n",
            "44/44 [==============================] - 25s 548ms/step - loss: 101.2306 - mae: 8.5159 - val_loss: 102.8170 - val_mae: 8.5722\n",
            "Epoch 422/500\n",
            "44/44 [==============================] - 27s 598ms/step - loss: 101.0509 - mae: 8.4930 - val_loss: 101.3353 - val_mae: 8.5274\n",
            "Epoch 423/500\n",
            "44/44 [==============================] - 21s 442ms/step - loss: 101.6121 - mae: 8.5173 - val_loss: 98.5931 - val_mae: 8.3665\n",
            "Epoch 424/500\n",
            "44/44 [==============================] - 27s 536ms/step - loss: 100.9654 - mae: 8.4884 - val_loss: 98.7963 - val_mae: 8.3619\n",
            "Epoch 425/500\n",
            "44/44 [==============================] - 22s 492ms/step - loss: 100.6847 - mae: 8.4745 - val_loss: 99.8753 - val_mae: 8.4533\n",
            "Epoch 426/500\n",
            "44/44 [==============================] - 20s 411ms/step - loss: 100.4954 - mae: 8.4641 - val_loss: 99.5370 - val_mae: 8.4062\n",
            "Epoch 427/500\n",
            "44/44 [==============================] - 27s 576ms/step - loss: 100.7230 - mae: 8.4615 - val_loss: 100.2347 - val_mae: 8.4574\n",
            "Epoch 428/500\n",
            "44/44 [==============================] - 27s 596ms/step - loss: 100.2189 - mae: 8.4533 - val_loss: 100.4855 - val_mae: 8.4617\n",
            "Epoch 429/500\n",
            "44/44 [==============================] - 25s 549ms/step - loss: 101.3783 - mae: 8.5173 - val_loss: 99.2778 - val_mae: 8.3887\n",
            "Epoch 430/500\n",
            "44/44 [==============================] - 20s 433ms/step - loss: 101.2352 - mae: 8.4994 - val_loss: 99.8622 - val_mae: 8.4216\n",
            "Epoch 431/500\n",
            "44/44 [==============================] - 29s 586ms/step - loss: 100.8610 - mae: 8.4745 - val_loss: 99.7225 - val_mae: 8.4152\n",
            "Epoch 432/500\n",
            "44/44 [==============================] - 26s 543ms/step - loss: 100.0322 - mae: 8.4363 - val_loss: 101.0415 - val_mae: 8.4865\n",
            "Epoch 433/500\n",
            "44/44 [==============================] - 25s 537ms/step - loss: 100.6480 - mae: 8.4693 - val_loss: 102.3328 - val_mae: 8.5596\n",
            "Epoch 434/500\n",
            "44/44 [==============================] - 24s 527ms/step - loss: 101.3499 - mae: 8.5068 - val_loss: 100.5713 - val_mae: 8.4616\n",
            "Epoch 435/500\n",
            "44/44 [==============================] - 25s 543ms/step - loss: 101.2209 - mae: 8.4911 - val_loss: 99.4978 - val_mae: 8.3807\n",
            "Epoch 436/500\n",
            "44/44 [==============================] - 24s 522ms/step - loss: 100.5839 - mae: 8.4644 - val_loss: 101.9769 - val_mae: 8.5226\n",
            "Epoch 437/500\n",
            "44/44 [==============================] - 25s 551ms/step - loss: 100.4140 - mae: 8.4594 - val_loss: 101.5414 - val_mae: 8.4983\n",
            "Epoch 438/500\n",
            "44/44 [==============================] - 26s 536ms/step - loss: 100.4669 - mae: 8.4512 - val_loss: 103.8336 - val_mae: 8.6410\n",
            "Epoch 439/500\n",
            "44/44 [==============================] - 26s 595ms/step - loss: 101.1010 - mae: 8.4927 - val_loss: 101.9859 - val_mae: 8.5519\n",
            "Epoch 440/500\n",
            "44/44 [==============================] - 26s 546ms/step - loss: 100.4578 - mae: 8.4671 - val_loss: 100.5983 - val_mae: 8.4580\n",
            "Epoch 441/500\n",
            "44/44 [==============================] - 22s 462ms/step - loss: 100.1557 - mae: 8.4470 - val_loss: 100.1073 - val_mae: 8.4203\n",
            "Epoch 442/500\n",
            "44/44 [==============================] - 27s 571ms/step - loss: 100.6360 - mae: 8.4672 - val_loss: 102.4717 - val_mae: 8.5506\n",
            "Epoch 443/500\n",
            "44/44 [==============================] - 27s 560ms/step - loss: 101.1712 - mae: 8.4984 - val_loss: 99.8401 - val_mae: 8.4062\n",
            "Epoch 444/500\n",
            "44/44 [==============================] - 25s 539ms/step - loss: 101.1313 - mae: 8.4978 - val_loss: 100.0327 - val_mae: 8.4351\n",
            "Epoch 445/500\n",
            "44/44 [==============================] - 21s 418ms/step - loss: 100.7472 - mae: 8.4765 - val_loss: 101.1809 - val_mae: 8.5082\n",
            "Epoch 446/500\n",
            "44/44 [==============================] - 25s 522ms/step - loss: 100.8999 - mae: 8.4815 - val_loss: 99.0498 - val_mae: 8.3781\n",
            "Epoch 447/500\n",
            "44/44 [==============================] - 19s 409ms/step - loss: 100.7746 - mae: 8.4677 - val_loss: 101.9627 - val_mae: 8.5212\n",
            "Epoch 448/500\n",
            "44/44 [==============================] - 28s 607ms/step - loss: 101.1842 - mae: 8.5026 - val_loss: 101.7232 - val_mae: 8.5018\n",
            "Epoch 449/500\n",
            "44/44 [==============================] - 28s 615ms/step - loss: 101.4395 - mae: 8.5173 - val_loss: 100.7501 - val_mae: 8.4615\n",
            "Epoch 450/500\n",
            "44/44 [==============================] - 22s 466ms/step - loss: 100.6190 - mae: 8.4678 - val_loss: 100.3222 - val_mae: 8.4632\n",
            "Epoch 451/500\n",
            "44/44 [==============================] - 29s 647ms/step - loss: 100.8242 - mae: 8.4734 - val_loss: 101.5158 - val_mae: 8.5072\n",
            "Epoch 452/500\n",
            "44/44 [==============================] - 26s 570ms/step - loss: 101.1237 - mae: 8.5021 - val_loss: 99.6259 - val_mae: 8.4097\n",
            "Epoch 453/500\n",
            "44/44 [==============================] - 26s 564ms/step - loss: 100.7509 - mae: 8.4761 - val_loss: 99.5356 - val_mae: 8.4203\n",
            "Epoch 454/500\n",
            "44/44 [==============================] - 26s 563ms/step - loss: 100.2935 - mae: 8.4477 - val_loss: 100.0944 - val_mae: 8.4272\n",
            "Epoch 455/500\n",
            "44/44 [==============================] - 26s 565ms/step - loss: 100.8487 - mae: 8.4807 - val_loss: 101.7904 - val_mae: 8.5293\n",
            "Epoch 456/500\n",
            "44/44 [==============================] - 26s 576ms/step - loss: 100.3575 - mae: 8.4441 - val_loss: 100.9481 - val_mae: 8.4823\n",
            "Epoch 457/500\n",
            "44/44 [==============================] - 24s 526ms/step - loss: 100.5520 - mae: 8.4634 - val_loss: 100.4726 - val_mae: 8.4554\n",
            "Epoch 458/500\n",
            "44/44 [==============================] - 24s 529ms/step - loss: 100.6324 - mae: 8.4633 - val_loss: 100.1846 - val_mae: 8.4311\n",
            "Epoch 459/500\n",
            "44/44 [==============================] - 27s 583ms/step - loss: 101.1481 - mae: 8.4973 - val_loss: 101.1986 - val_mae: 8.4796\n",
            "Epoch 460/500\n",
            "44/44 [==============================] - 25s 544ms/step - loss: 100.3464 - mae: 8.4532 - val_loss: 99.4391 - val_mae: 8.4384\n",
            "Epoch 461/500\n",
            "44/44 [==============================] - 20s 421ms/step - loss: 101.3927 - mae: 8.5076 - val_loss: 100.5354 - val_mae: 8.4614\n",
            "Epoch 462/500\n",
            "44/44 [==============================] - 28s 555ms/step - loss: 100.6439 - mae: 8.4746 - val_loss: 98.4748 - val_mae: 8.3430\n",
            "Epoch 463/500\n",
            "44/44 [==============================] - 26s 550ms/step - loss: 101.0584 - mae: 8.4926 - val_loss: 101.5969 - val_mae: 8.5058\n",
            "Epoch 464/500\n",
            "44/44 [==============================] - 26s 556ms/step - loss: 100.5619 - mae: 8.4672 - val_loss: 102.3828 - val_mae: 8.5539\n",
            "Epoch 465/500\n",
            "44/44 [==============================] - 25s 544ms/step - loss: 100.1708 - mae: 8.4468 - val_loss: 101.3076 - val_mae: 8.5113\n",
            "Epoch 466/500\n",
            "44/44 [==============================] - 27s 572ms/step - loss: 100.5356 - mae: 8.4603 - val_loss: 100.7522 - val_mae: 8.4795\n",
            "Epoch 467/500\n",
            "44/44 [==============================] - 28s 613ms/step - loss: 100.8518 - mae: 8.4739 - val_loss: 100.6054 - val_mae: 8.4614\n",
            "Epoch 468/500\n",
            "44/44 [==============================] - 28s 621ms/step - loss: 99.5369 - mae: 8.4191 - val_loss: 100.8159 - val_mae: 8.4737\n",
            "Epoch 469/500\n",
            "44/44 [==============================] - 26s 558ms/step - loss: 100.8044 - mae: 8.4729 - val_loss: 100.5812 - val_mae: 8.4687\n",
            "Epoch 470/500\n",
            "44/44 [==============================] - 25s 540ms/step - loss: 100.5049 - mae: 8.4681 - val_loss: 101.1455 - val_mae: 8.5158\n",
            "Epoch 471/500\n",
            "44/44 [==============================] - 25s 542ms/step - loss: 100.5921 - mae: 8.4703 - val_loss: 100.7016 - val_mae: 8.4447\n",
            "Epoch 472/500\n",
            "44/44 [==============================] - 30s 662ms/step - loss: 100.5954 - mae: 8.4610 - val_loss: 100.6661 - val_mae: 8.4486\n",
            "Epoch 473/500\n",
            "44/44 [==============================] - 30s 661ms/step - loss: 100.6521 - mae: 8.4644 - val_loss: 100.3498 - val_mae: 8.4529\n",
            "Epoch 474/500\n",
            "44/44 [==============================] - 26s 569ms/step - loss: 100.2223 - mae: 8.4369 - val_loss: 101.6266 - val_mae: 8.5259\n",
            "Epoch 475/500\n",
            "44/44 [==============================] - 27s 585ms/step - loss: 100.2248 - mae: 8.4453 - val_loss: 99.0699 - val_mae: 8.3726\n",
            "Epoch 476/500\n",
            "44/44 [==============================] - 26s 571ms/step - loss: 101.0065 - mae: 8.4988 - val_loss: 101.7666 - val_mae: 8.5127\n",
            "Epoch 477/500\n",
            "44/44 [==============================] - 27s 583ms/step - loss: 100.6105 - mae: 8.4749 - val_loss: 100.5845 - val_mae: 8.4505\n",
            "Epoch 478/500\n",
            "44/44 [==============================] - 26s 558ms/step - loss: 100.1028 - mae: 8.4362 - val_loss: 99.4328 - val_mae: 8.4123\n",
            "Epoch 479/500\n",
            "44/44 [==============================] - 24s 530ms/step - loss: 100.7939 - mae: 8.4769 - val_loss: 101.5038 - val_mae: 8.5269\n",
            "Epoch 480/500\n",
            "44/44 [==============================] - 26s 571ms/step - loss: 100.1593 - mae: 8.4482 - val_loss: 100.7606 - val_mae: 8.4804\n",
            "Epoch 481/500\n",
            "44/44 [==============================] - 24s 528ms/step - loss: 100.9577 - mae: 8.4752 - val_loss: 99.8678 - val_mae: 8.4226\n",
            "Epoch 482/500\n",
            "44/44 [==============================] - 25s 552ms/step - loss: 100.7246 - mae: 8.4717 - val_loss: 99.5903 - val_mae: 8.3916\n",
            "Epoch 483/500\n",
            "44/44 [==============================] - 19s 418ms/step - loss: 101.3361 - mae: 8.5102 - val_loss: 102.5710 - val_mae: 8.5857\n",
            "Epoch 484/500\n",
            "44/44 [==============================] - 27s 557ms/step - loss: 100.0647 - mae: 8.4374 - val_loss: 100.0555 - val_mae: 8.4248\n",
            "Epoch 485/500\n",
            "44/44 [==============================] - 24s 523ms/step - loss: 100.8438 - mae: 8.4825 - val_loss: 101.3128 - val_mae: 8.4599\n",
            "Epoch 486/500\n",
            "44/44 [==============================] - 25s 537ms/step - loss: 100.2476 - mae: 8.4540 - val_loss: 102.4344 - val_mae: 8.5513\n",
            "Epoch 487/500\n",
            "44/44 [==============================] - 25s 542ms/step - loss: 101.5001 - mae: 8.5229 - val_loss: 101.4109 - val_mae: 8.5172\n",
            "Epoch 488/500\n",
            "44/44 [==============================] - 26s 548ms/step - loss: 100.6034 - mae: 8.4689 - val_loss: 99.1661 - val_mae: 8.3929\n",
            "Epoch 489/500\n",
            "44/44 [==============================] - 25s 538ms/step - loss: 100.4255 - mae: 8.4545 - val_loss: 99.7145 - val_mae: 8.4013\n",
            "Epoch 490/500\n",
            "44/44 [==============================] - 24s 532ms/step - loss: 101.0508 - mae: 8.4914 - val_loss: 99.3357 - val_mae: 8.4029\n",
            "Epoch 491/500\n",
            "44/44 [==============================] - 25s 535ms/step - loss: 101.0151 - mae: 8.4907 - val_loss: 100.0652 - val_mae: 8.4675\n",
            "Epoch 492/500\n",
            "44/44 [==============================] - 24s 520ms/step - loss: 100.2042 - mae: 8.4406 - val_loss: 100.6038 - val_mae: 8.4829\n",
            "Epoch 493/500\n",
            "44/44 [==============================] - 26s 546ms/step - loss: 100.7761 - mae: 8.4780 - val_loss: 99.7715 - val_mae: 8.4337\n",
            "Epoch 494/500\n",
            "44/44 [==============================] - 26s 536ms/step - loss: 100.9593 - mae: 8.4872 - val_loss: 100.6909 - val_mae: 8.4451\n",
            "Epoch 495/500\n",
            "44/44 [==============================] - 22s 484ms/step - loss: 100.3746 - mae: 8.4496 - val_loss: 101.0070 - val_mae: 8.4954\n",
            "Epoch 496/500\n",
            "44/44 [==============================] - 25s 540ms/step - loss: 100.8773 - mae: 8.4822 - val_loss: 103.2924 - val_mae: 8.6162\n",
            "Epoch 497/500\n",
            "44/44 [==============================] - 26s 580ms/step - loss: 99.7067 - mae: 8.4266 - val_loss: 99.6336 - val_mae: 8.3978\n",
            "Epoch 498/500\n",
            "44/44 [==============================] - 25s 557ms/step - loss: 101.1447 - mae: 8.4925 - val_loss: 100.4425 - val_mae: 8.4614\n",
            "Epoch 499/500\n",
            "44/44 [==============================] - 25s 552ms/step - loss: 100.7054 - mae: 8.4662 - val_loss: 101.5125 - val_mae: 8.5193\n",
            "Epoch 500/500\n",
            "44/44 [==============================] - 25s 537ms/step - loss: 100.4890 - mae: 8.4604 - val_loss: 99.0257 - val_mae: 8.3937\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "mae = history.history['mae']\n",
        "val_mae = history.history['val_mae']\n",
        "\n",
        "\n",
        "epochs_x = range(len(loss))\n",
        "\n",
        "\n",
        "plt.plot(epochs_x, mae, 'co', label='Training MAE')\n",
        "plt.plot(epochs_x, val_mae, 'k', label='Validation MAE')\n",
        "plt.title('Training and validation MeanAbsoluteError')\n",
        "plt.legend()\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(epochs_x, loss, 'co', label='Training loss')\n",
        "plt.plot(epochs_x, val_loss, 'k', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Y3K89-CM-dfg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545
        },
        "outputId": "04d49618-12b5-4928-a253-bed03f153910"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "epochs_x"
      ],
      "metadata": {
        "id": "N_sP_ZmSY-Jv",
        "outputId": "3dbde258-fa05-4378-b223-ff15df34d84c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "range(0, 500)"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Download the model\n"
      ],
      "metadata": {
        "id": "R19IJQSYoW7J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "os.makedirs('/content/drive/My Drive/cut_panoramic/Model', exist_ok=True)\n",
        "model.save('/content/drive/My Drive/cut_panoramic/Model/2e-6_32_0.2_Male18_500.h5')"
      ],
      "metadata": {
        "id": "Zed4TdFcG2iJ"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "n5YxZ-5QjQ0-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# from google.colab import files\n",
        "# files.download('/content/drive/My Drive/cut_panoramic/Model/1.1_รอบแรก_Flimpano_Male125_250.h5')"
      ],
      "metadata": {
        "id": "P5eMxm1NV-oY"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "wY_pDlxkRwxS"
      },
      "execution_count": 24,
      "outputs": []
    }
  ]
}