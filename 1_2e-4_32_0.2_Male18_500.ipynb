{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Wanita-8943/Project_2023/blob/main/1_2e-4_32_0.2_Male18_500.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#เรียกใช้ CSV"
      ],
      "metadata": {
        "id": "ow7eWoNw6U-c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import shutil"
      ],
      "metadata": {
        "id": "DlQ2oT7cIR6o"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1_2Fe8u81d5r",
        "outputId": "8564b3b2-ebc6-440f-cf87-5ef92d84b11e"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Imports"
      ],
      "metadata": {
        "id": "5qxePnnn7TGW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import models\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import optimizers\n",
        "import os\n",
        "import glob\n",
        "import shutil\n",
        "import sys\n",
        "import numpy as np\n",
        "from skimage.io import imread\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import Image\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "D-hCRloc3t39"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras import backend as K"
      ],
      "metadata": {
        "id": "YZWXwjXeGxZP"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#กำหนดค่าพารามิเตอร์\n"
      ],
      "metadata": {
        "id": "RooqSdBc7QHC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 32\n",
        "width = 150\n",
        "height = 150\n",
        "epochs = 500\n",
        "NUM_TRAIN = 1425\n",
        "NUM_TEST = 475\n",
        "dropout_rate = 0.2\n",
        "input_shape = (height, width, 3)"
      ],
      "metadata": {
        "id": "thDb7U9B3xOo"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Clone efficientnet repo\n"
      ],
      "metadata": {
        "id": "pumGmy6f3eSW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#ดึงข้อมูลใน Github มาใช้\n",
        "import os\n",
        "%cd /content\n",
        "if not os.path.isdir(\"efficientnet_keras_transfer_learning\"):\n",
        " !git clone https://github.com/Wanita-8943/efficientnet_keras_transfer_learning\n",
        "%cd efficientnet_keras_transfer_learning/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P7iy2f8n16p0",
        "outputId": "d606a8c8-7925-4604-d17c-6e7fef603b3e"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "Cloning into 'efficientnet_keras_transfer_learning'...\n",
            "remote: Enumerating objects: 831, done.\u001b[K\n",
            "remote: Counting objects: 100% (353/353), done.\u001b[K\n",
            "remote: Compressing objects: 100% (166/166), done.\u001b[K\n",
            "remote: Total 831 (delta 249), reused 248 (delta 187), pack-reused 478\u001b[K\n",
            "Receiving objects: 100% (831/831), 13.73 MiB | 27.19 MiB/s, done.\n",
            "Resolving deltas: 100% (489/489), done.\n",
            "/content/efficientnet_keras_transfer_learning\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import keras"
      ],
      "metadata": {
        "id": "Vbdblwbv89fe"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ],
      "metadata": {
        "id": "vnLrobY_-GCx",
        "outputId": "a83e872c-8586-4544-b8a5-3989e1f81338",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.11.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Options: EfficientNetB0, EfficientNetB1, EfficientNetB2, EfficientNetB3\n",
        "# Higher the number, the more complex the model is.\n",
        "from efficientnet import EfficientNetB0 as Net\n",
        "from efficientnet import center_crop_and_resize, preprocess_input"
      ],
      "metadata": {
        "id": "tjZBRnfo3bN0"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# loading pretrained conv base model\n",
        "# โหลดโมเดล มาโดยตัด output ของโมเดลออก เเต่ยังใช้ input อันเดิม\n",
        "# เเละโหลด weight ของโมเดล มาด้วยที่ชื่อว่า imagenet\n",
        "conv_base = Net(weights='imagenet', include_top=False, input_shape=input_shape)"
      ],
      "metadata": {
        "id": "hNZAzbDp3lgA",
        "outputId": "12cc98cf-3d68-4956-a592-a6c617092941",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
            "Instructions for updating:\n",
            "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://github.com/qubvel/efficientnet/releases/download/v0.0.1/efficientnet-b0_imagenet_1000_notop.h5\n",
            "16717576/16717576 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = models.Sequential()\n",
        "model.add(conv_base)\n",
        "model.add(layers.GlobalMaxPooling2D(name=\"gap\"))\n",
        "# model.add(layers.Flatten(name=\"flatten\"))\n",
        "if dropout_rate > 0:\n",
        "    model.add(layers.Dropout(dropout_rate, name=\"dropout_out\"))\n",
        "# model.add(layers.Dense(256, activation='relu', name=\"fc1\"))\n",
        "model.add(layers.Dense(19, activation='softmax', name=\"fc_out\"))\n",
        "model.add(layers.Dense(1))"
      ],
      "metadata": {
        "id": "yWNKfQUt5rga"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "NadBB12251jh",
        "outputId": "e258d3f2-eeec-4416-f6ce-8645eef96de7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " efficientnet-b0 (Functional  (None, 5, 5, 1280)       4049564   \n",
            " )                                                               \n",
            "                                                                 \n",
            " gap (GlobalMaxPooling2D)    (None, 1280)              0         \n",
            "                                                                 \n",
            " dropout_out (Dropout)       (None, 1280)              0         \n",
            "                                                                 \n",
            " fc_out (Dense)              (None, 19)                24339     \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1)                 20        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4,073,923\n",
            "Trainable params: 4,031,907\n",
            "Non-trainable params: 42,016\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('This is the number of trainable layers '\n",
        "      'before freezing the conv base:', len(model.trainable_weights))\n",
        "\n",
        "conv_base.trainable = False\n",
        "\n",
        "print('This is the number of trainable layers '\n",
        "      'after freezing the conv base:', len(model.trainable_weights))"
      ],
      "metadata": {
        "id": "GepWq3yy53t5",
        "outputId": "8bd6a83c-14f2-4e9a-8db0-65ea839f15ec",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This is the number of trainable layers before freezing the conv base: 215\n",
            "This is the number of trainable layers after freezing the conv base: 4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "conv_base.summary() #ดู Summary"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iD76D6c_79py",
        "outputId": "60752f8f-2d95-4ea2-e09a-67f0e6bb5aec"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"efficientnet-b0\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 150, 150, 3  0           []                               \n",
            "                                )]                                                                \n",
            "                                                                                                  \n",
            " conv2d (Conv2D)                (None, 75, 75, 32)   864         ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " batch_normalization (BatchNorm  (None, 75, 75, 32)  128         ['conv2d[0][0]']                 \n",
            " alization)                                                                                       \n",
            "                                                                                                  \n",
            " swish (Swish)                  (None, 75, 75, 32)   0           ['batch_normalization[0][0]']    \n",
            "                                                                                                  \n",
            " depthwise_conv2d (DepthwiseCon  (None, 75, 75, 32)  288         ['swish[0][0]']                  \n",
            " v2D)                                                                                             \n",
            "                                                                                                  \n",
            " batch_normalization_1 (BatchNo  (None, 75, 75, 32)  128         ['depthwise_conv2d[0][0]']       \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " swish_1 (Swish)                (None, 75, 75, 32)   0           ['batch_normalization_1[0][0]']  \n",
            "                                                                                                  \n",
            " lambda (Lambda)                (None, 1, 1, 32)     0           ['swish_1[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d_1 (Conv2D)              (None, 1, 1, 8)      264         ['lambda[0][0]']                 \n",
            "                                                                                                  \n",
            " swish_2 (Swish)                (None, 1, 1, 8)      0           ['conv2d_1[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_2 (Conv2D)              (None, 1, 1, 32)     288         ['swish_2[0][0]']                \n",
            "                                                                                                  \n",
            " activation (Activation)        (None, 1, 1, 32)     0           ['conv2d_2[0][0]']               \n",
            "                                                                                                  \n",
            " multiply (Multiply)            (None, 75, 75, 32)   0           ['activation[0][0]',             \n",
            "                                                                  'swish_1[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d_3 (Conv2D)              (None, 75, 75, 16)   512         ['multiply[0][0]']               \n",
            "                                                                                                  \n",
            " batch_normalization_2 (BatchNo  (None, 75, 75, 16)  64          ['conv2d_3[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv2d_4 (Conv2D)              (None, 75, 75, 96)   1536        ['batch_normalization_2[0][0]']  \n",
            "                                                                                                  \n",
            " batch_normalization_3 (BatchNo  (None, 75, 75, 96)  384         ['conv2d_4[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " swish_3 (Swish)                (None, 75, 75, 96)   0           ['batch_normalization_3[0][0]']  \n",
            "                                                                                                  \n",
            " depthwise_conv2d_1 (DepthwiseC  (None, 38, 38, 96)  864         ['swish_3[0][0]']                \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_4 (BatchNo  (None, 38, 38, 96)  384         ['depthwise_conv2d_1[0][0]']     \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " swish_4 (Swish)                (None, 38, 38, 96)   0           ['batch_normalization_4[0][0]']  \n",
            "                                                                                                  \n",
            " lambda_1 (Lambda)              (None, 1, 1, 96)     0           ['swish_4[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d_5 (Conv2D)              (None, 1, 1, 4)      388         ['lambda_1[0][0]']               \n",
            "                                                                                                  \n",
            " swish_5 (Swish)                (None, 1, 1, 4)      0           ['conv2d_5[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_6 (Conv2D)              (None, 1, 1, 96)     480         ['swish_5[0][0]']                \n",
            "                                                                                                  \n",
            " activation_1 (Activation)      (None, 1, 1, 96)     0           ['conv2d_6[0][0]']               \n",
            "                                                                                                  \n",
            " multiply_1 (Multiply)          (None, 38, 38, 96)   0           ['activation_1[0][0]',           \n",
            "                                                                  'swish_4[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d_7 (Conv2D)              (None, 38, 38, 24)   2304        ['multiply_1[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_5 (BatchNo  (None, 38, 38, 24)  96          ['conv2d_7[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv2d_8 (Conv2D)              (None, 38, 38, 144)  3456        ['batch_normalization_5[0][0]']  \n",
            "                                                                                                  \n",
            " batch_normalization_6 (BatchNo  (None, 38, 38, 144)  576        ['conv2d_8[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " swish_6 (Swish)                (None, 38, 38, 144)  0           ['batch_normalization_6[0][0]']  \n",
            "                                                                                                  \n",
            " depthwise_conv2d_2 (DepthwiseC  (None, 38, 38, 144)  1296       ['swish_6[0][0]']                \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_7 (BatchNo  (None, 38, 38, 144)  576        ['depthwise_conv2d_2[0][0]']     \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " swish_7 (Swish)                (None, 38, 38, 144)  0           ['batch_normalization_7[0][0]']  \n",
            "                                                                                                  \n",
            " lambda_2 (Lambda)              (None, 1, 1, 144)    0           ['swish_7[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d_9 (Conv2D)              (None, 1, 1, 6)      870         ['lambda_2[0][0]']               \n",
            "                                                                                                  \n",
            " swish_8 (Swish)                (None, 1, 1, 6)      0           ['conv2d_9[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_10 (Conv2D)             (None, 1, 1, 144)    1008        ['swish_8[0][0]']                \n",
            "                                                                                                  \n",
            " activation_2 (Activation)      (None, 1, 1, 144)    0           ['conv2d_10[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_2 (Multiply)          (None, 38, 38, 144)  0           ['activation_2[0][0]',           \n",
            "                                                                  'swish_7[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d_11 (Conv2D)             (None, 38, 38, 24)   3456        ['multiply_2[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_8 (BatchNo  (None, 38, 38, 24)  96          ['conv2d_11[0][0]']              \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " drop_connect (DropConnect)     (None, 38, 38, 24)   0           ['batch_normalization_8[0][0]']  \n",
            "                                                                                                  \n",
            " add (Add)                      (None, 38, 38, 24)   0           ['drop_connect[0][0]',           \n",
            "                                                                  'batch_normalization_5[0][0]']  \n",
            "                                                                                                  \n",
            " conv2d_12 (Conv2D)             (None, 38, 38, 144)  3456        ['add[0][0]']                    \n",
            "                                                                                                  \n",
            " batch_normalization_9 (BatchNo  (None, 38, 38, 144)  576        ['conv2d_12[0][0]']              \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " swish_9 (Swish)                (None, 38, 38, 144)  0           ['batch_normalization_9[0][0]']  \n",
            "                                                                                                  \n",
            " depthwise_conv2d_3 (DepthwiseC  (None, 19, 19, 144)  3600       ['swish_9[0][0]']                \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_10 (BatchN  (None, 19, 19, 144)  576        ['depthwise_conv2d_3[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_10 (Swish)               (None, 19, 19, 144)  0           ['batch_normalization_10[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_3 (Lambda)              (None, 1, 1, 144)    0           ['swish_10[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_13 (Conv2D)             (None, 1, 1, 6)      870         ['lambda_3[0][0]']               \n",
            "                                                                                                  \n",
            " swish_11 (Swish)               (None, 1, 1, 6)      0           ['conv2d_13[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_14 (Conv2D)             (None, 1, 1, 144)    1008        ['swish_11[0][0]']               \n",
            "                                                                                                  \n",
            " activation_3 (Activation)      (None, 1, 1, 144)    0           ['conv2d_14[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_3 (Multiply)          (None, 19, 19, 144)  0           ['activation_3[0][0]',           \n",
            "                                                                  'swish_10[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_15 (Conv2D)             (None, 19, 19, 40)   5760        ['multiply_3[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_11 (BatchN  (None, 19, 19, 40)  160         ['conv2d_15[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_16 (Conv2D)             (None, 19, 19, 240)  9600        ['batch_normalization_11[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_12 (BatchN  (None, 19, 19, 240)  960        ['conv2d_16[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_12 (Swish)               (None, 19, 19, 240)  0           ['batch_normalization_12[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_4 (DepthwiseC  (None, 19, 19, 240)  6000       ['swish_12[0][0]']               \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_13 (BatchN  (None, 19, 19, 240)  960        ['depthwise_conv2d_4[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_13 (Swish)               (None, 19, 19, 240)  0           ['batch_normalization_13[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_4 (Lambda)              (None, 1, 1, 240)    0           ['swish_13[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_17 (Conv2D)             (None, 1, 1, 10)     2410        ['lambda_4[0][0]']               \n",
            "                                                                                                  \n",
            " swish_14 (Swish)               (None, 1, 1, 10)     0           ['conv2d_17[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_18 (Conv2D)             (None, 1, 1, 240)    2640        ['swish_14[0][0]']               \n",
            "                                                                                                  \n",
            " activation_4 (Activation)      (None, 1, 1, 240)    0           ['conv2d_18[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_4 (Multiply)          (None, 19, 19, 240)  0           ['activation_4[0][0]',           \n",
            "                                                                  'swish_13[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_19 (Conv2D)             (None, 19, 19, 40)   9600        ['multiply_4[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_14 (BatchN  (None, 19, 19, 40)  160         ['conv2d_19[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_1 (DropConnect)   (None, 19, 19, 40)   0           ['batch_normalization_14[0][0]'] \n",
            "                                                                                                  \n",
            " add_1 (Add)                    (None, 19, 19, 40)   0           ['drop_connect_1[0][0]',         \n",
            "                                                                  'batch_normalization_11[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_20 (Conv2D)             (None, 19, 19, 240)  9600        ['add_1[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_15 (BatchN  (None, 19, 19, 240)  960        ['conv2d_20[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_15 (Swish)               (None, 19, 19, 240)  0           ['batch_normalization_15[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_5 (DepthwiseC  (None, 10, 10, 240)  2160       ['swish_15[0][0]']               \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_16 (BatchN  (None, 10, 10, 240)  960        ['depthwise_conv2d_5[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_16 (Swish)               (None, 10, 10, 240)  0           ['batch_normalization_16[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_5 (Lambda)              (None, 1, 1, 240)    0           ['swish_16[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_21 (Conv2D)             (None, 1, 1, 10)     2410        ['lambda_5[0][0]']               \n",
            "                                                                                                  \n",
            " swish_17 (Swish)               (None, 1, 1, 10)     0           ['conv2d_21[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_22 (Conv2D)             (None, 1, 1, 240)    2640        ['swish_17[0][0]']               \n",
            "                                                                                                  \n",
            " activation_5 (Activation)      (None, 1, 1, 240)    0           ['conv2d_22[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_5 (Multiply)          (None, 10, 10, 240)  0           ['activation_5[0][0]',           \n",
            "                                                                  'swish_16[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_23 (Conv2D)             (None, 10, 10, 80)   19200       ['multiply_5[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_17 (BatchN  (None, 10, 10, 80)  320         ['conv2d_23[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_24 (Conv2D)             (None, 10, 10, 480)  38400       ['batch_normalization_17[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_18 (BatchN  (None, 10, 10, 480)  1920       ['conv2d_24[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_18 (Swish)               (None, 10, 10, 480)  0           ['batch_normalization_18[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_6 (DepthwiseC  (None, 10, 10, 480)  4320       ['swish_18[0][0]']               \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_19 (BatchN  (None, 10, 10, 480)  1920       ['depthwise_conv2d_6[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_19 (Swish)               (None, 10, 10, 480)  0           ['batch_normalization_19[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_6 (Lambda)              (None, 1, 1, 480)    0           ['swish_19[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_25 (Conv2D)             (None, 1, 1, 20)     9620        ['lambda_6[0][0]']               \n",
            "                                                                                                  \n",
            " swish_20 (Swish)               (None, 1, 1, 20)     0           ['conv2d_25[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_26 (Conv2D)             (None, 1, 1, 480)    10080       ['swish_20[0][0]']               \n",
            "                                                                                                  \n",
            " activation_6 (Activation)      (None, 1, 1, 480)    0           ['conv2d_26[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_6 (Multiply)          (None, 10, 10, 480)  0           ['activation_6[0][0]',           \n",
            "                                                                  'swish_19[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_27 (Conv2D)             (None, 10, 10, 80)   38400       ['multiply_6[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_20 (BatchN  (None, 10, 10, 80)  320         ['conv2d_27[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_2 (DropConnect)   (None, 10, 10, 80)   0           ['batch_normalization_20[0][0]'] \n",
            "                                                                                                  \n",
            " add_2 (Add)                    (None, 10, 10, 80)   0           ['drop_connect_2[0][0]',         \n",
            "                                                                  'batch_normalization_17[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_28 (Conv2D)             (None, 10, 10, 480)  38400       ['add_2[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_21 (BatchN  (None, 10, 10, 480)  1920       ['conv2d_28[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_21 (Swish)               (None, 10, 10, 480)  0           ['batch_normalization_21[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_7 (DepthwiseC  (None, 10, 10, 480)  4320       ['swish_21[0][0]']               \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_22 (BatchN  (None, 10, 10, 480)  1920       ['depthwise_conv2d_7[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_22 (Swish)               (None, 10, 10, 480)  0           ['batch_normalization_22[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_7 (Lambda)              (None, 1, 1, 480)    0           ['swish_22[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_29 (Conv2D)             (None, 1, 1, 20)     9620        ['lambda_7[0][0]']               \n",
            "                                                                                                  \n",
            " swish_23 (Swish)               (None, 1, 1, 20)     0           ['conv2d_29[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_30 (Conv2D)             (None, 1, 1, 480)    10080       ['swish_23[0][0]']               \n",
            "                                                                                                  \n",
            " activation_7 (Activation)      (None, 1, 1, 480)    0           ['conv2d_30[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_7 (Multiply)          (None, 10, 10, 480)  0           ['activation_7[0][0]',           \n",
            "                                                                  'swish_22[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_31 (Conv2D)             (None, 10, 10, 80)   38400       ['multiply_7[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_23 (BatchN  (None, 10, 10, 80)  320         ['conv2d_31[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_3 (DropConnect)   (None, 10, 10, 80)   0           ['batch_normalization_23[0][0]'] \n",
            "                                                                                                  \n",
            " add_3 (Add)                    (None, 10, 10, 80)   0           ['drop_connect_3[0][0]',         \n",
            "                                                                  'add_2[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_32 (Conv2D)             (None, 10, 10, 480)  38400       ['add_3[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_24 (BatchN  (None, 10, 10, 480)  1920       ['conv2d_32[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_24 (Swish)               (None, 10, 10, 480)  0           ['batch_normalization_24[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_8 (DepthwiseC  (None, 10, 10, 480)  12000      ['swish_24[0][0]']               \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_25 (BatchN  (None, 10, 10, 480)  1920       ['depthwise_conv2d_8[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_25 (Swish)               (None, 10, 10, 480)  0           ['batch_normalization_25[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_8 (Lambda)              (None, 1, 1, 480)    0           ['swish_25[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_33 (Conv2D)             (None, 1, 1, 20)     9620        ['lambda_8[0][0]']               \n",
            "                                                                                                  \n",
            " swish_26 (Swish)               (None, 1, 1, 20)     0           ['conv2d_33[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_34 (Conv2D)             (None, 1, 1, 480)    10080       ['swish_26[0][0]']               \n",
            "                                                                                                  \n",
            " activation_8 (Activation)      (None, 1, 1, 480)    0           ['conv2d_34[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_8 (Multiply)          (None, 10, 10, 480)  0           ['activation_8[0][0]',           \n",
            "                                                                  'swish_25[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_35 (Conv2D)             (None, 10, 10, 112)  53760       ['multiply_8[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_26 (BatchN  (None, 10, 10, 112)  448        ['conv2d_35[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_36 (Conv2D)             (None, 10, 10, 672)  75264       ['batch_normalization_26[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_27 (BatchN  (None, 10, 10, 672)  2688       ['conv2d_36[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_27 (Swish)               (None, 10, 10, 672)  0           ['batch_normalization_27[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_9 (DepthwiseC  (None, 10, 10, 672)  16800      ['swish_27[0][0]']               \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_28 (BatchN  (None, 10, 10, 672)  2688       ['depthwise_conv2d_9[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_28 (Swish)               (None, 10, 10, 672)  0           ['batch_normalization_28[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_9 (Lambda)              (None, 1, 1, 672)    0           ['swish_28[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_37 (Conv2D)             (None, 1, 1, 28)     18844       ['lambda_9[0][0]']               \n",
            "                                                                                                  \n",
            " swish_29 (Swish)               (None, 1, 1, 28)     0           ['conv2d_37[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_38 (Conv2D)             (None, 1, 1, 672)    19488       ['swish_29[0][0]']               \n",
            "                                                                                                  \n",
            " activation_9 (Activation)      (None, 1, 1, 672)    0           ['conv2d_38[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_9 (Multiply)          (None, 10, 10, 672)  0           ['activation_9[0][0]',           \n",
            "                                                                  'swish_28[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_39 (Conv2D)             (None, 10, 10, 112)  75264       ['multiply_9[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_29 (BatchN  (None, 10, 10, 112)  448        ['conv2d_39[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_4 (DropConnect)   (None, 10, 10, 112)  0           ['batch_normalization_29[0][0]'] \n",
            "                                                                                                  \n",
            " add_4 (Add)                    (None, 10, 10, 112)  0           ['drop_connect_4[0][0]',         \n",
            "                                                                  'batch_normalization_26[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_40 (Conv2D)             (None, 10, 10, 672)  75264       ['add_4[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_30 (BatchN  (None, 10, 10, 672)  2688       ['conv2d_40[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_30 (Swish)               (None, 10, 10, 672)  0           ['batch_normalization_30[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_10 (Depthwise  (None, 10, 10, 672)  16800      ['swish_30[0][0]']               \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_31 (BatchN  (None, 10, 10, 672)  2688       ['depthwise_conv2d_10[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_31 (Swish)               (None, 10, 10, 672)  0           ['batch_normalization_31[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_10 (Lambda)             (None, 1, 1, 672)    0           ['swish_31[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_41 (Conv2D)             (None, 1, 1, 28)     18844       ['lambda_10[0][0]']              \n",
            "                                                                                                  \n",
            " swish_32 (Swish)               (None, 1, 1, 28)     0           ['conv2d_41[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_42 (Conv2D)             (None, 1, 1, 672)    19488       ['swish_32[0][0]']               \n",
            "                                                                                                  \n",
            " activation_10 (Activation)     (None, 1, 1, 672)    0           ['conv2d_42[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_10 (Multiply)         (None, 10, 10, 672)  0           ['activation_10[0][0]',          \n",
            "                                                                  'swish_31[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_43 (Conv2D)             (None, 10, 10, 112)  75264       ['multiply_10[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_32 (BatchN  (None, 10, 10, 112)  448        ['conv2d_43[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_5 (DropConnect)   (None, 10, 10, 112)  0           ['batch_normalization_32[0][0]'] \n",
            "                                                                                                  \n",
            " add_5 (Add)                    (None, 10, 10, 112)  0           ['drop_connect_5[0][0]',         \n",
            "                                                                  'add_4[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_44 (Conv2D)             (None, 10, 10, 672)  75264       ['add_5[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_33 (BatchN  (None, 10, 10, 672)  2688       ['conv2d_44[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_33 (Swish)               (None, 10, 10, 672)  0           ['batch_normalization_33[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_11 (Depthwise  (None, 5, 5, 672)   16800       ['swish_33[0][0]']               \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_34 (BatchN  (None, 5, 5, 672)   2688        ['depthwise_conv2d_11[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_34 (Swish)               (None, 5, 5, 672)    0           ['batch_normalization_34[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_11 (Lambda)             (None, 1, 1, 672)    0           ['swish_34[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_45 (Conv2D)             (None, 1, 1, 28)     18844       ['lambda_11[0][0]']              \n",
            "                                                                                                  \n",
            " swish_35 (Swish)               (None, 1, 1, 28)     0           ['conv2d_45[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_46 (Conv2D)             (None, 1, 1, 672)    19488       ['swish_35[0][0]']               \n",
            "                                                                                                  \n",
            " activation_11 (Activation)     (None, 1, 1, 672)    0           ['conv2d_46[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_11 (Multiply)         (None, 5, 5, 672)    0           ['activation_11[0][0]',          \n",
            "                                                                  'swish_34[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_47 (Conv2D)             (None, 5, 5, 192)    129024      ['multiply_11[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_35 (BatchN  (None, 5, 5, 192)   768         ['conv2d_47[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_48 (Conv2D)             (None, 5, 5, 1152)   221184      ['batch_normalization_35[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_36 (BatchN  (None, 5, 5, 1152)  4608        ['conv2d_48[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_36 (Swish)               (None, 5, 5, 1152)   0           ['batch_normalization_36[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_12 (Depthwise  (None, 5, 5, 1152)  28800       ['swish_36[0][0]']               \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_37 (BatchN  (None, 5, 5, 1152)  4608        ['depthwise_conv2d_12[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_37 (Swish)               (None, 5, 5, 1152)   0           ['batch_normalization_37[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_12 (Lambda)             (None, 1, 1, 1152)   0           ['swish_37[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_49 (Conv2D)             (None, 1, 1, 48)     55344       ['lambda_12[0][0]']              \n",
            "                                                                                                  \n",
            " swish_38 (Swish)               (None, 1, 1, 48)     0           ['conv2d_49[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_50 (Conv2D)             (None, 1, 1, 1152)   56448       ['swish_38[0][0]']               \n",
            "                                                                                                  \n",
            " activation_12 (Activation)     (None, 1, 1, 1152)   0           ['conv2d_50[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_12 (Multiply)         (None, 5, 5, 1152)   0           ['activation_12[0][0]',          \n",
            "                                                                  'swish_37[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_51 (Conv2D)             (None, 5, 5, 192)    221184      ['multiply_12[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_38 (BatchN  (None, 5, 5, 192)   768         ['conv2d_51[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_6 (DropConnect)   (None, 5, 5, 192)    0           ['batch_normalization_38[0][0]'] \n",
            "                                                                                                  \n",
            " add_6 (Add)                    (None, 5, 5, 192)    0           ['drop_connect_6[0][0]',         \n",
            "                                                                  'batch_normalization_35[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_52 (Conv2D)             (None, 5, 5, 1152)   221184      ['add_6[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_39 (BatchN  (None, 5, 5, 1152)  4608        ['conv2d_52[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_39 (Swish)               (None, 5, 5, 1152)   0           ['batch_normalization_39[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_13 (Depthwise  (None, 5, 5, 1152)  28800       ['swish_39[0][0]']               \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_40 (BatchN  (None, 5, 5, 1152)  4608        ['depthwise_conv2d_13[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_40 (Swish)               (None, 5, 5, 1152)   0           ['batch_normalization_40[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_13 (Lambda)             (None, 1, 1, 1152)   0           ['swish_40[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_53 (Conv2D)             (None, 1, 1, 48)     55344       ['lambda_13[0][0]']              \n",
            "                                                                                                  \n",
            " swish_41 (Swish)               (None, 1, 1, 48)     0           ['conv2d_53[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_54 (Conv2D)             (None, 1, 1, 1152)   56448       ['swish_41[0][0]']               \n",
            "                                                                                                  \n",
            " activation_13 (Activation)     (None, 1, 1, 1152)   0           ['conv2d_54[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_13 (Multiply)         (None, 5, 5, 1152)   0           ['activation_13[0][0]',          \n",
            "                                                                  'swish_40[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_55 (Conv2D)             (None, 5, 5, 192)    221184      ['multiply_13[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_41 (BatchN  (None, 5, 5, 192)   768         ['conv2d_55[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_7 (DropConnect)   (None, 5, 5, 192)    0           ['batch_normalization_41[0][0]'] \n",
            "                                                                                                  \n",
            " add_7 (Add)                    (None, 5, 5, 192)    0           ['drop_connect_7[0][0]',         \n",
            "                                                                  'add_6[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_56 (Conv2D)             (None, 5, 5, 1152)   221184      ['add_7[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_42 (BatchN  (None, 5, 5, 1152)  4608        ['conv2d_56[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_42 (Swish)               (None, 5, 5, 1152)   0           ['batch_normalization_42[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_14 (Depthwise  (None, 5, 5, 1152)  28800       ['swish_42[0][0]']               \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_43 (BatchN  (None, 5, 5, 1152)  4608        ['depthwise_conv2d_14[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_43 (Swish)               (None, 5, 5, 1152)   0           ['batch_normalization_43[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_14 (Lambda)             (None, 1, 1, 1152)   0           ['swish_43[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_57 (Conv2D)             (None, 1, 1, 48)     55344       ['lambda_14[0][0]']              \n",
            "                                                                                                  \n",
            " swish_44 (Swish)               (None, 1, 1, 48)     0           ['conv2d_57[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_58 (Conv2D)             (None, 1, 1, 1152)   56448       ['swish_44[0][0]']               \n",
            "                                                                                                  \n",
            " activation_14 (Activation)     (None, 1, 1, 1152)   0           ['conv2d_58[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_14 (Multiply)         (None, 5, 5, 1152)   0           ['activation_14[0][0]',          \n",
            "                                                                  'swish_43[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_59 (Conv2D)             (None, 5, 5, 192)    221184      ['multiply_14[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_44 (BatchN  (None, 5, 5, 192)   768         ['conv2d_59[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_8 (DropConnect)   (None, 5, 5, 192)    0           ['batch_normalization_44[0][0]'] \n",
            "                                                                                                  \n",
            " add_8 (Add)                    (None, 5, 5, 192)    0           ['drop_connect_8[0][0]',         \n",
            "                                                                  'add_7[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_60 (Conv2D)             (None, 5, 5, 1152)   221184      ['add_8[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_45 (BatchN  (None, 5, 5, 1152)  4608        ['conv2d_60[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_45 (Swish)               (None, 5, 5, 1152)   0           ['batch_normalization_45[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_15 (Depthwise  (None, 5, 5, 1152)  10368       ['swish_45[0][0]']               \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_46 (BatchN  (None, 5, 5, 1152)  4608        ['depthwise_conv2d_15[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_46 (Swish)               (None, 5, 5, 1152)   0           ['batch_normalization_46[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_15 (Lambda)             (None, 1, 1, 1152)   0           ['swish_46[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_61 (Conv2D)             (None, 1, 1, 48)     55344       ['lambda_15[0][0]']              \n",
            "                                                                                                  \n",
            " swish_47 (Swish)               (None, 1, 1, 48)     0           ['conv2d_61[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_62 (Conv2D)             (None, 1, 1, 1152)   56448       ['swish_47[0][0]']               \n",
            "                                                                                                  \n",
            " activation_15 (Activation)     (None, 1, 1, 1152)   0           ['conv2d_62[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_15 (Multiply)         (None, 5, 5, 1152)   0           ['activation_15[0][0]',          \n",
            "                                                                  'swish_46[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_63 (Conv2D)             (None, 5, 5, 320)    368640      ['multiply_15[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_47 (BatchN  (None, 5, 5, 320)   1280        ['conv2d_63[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_64 (Conv2D)             (None, 5, 5, 1280)   409600      ['batch_normalization_47[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_48 (BatchN  (None, 5, 5, 1280)  5120        ['conv2d_64[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_48 (Swish)               (None, 5, 5, 1280)   0           ['batch_normalization_48[0][0]'] \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 4,049,564\n",
            "Trainable params: 0\n",
            "Non-trainable params: 4,049,564\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#สร้างโฟลเดอร์ Train Valodation และ Test"
      ],
      "metadata": {
        "id": "J36J9EAE7qSB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv (r'/content/drive/MyDrive/cut_panoramic/Data/New_Data_Male125.csv')\n",
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "skoKhKJDngAZ",
        "outputId": "d8b5a493-12d0-41d6-c122-b91c4a634dbc"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      Fig_Age  Fig_Person_Sex  Age(year) Class  Class_Re       Filename  \\\n",
              "0           1               1          7  Y07M         0       VV03.jpg   \n",
              "1           2               1          7  Y07M         0  Flip_VV03.jpg   \n",
              "2           3               2          7  Y07M         0       VV04.jpg   \n",
              "3           4               2          7  Y07M         0  Flip_VV04.jpg   \n",
              "4           5               3          7  Y07M         0       VV05.jpg   \n",
              "...       ...             ...        ...   ...       ...            ...   \n",
              "2370      121              77         25  Y25M        18  Flip_J463.jpg   \n",
              "2371      122              78         25  Y25M        18       J464.jpg   \n",
              "2372      123              78         25  Y25M        18  Flip_J464.jpg   \n",
              "2373      124              79         25  Y25M        18       J465.jpg   \n",
              "2374      125              79         25  Y25M        18  Flip_J465.jpg   \n",
              "\n",
              "                                          Path_filename     Sex Floder  \n",
              "0     /content/drive/My Drive/TVT_Male125/train/Y07M...  เพศชาย   Both  \n",
              "1     /content/drive/My Drive/TVT_Male125/train/Y07M...  เพศชาย   Both  \n",
              "2     /content/drive/My Drive/TVT_Male125/train/Y07M...  เพศชาย   Both  \n",
              "3     /content/drive/My Drive/TVT_Male125/train/Y07M...  เพศชาย   Both  \n",
              "4     /content/drive/My Drive/TVT_Male125/train/Y07M...  เพศชาย   Both  \n",
              "...                                                 ...     ...    ...  \n",
              "2370  /content/drive/My Drive/TVT_Male125/test/Y25M/...  เพศชาย   Both  \n",
              "2371  /content/drive/My Drive/TVT_Male125/test/Y25M/...  เพศชาย   Both  \n",
              "2372  /content/drive/My Drive/TVT_Male125/test/Y25M/...  เพศชาย   Both  \n",
              "2373  /content/drive/My Drive/TVT_Male125/test/Y25M/...  เพศชาย   Both  \n",
              "2374  /content/drive/My Drive/TVT_Male125/test/Y25M/...  เพศชาย   Both  \n",
              "\n",
              "[2375 rows x 9 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e1fd6c9f-f33d-4d6e-9d6a-11e6ae714016\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Fig_Age</th>\n",
              "      <th>Fig_Person_Sex</th>\n",
              "      <th>Age(year)</th>\n",
              "      <th>Class</th>\n",
              "      <th>Class_Re</th>\n",
              "      <th>Filename</th>\n",
              "      <th>Path_filename</th>\n",
              "      <th>Sex</th>\n",
              "      <th>Floder</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>Y07M</td>\n",
              "      <td>0</td>\n",
              "      <td>VV03.jpg</td>\n",
              "      <td>/content/drive/My Drive/TVT_Male125/train/Y07M...</td>\n",
              "      <td>เพศชาย</td>\n",
              "      <td>Both</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>Y07M</td>\n",
              "      <td>0</td>\n",
              "      <td>Flip_VV03.jpg</td>\n",
              "      <td>/content/drive/My Drive/TVT_Male125/train/Y07M...</td>\n",
              "      <td>เพศชาย</td>\n",
              "      <td>Both</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>7</td>\n",
              "      <td>Y07M</td>\n",
              "      <td>0</td>\n",
              "      <td>VV04.jpg</td>\n",
              "      <td>/content/drive/My Drive/TVT_Male125/train/Y07M...</td>\n",
              "      <td>เพศชาย</td>\n",
              "      <td>Both</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>7</td>\n",
              "      <td>Y07M</td>\n",
              "      <td>0</td>\n",
              "      <td>Flip_VV04.jpg</td>\n",
              "      <td>/content/drive/My Drive/TVT_Male125/train/Y07M...</td>\n",
              "      <td>เพศชาย</td>\n",
              "      <td>Both</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>7</td>\n",
              "      <td>Y07M</td>\n",
              "      <td>0</td>\n",
              "      <td>VV05.jpg</td>\n",
              "      <td>/content/drive/My Drive/TVT_Male125/train/Y07M...</td>\n",
              "      <td>เพศชาย</td>\n",
              "      <td>Both</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2370</th>\n",
              "      <td>121</td>\n",
              "      <td>77</td>\n",
              "      <td>25</td>\n",
              "      <td>Y25M</td>\n",
              "      <td>18</td>\n",
              "      <td>Flip_J463.jpg</td>\n",
              "      <td>/content/drive/My Drive/TVT_Male125/test/Y25M/...</td>\n",
              "      <td>เพศชาย</td>\n",
              "      <td>Both</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2371</th>\n",
              "      <td>122</td>\n",
              "      <td>78</td>\n",
              "      <td>25</td>\n",
              "      <td>Y25M</td>\n",
              "      <td>18</td>\n",
              "      <td>J464.jpg</td>\n",
              "      <td>/content/drive/My Drive/TVT_Male125/test/Y25M/...</td>\n",
              "      <td>เพศชาย</td>\n",
              "      <td>Both</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2372</th>\n",
              "      <td>123</td>\n",
              "      <td>78</td>\n",
              "      <td>25</td>\n",
              "      <td>Y25M</td>\n",
              "      <td>18</td>\n",
              "      <td>Flip_J464.jpg</td>\n",
              "      <td>/content/drive/My Drive/TVT_Male125/test/Y25M/...</td>\n",
              "      <td>เพศชาย</td>\n",
              "      <td>Both</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2373</th>\n",
              "      <td>124</td>\n",
              "      <td>79</td>\n",
              "      <td>25</td>\n",
              "      <td>Y25M</td>\n",
              "      <td>18</td>\n",
              "      <td>J465.jpg</td>\n",
              "      <td>/content/drive/My Drive/TVT_Male125/test/Y25M/...</td>\n",
              "      <td>เพศชาย</td>\n",
              "      <td>Both</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2374</th>\n",
              "      <td>125</td>\n",
              "      <td>79</td>\n",
              "      <td>25</td>\n",
              "      <td>Y25M</td>\n",
              "      <td>18</td>\n",
              "      <td>Flip_J465.jpg</td>\n",
              "      <td>/content/drive/My Drive/TVT_Male125/test/Y25M/...</td>\n",
              "      <td>เพศชาย</td>\n",
              "      <td>Both</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2375 rows × 9 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e1fd6c9f-f33d-4d6e-9d6a-11e6ae714016')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e1fd6c9f-f33d-4d6e-9d6a-11e6ae714016 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e1fd6c9f-f33d-4d6e-9d6a-11e6ae714016');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train = df[df['Fig_Age'].between(1,75)]\n",
        "val = df[df['Fig_Age'].between(76,100)]"
      ],
      "metadata": {
        "id": "Z1zBw01Gl8Ac"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DATA_PATH = \"/content/drive/My Drive/TVT_Male125\"\n",
        "os.chdir(DATA_PATH)\n",
        "train_dir = os.path.join(DATA_PATH, 'train')\n",
        "print(train_dir)\n",
        "validation_dir = os.path.join(DATA_PATH, 'validation')\n",
        "print(validation_dir)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QL0g-8iOnMC4",
        "outputId": "d6ab6fde-475e-4683-d0d9-937661cae577"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/My Drive/TVT_Male125/train\n",
            "/content/drive/My Drive/TVT_Male125/validation\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# base_dir = '/content/drive/MyDrive/TVT_Male125'\n",
        "# os.makedirs(base_dir, exist_ok=True)\n",
        "\n",
        "# # Directories for our training,\n",
        "# # validation and test splits\n",
        "# train_dir = os.path.join(base_dir, 'train')\n",
        "# os.makedirs(train_dir, exist_ok=True)\n",
        "# validation_dir = os.path.join(base_dir, 'validation')\n",
        "# os.makedirs(validation_dir, exist_ok=True)\n",
        "# test_dir = os.path.join(base_dir, 'test')\n",
        "# os.makedirs(test_dir, exist_ok=True)"
      ],
      "metadata": {
        "id": "nqCFbjRQ3okB"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "#Train"
      ],
      "metadata": {
        "id": "bWEnlTSwazL5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train ด้วย ImageDataGenerator ของ Keras ซึ่งจะเพิ่มข้อมูลเสริมระหว่างการฝึกเพื่อลดโอกาสเกิด overfitting\n",
        "#overfitting เกิดจากข้อมูลที่ซับซ้อนกันเกินไป\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "train_datagen = ImageDataGenerator(\n",
        "      rescale=1./255, #โมเดลส่วนใหญ่ต้องใช้ RGB ในช่วง 0–1\n",
        "      rotation_range=40,\n",
        "      width_shift_range=0.2,\n",
        "      height_shift_range=0.2,\n",
        "      shear_range=0.2,\n",
        "      zoom_range=0.2,\n",
        "      horizontal_flip=True,\n",
        "      fill_mode='nearest')\n",
        "\n",
        "# Note that the validation data should not be augmented!\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)"
      ],
      "metadata": {
        "id": "xGPrsn9no_pa"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_generator = train_datagen.flow_from_dataframe(\n",
        "        dataframe = train,\n",
        "        directory = train_dir,\n",
        "        x_col = 'Path_filename',\n",
        "        y_col = 'Class_Re',\n",
        "        class_mode = 'other',\n",
        "        target_size=(height, width),\n",
        "        batch_size=batch_size)\n",
        "\n",
        "validation_generator = test_datagen.flow_from_dataframe(\n",
        "        dataframe = val,\n",
        "        directory = validation_dir,\n",
        "        x_col = 'Path_filename',\n",
        "        y_col = 'Class_Re',\n",
        "        class_mode = 'other',\n",
        "        target_size=(height, width),\n",
        "        batch_size=batch_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8nVlmAszntK_",
        "outputId": "48f4a818-2203-450e-9347-a643df3894c0"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1425 validated image filenames.\n",
            "Found 475 validated image filenames.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='mse',\n",
        "          optimizer=Adam(learning_rate=2e-4),\n",
        "          metrics=['mae'])\n",
        "history = model.fit_generator(\n",
        "      train_generator,\n",
        "      steps_per_epoch= NUM_TRAIN //batch_size,\n",
        "      epochs=epochs,\n",
        "      validation_data=validation_generator,\n",
        "      validation_steps= NUM_TEST //batch_size,\n",
        "      verbose=1,\n",
        "      use_multiprocessing=True,\n",
        "      workers=4)"
      ],
      "metadata": {
        "id": "N6qUmmF856ZE",
        "outputId": "727fc713-ffd3-4e81-d9be-9fb2ae315ccb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-21-0f54266a785f>:4: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  history = model.fit_generator(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "44/44 [==============================] - 108s 2s/step - loss: 105.1562 - mae: 8.6968 - val_loss: 104.0818 - val_mae: 8.6436\n",
            "Epoch 2/500\n",
            "44/44 [==============================] - 25s 545ms/step - loss: 103.1141 - mae: 8.5976 - val_loss: 103.9339 - val_mae: 8.6448\n",
            "Epoch 3/500\n",
            "44/44 [==============================] - 25s 555ms/step - loss: 103.5798 - mae: 8.6256 - val_loss: 102.4270 - val_mae: 8.5602\n",
            "Epoch 4/500\n",
            "44/44 [==============================] - 20s 431ms/step - loss: 102.8807 - mae: 8.5708 - val_loss: 103.7953 - val_mae: 8.6246\n",
            "Epoch 5/500\n",
            "44/44 [==============================] - 27s 572ms/step - loss: 102.3559 - mae: 8.5570 - val_loss: 103.0425 - val_mae: 8.5796\n",
            "Epoch 6/500\n",
            "44/44 [==============================] - 27s 584ms/step - loss: 102.1758 - mae: 8.5548 - val_loss: 101.6257 - val_mae: 8.5013\n",
            "Epoch 7/500\n",
            "44/44 [==============================] - 26s 581ms/step - loss: 101.9744 - mae: 8.5367 - val_loss: 102.2189 - val_mae: 8.5749\n",
            "Epoch 8/500\n",
            "44/44 [==============================] - 27s 596ms/step - loss: 101.9016 - mae: 8.5297 - val_loss: 101.6328 - val_mae: 8.5079\n",
            "Epoch 9/500\n",
            "44/44 [==============================] - 26s 567ms/step - loss: 102.1052 - mae: 8.5530 - val_loss: 101.1043 - val_mae: 8.4740\n",
            "Epoch 10/500\n",
            "44/44 [==============================] - 24s 536ms/step - loss: 101.2362 - mae: 8.5014 - val_loss: 101.4130 - val_mae: 8.5031\n",
            "Epoch 11/500\n",
            "44/44 [==============================] - 25s 543ms/step - loss: 100.8169 - mae: 8.4853 - val_loss: 100.5269 - val_mae: 8.4521\n",
            "Epoch 12/500\n",
            "44/44 [==============================] - 25s 540ms/step - loss: 100.4834 - mae: 8.4576 - val_loss: 101.4805 - val_mae: 8.5040\n",
            "Epoch 13/500\n",
            "44/44 [==============================] - 25s 555ms/step - loss: 100.5966 - mae: 8.4700 - val_loss: 100.6791 - val_mae: 8.4941\n",
            "Epoch 14/500\n",
            "44/44 [==============================] - 25s 540ms/step - loss: 100.2778 - mae: 8.4431 - val_loss: 99.7523 - val_mae: 8.3967\n",
            "Epoch 15/500\n",
            "44/44 [==============================] - 25s 557ms/step - loss: 99.3525 - mae: 8.4051 - val_loss: 98.9648 - val_mae: 8.3640\n",
            "Epoch 16/500\n",
            "44/44 [==============================] - 19s 415ms/step - loss: 99.6629 - mae: 8.4207 - val_loss: 98.5579 - val_mae: 8.3410\n",
            "Epoch 17/500\n",
            "44/44 [==============================] - 23s 475ms/step - loss: 99.0925 - mae: 8.3732 - val_loss: 98.5589 - val_mae: 8.3606\n",
            "Epoch 18/500\n",
            "44/44 [==============================] - 27s 553ms/step - loss: 99.3327 - mae: 8.3972 - val_loss: 99.2347 - val_mae: 8.3862\n",
            "Epoch 19/500\n",
            "44/44 [==============================] - 24s 531ms/step - loss: 98.3154 - mae: 8.3442 - val_loss: 97.7968 - val_mae: 8.3363\n",
            "Epoch 20/500\n",
            "44/44 [==============================] - 20s 430ms/step - loss: 98.1148 - mae: 8.3252 - val_loss: 99.1697 - val_mae: 8.3979\n",
            "Epoch 21/500\n",
            "44/44 [==============================] - 27s 550ms/step - loss: 99.1073 - mae: 8.4010 - val_loss: 97.8419 - val_mae: 8.3098\n",
            "Epoch 22/500\n",
            "44/44 [==============================] - 26s 576ms/step - loss: 97.4830 - mae: 8.3049 - val_loss: 98.7614 - val_mae: 8.3625\n",
            "Epoch 23/500\n",
            "44/44 [==============================] - 27s 588ms/step - loss: 97.3542 - mae: 8.2922 - val_loss: 97.7670 - val_mae: 8.2981\n",
            "Epoch 24/500\n",
            "44/44 [==============================] - 26s 572ms/step - loss: 97.0236 - mae: 8.2675 - val_loss: 98.5347 - val_mae: 8.3446\n",
            "Epoch 25/500\n",
            "44/44 [==============================] - 24s 530ms/step - loss: 96.7557 - mae: 8.2589 - val_loss: 96.3943 - val_mae: 8.2534\n",
            "Epoch 26/500\n",
            "44/44 [==============================] - 25s 551ms/step - loss: 95.5373 - mae: 8.1882 - val_loss: 96.6483 - val_mae: 8.2662\n",
            "Epoch 27/500\n",
            "44/44 [==============================] - 25s 545ms/step - loss: 95.8732 - mae: 8.2101 - val_loss: 97.4369 - val_mae: 8.2706\n",
            "Epoch 28/500\n",
            "44/44 [==============================] - 27s 575ms/step - loss: 96.2061 - mae: 8.2166 - val_loss: 97.4799 - val_mae: 8.2976\n",
            "Epoch 29/500\n",
            "44/44 [==============================] - 26s 580ms/step - loss: 95.4065 - mae: 8.1844 - val_loss: 95.4047 - val_mae: 8.1957\n",
            "Epoch 30/500\n",
            "44/44 [==============================] - 26s 579ms/step - loss: 95.2504 - mae: 8.1631 - val_loss: 94.7992 - val_mae: 8.1513\n",
            "Epoch 31/500\n",
            "44/44 [==============================] - 25s 551ms/step - loss: 95.3029 - mae: 8.1760 - val_loss: 96.1182 - val_mae: 8.2455\n",
            "Epoch 32/500\n",
            "44/44 [==============================] - 25s 558ms/step - loss: 94.6922 - mae: 8.1350 - val_loss: 94.8523 - val_mae: 8.1252\n",
            "Epoch 33/500\n",
            "44/44 [==============================] - 24s 530ms/step - loss: 94.5908 - mae: 8.1412 - val_loss: 93.6448 - val_mae: 8.0831\n",
            "Epoch 34/500\n",
            "44/44 [==============================] - 25s 541ms/step - loss: 94.5215 - mae: 8.1283 - val_loss: 95.9997 - val_mae: 8.2399\n",
            "Epoch 35/500\n",
            "44/44 [==============================] - 25s 542ms/step - loss: 94.0422 - mae: 8.1060 - val_loss: 94.7887 - val_mae: 8.1269\n",
            "Epoch 36/500\n",
            "44/44 [==============================] - 25s 552ms/step - loss: 94.0275 - mae: 8.1086 - val_loss: 92.0579 - val_mae: 7.9906\n",
            "Epoch 37/500\n",
            "44/44 [==============================] - 26s 583ms/step - loss: 93.7200 - mae: 8.0979 - val_loss: 94.2702 - val_mae: 8.1357\n",
            "Epoch 38/500\n",
            "44/44 [==============================] - 20s 441ms/step - loss: 93.5285 - mae: 8.0768 - val_loss: 94.6446 - val_mae: 8.1576\n",
            "Epoch 39/500\n",
            "44/44 [==============================] - 28s 560ms/step - loss: 93.1098 - mae: 8.0620 - val_loss: 93.0599 - val_mae: 8.0579\n",
            "Epoch 40/500\n",
            "44/44 [==============================] - 23s 501ms/step - loss: 92.0640 - mae: 7.9993 - val_loss: 92.9631 - val_mae: 8.0276\n",
            "Epoch 41/500\n",
            "44/44 [==============================] - 26s 557ms/step - loss: 92.2890 - mae: 8.0146 - val_loss: 93.6391 - val_mae: 8.1121\n",
            "Epoch 42/500\n",
            "44/44 [==============================] - 25s 550ms/step - loss: 92.4295 - mae: 8.0266 - val_loss: 93.2080 - val_mae: 8.0956\n",
            "Epoch 43/500\n",
            "44/44 [==============================] - 25s 543ms/step - loss: 92.1594 - mae: 8.0215 - val_loss: 91.4088 - val_mae: 7.9719\n",
            "Epoch 44/500\n",
            "44/44 [==============================] - 25s 548ms/step - loss: 91.2172 - mae: 7.9701 - val_loss: 93.0977 - val_mae: 8.0592\n",
            "Epoch 45/500\n",
            "44/44 [==============================] - 24s 526ms/step - loss: 91.5572 - mae: 7.9799 - val_loss: 90.5832 - val_mae: 7.9075\n",
            "Epoch 46/500\n",
            "44/44 [==============================] - 20s 425ms/step - loss: 91.8018 - mae: 7.9917 - val_loss: 90.8181 - val_mae: 7.9520\n",
            "Epoch 47/500\n",
            "44/44 [==============================] - 27s 573ms/step - loss: 90.8053 - mae: 7.9467 - val_loss: 91.6757 - val_mae: 8.0170\n",
            "Epoch 48/500\n",
            "44/44 [==============================] - 27s 599ms/step - loss: 91.1350 - mae: 7.9710 - val_loss: 90.6093 - val_mae: 7.9436\n",
            "Epoch 49/500\n",
            "44/44 [==============================] - 22s 465ms/step - loss: 89.9421 - mae: 7.8979 - val_loss: 90.8605 - val_mae: 7.9461\n",
            "Epoch 50/500\n",
            "44/44 [==============================] - 26s 546ms/step - loss: 89.4901 - mae: 7.8844 - val_loss: 89.3027 - val_mae: 7.8581\n",
            "Epoch 51/500\n",
            "44/44 [==============================] - 24s 542ms/step - loss: 89.7316 - mae: 7.8876 - val_loss: 90.1803 - val_mae: 7.9193\n",
            "Epoch 52/500\n",
            "44/44 [==============================] - 24s 527ms/step - loss: 89.4731 - mae: 7.8738 - val_loss: 89.0909 - val_mae: 7.8594\n",
            "Epoch 53/500\n",
            "44/44 [==============================] - 26s 564ms/step - loss: 88.8793 - mae: 7.8461 - val_loss: 89.0458 - val_mae: 7.8603\n",
            "Epoch 54/500\n",
            "44/44 [==============================] - 25s 549ms/step - loss: 89.1461 - mae: 7.8591 - val_loss: 88.8229 - val_mae: 7.8275\n",
            "Epoch 55/500\n",
            "44/44 [==============================] - 26s 565ms/step - loss: 89.0091 - mae: 7.8527 - val_loss: 87.0789 - val_mae: 7.7503\n",
            "Epoch 56/500\n",
            "44/44 [==============================] - 25s 557ms/step - loss: 88.0493 - mae: 7.8079 - val_loss: 87.0472 - val_mae: 7.7223\n",
            "Epoch 57/500\n",
            "44/44 [==============================] - 24s 528ms/step - loss: 88.2096 - mae: 7.8150 - val_loss: 88.1526 - val_mae: 7.8253\n",
            "Epoch 58/500\n",
            "44/44 [==============================] - 26s 562ms/step - loss: 88.5382 - mae: 7.8445 - val_loss: 88.2754 - val_mae: 7.8522\n",
            "Epoch 59/500\n",
            "44/44 [==============================] - 25s 546ms/step - loss: 87.3489 - mae: 7.7724 - val_loss: 87.3719 - val_mae: 7.7639\n",
            "Epoch 60/500\n",
            "44/44 [==============================] - 24s 522ms/step - loss: 87.7459 - mae: 7.7894 - val_loss: 86.7579 - val_mae: 7.7803\n",
            "Epoch 61/500\n",
            "44/44 [==============================] - 25s 545ms/step - loss: 87.4715 - mae: 7.7666 - val_loss: 88.1080 - val_mae: 7.8082\n",
            "Epoch 62/500\n",
            "44/44 [==============================] - 26s 551ms/step - loss: 87.7187 - mae: 7.7928 - val_loss: 86.6672 - val_mae: 7.7286\n",
            "Epoch 63/500\n",
            "44/44 [==============================] - 26s 549ms/step - loss: 86.4946 - mae: 7.7195 - val_loss: 88.2861 - val_mae: 7.8316\n",
            "Epoch 64/500\n",
            "44/44 [==============================] - 26s 579ms/step - loss: 86.2722 - mae: 7.7164 - val_loss: 85.3454 - val_mae: 7.6731\n",
            "Epoch 65/500\n",
            "44/44 [==============================] - 25s 557ms/step - loss: 86.2461 - mae: 7.7024 - val_loss: 85.6596 - val_mae: 7.6889\n",
            "Epoch 66/500\n",
            "44/44 [==============================] - 19s 413ms/step - loss: 85.6399 - mae: 7.6761 - val_loss: 85.4957 - val_mae: 7.6847\n",
            "Epoch 67/500\n",
            "44/44 [==============================] - 22s 418ms/step - loss: 85.2049 - mae: 7.6614 - val_loss: 87.7865 - val_mae: 7.8270\n",
            "Epoch 68/500\n",
            "44/44 [==============================] - 25s 529ms/step - loss: 85.4299 - mae: 7.6662 - val_loss: 84.3206 - val_mae: 7.5803\n",
            "Epoch 69/500\n",
            "44/44 [==============================] - 24s 535ms/step - loss: 85.2814 - mae: 7.6622 - val_loss: 84.2460 - val_mae: 7.6091\n",
            "Epoch 70/500\n",
            "44/44 [==============================] - 25s 551ms/step - loss: 85.3417 - mae: 7.6536 - val_loss: 85.0215 - val_mae: 7.6367\n",
            "Epoch 71/500\n",
            "44/44 [==============================] - 24s 533ms/step - loss: 84.5960 - mae: 7.6247 - val_loss: 84.0922 - val_mae: 7.5737\n",
            "Epoch 72/500\n",
            "44/44 [==============================] - 25s 551ms/step - loss: 84.4686 - mae: 7.6152 - val_loss: 85.5545 - val_mae: 7.6710\n",
            "Epoch 73/500\n",
            "44/44 [==============================] - 20s 425ms/step - loss: 84.1757 - mae: 7.6019 - val_loss: 84.2889 - val_mae: 7.6173\n",
            "Epoch 74/500\n",
            "44/44 [==============================] - 27s 535ms/step - loss: 84.1603 - mae: 7.6010 - val_loss: 84.2385 - val_mae: 7.6161\n",
            "Epoch 75/500\n",
            "44/44 [==============================] - 25s 544ms/step - loss: 83.7488 - mae: 7.5813 - val_loss: 82.8406 - val_mae: 7.5374\n",
            "Epoch 76/500\n",
            "44/44 [==============================] - 25s 527ms/step - loss: 84.0106 - mae: 7.5901 - val_loss: 83.4996 - val_mae: 7.5658\n",
            "Epoch 77/500\n",
            "44/44 [==============================] - 25s 547ms/step - loss: 83.7015 - mae: 7.5700 - val_loss: 83.2572 - val_mae: 7.5556\n",
            "Epoch 78/500\n",
            "44/44 [==============================] - 26s 544ms/step - loss: 82.6837 - mae: 7.5166 - val_loss: 83.3197 - val_mae: 7.5629\n",
            "Epoch 79/500\n",
            "44/44 [==============================] - 26s 538ms/step - loss: 82.6733 - mae: 7.5155 - val_loss: 83.1425 - val_mae: 7.5451\n",
            "Epoch 80/500\n",
            "44/44 [==============================] - 26s 565ms/step - loss: 82.0590 - mae: 7.4865 - val_loss: 82.8128 - val_mae: 7.5333\n",
            "Epoch 81/500\n",
            "44/44 [==============================] - 27s 584ms/step - loss: 82.6992 - mae: 7.5222 - val_loss: 81.3402 - val_mae: 7.4329\n",
            "Epoch 82/500\n",
            "44/44 [==============================] - 21s 464ms/step - loss: 81.8130 - mae: 7.4730 - val_loss: 81.5240 - val_mae: 7.4565\n",
            "Epoch 83/500\n",
            "44/44 [==============================] - 27s 541ms/step - loss: 82.1675 - mae: 7.4929 - val_loss: 82.9138 - val_mae: 7.5391\n",
            "Epoch 84/500\n",
            "44/44 [==============================] - 25s 540ms/step - loss: 81.4368 - mae: 7.4463 - val_loss: 81.3810 - val_mae: 7.4426\n",
            "Epoch 85/500\n",
            "44/44 [==============================] - 26s 546ms/step - loss: 81.4250 - mae: 7.4554 - val_loss: 80.8965 - val_mae: 7.3856\n",
            "Epoch 86/500\n",
            "44/44 [==============================] - 27s 598ms/step - loss: 80.8826 - mae: 7.4101 - val_loss: 80.3562 - val_mae: 7.3709\n",
            "Epoch 87/500\n",
            "44/44 [==============================] - 22s 488ms/step - loss: 79.7370 - mae: 7.3526 - val_loss: 80.3414 - val_mae: 7.4050\n",
            "Epoch 88/500\n",
            "44/44 [==============================] - 26s 535ms/step - loss: 80.4930 - mae: 7.3989 - val_loss: 80.7893 - val_mae: 7.4185\n",
            "Epoch 89/500\n",
            "44/44 [==============================] - 25s 545ms/step - loss: 80.0135 - mae: 7.3695 - val_loss: 80.4001 - val_mae: 7.3768\n",
            "Epoch 90/500\n",
            "44/44 [==============================] - 25s 553ms/step - loss: 80.0208 - mae: 7.3759 - val_loss: 79.3966 - val_mae: 7.3736\n",
            "Epoch 91/500\n",
            "44/44 [==============================] - 20s 425ms/step - loss: 79.9465 - mae: 7.3723 - val_loss: 78.0943 - val_mae: 7.2481\n",
            "Epoch 92/500\n",
            "44/44 [==============================] - 26s 551ms/step - loss: 79.5060 - mae: 7.3396 - val_loss: 81.3795 - val_mae: 7.4564\n",
            "Epoch 93/500\n",
            "44/44 [==============================] - 25s 544ms/step - loss: 79.6998 - mae: 7.3590 - val_loss: 79.4793 - val_mae: 7.3108\n",
            "Epoch 94/500\n",
            "44/44 [==============================] - 24s 526ms/step - loss: 78.8678 - mae: 7.3004 - val_loss: 79.3922 - val_mae: 7.3357\n",
            "Epoch 95/500\n",
            "44/44 [==============================] - 24s 537ms/step - loss: 78.8604 - mae: 7.3159 - val_loss: 80.2634 - val_mae: 7.4000\n",
            "Epoch 96/500\n",
            "44/44 [==============================] - 26s 574ms/step - loss: 78.3541 - mae: 7.2845 - val_loss: 77.5171 - val_mae: 7.2437\n",
            "Epoch 97/500\n",
            "44/44 [==============================] - 24s 529ms/step - loss: 78.6136 - mae: 7.2993 - val_loss: 77.8962 - val_mae: 7.2652\n",
            "Epoch 98/500\n",
            "44/44 [==============================] - 24s 528ms/step - loss: 78.6517 - mae: 7.3018 - val_loss: 80.0095 - val_mae: 7.3677\n",
            "Epoch 99/500\n",
            "44/44 [==============================] - 25s 542ms/step - loss: 77.8881 - mae: 7.2568 - val_loss: 79.0607 - val_mae: 7.3464\n",
            "Epoch 100/500\n",
            "44/44 [==============================] - 20s 423ms/step - loss: 78.0873 - mae: 7.2840 - val_loss: 78.4961 - val_mae: 7.2855\n",
            "Epoch 101/500\n",
            "44/44 [==============================] - 26s 548ms/step - loss: 77.6592 - mae: 7.2404 - val_loss: 76.6438 - val_mae: 7.2058\n",
            "Epoch 102/500\n",
            "44/44 [==============================] - 25s 545ms/step - loss: 77.3903 - mae: 7.2324 - val_loss: 78.2452 - val_mae: 7.2976\n",
            "Epoch 103/500\n",
            "44/44 [==============================] - 27s 585ms/step - loss: 77.2594 - mae: 7.2435 - val_loss: 77.6501 - val_mae: 7.2421\n",
            "Epoch 104/500\n",
            "44/44 [==============================] - 25s 552ms/step - loss: 76.4316 - mae: 7.1790 - val_loss: 77.0980 - val_mae: 7.2138\n",
            "Epoch 105/500\n",
            "44/44 [==============================] - 24s 537ms/step - loss: 76.9614 - mae: 7.2131 - val_loss: 76.7187 - val_mae: 7.2180\n",
            "Epoch 106/500\n",
            "44/44 [==============================] - 24s 532ms/step - loss: 76.1893 - mae: 7.1765 - val_loss: 75.3533 - val_mae: 7.1327\n",
            "Epoch 107/500\n",
            "44/44 [==============================] - 25s 534ms/step - loss: 76.0418 - mae: 7.1620 - val_loss: 76.4149 - val_mae: 7.2063\n",
            "Epoch 108/500\n",
            "44/44 [==============================] - 19s 419ms/step - loss: 75.4573 - mae: 7.1375 - val_loss: 76.3611 - val_mae: 7.1800\n",
            "Epoch 109/500\n",
            "44/44 [==============================] - 29s 603ms/step - loss: 75.4854 - mae: 7.1441 - val_loss: 75.3921 - val_mae: 7.1109\n",
            "Epoch 110/500\n",
            "44/44 [==============================] - 25s 546ms/step - loss: 75.2645 - mae: 7.1261 - val_loss: 74.7761 - val_mae: 7.1129\n",
            "Epoch 111/500\n",
            "44/44 [==============================] - 24s 535ms/step - loss: 75.9528 - mae: 7.1703 - val_loss: 75.5762 - val_mae: 7.1636\n",
            "Epoch 112/500\n",
            "44/44 [==============================] - 25s 537ms/step - loss: 75.1249 - mae: 7.1193 - val_loss: 74.9348 - val_mae: 7.0919\n",
            "Epoch 113/500\n",
            "44/44 [==============================] - 24s 530ms/step - loss: 75.1615 - mae: 7.1288 - val_loss: 75.8523 - val_mae: 7.1829\n",
            "Epoch 114/500\n",
            "44/44 [==============================] - 25s 544ms/step - loss: 74.4325 - mae: 7.0820 - val_loss: 75.4656 - val_mae: 7.1679\n",
            "Epoch 115/500\n",
            "44/44 [==============================] - 25s 540ms/step - loss: 74.8059 - mae: 7.1032 - val_loss: 74.8138 - val_mae: 7.1184\n",
            "Epoch 116/500\n",
            "44/44 [==============================] - 25s 551ms/step - loss: 74.5080 - mae: 7.0874 - val_loss: 73.7535 - val_mae: 7.0637\n",
            "Epoch 117/500\n",
            "44/44 [==============================] - 25s 550ms/step - loss: 74.0231 - mae: 7.0608 - val_loss: 71.7444 - val_mae: 6.9373\n",
            "Epoch 118/500\n",
            "44/44 [==============================] - 25s 548ms/step - loss: 74.2595 - mae: 7.0799 - val_loss: 72.9991 - val_mae: 7.0273\n",
            "Epoch 119/500\n",
            "44/44 [==============================] - 21s 432ms/step - loss: 73.4973 - mae: 7.0427 - val_loss: 74.4349 - val_mae: 7.1270\n",
            "Epoch 120/500\n",
            "44/44 [==============================] - 26s 569ms/step - loss: 73.8533 - mae: 7.0679 - val_loss: 72.5751 - val_mae: 7.0056\n",
            "Epoch 121/500\n",
            "44/44 [==============================] - 24s 523ms/step - loss: 72.9130 - mae: 7.0114 - val_loss: 72.8993 - val_mae: 7.0034\n",
            "Epoch 122/500\n",
            "44/44 [==============================] - 25s 537ms/step - loss: 72.8147 - mae: 7.0075 - val_loss: 70.9972 - val_mae: 6.8910\n",
            "Epoch 123/500\n",
            "44/44 [==============================] - 26s 550ms/step - loss: 72.6846 - mae: 7.0005 - val_loss: 72.1440 - val_mae: 6.9786\n",
            "Epoch 124/500\n",
            "44/44 [==============================] - 27s 569ms/step - loss: 73.0282 - mae: 7.0135 - val_loss: 72.8315 - val_mae: 7.0074\n",
            "Epoch 125/500\n",
            "44/44 [==============================] - 25s 526ms/step - loss: 72.0818 - mae: 6.9669 - val_loss: 72.1967 - val_mae: 6.9805\n",
            "Epoch 126/500\n",
            "44/44 [==============================] - 26s 569ms/step - loss: 71.9592 - mae: 6.9551 - val_loss: 71.5015 - val_mae: 6.9357\n",
            "Epoch 127/500\n",
            "44/44 [==============================] - 25s 542ms/step - loss: 71.5419 - mae: 6.9329 - val_loss: 71.8395 - val_mae: 6.9760\n",
            "Epoch 128/500\n",
            "44/44 [==============================] - 25s 553ms/step - loss: 71.5900 - mae: 6.9381 - val_loss: 69.3474 - val_mae: 6.7952\n",
            "Epoch 129/500\n",
            "44/44 [==============================] - 25s 543ms/step - loss: 71.5344 - mae: 6.9324 - val_loss: 69.9679 - val_mae: 6.8245\n",
            "Epoch 130/500\n",
            "44/44 [==============================] - 25s 545ms/step - loss: 71.7915 - mae: 6.9479 - val_loss: 70.3823 - val_mae: 6.8725\n",
            "Epoch 131/500\n",
            "44/44 [==============================] - 25s 539ms/step - loss: 70.9659 - mae: 6.9044 - val_loss: 70.7414 - val_mae: 6.9026\n",
            "Epoch 132/500\n",
            "44/44 [==============================] - 25s 547ms/step - loss: 70.6883 - mae: 6.8883 - val_loss: 72.0214 - val_mae: 6.9893\n",
            "Epoch 133/500\n",
            "44/44 [==============================] - 24s 527ms/step - loss: 70.2991 - mae: 6.8779 - val_loss: 69.0204 - val_mae: 6.7900\n",
            "Epoch 134/500\n",
            "44/44 [==============================] - 24s 530ms/step - loss: 70.6489 - mae: 6.8881 - val_loss: 72.1380 - val_mae: 6.9901\n",
            "Epoch 135/500\n",
            "44/44 [==============================] - 26s 549ms/step - loss: 70.1882 - mae: 6.8607 - val_loss: 69.8787 - val_mae: 6.8391\n",
            "Epoch 136/500\n",
            "44/44 [==============================] - 24s 535ms/step - loss: 69.4775 - mae: 6.8155 - val_loss: 70.8738 - val_mae: 6.9117\n",
            "Epoch 137/500\n",
            "44/44 [==============================] - 26s 548ms/step - loss: 69.4442 - mae: 6.8203 - val_loss: 70.3973 - val_mae: 6.8849\n",
            "Epoch 138/500\n",
            "44/44 [==============================] - 25s 533ms/step - loss: 69.1868 - mae: 6.8095 - val_loss: 68.3410 - val_mae: 6.7385\n",
            "Epoch 139/500\n",
            "44/44 [==============================] - 26s 542ms/step - loss: 69.6200 - mae: 6.8360 - val_loss: 68.4901 - val_mae: 6.7439\n",
            "Epoch 140/500\n",
            "44/44 [==============================] - 25s 530ms/step - loss: 69.1145 - mae: 6.8079 - val_loss: 69.3024 - val_mae: 6.8231\n",
            "Epoch 141/500\n",
            "44/44 [==============================] - 20s 430ms/step - loss: 68.1622 - mae: 6.7458 - val_loss: 69.6415 - val_mae: 6.8254\n",
            "Epoch 142/500\n",
            "44/44 [==============================] - 26s 554ms/step - loss: 69.1103 - mae: 6.8086 - val_loss: 69.4270 - val_mae: 6.8243\n",
            "Epoch 143/500\n",
            "44/44 [==============================] - 25s 546ms/step - loss: 68.1990 - mae: 6.7458 - val_loss: 70.3801 - val_mae: 6.9096\n",
            "Epoch 144/500\n",
            "44/44 [==============================] - 19s 419ms/step - loss: 68.1948 - mae: 6.7553 - val_loss: 67.8377 - val_mae: 6.7196\n",
            "Epoch 145/500\n",
            "44/44 [==============================] - 27s 578ms/step - loss: 67.8690 - mae: 6.7305 - val_loss: 67.6810 - val_mae: 6.7159\n",
            "Epoch 146/500\n",
            "44/44 [==============================] - 24s 531ms/step - loss: 68.1308 - mae: 6.7527 - val_loss: 67.2700 - val_mae: 6.7232\n",
            "Epoch 147/500\n",
            "44/44 [==============================] - 24s 535ms/step - loss: 67.2722 - mae: 6.6974 - val_loss: 68.5399 - val_mae: 6.7934\n",
            "Epoch 148/500\n",
            "44/44 [==============================] - 24s 536ms/step - loss: 67.6681 - mae: 6.7279 - val_loss: 66.9919 - val_mae: 6.6778\n",
            "Epoch 149/500\n",
            "44/44 [==============================] - 20s 423ms/step - loss: 67.4050 - mae: 6.7027 - val_loss: 67.3867 - val_mae: 6.7211\n",
            "Epoch 150/500\n",
            "44/44 [==============================] - 28s 596ms/step - loss: 66.7266 - mae: 6.6735 - val_loss: 66.1025 - val_mae: 6.6377\n",
            "Epoch 151/500\n",
            "44/44 [==============================] - 25s 542ms/step - loss: 67.3454 - mae: 6.7102 - val_loss: 67.0574 - val_mae: 6.7018\n",
            "Epoch 152/500\n",
            "44/44 [==============================] - 26s 563ms/step - loss: 66.7938 - mae: 6.6710 - val_loss: 65.6915 - val_mae: 6.5857\n",
            "Epoch 153/500\n",
            "44/44 [==============================] - 24s 525ms/step - loss: 66.2159 - mae: 6.6368 - val_loss: 66.7628 - val_mae: 6.6804\n",
            "Epoch 154/500\n",
            "44/44 [==============================] - 24s 532ms/step - loss: 66.1402 - mae: 6.6376 - val_loss: 65.3429 - val_mae: 6.5910\n",
            "Epoch 155/500\n",
            "44/44 [==============================] - 25s 523ms/step - loss: 66.2725 - mae: 6.6551 - val_loss: 65.8688 - val_mae: 6.6219\n",
            "Epoch 156/500\n",
            "44/44 [==============================] - 25s 540ms/step - loss: 65.1310 - mae: 6.5819 - val_loss: 66.5599 - val_mae: 6.6837\n",
            "Epoch 157/500\n",
            "44/44 [==============================] - 24s 530ms/step - loss: 65.3953 - mae: 6.5976 - val_loss: 66.4230 - val_mae: 6.6477\n",
            "Epoch 158/500\n",
            "44/44 [==============================] - 22s 488ms/step - loss: 65.6451 - mae: 6.6104 - val_loss: 67.0681 - val_mae: 6.7137\n",
            "Epoch 159/500\n",
            "44/44 [==============================] - 24s 535ms/step - loss: 65.4613 - mae: 6.6027 - val_loss: 64.0673 - val_mae: 6.5314\n",
            "Epoch 160/500\n",
            "44/44 [==============================] - 25s 546ms/step - loss: 64.8094 - mae: 6.5665 - val_loss: 63.9302 - val_mae: 6.5121\n",
            "Epoch 161/500\n",
            "44/44 [==============================] - 22s 477ms/step - loss: 64.9694 - mae: 6.5784 - val_loss: 65.1102 - val_mae: 6.5835\n",
            "Epoch 162/500\n",
            "44/44 [==============================] - 25s 545ms/step - loss: 65.2304 - mae: 6.5968 - val_loss: 65.0380 - val_mae: 6.5909\n",
            "Epoch 163/500\n",
            "44/44 [==============================] - 25s 545ms/step - loss: 64.6432 - mae: 6.5613 - val_loss: 64.4719 - val_mae: 6.5551\n",
            "Epoch 164/500\n",
            "44/44 [==============================] - 24s 530ms/step - loss: 64.1748 - mae: 6.5338 - val_loss: 64.8827 - val_mae: 6.5903\n",
            "Epoch 165/500\n",
            "44/44 [==============================] - 24s 524ms/step - loss: 64.0698 - mae: 6.5371 - val_loss: 64.0921 - val_mae: 6.5204\n",
            "Epoch 166/500\n",
            "44/44 [==============================] - 25s 541ms/step - loss: 64.0285 - mae: 6.5308 - val_loss: 65.2297 - val_mae: 6.6306\n",
            "Epoch 167/500\n",
            "44/44 [==============================] - 24s 528ms/step - loss: 63.6625 - mae: 6.5163 - val_loss: 63.4960 - val_mae: 6.5238\n",
            "Epoch 168/500\n",
            "44/44 [==============================] - 25s 544ms/step - loss: 63.1349 - mae: 6.4805 - val_loss: 63.1550 - val_mae: 6.5073\n",
            "Epoch 169/500\n",
            "44/44 [==============================] - 25s 554ms/step - loss: 63.2440 - mae: 6.4879 - val_loss: 64.4785 - val_mae: 6.5711\n",
            "Epoch 170/500\n",
            "44/44 [==============================] - 24s 531ms/step - loss: 63.0520 - mae: 6.4779 - val_loss: 63.2738 - val_mae: 6.5090\n",
            "Epoch 171/500\n",
            "44/44 [==============================] - 25s 537ms/step - loss: 62.5981 - mae: 6.4445 - val_loss: 62.4703 - val_mae: 6.4595\n",
            "Epoch 172/500\n",
            "44/44 [==============================] - 26s 538ms/step - loss: 62.9263 - mae: 6.4808 - val_loss: 62.9242 - val_mae: 6.4745\n",
            "Epoch 173/500\n",
            "44/44 [==============================] - 21s 464ms/step - loss: 62.5166 - mae: 6.4551 - val_loss: 63.3583 - val_mae: 6.5097\n",
            "Epoch 174/500\n",
            "44/44 [==============================] - 27s 589ms/step - loss: 62.8093 - mae: 6.4849 - val_loss: 61.3446 - val_mae: 6.3833\n",
            "Epoch 175/500\n",
            "44/44 [==============================] - 26s 579ms/step - loss: 62.1046 - mae: 6.4361 - val_loss: 61.3209 - val_mae: 6.3963\n",
            "Epoch 176/500\n",
            "44/44 [==============================] - 26s 573ms/step - loss: 61.9076 - mae: 6.4206 - val_loss: 62.1411 - val_mae: 6.4419\n",
            "Epoch 177/500\n",
            "44/44 [==============================] - 25s 556ms/step - loss: 61.5977 - mae: 6.4059 - val_loss: 62.5808 - val_mae: 6.4873\n",
            "Epoch 178/500\n",
            "44/44 [==============================] - 19s 418ms/step - loss: 61.4593 - mae: 6.4105 - val_loss: 61.3677 - val_mae: 6.3938\n",
            "Epoch 179/500\n",
            "44/44 [==============================] - 28s 559ms/step - loss: 61.5110 - mae: 6.4060 - val_loss: 60.4218 - val_mae: 6.3226\n",
            "Epoch 180/500\n",
            "44/44 [==============================] - 26s 580ms/step - loss: 61.3539 - mae: 6.4006 - val_loss: 61.0374 - val_mae: 6.3914\n",
            "Epoch 181/500\n",
            "44/44 [==============================] - 27s 584ms/step - loss: 61.5504 - mae: 6.4124 - val_loss: 61.8764 - val_mae: 6.4545\n",
            "Epoch 182/500\n",
            "44/44 [==============================] - 26s 577ms/step - loss: 61.2151 - mae: 6.3903 - val_loss: 62.0776 - val_mae: 6.4544\n",
            "Epoch 183/500\n",
            "44/44 [==============================] - 25s 557ms/step - loss: 61.2394 - mae: 6.4077 - val_loss: 60.7000 - val_mae: 6.3569\n",
            "Epoch 184/500\n",
            "44/44 [==============================] - 25s 542ms/step - loss: 60.6442 - mae: 6.3661 - val_loss: 60.1276 - val_mae: 6.3254\n",
            "Epoch 185/500\n",
            "44/44 [==============================] - 24s 540ms/step - loss: 60.5694 - mae: 6.3632 - val_loss: 59.8490 - val_mae: 6.2957\n",
            "Epoch 186/500\n",
            "44/44 [==============================] - 26s 572ms/step - loss: 60.7286 - mae: 6.3808 - val_loss: 59.8008 - val_mae: 6.2840\n",
            "Epoch 187/500\n",
            "44/44 [==============================] - 21s 447ms/step - loss: 59.8872 - mae: 6.3299 - val_loss: 59.1956 - val_mae: 6.2859\n",
            "Epoch 188/500\n",
            "44/44 [==============================] - 25s 551ms/step - loss: 60.0075 - mae: 6.3299 - val_loss: 59.1099 - val_mae: 6.2880\n",
            "Epoch 189/500\n",
            "44/44 [==============================] - 26s 559ms/step - loss: 59.8277 - mae: 6.3163 - val_loss: 59.8609 - val_mae: 6.3427\n",
            "Epoch 190/500\n",
            "44/44 [==============================] - 20s 429ms/step - loss: 59.7392 - mae: 6.3123 - val_loss: 58.0223 - val_mae: 6.2200\n",
            "Epoch 191/500\n",
            "44/44 [==============================] - 22s 450ms/step - loss: 59.5380 - mae: 6.3091 - val_loss: 59.7489 - val_mae: 6.3163\n",
            "Epoch 192/500\n",
            "44/44 [==============================] - 26s 556ms/step - loss: 59.2199 - mae: 6.2813 - val_loss: 60.1098 - val_mae: 6.3461\n",
            "Epoch 193/500\n",
            "44/44 [==============================] - 25s 558ms/step - loss: 58.6311 - mae: 6.2515 - val_loss: 58.7814 - val_mae: 6.2504\n",
            "Epoch 194/500\n",
            "44/44 [==============================] - 20s 436ms/step - loss: 58.8795 - mae: 6.2713 - val_loss: 58.6194 - val_mae: 6.2679\n",
            "Epoch 195/500\n",
            "44/44 [==============================] - 28s 575ms/step - loss: 58.5966 - mae: 6.2501 - val_loss: 58.4528 - val_mae: 6.2551\n",
            "Epoch 196/500\n",
            "44/44 [==============================] - 27s 593ms/step - loss: 57.9906 - mae: 6.2196 - val_loss: 59.4243 - val_mae: 6.3244\n",
            "Epoch 197/500\n",
            "44/44 [==============================] - 25s 560ms/step - loss: 58.5646 - mae: 6.2504 - val_loss: 59.6728 - val_mae: 6.3441\n",
            "Epoch 198/500\n",
            "44/44 [==============================] - 24s 533ms/step - loss: 58.3033 - mae: 6.2371 - val_loss: 57.3717 - val_mae: 6.1727\n",
            "Epoch 199/500\n",
            "44/44 [==============================] - 26s 568ms/step - loss: 58.1644 - mae: 6.2412 - val_loss: 59.2885 - val_mae: 6.3081\n",
            "Epoch 200/500\n",
            "44/44 [==============================] - 25s 548ms/step - loss: 57.7530 - mae: 6.2085 - val_loss: 57.8914 - val_mae: 6.2111\n",
            "Epoch 201/500\n",
            "44/44 [==============================] - 24s 530ms/step - loss: 57.7399 - mae: 6.2077 - val_loss: 58.8727 - val_mae: 6.2866\n",
            "Epoch 202/500\n",
            "44/44 [==============================] - 26s 564ms/step - loss: 57.2617 - mae: 6.1809 - val_loss: 57.5907 - val_mae: 6.2115\n",
            "Epoch 203/500\n",
            "44/44 [==============================] - 25s 552ms/step - loss: 57.2385 - mae: 6.1794 - val_loss: 56.2602 - val_mae: 6.1007\n",
            "Epoch 204/500\n",
            "44/44 [==============================] - 25s 546ms/step - loss: 57.3551 - mae: 6.1904 - val_loss: 56.1814 - val_mae: 6.1015\n",
            "Epoch 205/500\n",
            "44/44 [==============================] - 25s 548ms/step - loss: 57.2225 - mae: 6.1811 - val_loss: 57.0738 - val_mae: 6.1679\n",
            "Epoch 206/500\n",
            "44/44 [==============================] - 26s 571ms/step - loss: 56.6524 - mae: 6.1461 - val_loss: 56.2012 - val_mae: 6.1195\n",
            "Epoch 207/500\n",
            "44/44 [==============================] - 26s 559ms/step - loss: 56.3697 - mae: 6.1277 - val_loss: 56.3301 - val_mae: 6.1349\n",
            "Epoch 208/500\n",
            "44/44 [==============================] - 20s 430ms/step - loss: 56.1287 - mae: 6.1148 - val_loss: 55.9628 - val_mae: 6.0934\n",
            "Epoch 209/500\n",
            "44/44 [==============================] - 28s 549ms/step - loss: 56.3807 - mae: 6.1314 - val_loss: 56.8822 - val_mae: 6.1811\n",
            "Epoch 210/500\n",
            "44/44 [==============================] - 26s 545ms/step - loss: 56.3207 - mae: 6.1283 - val_loss: 56.8909 - val_mae: 6.1985\n",
            "Epoch 211/500\n",
            "44/44 [==============================] - 26s 547ms/step - loss: 56.3940 - mae: 6.1322 - val_loss: 56.0617 - val_mae: 6.1353\n",
            "Epoch 212/500\n",
            "44/44 [==============================] - 26s 558ms/step - loss: 55.8896 - mae: 6.1116 - val_loss: 56.3816 - val_mae: 6.1493\n",
            "Epoch 213/500\n",
            "44/44 [==============================] - 22s 472ms/step - loss: 55.8417 - mae: 6.1002 - val_loss: 54.4528 - val_mae: 6.0096\n",
            "Epoch 214/500\n",
            "44/44 [==============================] - 27s 552ms/step - loss: 55.3626 - mae: 6.0744 - val_loss: 55.2039 - val_mae: 6.0658\n",
            "Epoch 215/500\n",
            "44/44 [==============================] - 26s 562ms/step - loss: 55.3521 - mae: 6.0704 - val_loss: 55.8838 - val_mae: 6.1102\n",
            "Epoch 216/500\n",
            "44/44 [==============================] - 20s 425ms/step - loss: 55.4279 - mae: 6.0747 - val_loss: 54.5989 - val_mae: 6.0021\n",
            "Epoch 217/500\n",
            "44/44 [==============================] - 28s 602ms/step - loss: 54.9731 - mae: 6.0446 - val_loss: 55.4360 - val_mae: 6.0920\n",
            "Epoch 218/500\n",
            "44/44 [==============================] - 26s 576ms/step - loss: 54.6450 - mae: 6.0333 - val_loss: 53.8728 - val_mae: 5.9729\n",
            "Epoch 219/500\n",
            "44/44 [==============================] - 20s 434ms/step - loss: 55.0777 - mae: 6.0655 - val_loss: 54.0293 - val_mae: 5.9992\n",
            "Epoch 220/500\n",
            "44/44 [==============================] - 28s 542ms/step - loss: 54.3664 - mae: 6.0165 - val_loss: 53.6812 - val_mae: 5.9864\n",
            "Epoch 221/500\n",
            "44/44 [==============================] - 26s 569ms/step - loss: 54.9043 - mae: 6.0637 - val_loss: 56.1034 - val_mae: 6.1378\n",
            "Epoch 222/500\n",
            "44/44 [==============================] - 26s 568ms/step - loss: 54.0254 - mae: 6.0036 - val_loss: 53.5540 - val_mae: 5.9709\n",
            "Epoch 223/500\n",
            "44/44 [==============================] - 25s 554ms/step - loss: 53.6246 - mae: 5.9733 - val_loss: 52.6838 - val_mae: 5.9106\n",
            "Epoch 224/500\n",
            "44/44 [==============================] - 26s 565ms/step - loss: 53.8479 - mae: 5.9991 - val_loss: 54.1246 - val_mae: 6.0165\n",
            "Epoch 225/500\n",
            "44/44 [==============================] - 25s 550ms/step - loss: 53.5089 - mae: 5.9719 - val_loss: 54.6367 - val_mae: 6.0606\n",
            "Epoch 226/500\n",
            "44/44 [==============================] - 24s 528ms/step - loss: 53.3862 - mae: 5.9714 - val_loss: 52.9379 - val_mae: 5.9321\n",
            "Epoch 227/500\n",
            "44/44 [==============================] - 24s 534ms/step - loss: 53.4389 - mae: 5.9789 - val_loss: 52.9769 - val_mae: 5.9409\n",
            "Epoch 228/500\n",
            "44/44 [==============================] - 25s 548ms/step - loss: 53.1730 - mae: 5.9587 - val_loss: 52.2106 - val_mae: 5.8989\n",
            "Epoch 229/500\n",
            "44/44 [==============================] - 25s 540ms/step - loss: 53.2325 - mae: 5.9688 - val_loss: 52.1810 - val_mae: 5.9034\n",
            "Epoch 230/500\n",
            "44/44 [==============================] - 25s 558ms/step - loss: 52.5541 - mae: 5.9290 - val_loss: 52.9482 - val_mae: 5.9554\n",
            "Epoch 231/500\n",
            "44/44 [==============================] - 26s 566ms/step - loss: 53.2814 - mae: 5.9840 - val_loss: 52.9357 - val_mae: 5.9587\n",
            "Epoch 232/500\n",
            "44/44 [==============================] - 25s 548ms/step - loss: 52.8861 - mae: 5.9527 - val_loss: 52.2706 - val_mae: 5.9155\n",
            "Epoch 233/500\n",
            "44/44 [==============================] - 26s 547ms/step - loss: 52.5565 - mae: 5.9293 - val_loss: 51.6204 - val_mae: 5.8900\n",
            "Epoch 234/500\n",
            "44/44 [==============================] - 26s 552ms/step - loss: 52.1563 - mae: 5.9078 - val_loss: 52.7891 - val_mae: 5.9602\n",
            "Epoch 235/500\n",
            "44/44 [==============================] - 25s 526ms/step - loss: 52.3361 - mae: 5.9149 - val_loss: 52.8208 - val_mae: 5.9548\n",
            "Epoch 236/500\n",
            "44/44 [==============================] - 26s 581ms/step - loss: 52.3780 - mae: 5.9278 - val_loss: 50.8259 - val_mae: 5.8229\n",
            "Epoch 237/500\n",
            "44/44 [==============================] - 25s 543ms/step - loss: 51.9781 - mae: 5.9087 - val_loss: 52.3346 - val_mae: 5.9178\n",
            "Epoch 238/500\n",
            "44/44 [==============================] - 26s 566ms/step - loss: 51.6538 - mae: 5.8907 - val_loss: 51.0080 - val_mae: 5.8412\n",
            "Epoch 239/500\n",
            "44/44 [==============================] - 25s 552ms/step - loss: 51.7479 - mae: 5.9010 - val_loss: 50.6935 - val_mae: 5.8239\n",
            "Epoch 240/500\n",
            "44/44 [==============================] - 25s 557ms/step - loss: 51.8996 - mae: 5.9081 - val_loss: 50.5225 - val_mae: 5.8163\n",
            "Epoch 241/500\n",
            "44/44 [==============================] - 25s 559ms/step - loss: 51.0522 - mae: 5.8557 - val_loss: 51.6980 - val_mae: 5.9220\n",
            "Epoch 242/500\n",
            "44/44 [==============================] - 25s 544ms/step - loss: 50.4123 - mae: 5.8103 - val_loss: 51.5641 - val_mae: 5.9207\n",
            "Epoch 243/500\n",
            "44/44 [==============================] - 24s 534ms/step - loss: 51.3861 - mae: 5.8767 - val_loss: 51.5416 - val_mae: 5.9062\n",
            "Epoch 244/500\n",
            "44/44 [==============================] - 24s 535ms/step - loss: 51.1837 - mae: 5.8735 - val_loss: 50.9784 - val_mae: 5.8381\n",
            "Epoch 245/500\n",
            "44/44 [==============================] - 25s 549ms/step - loss: 50.9313 - mae: 5.8500 - val_loss: 50.4109 - val_mae: 5.8280\n",
            "Epoch 246/500\n",
            "44/44 [==============================] - 25s 547ms/step - loss: 50.5506 - mae: 5.8222 - val_loss: 50.6897 - val_mae: 5.8387\n",
            "Epoch 247/500\n",
            "44/44 [==============================] - 25s 553ms/step - loss: 50.3917 - mae: 5.8316 - val_loss: 51.7277 - val_mae: 5.9272\n",
            "Epoch 248/500\n",
            "44/44 [==============================] - 25s 542ms/step - loss: 50.3501 - mae: 5.8230 - val_loss: 50.7023 - val_mae: 5.8594\n",
            "Epoch 249/500\n",
            "44/44 [==============================] - 26s 574ms/step - loss: 50.3598 - mae: 5.8270 - val_loss: 50.1265 - val_mae: 5.7939\n",
            "Epoch 250/500\n",
            "44/44 [==============================] - 26s 573ms/step - loss: 50.2005 - mae: 5.8208 - val_loss: 49.7163 - val_mae: 5.8078\n",
            "Epoch 251/500\n",
            "44/44 [==============================] - 25s 548ms/step - loss: 50.2044 - mae: 5.8117 - val_loss: 50.6174 - val_mae: 5.8408\n",
            "Epoch 252/500\n",
            "44/44 [==============================] - 26s 564ms/step - loss: 49.8357 - mae: 5.7918 - val_loss: 49.7428 - val_mae: 5.8026\n",
            "Epoch 253/500\n",
            "44/44 [==============================] - 26s 578ms/step - loss: 49.4200 - mae: 5.7679 - val_loss: 49.9038 - val_mae: 5.8011\n",
            "Epoch 254/500\n",
            "44/44 [==============================] - 20s 430ms/step - loss: 49.5347 - mae: 5.7802 - val_loss: 49.3661 - val_mae: 5.7702\n",
            "Epoch 255/500\n",
            "44/44 [==============================] - 28s 551ms/step - loss: 49.2067 - mae: 5.7604 - val_loss: 50.0661 - val_mae: 5.8344\n",
            "Epoch 256/500\n",
            "44/44 [==============================] - 27s 595ms/step - loss: 49.1631 - mae: 5.7561 - val_loss: 49.3146 - val_mae: 5.7661\n",
            "Epoch 257/500\n",
            "44/44 [==============================] - 26s 573ms/step - loss: 48.8151 - mae: 5.7275 - val_loss: 47.8022 - val_mae: 5.6717\n",
            "Epoch 258/500\n",
            "44/44 [==============================] - 20s 420ms/step - loss: 48.9394 - mae: 5.7483 - val_loss: 49.6227 - val_mae: 5.7751\n",
            "Epoch 259/500\n",
            "44/44 [==============================] - 28s 558ms/step - loss: 48.3598 - mae: 5.7014 - val_loss: 47.9358 - val_mae: 5.6703\n",
            "Epoch 260/500\n",
            "44/44 [==============================] - 26s 573ms/step - loss: 48.7868 - mae: 5.7395 - val_loss: 48.8365 - val_mae: 5.7404\n",
            "Epoch 261/500\n",
            "44/44 [==============================] - 25s 544ms/step - loss: 48.4406 - mae: 5.7128 - val_loss: 48.2641 - val_mae: 5.7201\n",
            "Epoch 262/500\n",
            "44/44 [==============================] - 24s 534ms/step - loss: 48.4403 - mae: 5.7266 - val_loss: 48.5190 - val_mae: 5.7218\n",
            "Epoch 263/500\n",
            "44/44 [==============================] - 25s 540ms/step - loss: 48.2417 - mae: 5.7064 - val_loss: 48.1871 - val_mae: 5.7153\n",
            "Epoch 264/500\n",
            "44/44 [==============================] - 25s 552ms/step - loss: 48.1149 - mae: 5.7094 - val_loss: 48.4252 - val_mae: 5.7112\n",
            "Epoch 265/500\n",
            "44/44 [==============================] - 25s 551ms/step - loss: 47.9955 - mae: 5.6965 - val_loss: 47.3252 - val_mae: 5.6480\n",
            "Epoch 266/500\n",
            "44/44 [==============================] - 25s 536ms/step - loss: 47.8377 - mae: 5.6816 - val_loss: 48.3317 - val_mae: 5.7088\n",
            "Epoch 267/500\n",
            "44/44 [==============================] - 24s 529ms/step - loss: 47.5179 - mae: 5.6619 - val_loss: 48.3637 - val_mae: 5.7236\n",
            "Epoch 268/500\n",
            "44/44 [==============================] - 22s 473ms/step - loss: 47.7509 - mae: 5.6920 - val_loss: 47.9881 - val_mae: 5.6928\n",
            "Epoch 269/500\n",
            "44/44 [==============================] - 24s 462ms/step - loss: 47.2106 - mae: 5.6446 - val_loss: 46.5437 - val_mae: 5.6122\n",
            "Epoch 270/500\n",
            "44/44 [==============================] - 26s 572ms/step - loss: 47.3072 - mae: 5.6630 - val_loss: 46.2174 - val_mae: 5.5656\n",
            "Epoch 271/500\n",
            "44/44 [==============================] - 26s 574ms/step - loss: 46.9982 - mae: 5.6375 - val_loss: 46.7636 - val_mae: 5.6186\n",
            "Epoch 272/500\n",
            "44/44 [==============================] - 24s 534ms/step - loss: 46.9756 - mae: 5.6327 - val_loss: 47.1739 - val_mae: 5.6506\n",
            "Epoch 273/500\n",
            "44/44 [==============================] - 25s 548ms/step - loss: 46.8260 - mae: 5.6235 - val_loss: 45.6076 - val_mae: 5.5315\n",
            "Epoch 274/500\n",
            "44/44 [==============================] - 25s 546ms/step - loss: 46.9392 - mae: 5.6317 - val_loss: 47.5153 - val_mae: 5.6676\n",
            "Epoch 275/500\n",
            "44/44 [==============================] - 25s 539ms/step - loss: 46.6405 - mae: 5.6130 - val_loss: 46.8063 - val_mae: 5.6334\n",
            "Epoch 276/500\n",
            "44/44 [==============================] - 29s 641ms/step - loss: 46.2718 - mae: 5.5925 - val_loss: 46.7593 - val_mae: 5.6089\n",
            "Epoch 277/500\n",
            "44/44 [==============================] - 25s 549ms/step - loss: 45.9337 - mae: 5.5653 - val_loss: 46.3186 - val_mae: 5.6084\n",
            "Epoch 278/500\n",
            "44/44 [==============================] - 20s 442ms/step - loss: 46.4117 - mae: 5.6041 - val_loss: 46.7278 - val_mae: 5.6386\n",
            "Epoch 279/500\n",
            "44/44 [==============================] - 28s 570ms/step - loss: 46.0684 - mae: 5.5859 - val_loss: 46.5906 - val_mae: 5.6406\n",
            "Epoch 280/500\n",
            "44/44 [==============================] - 28s 607ms/step - loss: 45.8692 - mae: 5.5706 - val_loss: 46.3730 - val_mae: 5.6053\n",
            "Epoch 281/500\n",
            "44/44 [==============================] - 26s 564ms/step - loss: 45.8043 - mae: 5.5680 - val_loss: 46.8220 - val_mae: 5.6374\n",
            "Epoch 282/500\n",
            "44/44 [==============================] - 20s 429ms/step - loss: 45.8292 - mae: 5.5715 - val_loss: 45.7866 - val_mae: 5.5774\n",
            "Epoch 283/500\n",
            "44/44 [==============================] - 28s 548ms/step - loss: 45.4365 - mae: 5.5444 - val_loss: 45.0380 - val_mae: 5.5052\n",
            "Epoch 284/500\n",
            "44/44 [==============================] - 27s 585ms/step - loss: 45.5573 - mae: 5.5614 - val_loss: 46.0244 - val_mae: 5.5976\n",
            "Epoch 285/500\n",
            "44/44 [==============================] - 26s 576ms/step - loss: 45.4785 - mae: 5.5570 - val_loss: 45.1018 - val_mae: 5.5386\n",
            "Epoch 286/500\n",
            "44/44 [==============================] - 27s 589ms/step - loss: 45.2123 - mae: 5.5503 - val_loss: 44.6435 - val_mae: 5.4780\n",
            "Epoch 287/500\n",
            "44/44 [==============================] - 27s 601ms/step - loss: 44.9786 - mae: 5.5331 - val_loss: 45.7270 - val_mae: 5.5685\n",
            "Epoch 288/500\n",
            "44/44 [==============================] - 25s 554ms/step - loss: 45.1052 - mae: 5.5384 - val_loss: 44.2819 - val_mae: 5.4901\n",
            "Epoch 289/500\n",
            "44/44 [==============================] - 25s 546ms/step - loss: 44.8951 - mae: 5.5260 - val_loss: 44.4429 - val_mae: 5.5067\n",
            "Epoch 290/500\n",
            "44/44 [==============================] - 24s 528ms/step - loss: 44.9296 - mae: 5.5355 - val_loss: 44.7107 - val_mae: 5.5240\n",
            "Epoch 291/500\n",
            "44/44 [==============================] - 20s 428ms/step - loss: 44.6584 - mae: 5.5212 - val_loss: 44.4298 - val_mae: 5.4818\n",
            "Epoch 292/500\n",
            "44/44 [==============================] - 27s 574ms/step - loss: 44.6848 - mae: 5.5191 - val_loss: 45.4622 - val_mae: 5.5828\n",
            "Epoch 293/500\n",
            "44/44 [==============================] - 25s 553ms/step - loss: 44.3424 - mae: 5.5018 - val_loss: 42.9003 - val_mae: 5.3984\n",
            "Epoch 294/500\n",
            "44/44 [==============================] - 25s 549ms/step - loss: 44.0356 - mae: 5.4836 - val_loss: 43.9201 - val_mae: 5.4669\n",
            "Epoch 295/500\n",
            "44/44 [==============================] - 25s 546ms/step - loss: 43.9151 - mae: 5.4707 - val_loss: 44.7794 - val_mae: 5.5282\n",
            "Epoch 296/500\n",
            "44/44 [==============================] - 25s 532ms/step - loss: 43.7640 - mae: 5.4705 - val_loss: 44.0275 - val_mae: 5.4779\n",
            "Epoch 297/500\n",
            "44/44 [==============================] - 25s 548ms/step - loss: 43.8187 - mae: 5.4761 - val_loss: 43.3731 - val_mae: 5.4397\n",
            "Epoch 298/500\n",
            "44/44 [==============================] - 25s 559ms/step - loss: 43.7032 - mae: 5.4724 - val_loss: 42.1991 - val_mae: 5.3563\n",
            "Epoch 299/500\n",
            "44/44 [==============================] - 25s 540ms/step - loss: 43.8268 - mae: 5.4793 - val_loss: 43.3789 - val_mae: 5.4265\n",
            "Epoch 300/500\n",
            "44/44 [==============================] - 24s 531ms/step - loss: 43.2808 - mae: 5.4437 - val_loss: 43.3655 - val_mae: 5.4410\n",
            "Epoch 301/500\n",
            "44/44 [==============================] - 20s 433ms/step - loss: 43.6015 - mae: 5.4628 - val_loss: 43.1832 - val_mae: 5.4436\n",
            "Epoch 302/500\n",
            "44/44 [==============================] - 23s 445ms/step - loss: 43.5608 - mae: 5.4719 - val_loss: 43.7206 - val_mae: 5.4865\n",
            "Epoch 303/500\n",
            "44/44 [==============================] - 26s 560ms/step - loss: 43.3483 - mae: 5.4665 - val_loss: 42.3759 - val_mae: 5.3815\n",
            "Epoch 304/500\n",
            "44/44 [==============================] - 26s 557ms/step - loss: 43.2862 - mae: 5.4554 - val_loss: 41.8457 - val_mae: 5.3470\n",
            "Epoch 305/500\n",
            "44/44 [==============================] - 24s 530ms/step - loss: 42.7316 - mae: 5.4147 - val_loss: 42.1436 - val_mae: 5.3784\n",
            "Epoch 306/500\n",
            "44/44 [==============================] - 21s 450ms/step - loss: 42.8013 - mae: 5.4197 - val_loss: 42.8824 - val_mae: 5.4448\n",
            "Epoch 307/500\n",
            "44/44 [==============================] - 24s 532ms/step - loss: 42.5832 - mae: 5.4078 - val_loss: 42.9482 - val_mae: 5.4115\n",
            "Epoch 308/500\n",
            "44/44 [==============================] - 24s 530ms/step - loss: 42.5511 - mae: 5.4072 - val_loss: 42.3653 - val_mae: 5.4030\n",
            "Epoch 309/500\n",
            "44/44 [==============================] - 24s 535ms/step - loss: 42.7404 - mae: 5.4262 - val_loss: 42.6560 - val_mae: 5.4064\n",
            "Epoch 310/500\n",
            "44/44 [==============================] - 25s 554ms/step - loss: 42.4440 - mae: 5.4036 - val_loss: 42.3983 - val_mae: 5.4028\n",
            "Epoch 311/500\n",
            "44/44 [==============================] - 25s 549ms/step - loss: 42.3599 - mae: 5.3965 - val_loss: 43.1016 - val_mae: 5.4641\n",
            "Epoch 312/500\n",
            "44/44 [==============================] - 27s 575ms/step - loss: 42.4510 - mae: 5.4081 - val_loss: 40.9608 - val_mae: 5.2823\n",
            "Epoch 313/500\n",
            "44/44 [==============================] - 26s 572ms/step - loss: 42.3278 - mae: 5.4004 - val_loss: 42.8839 - val_mae: 5.4549\n",
            "Epoch 314/500\n",
            "44/44 [==============================] - 21s 449ms/step - loss: 41.9441 - mae: 5.3731 - val_loss: 41.1122 - val_mae: 5.2997\n",
            "Epoch 315/500\n",
            "44/44 [==============================] - 24s 528ms/step - loss: 41.8712 - mae: 5.3766 - val_loss: 42.1579 - val_mae: 5.3695\n",
            "Epoch 316/500\n",
            "44/44 [==============================] - 27s 587ms/step - loss: 41.7359 - mae: 5.3604 - val_loss: 40.8471 - val_mae: 5.3027\n",
            "Epoch 317/500\n",
            "44/44 [==============================] - 25s 540ms/step - loss: 41.5595 - mae: 5.3577 - val_loss: 42.4641 - val_mae: 5.4229\n",
            "Epoch 318/500\n",
            "44/44 [==============================] - 25s 545ms/step - loss: 41.9417 - mae: 5.3892 - val_loss: 40.9688 - val_mae: 5.3112\n",
            "Epoch 319/500\n",
            "44/44 [==============================] - 24s 525ms/step - loss: 41.1737 - mae: 5.3332 - val_loss: 41.4032 - val_mae: 5.3487\n",
            "Epoch 320/500\n",
            "44/44 [==============================] - 29s 624ms/step - loss: 41.4320 - mae: 5.3542 - val_loss: 40.6859 - val_mae: 5.3025\n",
            "Epoch 321/500\n",
            "44/44 [==============================] - 25s 536ms/step - loss: 41.4841 - mae: 5.3606 - val_loss: 41.7164 - val_mae: 5.3574\n",
            "Epoch 322/500\n",
            "44/44 [==============================] - 25s 535ms/step - loss: 40.8491 - mae: 5.3136 - val_loss: 41.1382 - val_mae: 5.3377\n",
            "Epoch 323/500\n",
            "44/44 [==============================] - 25s 550ms/step - loss: 40.8365 - mae: 5.3094 - val_loss: 41.4812 - val_mae: 5.3571\n",
            "Epoch 324/500\n",
            "44/44 [==============================] - 25s 542ms/step - loss: 40.8711 - mae: 5.3206 - val_loss: 40.4988 - val_mae: 5.2854\n",
            "Epoch 325/500\n",
            "44/44 [==============================] - 25s 548ms/step - loss: 40.9070 - mae: 5.3252 - val_loss: 41.0901 - val_mae: 5.3555\n",
            "Epoch 326/500\n",
            "44/44 [==============================] - 25s 544ms/step - loss: 40.7314 - mae: 5.3137 - val_loss: 40.3643 - val_mae: 5.2690\n",
            "Epoch 327/500\n",
            "44/44 [==============================] - 25s 542ms/step - loss: 40.5821 - mae: 5.2986 - val_loss: 40.3435 - val_mae: 5.2961\n",
            "Epoch 328/500\n",
            "44/44 [==============================] - 28s 606ms/step - loss: 40.5780 - mae: 5.3069 - val_loss: 40.9201 - val_mae: 5.3473\n",
            "Epoch 329/500\n",
            "44/44 [==============================] - 24s 526ms/step - loss: 40.3461 - mae: 5.2881 - val_loss: 40.2491 - val_mae: 5.2628\n",
            "Epoch 330/500\n",
            "44/44 [==============================] - 24s 534ms/step - loss: 40.5077 - mae: 5.3000 - val_loss: 40.4124 - val_mae: 5.3000\n",
            "Epoch 331/500\n",
            "44/44 [==============================] - 21s 434ms/step - loss: 40.4511 - mae: 5.2974 - val_loss: 40.2616 - val_mae: 5.2875\n",
            "Epoch 332/500\n",
            "44/44 [==============================] - 27s 564ms/step - loss: 40.1877 - mae: 5.2808 - val_loss: 40.4053 - val_mae: 5.3030\n",
            "Epoch 333/500\n",
            "44/44 [==============================] - 25s 542ms/step - loss: 39.8179 - mae: 5.2545 - val_loss: 39.5338 - val_mae: 5.2423\n",
            "Epoch 334/500\n",
            "44/44 [==============================] - 24s 534ms/step - loss: 39.9790 - mae: 5.2726 - val_loss: 40.4084 - val_mae: 5.3316\n",
            "Epoch 335/500\n",
            "44/44 [==============================] - 24s 524ms/step - loss: 39.9901 - mae: 5.2698 - val_loss: 40.5767 - val_mae: 5.3014\n",
            "Epoch 336/500\n",
            "44/44 [==============================] - 25s 540ms/step - loss: 39.8304 - mae: 5.2586 - val_loss: 39.5098 - val_mae: 5.2430\n",
            "Epoch 337/500\n",
            "44/44 [==============================] - 25s 539ms/step - loss: 39.8101 - mae: 5.2588 - val_loss: 39.5794 - val_mae: 5.2317\n",
            "Epoch 338/500\n",
            "44/44 [==============================] - 24s 525ms/step - loss: 39.9052 - mae: 5.2675 - val_loss: 39.3701 - val_mae: 5.2403\n",
            "Epoch 339/500\n",
            "44/44 [==============================] - 27s 563ms/step - loss: 39.6929 - mae: 5.2499 - val_loss: 39.6953 - val_mae: 5.2671\n",
            "Epoch 340/500\n",
            "44/44 [==============================] - 19s 414ms/step - loss: 39.1816 - mae: 5.2192 - val_loss: 39.2767 - val_mae: 5.2278\n",
            "Epoch 341/500\n",
            "44/44 [==============================] - 26s 556ms/step - loss: 39.3480 - mae: 5.2380 - val_loss: 39.2055 - val_mae: 5.2467\n",
            "Epoch 342/500\n",
            "44/44 [==============================] - 25s 548ms/step - loss: 39.3374 - mae: 5.2369 - val_loss: 38.9203 - val_mae: 5.2123\n",
            "Epoch 343/500\n",
            "44/44 [==============================] - 20s 433ms/step - loss: 39.1755 - mae: 5.2291 - val_loss: 38.9918 - val_mae: 5.2114\n",
            "Epoch 344/500\n",
            "44/44 [==============================] - 27s 546ms/step - loss: 38.7437 - mae: 5.1892 - val_loss: 39.9318 - val_mae: 5.2639\n",
            "Epoch 345/500\n",
            "44/44 [==============================] - 24s 531ms/step - loss: 38.9790 - mae: 5.2187 - val_loss: 40.1928 - val_mae: 5.3197\n",
            "Epoch 346/500\n",
            "44/44 [==============================] - 26s 546ms/step - loss: 38.6050 - mae: 5.1855 - val_loss: 38.7043 - val_mae: 5.1825\n",
            "Epoch 347/500\n",
            "44/44 [==============================] - 25s 553ms/step - loss: 38.7340 - mae: 5.1957 - val_loss: 38.8298 - val_mae: 5.2271\n",
            "Epoch 348/500\n",
            "44/44 [==============================] - 26s 560ms/step - loss: 38.4652 - mae: 5.1777 - val_loss: 39.0962 - val_mae: 5.2365\n",
            "Epoch 349/500\n",
            "44/44 [==============================] - 25s 541ms/step - loss: 38.7017 - mae: 5.2001 - val_loss: 38.6429 - val_mae: 5.1869\n",
            "Epoch 350/500\n",
            "44/44 [==============================] - 24s 528ms/step - loss: 38.3184 - mae: 5.1718 - val_loss: 38.6408 - val_mae: 5.2153\n",
            "Epoch 351/500\n",
            "44/44 [==============================] - 25s 534ms/step - loss: 38.3722 - mae: 5.1869 - val_loss: 38.2318 - val_mae: 5.1753\n",
            "Epoch 352/500\n",
            "44/44 [==============================] - 21s 463ms/step - loss: 38.4575 - mae: 5.1918 - val_loss: 38.1848 - val_mae: 5.1947\n",
            "Epoch 353/500\n",
            "44/44 [==============================] - 28s 587ms/step - loss: 38.1820 - mae: 5.1716 - val_loss: 38.3959 - val_mae: 5.1957\n",
            "Epoch 354/500\n",
            "44/44 [==============================] - 20s 424ms/step - loss: 38.3024 - mae: 5.1902 - val_loss: 37.1649 - val_mae: 5.1110\n",
            "Epoch 355/500\n",
            "44/44 [==============================] - 28s 544ms/step - loss: 38.0651 - mae: 5.1750 - val_loss: 37.2971 - val_mae: 5.0981\n",
            "Epoch 356/500\n",
            "44/44 [==============================] - 27s 581ms/step - loss: 37.8599 - mae: 5.1570 - val_loss: 37.7616 - val_mae: 5.1307\n",
            "Epoch 357/500\n",
            "44/44 [==============================] - 26s 571ms/step - loss: 37.7510 - mae: 5.1520 - val_loss: 37.4164 - val_mae: 5.1419\n",
            "Epoch 358/500\n",
            "44/44 [==============================] - 26s 575ms/step - loss: 37.7952 - mae: 5.1608 - val_loss: 37.5944 - val_mae: 5.1300\n",
            "Epoch 359/500\n",
            "44/44 [==============================] - 23s 496ms/step - loss: 37.4659 - mae: 5.1283 - val_loss: 36.8100 - val_mae: 5.0995\n",
            "Epoch 360/500\n",
            "44/44 [==============================] - 21s 432ms/step - loss: 37.8019 - mae: 5.1631 - val_loss: 37.2111 - val_mae: 5.1124\n",
            "Epoch 361/500\n",
            "44/44 [==============================] - 31s 643ms/step - loss: 37.7211 - mae: 5.1540 - val_loss: 37.7290 - val_mae: 5.1599\n",
            "Epoch 362/500\n",
            "44/44 [==============================] - 26s 533ms/step - loss: 37.6849 - mae: 5.1528 - val_loss: 37.3188 - val_mae: 5.1301\n",
            "Epoch 363/500\n",
            "44/44 [==============================] - 25s 543ms/step - loss: 37.2426 - mae: 5.1268 - val_loss: 37.3989 - val_mae: 5.1312\n",
            "Epoch 364/500\n",
            "44/44 [==============================] - 20s 430ms/step - loss: 37.2753 - mae: 5.1280 - val_loss: 36.7819 - val_mae: 5.0965\n",
            "Epoch 365/500\n",
            "44/44 [==============================] - 27s 576ms/step - loss: 37.4830 - mae: 5.1537 - val_loss: 37.5308 - val_mae: 5.1408\n",
            "Epoch 366/500\n",
            "44/44 [==============================] - 25s 546ms/step - loss: 37.1204 - mae: 5.1242 - val_loss: 36.3448 - val_mae: 5.0438\n",
            "Epoch 367/500\n",
            "44/44 [==============================] - 26s 565ms/step - loss: 37.0865 - mae: 5.1183 - val_loss: 37.0719 - val_mae: 5.1278\n",
            "Epoch 368/500\n",
            "44/44 [==============================] - 26s 565ms/step - loss: 37.2962 - mae: 5.1398 - val_loss: 36.8576 - val_mae: 5.1081\n",
            "Epoch 369/500\n",
            "44/44 [==============================] - 22s 480ms/step - loss: 37.2003 - mae: 5.1370 - val_loss: 36.1915 - val_mae: 5.0431\n",
            "Epoch 370/500\n",
            "44/44 [==============================] - 27s 541ms/step - loss: 36.7036 - mae: 5.0942 - val_loss: 36.9579 - val_mae: 5.1169\n",
            "Epoch 371/500\n",
            "44/44 [==============================] - 28s 606ms/step - loss: 36.9076 - mae: 5.1212 - val_loss: 37.5299 - val_mae: 5.1687\n",
            "Epoch 372/500\n",
            "44/44 [==============================] - 26s 572ms/step - loss: 36.5349 - mae: 5.0935 - val_loss: 36.4518 - val_mae: 5.0682\n",
            "Epoch 373/500\n",
            "44/44 [==============================] - 27s 592ms/step - loss: 36.4160 - mae: 5.0886 - val_loss: 36.6487 - val_mae: 5.1049\n",
            "Epoch 374/500\n",
            "44/44 [==============================] - 26s 575ms/step - loss: 36.6240 - mae: 5.0987 - val_loss: 36.5171 - val_mae: 5.0772\n",
            "Epoch 375/500\n",
            "44/44 [==============================] - 26s 561ms/step - loss: 36.2792 - mae: 5.0760 - val_loss: 36.5008 - val_mae: 5.0817\n",
            "Epoch 376/500\n",
            "44/44 [==============================] - 25s 546ms/step - loss: 36.4771 - mae: 5.0879 - val_loss: 36.0605 - val_mae: 5.0758\n",
            "Epoch 377/500\n",
            "44/44 [==============================] - 27s 586ms/step - loss: 36.3087 - mae: 5.0827 - val_loss: 35.6471 - val_mae: 5.0229\n",
            "Epoch 378/500\n",
            "44/44 [==============================] - 25s 550ms/step - loss: 36.1063 - mae: 5.0623 - val_loss: 36.1431 - val_mae: 5.0660\n",
            "Epoch 379/500\n",
            "44/44 [==============================] - 26s 557ms/step - loss: 36.1506 - mae: 5.0686 - val_loss: 36.5491 - val_mae: 5.0910\n",
            "Epoch 380/500\n",
            "44/44 [==============================] - 27s 559ms/step - loss: 35.9915 - mae: 5.0645 - val_loss: 35.6018 - val_mae: 5.0361\n",
            "Epoch 381/500\n",
            "44/44 [==============================] - 27s 569ms/step - loss: 36.1105 - mae: 5.0730 - val_loss: 36.2102 - val_mae: 5.0802\n",
            "Epoch 382/500\n",
            "44/44 [==============================] - 26s 544ms/step - loss: 35.8215 - mae: 5.0488 - val_loss: 35.8680 - val_mae: 5.0549\n",
            "Epoch 383/500\n",
            "44/44 [==============================] - 25s 546ms/step - loss: 36.1439 - mae: 5.0757 - val_loss: 35.6421 - val_mae: 5.0535\n",
            "Epoch 384/500\n",
            "44/44 [==============================] - 27s 597ms/step - loss: 35.7435 - mae: 5.0450 - val_loss: 36.1129 - val_mae: 5.0850\n",
            "Epoch 385/500\n",
            "44/44 [==============================] - 26s 575ms/step - loss: 35.7831 - mae: 5.0539 - val_loss: 35.2097 - val_mae: 5.0082\n",
            "Epoch 386/500\n",
            "44/44 [==============================] - 25s 544ms/step - loss: 35.5796 - mae: 5.0365 - val_loss: 35.4657 - val_mae: 5.0226\n",
            "Epoch 387/500\n",
            "44/44 [==============================] - 20s 427ms/step - loss: 35.5995 - mae: 5.0413 - val_loss: 36.3736 - val_mae: 5.1007\n",
            "Epoch 388/500\n",
            "44/44 [==============================] - 27s 576ms/step - loss: 35.6216 - mae: 5.0478 - val_loss: 35.2295 - val_mae: 5.0001\n",
            "Epoch 389/500\n",
            "44/44 [==============================] - 27s 599ms/step - loss: 35.4032 - mae: 5.0301 - val_loss: 35.5277 - val_mae: 5.0301\n",
            "Epoch 390/500\n",
            "44/44 [==============================] - 21s 456ms/step - loss: 35.1695 - mae: 5.0132 - val_loss: 35.4095 - val_mae: 5.0380\n",
            "Epoch 391/500\n",
            "44/44 [==============================] - 26s 529ms/step - loss: 35.4853 - mae: 5.0369 - val_loss: 35.3085 - val_mae: 5.0138\n",
            "Epoch 392/500\n",
            "44/44 [==============================] - 26s 563ms/step - loss: 35.3318 - mae: 5.0267 - val_loss: 35.2146 - val_mae: 5.0276\n",
            "Epoch 393/500\n",
            "44/44 [==============================] - 26s 563ms/step - loss: 35.0246 - mae: 5.0106 - val_loss: 35.2833 - val_mae: 5.0156\n",
            "Epoch 394/500\n",
            "44/44 [==============================] - 22s 473ms/step - loss: 35.1964 - mae: 5.0232 - val_loss: 35.1167 - val_mae: 5.0241\n",
            "Epoch 395/500\n",
            "44/44 [==============================] - 19s 411ms/step - loss: 34.9825 - mae: 5.0034 - val_loss: 35.0370 - val_mae: 5.0159\n",
            "Epoch 396/500\n",
            "44/44 [==============================] - 28s 547ms/step - loss: 34.9889 - mae: 5.0059 - val_loss: 34.9996 - val_mae: 5.0068\n",
            "Epoch 397/500\n",
            "44/44 [==============================] - 27s 589ms/step - loss: 34.8098 - mae: 4.9978 - val_loss: 34.4446 - val_mae: 4.9783\n",
            "Epoch 398/500\n",
            "44/44 [==============================] - 27s 600ms/step - loss: 34.9754 - mae: 5.0097 - val_loss: 35.0166 - val_mae: 5.0125\n",
            "Epoch 399/500\n",
            "44/44 [==============================] - 28s 607ms/step - loss: 34.8926 - mae: 5.0084 - val_loss: 35.2732 - val_mae: 5.0388\n",
            "Epoch 400/500\n",
            "44/44 [==============================] - 26s 560ms/step - loss: 34.4632 - mae: 4.9694 - val_loss: 35.0590 - val_mae: 5.0170\n",
            "Epoch 401/500\n",
            "44/44 [==============================] - 26s 559ms/step - loss: 34.6764 - mae: 4.9862 - val_loss: 33.8605 - val_mae: 4.9077\n",
            "Epoch 402/500\n",
            "44/44 [==============================] - 20s 426ms/step - loss: 34.4517 - mae: 4.9741 - val_loss: 34.5443 - val_mae: 4.9754\n",
            "Epoch 403/500\n",
            "44/44 [==============================] - 27s 574ms/step - loss: 34.5712 - mae: 4.9888 - val_loss: 34.6731 - val_mae: 4.9834\n",
            "Epoch 404/500\n",
            "44/44 [==============================] - 26s 576ms/step - loss: 34.3657 - mae: 4.9682 - val_loss: 34.9237 - val_mae: 5.0131\n",
            "Epoch 405/500\n",
            "44/44 [==============================] - 27s 599ms/step - loss: 34.4583 - mae: 4.9799 - val_loss: 34.5869 - val_mae: 4.9883\n",
            "Epoch 406/500\n",
            "44/44 [==============================] - 27s 593ms/step - loss: 34.2328 - mae: 4.9576 - val_loss: 35.1094 - val_mae: 5.0122\n",
            "Epoch 407/500\n",
            "44/44 [==============================] - 26s 569ms/step - loss: 34.2325 - mae: 4.9582 - val_loss: 34.4314 - val_mae: 4.9684\n",
            "Epoch 408/500\n",
            "44/44 [==============================] - 24s 536ms/step - loss: 34.4346 - mae: 4.9745 - val_loss: 34.6064 - val_mae: 4.9886\n",
            "Epoch 409/500\n",
            "44/44 [==============================] - 25s 551ms/step - loss: 34.3757 - mae: 4.9752 - val_loss: 34.2588 - val_mae: 4.9735\n",
            "Epoch 410/500\n",
            "44/44 [==============================] - 27s 550ms/step - loss: 33.9658 - mae: 4.9441 - val_loss: 34.3529 - val_mae: 4.9614\n",
            "Epoch 411/500\n",
            "44/44 [==============================] - 25s 547ms/step - loss: 34.0329 - mae: 4.9478 - val_loss: 34.0478 - val_mae: 4.9645\n",
            "Epoch 412/500\n",
            "44/44 [==============================] - 25s 550ms/step - loss: 33.9660 - mae: 4.9441 - val_loss: 34.1767 - val_mae: 4.9587\n",
            "Epoch 413/500\n",
            "44/44 [==============================] - 27s 585ms/step - loss: 34.0967 - mae: 4.9520 - val_loss: 34.4142 - val_mae: 4.9932\n",
            "Epoch 414/500\n",
            "44/44 [==============================] - 24s 534ms/step - loss: 33.7803 - mae: 4.9321 - val_loss: 33.7023 - val_mae: 4.9061\n",
            "Epoch 415/500\n",
            "44/44 [==============================] - 25s 540ms/step - loss: 34.1235 - mae: 4.9627 - val_loss: 33.7319 - val_mae: 4.9243\n",
            "Epoch 416/500\n",
            "44/44 [==============================] - 24s 529ms/step - loss: 33.8992 - mae: 4.9441 - val_loss: 33.8647 - val_mae: 4.9607\n",
            "Epoch 417/500\n",
            "44/44 [==============================] - 25s 544ms/step - loss: 33.8870 - mae: 4.9445 - val_loss: 33.8844 - val_mae: 4.9465\n",
            "Epoch 418/500\n",
            "44/44 [==============================] - 27s 587ms/step - loss: 33.6127 - mae: 4.9314 - val_loss: 34.6312 - val_mae: 5.0255\n",
            "Epoch 419/500\n",
            "44/44 [==============================] - 24s 528ms/step - loss: 33.6319 - mae: 4.9282 - val_loss: 33.6999 - val_mae: 4.9196\n",
            "Epoch 420/500\n",
            "44/44 [==============================] - 26s 538ms/step - loss: 33.7528 - mae: 4.9375 - val_loss: 33.2753 - val_mae: 4.8919\n",
            "Epoch 421/500\n",
            "44/44 [==============================] - 27s 595ms/step - loss: 33.5113 - mae: 4.9222 - val_loss: 32.9981 - val_mae: 4.8777\n",
            "Epoch 422/500\n",
            "44/44 [==============================] - 27s 594ms/step - loss: 33.3655 - mae: 4.9116 - val_loss: 33.8155 - val_mae: 4.9576\n",
            "Epoch 423/500\n",
            "44/44 [==============================] - 26s 560ms/step - loss: 33.3515 - mae: 4.9152 - val_loss: 33.2729 - val_mae: 4.8986\n",
            "Epoch 424/500\n",
            "44/44 [==============================] - 25s 548ms/step - loss: 33.4512 - mae: 4.9253 - val_loss: 32.4044 - val_mae: 4.8354\n",
            "Epoch 425/500\n",
            "44/44 [==============================] - 20s 433ms/step - loss: 33.5263 - mae: 4.9373 - val_loss: 33.1023 - val_mae: 4.9020\n",
            "Epoch 426/500\n",
            "44/44 [==============================] - 29s 558ms/step - loss: 33.2291 - mae: 4.9038 - val_loss: 33.2819 - val_mae: 4.9201\n",
            "Epoch 427/500\n",
            "44/44 [==============================] - 21s 432ms/step - loss: 33.2296 - mae: 4.9092 - val_loss: 33.1068 - val_mae: 4.9069\n",
            "Epoch 428/500\n",
            "44/44 [==============================] - 25s 549ms/step - loss: 33.3486 - mae: 4.9314 - val_loss: 33.1911 - val_mae: 4.9053\n",
            "Epoch 429/500\n",
            "44/44 [==============================] - 26s 536ms/step - loss: 33.2347 - mae: 4.9097 - val_loss: 32.8336 - val_mae: 4.8941\n",
            "Epoch 430/500\n",
            "44/44 [==============================] - 27s 593ms/step - loss: 33.2120 - mae: 4.9184 - val_loss: 33.7538 - val_mae: 4.9772\n",
            "Epoch 431/500\n",
            "44/44 [==============================] - 27s 592ms/step - loss: 33.1714 - mae: 4.9148 - val_loss: 32.3182 - val_mae: 4.8388\n",
            "Epoch 432/500\n",
            "44/44 [==============================] - 25s 548ms/step - loss: 33.0268 - mae: 4.9034 - val_loss: 32.9705 - val_mae: 4.8979\n",
            "Epoch 433/500\n",
            "44/44 [==============================] - 22s 482ms/step - loss: 32.9814 - mae: 4.9093 - val_loss: 32.7675 - val_mae: 4.8957\n",
            "Epoch 434/500\n",
            "44/44 [==============================] - 22s 465ms/step - loss: 33.0847 - mae: 4.9133 - val_loss: 32.4696 - val_mae: 4.8662\n",
            "Epoch 435/500\n",
            "44/44 [==============================] - 25s 549ms/step - loss: 32.7942 - mae: 4.8970 - val_loss: 33.6500 - val_mae: 4.9817\n",
            "Epoch 436/500\n",
            "44/44 [==============================] - 25s 537ms/step - loss: 32.7524 - mae: 4.8825 - val_loss: 32.8312 - val_mae: 4.9040\n",
            "Epoch 437/500\n",
            "44/44 [==============================] - 25s 550ms/step - loss: 32.7310 - mae: 4.8849 - val_loss: 32.7214 - val_mae: 4.8924\n",
            "Epoch 438/500\n",
            "44/44 [==============================] - 26s 561ms/step - loss: 32.8053 - mae: 4.8963 - val_loss: 32.7800 - val_mae: 4.8928\n",
            "Epoch 439/500\n",
            "44/44 [==============================] - 21s 457ms/step - loss: 32.6090 - mae: 4.8838 - val_loss: 32.1282 - val_mae: 4.8363\n",
            "Epoch 440/500\n",
            "44/44 [==============================] - 30s 610ms/step - loss: 32.7375 - mae: 4.8984 - val_loss: 33.3056 - val_mae: 4.9519\n",
            "Epoch 441/500\n",
            "44/44 [==============================] - 25s 523ms/step - loss: 32.6953 - mae: 4.8919 - val_loss: 32.9802 - val_mae: 4.9325\n",
            "Epoch 442/500\n",
            "44/44 [==============================] - 26s 578ms/step - loss: 32.5097 - mae: 4.8818 - val_loss: 32.8484 - val_mae: 4.9099\n",
            "Epoch 443/500\n",
            "44/44 [==============================] - 28s 610ms/step - loss: 32.7219 - mae: 4.9008 - val_loss: 32.5244 - val_mae: 4.8909\n",
            "Epoch 444/500\n",
            "44/44 [==============================] - 26s 569ms/step - loss: 32.4572 - mae: 4.8757 - val_loss: 32.2742 - val_mae: 4.8742\n",
            "Epoch 445/500\n",
            "44/44 [==============================] - 25s 538ms/step - loss: 32.5403 - mae: 4.8861 - val_loss: 32.1233 - val_mae: 4.8554\n",
            "Epoch 446/500\n",
            "44/44 [==============================] - 25s 557ms/step - loss: 32.2610 - mae: 4.8618 - val_loss: 32.7907 - val_mae: 4.9046\n",
            "Epoch 447/500\n",
            "44/44 [==============================] - 29s 643ms/step - loss: 32.3284 - mae: 4.8697 - val_loss: 32.2016 - val_mae: 4.8594\n",
            "Epoch 448/500\n",
            "44/44 [==============================] - 25s 550ms/step - loss: 32.2646 - mae: 4.8595 - val_loss: 32.5612 - val_mae: 4.8782\n",
            "Epoch 449/500\n",
            "44/44 [==============================] - 24s 532ms/step - loss: 32.2689 - mae: 4.8636 - val_loss: 32.5868 - val_mae: 4.9139\n",
            "Epoch 450/500\n",
            "44/44 [==============================] - 26s 558ms/step - loss: 32.3634 - mae: 4.8817 - val_loss: 32.5543 - val_mae: 4.8938\n",
            "Epoch 451/500\n",
            "44/44 [==============================] - 24s 534ms/step - loss: 32.1302 - mae: 4.8604 - val_loss: 32.0408 - val_mae: 4.8652\n",
            "Epoch 452/500\n",
            "44/44 [==============================] - 20s 431ms/step - loss: 32.2590 - mae: 4.8713 - val_loss: 32.3121 - val_mae: 4.8763\n",
            "Epoch 453/500\n",
            "44/44 [==============================] - 28s 582ms/step - loss: 32.1502 - mae: 4.8623 - val_loss: 32.1791 - val_mae: 4.8662\n",
            "Epoch 454/500\n",
            "44/44 [==============================] - 27s 585ms/step - loss: 32.1311 - mae: 4.8652 - val_loss: 32.3338 - val_mae: 4.8715\n",
            "Epoch 455/500\n",
            "44/44 [==============================] - 26s 570ms/step - loss: 32.1048 - mae: 4.8547 - val_loss: 31.8527 - val_mae: 4.8394\n",
            "Epoch 456/500\n",
            "44/44 [==============================] - 25s 554ms/step - loss: 32.1028 - mae: 4.8609 - val_loss: 31.9887 - val_mae: 4.8506\n",
            "Epoch 457/500\n",
            "44/44 [==============================] - 24s 531ms/step - loss: 32.0373 - mae: 4.8572 - val_loss: 31.2675 - val_mae: 4.7971\n",
            "Epoch 458/500\n",
            "44/44 [==============================] - 25s 556ms/step - loss: 32.1940 - mae: 4.8729 - val_loss: 31.7191 - val_mae: 4.8116\n",
            "Epoch 459/500\n",
            "44/44 [==============================] - 21s 446ms/step - loss: 31.9405 - mae: 4.8503 - val_loss: 32.0652 - val_mae: 4.8536\n",
            "Epoch 460/500\n",
            "44/44 [==============================] - 27s 558ms/step - loss: 32.0679 - mae: 4.8614 - val_loss: 31.6496 - val_mae: 4.8197\n",
            "Epoch 461/500\n",
            "44/44 [==============================] - 28s 632ms/step - loss: 31.8778 - mae: 4.8448 - val_loss: 31.7729 - val_mae: 4.8356\n",
            "Epoch 462/500\n",
            "44/44 [==============================] - 27s 586ms/step - loss: 31.7277 - mae: 4.8342 - val_loss: 32.5774 - val_mae: 4.9208\n",
            "Epoch 463/500\n",
            "44/44 [==============================] - 29s 648ms/step - loss: 31.8054 - mae: 4.8397 - val_loss: 31.7189 - val_mae: 4.8464\n",
            "Epoch 464/500\n",
            "44/44 [==============================] - 27s 582ms/step - loss: 31.7216 - mae: 4.8354 - val_loss: 31.4491 - val_mae: 4.8198\n",
            "Epoch 465/500\n",
            "44/44 [==============================] - 25s 547ms/step - loss: 31.7812 - mae: 4.8368 - val_loss: 31.9310 - val_mae: 4.8730\n",
            "Epoch 466/500\n",
            "44/44 [==============================] - 25s 551ms/step - loss: 31.6119 - mae: 4.8210 - val_loss: 32.1166 - val_mae: 4.8655\n",
            "Epoch 467/500\n",
            "44/44 [==============================] - 25s 544ms/step - loss: 31.9200 - mae: 4.8642 - val_loss: 31.7396 - val_mae: 4.8136\n",
            "Epoch 468/500\n",
            "44/44 [==============================] - 26s 559ms/step - loss: 31.7105 - mae: 4.8402 - val_loss: 31.4294 - val_mae: 4.8210\n",
            "Epoch 469/500\n",
            "44/44 [==============================] - 25s 551ms/step - loss: 31.8077 - mae: 4.8464 - val_loss: 32.0499 - val_mae: 4.8607\n",
            "Epoch 470/500\n",
            "44/44 [==============================] - 27s 589ms/step - loss: 31.5402 - mae: 4.8256 - val_loss: 32.0643 - val_mae: 4.8765\n",
            "Epoch 471/500\n",
            "44/44 [==============================] - 25s 551ms/step - loss: 31.6028 - mae: 4.8324 - val_loss: 31.4645 - val_mae: 4.8211\n",
            "Epoch 472/500\n",
            "44/44 [==============================] - 25s 548ms/step - loss: 31.5259 - mae: 4.8295 - val_loss: 31.3424 - val_mae: 4.8171\n",
            "Epoch 473/500\n",
            "44/44 [==============================] - 24s 529ms/step - loss: 31.3162 - mae: 4.8069 - val_loss: 31.3453 - val_mae: 4.8137\n",
            "Epoch 474/500\n",
            "44/44 [==============================] - 25s 557ms/step - loss: 30.4354 - mae: 4.6923 - val_loss: 25.0536 - val_mae: 4.1098\n",
            "Epoch 475/500\n",
            "44/44 [==============================] - 22s 446ms/step - loss: 26.6769 - mae: 4.2006 - val_loss: 24.7521 - val_mae: 4.0118\n",
            "Epoch 476/500\n",
            "44/44 [==============================] - 27s 578ms/step - loss: 25.2290 - mae: 4.0509 - val_loss: 23.3725 - val_mae: 3.8383\n",
            "Epoch 477/500\n",
            "44/44 [==============================] - 26s 573ms/step - loss: 24.7867 - mae: 3.9854 - val_loss: 24.0812 - val_mae: 3.9324\n",
            "Epoch 478/500\n",
            "44/44 [==============================] - 27s 595ms/step - loss: 24.0592 - mae: 3.9142 - val_loss: 24.1473 - val_mae: 3.8986\n",
            "Epoch 479/500\n",
            "44/44 [==============================] - 26s 564ms/step - loss: 24.1440 - mae: 3.9311 - val_loss: 22.8940 - val_mae: 3.8044\n",
            "Epoch 480/500\n",
            "44/44 [==============================] - 27s 596ms/step - loss: 24.1343 - mae: 3.9274 - val_loss: 23.0893 - val_mae: 3.8312\n",
            "Epoch 481/500\n",
            "44/44 [==============================] - 25s 544ms/step - loss: 24.0086 - mae: 3.8956 - val_loss: 22.8833 - val_mae: 3.7995\n",
            "Epoch 482/500\n",
            "44/44 [==============================] - 26s 570ms/step - loss: 23.6585 - mae: 3.8646 - val_loss: 23.1060 - val_mae: 3.8088\n",
            "Epoch 483/500\n",
            "44/44 [==============================] - 25s 549ms/step - loss: 23.4141 - mae: 3.8487 - val_loss: 22.7703 - val_mae: 3.7110\n",
            "Epoch 484/500\n",
            "44/44 [==============================] - 27s 592ms/step - loss: 23.4501 - mae: 3.8354 - val_loss: 22.4139 - val_mae: 3.7061\n",
            "Epoch 485/500\n",
            "44/44 [==============================] - 27s 597ms/step - loss: 23.4511 - mae: 3.8624 - val_loss: 23.0321 - val_mae: 3.7376\n",
            "Epoch 486/500\n",
            "44/44 [==============================] - 25s 549ms/step - loss: 23.0286 - mae: 3.8040 - val_loss: 22.3394 - val_mae: 3.6873\n",
            "Epoch 487/500\n",
            "44/44 [==============================] - 28s 608ms/step - loss: 22.9364 - mae: 3.7863 - val_loss: 22.1296 - val_mae: 3.6454\n",
            "Epoch 488/500\n",
            "44/44 [==============================] - 26s 578ms/step - loss: 22.6126 - mae: 3.7640 - val_loss: 22.7357 - val_mae: 3.7208\n",
            "Epoch 489/500\n",
            "44/44 [==============================] - 26s 557ms/step - loss: 23.0496 - mae: 3.8294 - val_loss: 22.1936 - val_mae: 3.6543\n",
            "Epoch 490/500\n",
            "44/44 [==============================] - 25s 550ms/step - loss: 22.7537 - mae: 3.7925 - val_loss: 20.9888 - val_mae: 3.5529\n",
            "Epoch 491/500\n",
            "44/44 [==============================] - 27s 597ms/step - loss: 22.7350 - mae: 3.7853 - val_loss: 21.4262 - val_mae: 3.5870\n",
            "Epoch 492/500\n",
            "44/44 [==============================] - 25s 555ms/step - loss: 22.6168 - mae: 3.7770 - val_loss: 21.1525 - val_mae: 3.5695\n",
            "Epoch 493/500\n",
            "44/44 [==============================] - 25s 540ms/step - loss: 22.2181 - mae: 3.7400 - val_loss: 21.4380 - val_mae: 3.6104\n",
            "Epoch 494/500\n",
            "44/44 [==============================] - 26s 591ms/step - loss: 21.9179 - mae: 3.6980 - val_loss: 21.5158 - val_mae: 3.5898\n",
            "Epoch 495/500\n",
            "44/44 [==============================] - 25s 556ms/step - loss: 22.1472 - mae: 3.7488 - val_loss: 22.3609 - val_mae: 3.6537\n",
            "Epoch 496/500\n",
            "44/44 [==============================] - 21s 454ms/step - loss: 22.1299 - mae: 3.7459 - val_loss: 21.3428 - val_mae: 3.5788\n",
            "Epoch 497/500\n",
            "44/44 [==============================] - 24s 480ms/step - loss: 21.7887 - mae: 3.7136 - val_loss: 21.2955 - val_mae: 3.6399\n",
            "Epoch 498/500\n",
            "44/44 [==============================] - 25s 535ms/step - loss: 21.8541 - mae: 3.7148 - val_loss: 20.5391 - val_mae: 3.5430\n",
            "Epoch 499/500\n",
            "44/44 [==============================] - 21s 431ms/step - loss: 21.5580 - mae: 3.6748 - val_loss: 20.3129 - val_mae: 3.4925\n",
            "Epoch 500/500\n",
            "44/44 [==============================] - 29s 607ms/step - loss: 21.5099 - mae: 3.6815 - val_loss: 21.0789 - val_mae: 3.5658\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "mae = history.history['mae']\n",
        "val_mae = history.history['val_mae']\n",
        "\n",
        "\n",
        "epochs_x = range(len(loss))\n",
        "\n",
        "\n",
        "plt.plot(epochs_x, mae, 'co', label='Training MAE')\n",
        "plt.plot(epochs_x, val_mae, 'k', label='Validation MAE')\n",
        "plt.title('Training and validation MeanAbsoluteError')\n",
        "plt.legend()\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(epochs_x, loss, 'co', label='Training loss')\n",
        "plt.plot(epochs_x, val_loss, 'k', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Y3K89-CM-dfg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545
        },
        "outputId": "da42a5d6-8da3-4033-b859-bfb3e33c997b"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAEICAYAAACktLTqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3dd3xVVbbA8d9KCEEIRQJcgdCiaUpJ6EU0iI6i2MuooYlK0VGxjINiQR3GYcb3RHwmiiKgRMHREVGwEYiAOCAgg2BCEYlCIELoLZCw3x/73JubSkjPzfp+Pvnce2r2SVnZWWeftcUYg1JKKd/iV9UNUEopVf40uCullA/S4K6UUj5Ig7tSSvkgDe5KKeWDNLgrpZQP0uCuzkhEPheR4eW9b1USke0icnkFnNeIyAXO+9dF5OmS7FuKzxMnIl+Vtp3FnDdWRHaU93lV5atT1Q1QFUNEjngt1geygBxnebQxJrGk5zLGDKqIfX2dMWZMeZxHRNoDvwABxphs59yJQIm/h6r20eDuo4wxQe73IrIduMcYsyj/fiJSxx0wlFK+Q9MytYz7324R+YuI7AZmiMi5IvKZiOwRkf3O+xCvY5JF5B7n/QgRWS4iLzn7/iIig0q5bwcRWSoih0VkkYi8JiKzi2h3Sdr4goh865zvKxFp5rV9qIikiUimiEwo5uvTS0R2i4i/17obRWS9876niHwnIgdEZJeI/J+I1C3iXDNF5K9ey392jkkXkZH59r1GRH4QkUMi8puITPTavNR5PSAiR0Skj/tr63V8XxH5XkQOOq99S/q1KY6IRDnHHxCRjSJynde2q0XkJ+ecO0XkMWd9M+f7c0BE9onIMhHRWFPJ9AteO50HNAXaAaOwPwcznOW2wHHg/4o5vhewCWgG/AOYLiJSin3fA1YBwcBEYGgxn7MkbbwTuAtoAdQF3MHmQiDBOX8r5/OFUAhjzErgKHBZvvO+57zPAR52rqcPMBC4r5h247ThKqc9VwBhQP58/1FgGNAEuAYYKyI3ONsucV6bGGOCjDHf5Tt3U2ABMNW5tv8FFohIcL5rKPC1OUObA4BPga+c4x4AEkUkwtllOjbF1xDoCCx21j8K7ACaAy7gSUDrnFQyDe6102ngWWNMljHmuDEm0xjzkTHmmDHmMDAJuLSY49OMMW8aY3KAWUBL7C9xifcVkbZAD+AZY8xJY8xyYH5Rn7CEbZxhjNlsjDkOfABEO+tvAT4zxiw1xmQBTztfg6K8D9wBICINgauddRhj1hhj/mOMyTbGbAfeKKQdhbnNad8GY8xR7B8z7+tLNsb8aIw5bYxZ73y+kpwX7B+DLcaYd512vQ+kAtd67VPU16Y4vYEg4O/O92gx8BnO1wY4BVwoIo2MMfuNMWu91rcE2hljThljlhktYlXpNLjXTnuMMSfcCyJSX0TecNIWh7BpgCbeqYl8drvfGGOOOW+DznLfVsA+r3UAvxXV4BK2cbfX+2NebWrlfW4nuGYW9bmwvfSbRCQQuAlYa4xJc9oR7qQcdjvt+Bu2F38medoApOW7vl4issRJOx0ExpTwvO5zp+Vblwa09lou6mtzxjYbY7z/EHqf92bsH740EflGRPo46/8JbAW+EpFtIjK+ZJehypMG99opfy/qUSAC6GWMaURuGqCoVEt52AU0FZH6XuvaFLN/Wdq4y/vczucMLmpnY8xP2CA2iLwpGbDpnVQgzGnHk6VpAza15O097H8ubYwxjYHXvc57pl5vOjZd5a0tsLME7TrTedvky5d7zmuM+d4Ycz02ZTMP+x8BxpjDxphHjTGhwHXAIyIysIxtUWdJg7sCaIjNYR9w8rfPVvQndHrCq4GJIlLX6fVdW8whZWnjh8BgEbnYufn5PGf+2X8PeAj7R+Rf+dpxCDgiIpHA2BK24QNghIhc6Pxxyd/+htj/ZE6ISE/sHxW3Pdg0UmgR514IhIvInSJSR0T+CFyITaGUxUpsL/9xEQkQkVjs92iO8z2LE5HGxphT2K/JaQARGSwiFzj3Vg5i71MUlwZTFUCDuwKYApwD7AX+A3xRSZ83DntTMhP4KzAXOx6/MKVuozFmI3A/NmDvAvZjb/gVx53zXmyM2eu1/jFs4D0MvOm0uSRt+Ny5hsXYlMXifLvcBzwvIoeBZ3B6wc6xx7D3GL51RqD0znfuTGAw9r+bTOBxYHC+dp81Y8xJbDAfhP26xwPDjDGpzi5Dge1OemoM9vsJ9obxIuAI8B0Qb4xZUpa2qLMnep9DVRciMhdINcZU+H8OSvk67bmrKiMiPUTkfBHxc4YKXo/N3SqlykifUFVV6Tzg39ibmzuAscaYH6q2SUr5Bk3LKKWUD9K0jFJK+aBqkZZp1qyZad++fVU3QymlapQ1a9bsNcY0L2xbtQju7du3Z/Xq1VXdDKWUqlFEJP+TyR6allFKKR+kwV0ppXyQBnellPJB1SLnrpSqfKdOnWLHjh2cOHHizDurKlWvXj1CQkIICAgo8TEa3JWqpXbs2EHDhg1p3749Rc+1oqqaMYbMzEx27NhBhw4dSnxcjU3LJGZk0P677/BLTqb9d9+RmJFR1U1SqkY5ceIEwcHBGtirOREhODj4rP/DqpE998SMDEZt2sSx07aKaFpWFqM2bQIgzlXUhEBKqfw0sNcMpfk+1cie+4Rt2zyB3e3Y6dNM2LatilqklFLVS40M7r9mFV7yu6j1SqnqJzMzk+joaKKjoznvvPNo3bq1Z/nkyZPFHrt69WoefPDBM36Ovn37lktbk5OTGTx4cLmcq7LUyLRM28BA0rKyIDsbjh2DRo0A+5cqMSNDUzNKVYDEjAwmbNvGr1lZtA0MZFJoaJl+14KDg1m3bh0AEydOJCgoiMcee8yzPTs7mzp1Cg9R3bt3p3v37mf8HCtWrCh1+2q6GtlznxQaSn0/P5g3D4YMgS++gN9+IwcYtWmT3lxVqpy573OlZWVhyL3PVd6/ayNGjGDMmDH06tWLxx9/nFWrVtGnTx9iYmLo27cvm5x7a9496YkTJzJy5EhiY2MJDQ1l6tSpnvMFBQV59o+NjeWWW24hMjKSuLg43BVxFy5cSGRkJN26dePBBx88Yw9937593HDDDXTu3JnevXuzfv16AL755hvPfx4xMTEcPnyYXbt2cckllxAdHU3Hjh1ZtmxZuX69ilMje+5xLhffHjxIQteu8O67MHmy3fDVVxwLCGDCtm3ae1eqHBV3n6u8f9d27NjBihUr8Pf359ChQyxbtow6deqwaNEinnzyST766KMCx6SmprJkyRIOHz5MREQEY8eOLTAm/IcffmDjxo20atWKfv368e2339K9e3dGjx7N0qVL6dChA3fccccZ2/fss88SExPDvHnzWLx4McOGDWPdunW89NJLvPbaa/Tr148jR45Qr149pk2bxpVXXsmECRPIycnh2LFj5fZ1OpMa2XMHWJiZCaGh4J1Tc4qPpWVl6fBIpcpRZd7nuvXWW/H39wfg4MGD3HrrrXTs2JGHH36YjRs3FnrMNddcQ2BgIM2aNaNFixZkFPK737NnT0JCQvDz8yM6Oprt27eTmppKaGioZ/x4SYL78uXLGTp0KACXXXYZmZmZHDp0iH79+vHII48wdepUDhw4QJ06dejRowczZsxg4sSJ/PjjjzRs2LC0X5azVmODu+eH6rzzcleuXet5m5aVxcjUVA3wSpWDtoGBZ7W+LBo0aOB5//TTTzNgwAA2bNjAp59+WuRY70Cvdvj7+5OdnV2qfcpi/PjxvPXWWxw/fpx+/fqRmprKJZdcwtKlS2ndujUjRozgnXfeKdfPWZwaG9w9P1Tt2uWu/PBD+OYbz+JJYxidmopSqmw897m81PfzY1JoaIV+3oMHD9K6dWsAZs6cWe7nj4iIYNu2bWzfvh2AuXPnnvGY/v37k5iYCNhcfrNmzWjUqBE///wznTp14i9/+Qs9evQgNTWVtLQ0XC4X9957L/fccw9rvTqgFa3GBvdJoaEIwKWXwiuv5KZnJk60I2gcR43R3rtSZRTncjEtIoJ2gYEI0C4wkGkRERV+b+vxxx/niSeeICYmptx72gDnnHMO8fHxXHXVVXTr1o2GDRvSuHHjYo+ZOHEia9asoXPnzowfP55Zs2YBMGXKFDp27Ejnzp0JCAhg0KBBJCcn06VLF2JiYpg7dy4PPfRQuV9DUarFHKrdu3c3pZms477Nm0lIT7cLH34Ir72WuzEsDDp3hj/9CQHejYrSm6xKeUlJSSEqKqqqm1Hljhw5QlBQEMYY7r//fsLCwnj44YerulkFFPb9EpE1xphCx4SesecuIm+LyO8issFrXVMR+VpEtjiv5zrrRUSmishWEVkvIl3LeD3Fig8PZ2CTJnbhxhvhgw/sTVaALVvgo4/g+HEMMDwlRXvwSqkC3nzzTaKjo7nooos4ePAgo0ePruomlYuSpGVmAlflWzceSDLGhAFJzjLAICDM+RgFJJRPM4u2KDraBnh/f2jeHP7xD/AeAuX8R5ADmn9XShXw8MMPs27dOn766ScSExOpX79+VTepXJwxuBtjlgL78q2+HpjlvJ8F3OC1/h1j/QdoIiIty6uxRVkUHc3sqCibgw8Ohrfegv79bZBfvtyz31FjkORkmi1frr14pZRPK+0NVZcxZpfzfjfgTma3Bn7z2m+Hs64AERklIqtFZPWePXtK2YxccS4X77rzUW3bwvPPQ2wsfPcd5OTk2TczO1uHSSqlfFqZR8sYe0f2rO/KGmOmGWO6G2O6N2/evKzNAGyAH9uqVe6Kiy+Gw4ft+PepU2HOHJuLxw6T1CqSSilfVdryAxki0tIYs8tJu/zurN8JtPHaL8RZV2niw8MB7CiaHj2gbl14/PG8Oz31FAwYoFUklVI+q7Q99/nAcOf9cOATr/XDnFEzvYGDXumbShMfHk4DETjnHLjlloI7/PWvMHAg5vhxTc0oVUUGDBjAl19+mWfdlClTGDt2bJHHxMbG4h42ffXVV3PgwIEC+0ycOJGXXnqp2M89b948fvrpJ8/yM888w6JFi86m+YWqTqWBSzIU8n3gOyBCRHaIyN3A34ErRGQLcLmzDLAQ2AZsBd4E7quQVpfAG5GR9uJGjoQXXih8p/R0HSKpVBW54447mDNnTp51c+bMKVF9F7DVHJu4h0KfpfzB/fnnn+fyyy8v1bmqq5KMlrnDGNPSGBNgjAkxxkw3xmQaYwYaY8KMMZcbY/Y5+xpjzP3GmPONMZ2MMWf/ZFI5iXO5eCcqCj9/f5t7j4sruNN335Hz6qvcu3Bh5TdQqVrulltuYcGCBZ6JObZv3056ejr9+/dn7NixdO/enYsuuohnn3220OPbt2/P3r17AZg0aRLh4eFcfPHFnrLAYMew9+jRgy5dunDzzTdz7NgxVqxYwfz58/nzn/9MdHQ0P//8MyNGjODDDz8EICkpiZiYGDp16sTIkSPJctK37du359lnn6Vr16506tSJ1DMMra7q0sA1suRvSbmfSB2akoIZOdLWfq9XD7ZuhXvvhenTATguQrOwMF4JC9OnWFWtNG7cOM/EGeUlOjqaKVOmFLm9adOm9OzZk88//5zrr7+eOXPmcNtttyEiTJo0iaZNm5KTk8PAgQNZv349nTt3LvQ8a9asYc6cOaxbt47s7Gy6du1Kt27dALjpppu49957AXjqqaeYPn06DzzwANdddx2DBw/mlnxp2xMnTjBixAiSkpIIDw9n2LBhJCQkMG7cOACaNWvG2rVriY+P56WXXuKtt94q8vqqujRwja0tU1JxLhdjWrUCPz8b2AHOPz/vTrt3k5mdrRN9KFXJvFMz3imZDz74gK5duxITE8PGjRvzpFDyW7ZsGTfeeCP169enUaNGXHfddZ5tGzZsoH///nTq1InExMQiSwa7bdq0iQ4dOhDuDMwYPnw4S5cu9Wy/6aabAOjWrZun2FhRqro0sE/33N3yjKABELGB/sQJOyZ+1y745huO9enD0JUroVcv7cGrWqW4HnZFuv7663n44YdZu3Ytx44do1u3bvzyyy+89NJLfP/995x77rmMGDGiyFK/ZzJixAjmzZtHly5dmDlzJsnJyWVqr7tscFlKBo8fP55rrrmGhQsX0q9fP7788ktPaeAFCxYwYsQIHnnkEYYNG1amtvp8z90tPjw87xj4V16BWbOgWzfYts1Wkxw6FHP99YyYP1978EpVgqCgIAYMGMDIkSM9vfZDhw7RoEEDGjduTEZGBp9//nmx57jkkkuYN28ex48f5/Dhw3z66aeebYcPH6Zly5acOnXKU6YXoGHDhhw+fLjAuSIiIti+fTtbt24F4N133+XSSy8t1bVVdWngWtFzd8vTg3fe55ns43c7XD979WpGh4dr712pSnDHHXdw4403etIz7hK5kZGRtGnThn79+hV7fNeuXfnjH/9Ily5daNGiBT169PBse+GFF+jVqxfNmzenV69enoB+++23c++99zJ16lTPjVSAevXqMWPGDG699Vays7Pp0aMHY8aMKdV1ued27dy5M/Xr189TGnjJkiX4+flx0UUXMWjQIObMmcM///lPAgICCAoKKpdJPWp0yd/SEu9/zVJS4L58IzavuQYefZR6fn68FRmpQV75JC35W7OUe8lfXxTszM8IQFQUtGiRd4cNG2D4cE68+y5DUlK4b/Pmym2gUkqVUa0M7q+Eh+e98NmzYdKk3OW0NPjtN1uLBpvG0Ry8UqomqZXB3f2Ak6cHHxAAF11UcEd/f3j9dfj5Zx7S3rvyQdUhLavOrDTfp1oZ3MEG+L39+zM7Ksp+ERo3hhtugO5e6atDh2DuXBg9mszlyxmrk30oH1KvXj0yMzM1wFdzxhgyMzOp535Op4Rq5Q3V/BIzMhiZksJJgORkeO65wnd89FEYPJh2gYFMCg3VG62qRjt16hQ7duwo9RhyVXnq1atHSEgIAd6zzFH8DdVaNRSyKHEuF3Eul51wu2lTuzI01AbzjRshPt6uy8wEIC0ri1FO/QoN8KqmCggIoEOHDlXdDFVBam1apjDx4eHc5v5hb9MGLrzQzubkZgw4T6UdO31a8/BKqWpLg3s+c6+9Fp54Ah57zK4IDs7dOGsWXHEF7N8PQGZOjo6iUUpVSxrcC9Hu2mshKMgu+PkVLDSWlGR78aBT9SmlqiUN7oWYFBpKfT+vL81bb0FkZO7ya6/BqlWAzb9r710pVd1ocC9EnMvFtIgI2jkV4AAYONA+zTpggF2ePNnWhQedzUkpVe3oUMgzSMzIYEhKSt6VV1xhb6w2agSffOJZPbZVK09xMqWUqmhaW6YM4lwuxrZqhXivdNdxPnTIk3sHW6ag4bJl2otXSlU5De4lEB8ezrve1dgefzz3/QMPwNGjnsUjOTk6o5NSqsppcC+hOJeL4DrOM1+DBsHChTBsmH3IKSkJjh+3H8Cx48cZ8v33Wk1SKVVlNLifhVfCwvAUCz7nHBg+3E7Xt2IFXHstPPIIzJwJV10F115LQnq6BnilVJXQ4H4W4lwuZkVF0UCcDLyfH4SEwMqVkJMDqan2QSe3X38lISKC5cuXV02DlVK1lgb3sxTncnHk0kuZ7c7Bh4QUvbMza/p906ZVQsuUUiqXBvdSco+i8TzcdPPNBXfavRuAH7OzNT2jlKpUGtzLID48nDHjxtmZnEaPtg82nXtu7g47d9pXPz8S0tNptny5jqJRSlUKDe5llBARwezLL7d1lnv2hH//GxIS7Eb3w0/OjOuZ2dmMSE3VAK+UqnAa3MtBnMvFjKio3JE07t57VpZ9PXQIjh2D8ePJTktjqJYrUEpVMA3u5cQ9ksYPwD3hh9v27Xbij5Ur4dVXMcCQlBTNwyulKowG93LknnhbAgLg009h8WLo29cGd/f8q86DTqDlCpRSFUeDezmLc7lsqYKgIBCxE29727gRvv3Ws3gkJ4eRmodXSpUzDe4VwDNMEuCmm+APf7DvGzWyr19+mWf/k8bopB9KqXKlwb2CxIeHMzsqigZhYXbavsWLbXng2FhYtgzuvBOmT4cjRwCd9EMpVb40uFcg99OsY1u1sikayB1Js2uXHR//l7/Atm3w5psM2bhRb7IqpcqFBvdKEB8enpumufJKO5rGHdh/+gnuvhveew927iQhPV178EqpMqtT1Q2oLeLDw+nXuDFDAD76yK50T8LtlpYGbdow1Hn4Kc7lqtQ2KqV8h/bcK1Gcy5V3XtbGjfOWK/jlFwAMdl7Wd3bu5PTp05XbSKWUT9DgXskmhYbmXeFO1wD8+KPnbQ4wPCSEUaNGVU7DlFI+pUzBXUQeFpGNIrJBRN4XkXoi0kFEVorIVhGZKyJ1y6uxviDPMEmwU/ZNngx33QXffw9ffAEvvwwHDwIwffp0vcmqlDprpQ7uItIaeBDobozpCPgDtwOTgZeNMRcA+4G7y6OhvsQ9TDLY3x/atrUFx26+2Y6DnzwZ5s+HKVM8+ye8/TaRSUlV2GKlVE1T1rRMHeAcEakD1Ad2AZcBHzrbZwE3lPFz+KQ4l4u9/fvn9uIbNLD1Z6KiICAAkpNzd548mU3PPEPQBRfw66+/Vkl7lVI1S6mDuzFmJ/AS8Cs2qB8E1gAHjDHZzm47gNaFHS8io0RktYis3rNnT2mbUePlGSZ5ySUQHw8PPFBwxxUrOPrzz7T78581TaOUOqOypGXOBa4HOgCtgAbAVSU93hgzzRjT3RjTvXnz5qVthk+IDw/PnZcVICam6J1/+UULjimlzqgsaZnLgV+MMXuMMaeAfwP9gCZOmgYgBNhZxjbWCm9ERuZ+M1p7/bPz8cfgPcJmzRrYvZsjOTncpXXhlVJFKEtw/xXoLSL1RUSAgcBPwBLgFmef4cAnZWti7eAuFxzs759bqgCgYcPc+vAuF5w+DcOGwYIFnAKd+EMpVaiy5NxXYm+crgV+dM41DfgL8IiIbAWCgenl0M5awX2T1cTG0ubOO6F+ffD3tzdbATp3tsH+1Cl44w04flwn/lBKFapMo2WMMc8aYyKNMR2NMUONMVnGmG3GmJ7GmAuMMbcaY7LKq7G1ya+JiQR98YVdcJcKvvpqO5IG7LysCxZ49n9da9IopbzoE6rV2Ovh4dQVsYXFpk6F6GjIdgYiNWoEc+d6Sga7e/Dtv/tOg7xSSoN7dRbncvF2ZCTBTZtCp052ZVSUfZ0wATIz7euHH8LJk4CtCz9q0yYN8ErVcloVspqLc7mIc7lIzMhgdGoqR596CjZvhq5dISQE1q+3Hw0awKBBkJ7OsZYtGaaVJZWq1bTnXkO4J/4IbtLEBnaAevVyd1i0CF58EeLi4NVXOY3eaFWqNtPgXsO8EhaGZ6Dk+efb1/BwWLsWvvrKLn/8MezfD0BCejrNli/XNI1StYwG9xomzuVijLtcwQMPwN//DoWVBXYHeiAzO5uh2otXqlbR4F4DuatK1q1fH3r1smmaa6+FP/0JZs2CCy6AlSthyRIYPRpycjDocEmlahO9oVpDuW+0Xr5uHUkHDsAjj+Ru7NIFPvsMfvjBLu/dCy6XZ4Yn9/FKKd+lPfcablF0NLOjovJ+Izt1giyvZ8d25pb3yQFGpqZqD14pH6fB3Qe469IEuFeEhOTdYcECyMmBffsAOGkMo1NTK7WNSqnKpWkZH+FOs4xOTeVoy5Z5Ny5ebEfP/PCDfaq1RQuOGoMkJxNcpw6vhIVpmkYpH6M9dx/iHgs/9oILoHFju9IdtN35988/zz3g2DEyf/qJ4c89x7u7dlVuY5VSFUqDuw+KDw+nRdu2tv5MYmLejTNnwt/+Zt8/+CCMHk1OQgL3z5hR6e1USlUcDe4+6pnRo+kxfLgtGew2fLh9/fprMAZ+/tmz6fDBg1y+bl0lt1IpVVE0uPuo+++/n1VTpzLbXWgMYOhQ6NvXvneeYPWYOpWk1FQN8Er5CA3uPi7O5WLlypXUmzTJ9uKvuMJumDs3744nTsC4cSQdOMA533zD0598QoozJl4pVfNocK8FevbsyVt3340/QLNmduUHH+QtPAaQkQEnTnAiO5u/3nADF3bsqOPhlaqhNLjXEnEuF7OiomjSokXuyhdfLLjjL7/AXXfZ96dP6wNPStVQGtxrkTiXi4wbbrAL556bO/EHwD//aV+ffx5++82+r1uXk8YwTCfhVqrG0eBey9StW5ekpCQSvv2WuoGBduXFF0OHDvb97t1w2WVw1VV2Sr+cHE7v36+14ZWqYTS410KXXXYZY6KiyIqN5dJly+DZZ6Fp09wdBgyAiAg4fRr+7//gppsgM5OE9HQkOVnrwytVA2hwr+WSL76Ygc2agQiMGGE/+vbNvfE6b5593b7dc0xmdrbm4pWq5jS4q9zKksOH2wed/Pxsz71+/dydXn0Vjh/3LJ40hgnbtlVBa5VSJaHBXQGFVJZs3hxefjl3h7Q0uPlm8HrIKe3jj+n35JOV2k6lVMmIMaaq20D37t3N6tWrq7oZCkjMyLCVJd0/F+np8N57tmywW0wMxMZ6gn/Q0qW8Hh6ulSWVqmQissYY073QbRrcVWGaLV9OZnZ27ooBA4reeckSAIL8/TXIK1WJigvumpZRhXolLIz6fl4/HvfdV3Cnzp3t68mTABzJyWGE3mhVqlrQ4K4KFedyMS0igmB3Vclbb4WEhNwdGjbMrVPz669w8CAA2T/+yL0LF1Zya5VS+elMTKpI7km4PXn4yEj48kt46SWIi4MdO+yO995rX2Ni4IcfOA6cExrKW5GRmqJRqopoz12dkXuGp9lRUVC3Ljz5JLRrZ0sYeHPP9gSceP11hvzrX/pUq1JVRIO7KrE4l4uxrVrlrmjSJPf9Lbfk3XnOHBg3joT0dK0Rr1QV0OCuzkp8eDhjW7VCwM7P2rs3tGxpUzPvvgvewT8nB4wh6ffftWyBUpVMh0KqUiswJh5g504YMiR3eeBA2LAB3n8fRKgrwtuai1eqXOhQSFUh3Ln4gd7pmdat4YEH4IIL7HJSkp0E5NAh2LKFkydP8pDm4ZWqcBrcVZktio7Om4u/6SaYNg3OOy933bx5MGoUfPQRmTk5yFdfEbR0qaZplKogGtxVuYgPD2d2VJTNxYOtMvncczB+vF2eOdO+pqbC4sVw5ZUc/Syezk4AABgLSURBVOILhqSk6A1XpSqABndVbuJcLt6NiqKue0V4OPTvn3enrVvhnXfse+c+S9KBA0hysg6bVKoclSm4i0gTEflQRFJFJEVE+ohIUxH5WkS2OK/nnvlMylfEuVxkxcbmpmnq14eQEPv+6qvtDde0NLv88895jtVhk0qVn7L23F8BvjDGRAJdgBRgPJBkjAkDkpxlVcu4h0wCMH06zJ8PN96Yu8OVV9ogf+xYnuOSDhyg4bJlmotXqoxKHdxFpDFwCTAdwBhz0hhzALgemOXsNgu4oayNVDWTOw9ft25dW4vm/PPthshIuP56Ow5+/vy8By1cyJFfftE5W5Uqo1KPcxeRaGAa8BO2174GeAjYaYxp4uwjwH73cr7jRwGjANq2bdstzf2vuvJJ923eTEJ6Ohw4APXq2Y/x42HlShg8GPbts2majAzo1g3++U/4+mtu69uXuYMHV3XzlaqWKqSeu4h0B/4D9DPGrBSRV4BDwAPewVxE9htjis2760NMtcvl69aRdOAAHDkCL7wAq1bl3aF9ezvr0//8D9SpA088wdghQ4gPD6+S9ipVXVXUQ0w7gB3GmJXO8odAVyBDRFo6n7gl8HsZPofyQe45WwkKgmeesb14b7/9Bl98Yd9nZ8MLL5Dw178y0KswmVKqeKUO7saY3cBvIhLhrBqITdHMB4Y764YDn5SphconxblcdlLuBg3gX/+CG5xbM40a2Vz8xo15D3j3XRbrmHilSqyso2UeABJFZD0QDfwN+DtwhYhsAS53lpUqwD0pd4OGDeHCC+3K7t1hyhTo0we6ds17wObNnjHxOqJGqeKVabIOY8w6oLB8z8CynFfVHu4JQYKzsti3dKmtLnneedCli52Ae+3a3J03bbITc2On9BuakuI5h1IqL31CVVULU7t0of6kSXnr0biHTk6aBGFhsHkzLF1qR9YAJiuLISkp+OnTrUoVoCV/VbWRmJHBQ5s3k5mTY1cYYwN6RISd2m/BAru+Y0ebvpk5E8aOhdtuA6CeiE7tp2oVLfmraoQ4l4u9/fszOyqKdoGBtvhYhHO/3nsY5IYNuYXIEhI8tWpOGOMpRLZz587KbbxS1YwGd1XtxLlcbO/TBxMbm1srvlevvNP6Qe7yjBk2wDtDJZM+/ZSQkBAaT5miN11VrVWmG6pKVbRF0dEkZmQwEjj54Yd2ZVaWnaP1pptgwgRbRnjGDNvTf+IJm8oBDqWkMDI1FdCbrqr20Z67qvY8lSbbtAF/f1tpcuRI23P/wx/g9Gm7ozHwt7/ZV8dJY3TmJ1UraXBXNYa7EFkDkdyVLVsW3PHAAft68CC8+SaZn32mDz+pWkdHy6ga677Nm0lYvx7uvNNO4ZeQkNuLB2jTxpYyAFiyJM+x7QIDmRQaqukaVaMVN1pGc+6qxooPD6df48bc9emnnAoMhN69YejQ3B3cgT0goMCxaVlZ3KUPQSkfpmkZVaPFuVycvPJKOzFISAg89VTuzE9up07ZFE0+p4AhKSk0W75cR9Uon6NpGeUzPDXjARYutDXh3dq2tfVqVq2CceNsWYMLL4SePT27BNepwythYdqTVzWGpmVUreBO04xMSeFk79525Q032AlBfv3VfgA8+SQcPWpH3bzwgqdAWWZ2NqM2bQI0VaNqPu25K590+bp1JKWmQrNmcOiQnfwDbI2aLVvy7rxggQ30XrQXr2oCLT+gap1F0dHMHjCABgEB0LQpTJ0Kzz0Hjz1WcOcNG+xomwkT4KefIDmZzNhYhqxapQXJVI2laRnls9zlhBMzMhjl58cx9zDJuDg4edJOEgLw6ae2N79lC2zbZicLycmBdetIaNiQhPR0gvz9eT08XHvyqsbQnrvyeXEuF9MiIgj297cr7rkHBnpNObB8uX19/HHYvRv27LHLP/wAa9bAvn2e+vE6qkbVFBrcVa1QoOJkeDjcf7+9oQp2Uu4rr7Tzurp98olN4zz2GOTkYI4e1QCvagy9oapqLc/QyQMHbBomOBi2boWdO23dmnHjCh60YAHUrUtQYKCmaVSVK+6GqgZ3Vau1/+470rKyCt/46KN5p/lza9wY5s0DQIAxrVoR711vXqlKoqNllCrCpNBQ6vsV8Wvwj3/AZ59BYiJ499APHvSMmTdAQno6olP9qWpGg7uq1dw3W9sFBiJAsL9/btVJf39o0ABatbL146Ojcw8cPtwOr1y/Ho4cgZ07SUhP55xvvtGcvKoWNC2jVBHylDMAePrp3JE1hRk3Dq6/HoCBTZqwyPuPgVIVQNMySpVCfHi4LUjm1qxZ7vumTeHGG/MeMHOmZ6KQpO3bka++ouGyZdqTV1VCH2JSqhjuG6UJ6elw9932ZmqfPnD++VCnjk3L/PwzXHYZLF4Me/fCpk22lx8Tw5H//V+GpKQwZvNmHV2jKpWmZZQqgcSMDB7avJnMnJy8G375xY6Hv+QSO7qmSxf4739zt7/4ov0jIGJr3AwYoBOFqHKjQyGVKieJGRlM2Lat4PDJw4fhuuvOfIKkJHBG52hJA1VWmnNXqpzEuVxs79MHExuLiY3Nzck3bAj9+uXd+bnnoFEjiIzMXffii5CcDMCRnByGpKTo/K6qQmjPXakySszIsDXks7Nhxw646y674csv7XBKf39br+a22/Ie+Kc/2VLE69dDSAhBzZtrT16dFe25K1WB4lwusmJjmd2pE3Xbt4eXX4Zhw6BuXRvYAZo3L3jgm2/CsWPw0EPw9NNanEyVK+25K1XOEjMyGJ2aytH8v1sff2wffHITgZYtIT3d3nSNibF15S+4ANCcvDozvaGqVBXwpGu8Vxpje+zvv1/4QVdcYacBzEcDvSqMpmWUqgKedE1UVG4teRHbO3/zTejVywZy74ejli2zqRqwE4fs3QvYm68jUlM1ZaNKTHvuSlWiQnvzr78Oc+faGjbp6bb3XreuLS/cvj3MmFHouXSeV6U9d6WqCe/efF33SnfP/fbbbfXJr7+2gR1g+3Y4cQLee8/ODLV2Ldx7LyxeTObx4wxJSdFqlKpQWn5AqSrgnt/1vs2bSYiIgHPPtWUNVq+GjAwYNMiWFl6xAuLj7Tyv3l54Af74Rxg0iIStW0lIT9eevMpDg7tSVSg+PJx+jRszunNnO7omONhu6NQJWrSwwT1/YHebO9d+ACxZQmZ2NkNSUpixa5dWpFQa3JWqau5ePMDejh0Z2KgR6wcMgIAAqF/f3mCdPBnOO8+Omx8ypOBJ9uyBd96BO+8k6fRpxHkKVnvztZfeUFWqmrpv82YSVqywgbtHj9wNAwYUf+CIEXDLLXaiES8a6H1PhY5zFxF/YDWw0xgzWEQ6AHOAYGANMNQYc7K4c2hwV6pw923ezOvp6eT5LT1TcAcIDbUPSF1zjc3lF0LHztd8FR3cHwG6A42c4P4B8G9jzBwReR34rzEmobhzaHBX6sw8ZYfXrIGcHJuyeecduPBCePtt27s/eTJvyWGwAb5RI5u/v+ACeOopzyYBZoaFcVPjxgQFBVXuBakyq7DgLiIhwCxgEvAIcC2wBzjPGJMtIn2AicaYK4s7jwZ3pUqu0PIGhw5BvXrw++824K9cadcV5quvbD4f4PhxOx9sUBDB77yjaZsapiKD+4fAi0BD4DFgBPAfY8wFzvY2wOfGmI6FHDsKGAXQtm3bbmlpaaVuh1K1VaEPRbkZY4P9jh3w2GN5t517rr1Ju307/O1vdt3ChXDOOQA6oUgNUSEPMYnIYOB3Y8ya0hxvjJlmjOlujOnevLCKeUqpM/J+KKqBSN6NIvahqK5doX9/ePhhaNPGbtu/Hx54IDewg03trLG/zmlZWQxJSUGSk2m2fLmWPaiBSt1zF5EXgaFANlAPaAR8DFyJpmWUqjJFVqV0273bPij12muwZQt0724fnnJ78klbAqEIfsDoVq0888uqqlPhVSFFJBZ4zLmh+i/gI68bquuNMfHFHa/BXamKUWygP37cTuZ94YXw0kv2Zux//gNZWbaH37s33HffGT+HpnCqTmUH91DsUMimwA/AEGNMVnHHa3BXqnLct3kzCenpRe9w/Dj8+c+wcaNdnjwZWre2D1Bt22Zz9d5VLL3o0MrKp/XclVIeZ0zbAHzyCUyZkrscGmqDO9hx83v3wquvQmAg/OMf0LgxjB7t2V0fmKocGtyVUoUqcrTN1q22+mRxRGDkSJg+3S4vXmzXFUKDfcXQ4K6UKpbnAamcnNyVq1ZBWJhN1cTF2Yehbr8dhg4t/CQNGsAdd9iJwD/+2B4bE5O7ffduaNoUqVuXMXpDtlxocFdKnZUCqZtdu+ywSj8/+OUX22P3FhQER47Y93372qdhwf5BCAuzT8g+/7xdzjfmXnv1pafBXSlVaokZGUzYto20LK9xEbt323z7J5/YHHx4uE3JPPOMnSqwOO+/b2/QFkGDfclpcFdKlZtib8ju2QNPPw0XX2ynB+zbF5YvL7hf5862sNmVV8JFF9nZp/bvt2kdf384dQrS0mwtHHRsfVE0uCulyl2hPfrCpKfbYmXdusH69dCzJyQn2/WnT+fd9+GH7Xr3JCSvvw4REQXPuW8fDZo1442IiFrdw9fgrpSqUCUO9N6OHLFB/n/+xy43alR4sbOYGHtDd8UKe0P3xAkYNgzuv9/WrfdS21I6GtyVUpWu0BE4hXnjDTut4Msv2/Hzw4dDly62JMJ77+XdNzYWDhyAdetsj37yZBvsvYP5yZM2/+9UvhTw2dE5GtyVUlWu2AqWAB98AAkJds5Yd235kychJQWWLLHBfufO3P3POcfe1D1wAL74AurUsfn6a6+FkBB7rrfftucYM8bWwD99OrfcMTW/p6/BXSlVbRSZwjHGBuA6RUztvGuXTc3ExNh977knd1u7dnZ7vXq5qZ23384dsrlwIbzyih27/9Zb0LRpidpa3YO/BnelVLVWopII+X3wgX069qTzv0BAgB1lUxjvfH6jRrZkQny8nb2qYUPo2BHOP7/gcTk5duKT3r3tGH8v1aGWjgZ3pVSNdMZCZ9nZdiTOypU2d9+iha2J8803uftcdpktjQBw9dW29753b8FztWljA/2DD9p8/r599rjXXrNlkMPDcycdz8qyBdWo2py+BnelVI3mTuX8mpVFfZG8Pfx9++CHH2wQF7GBNyEB/vhHG8Q7dbJB+oUXbKrGGHj8ccjMhA4dbDmF55/P+wmjo+1NW7cGDeDoUfvw1b599r+FGTOgfXvPLmOrIMBrcFdK+ZwSj8ZxO3bMTioOtsefnW1z9GBLKjRvbsfhT5hQsvOFhdk6OpdfDtge/OnY2LO6hrLS4K6UqnVKlccH+0Tt00/bvLzLBcHB8Oabti7Or7/aJ2ebNrU3aAMD7Ugdx+yoqErNwWtwV0opzuJhqyNHcodjFuXtt2H2bEhK8pQ6bhcYyPY+fcqptWdWXHAvYsyRUkr5njiXq9ietSf4l+RkgYE2f3/qFNStC8CvZ/OEbgXT4K6UUo6igr93j18AA7n5+uPHPcG9bWBgpbX1TDS4K6XUGeQP+okZGYysX98+bXviBDRuTH0/PyaFhlZZG/PzO/MuSimlvMW5XNzToYNdyMqiXWAg06pZhUrtuSulVClc2aoV8cDqiy6iW7duVd2cArTnrpRSpdDAeVr16NGjVdySwmlwV0qpUljujIy59D//of1335GYkVHFLcpLg7tSSp2lxIwM/u4O5sePk5aVxahNm6pVgNfgrpRSZ2nCtm2ccIY/4vTgj50+zYRt26qwVXlpcFdKqbP0a1aWnSwE7FBIx1lNM1jBNLgrpdRZahsYaJ9QhTzBHWyZ4upAg7tSSp2lSaGhuU+o5gvur6enV4vcuwZ3pZQ6S3Eul52vNSAAfv89zzYDDE1JqfIAr8FdKaVKoV1goJ0gZMGCvBN3YwP8kJSUKk3RaHBXSqlSmBQaCrfeahfGjYOXX7ZVIr0kpKfTcNmyKunFa3BXSqlSiHO5oF07u7B3L8yfD3v2FNjvSE4OQ1JSkORk/JOTK603r8FdKaVKqZ17wmy3jz+GH3+0Y98PHiyw/2lsb/6ilSsrvG06E5NSSpVSYkYGQz/4AHPsGIwfn7uhTRv47Tc7H6sxdp5VZ7YmbwKMKcPE2jrNnlJKVRDPXK3z58OqVbBxI+zfn3enyZOhZ087Kff778PgwXDuuZ7N9UR4KzLyrEsG6zR7SilVQdwTeSRGRjI8JYUcY2D6dFi61PbeAT75xAb3FSvs3Kvp6fCXv3jOccIYRqames5XHjTnrpRS5SDO5WJWVBQN/Pzgnntg1iyYNAn697dBfflyO6E2QEpKgZE1J40p19o0pQ7uItJGRJaIyE8islFEHnLWNxWRr0Vki/N67pnOpZRSviDO5eLIpZcytlUrm2Pv2xe6O1mTp5+GLVvs+7Q0eOsteO45WLfOc3x5TrBdlp57NvCoMeZCoDdwv4hcCIwHkowxYUCSs6yUUrVGfHg4s6Oi7INO7lmamjSxufeFCyEsDN57D5KT84yqKc8Jtksd3I0xu4wxa533h4EUoDVwPTDL2W0WcENZG6mUUjVNnMvF9j59MHFxnDx5ktmpqTTo1ctWkxwxInfH3r0BqCtSrhNsl8sNVRFpD8QAKwGXMWaXs2k3UH1mjFVKqSoQEBDgufEKMDsykjFHjnBUBAIDCa5Th1fCwsp1gu0yD4UUkSDgG2CSMebfInLAGNPEa/t+Y0yBvLuIjAJGAbRt27ZbWlpamdqhlFK1TXFDIcs0WkZEAoCPgERjzL+d1Rki0tLZ3hL4vbBjjTHTjDHdjTHdmzdvXpZmKKWUyqcso2UEmA6kGGP+12vTfGC483448Enpm6eUUqo0ypJz7wcMBX4UEfdYnieBvwMfiMjdQBpwW9maqJRS6myVOrgbY5ZjSyMUZmBpz6uUUqrs9AlVpZTyQRrclVLKB2lwV0opH6TBXSmlfFC1qOcuInuwI2tKoxmwtxybUxPoNdcOes21Q1muuZ0xptAHhapFcC8LEVld1BNavkqvuXbQa64dKuqaNS2jlFI+SIO7Ukr5IF8I7tOqugFVQK+5dtBrrh0q5JprfM5dKaVUQb7Qc1dKKZWPBnellPJBNTq4i8hVIrJJRLaKiM/M1Soib4vI7yKywWtdoROPizXV+RqsF5GuVdfy0jvbCdd94bpFpJ6IrBKR/zrX/JyzvoOIrHSuba6I1HXWBzrLW53t7auy/aUlIv4i8oOIfOYs+/T1AojIdhH5UUTWichqZ12F/mzX2OAuIv7Aa8Ag4ELgDmeCbl8wE7gq37qiJh4fBIQ5H6OAhEpqY3k72wnXfeG6s4DLjDFdgGjgKhHpDUwGXjbGXADsB+529r8b2O+sf9nZryZ6CDvnspuvX6/bAGNMtNeY9or92TbG1MgPoA/wpdfyE8ATVd2ucry+9sAGr+VNQEvnfUtgk/P+DeCOwvaryR/YSV6uqC3XDdQH1gK9sE8r1nHWe37OgS+BPs77Os5+UtVtP8vrDHEC2WXAZ9iy4T57vV7XvR1olm9dhf5s19ieO9Aa+M1reYezzlcVNfG4z30dSjjhuk9ct5OiWIedjvJr4GfggDEm29nF+7o81+xsPwgEV26Ly2wK8Dhw2lkOxrev180AX4nIGmf+aKjgn+2yzMSkqogxxoiIT45hdSZc/wgYZ4w5ZGdztHzxuo0xOUC0iDQBPgYiq7hJFUZEBgO/G2PWiEhsVbenkl1sjNkpIi2Ar0Uk1XtjRfxs1+Se+06gjddyiLPOVxU18bjPfB3OcsJ1n7luAGPMAWAJNi3RRETcHS/v6/Jcs7O9MZBZyU0ti37AdSKyHZiDTc28gu9er4cxZqfz+jv2j3hPKvhnuyYH9++BMOdOe13gduzk3L6qqInH5wPDnDvsvYGDXv/q1RgiZz3heo2/bhFp7vTYEZFzsPcYUrBB/hZnt/zX7P5a3AIsNk5StiYwxjxhjAkxxrTH/r4uNsbE4aPX6yYiDUSkofs98AdgAxX9s13VNxrKeJPiamAzNk85oarbU47X9T6wCziFzbfdjc01JgFbgEVAU2dfwY4a+hn4Eehe1e0v5TVfjM1LrgfWOR9X+/J1A52BH5xr3gA846wPBVYBW4F/AYHO+nrO8lZne2hVX0MZrj0W+Kw2XK9zff91Pja6Y1VF/2xr+QGllPJBNTkto5RSqgga3JVSygdpcFdKKR+kwV0ppXyQBnellPJBGtyVUsoHaXBXSikf9P/AtwPr6lzPkwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "epochs_x"
      ],
      "metadata": {
        "id": "N_sP_ZmSY-Jv",
        "outputId": "8819ed59-ec3a-41af-b843-5c56c04c0a30",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "range(0, 500)"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Download the model\n"
      ],
      "metadata": {
        "id": "R19IJQSYoW7J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "os.makedirs('/content/drive/My Drive/cut_panoramic/Model', exist_ok=True)\n",
        "model.save('/content/drive/My Drive/cut_panoramic/Model/2e-4_32_0.2_Male18_500.h5')"
      ],
      "metadata": {
        "id": "Zed4TdFcG2iJ"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "n5YxZ-5QjQ0-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# from google.colab import files\n",
        "# files.download('/content/drive/My Drive/cut_panoramic/Model/1.1_รอบแรก_Flimpano_Male125_250.h5')"
      ],
      "metadata": {
        "id": "P5eMxm1NV-oY"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "wY_pDlxkRwxS"
      },
      "execution_count": 25,
      "outputs": []
    }
  ]
}