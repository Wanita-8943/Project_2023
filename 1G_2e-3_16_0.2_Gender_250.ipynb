{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Wanita-8943/Project_2023/blob/main/1G_2e-3_16_0.2_Gender_250.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#เรียกใช้ CSV"
      ],
      "metadata": {
        "id": "ow7eWoNw6U-c"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "z8o_VVNXzcL8"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import shutil"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1_2Fe8u81d5r",
        "outputId": "b03dbbf8-a638-424e-f5b2-8cd4bd9e8fd1"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Imports"
      ],
      "metadata": {
        "id": "5qxePnnn7TGW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import models\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import optimizers\n",
        "import os\n",
        "import glob\n",
        "import shutil\n",
        "import sys\n",
        "import numpy as np\n",
        "from skimage.io import imread\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import Image\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "D-hCRloc3t39"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras import backend as K"
      ],
      "metadata": {
        "id": "YZWXwjXeGxZP"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#กำหนดค่าพารามิเตอร์\n"
      ],
      "metadata": {
        "id": "RooqSdBc7QHC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 16\n",
        "width = 150\n",
        "height = 150\n",
        "epochs = 250\n",
        "NUM_TRAIN = 2850\n",
        "NUM_TEST = 950\n",
        "dropout_rate = 0.2\n",
        "input_shape = (height, width, 3)"
      ],
      "metadata": {
        "id": "thDb7U9B3xOo"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Clone efficientnet repo\n"
      ],
      "metadata": {
        "id": "pumGmy6f3eSW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#ดึงข้อมูลใน Github มาใช้\n",
        "import os\n",
        "%cd /content\n",
        "if not os.path.isdir(\"efficientnet_keras_transfer_learning\"):\n",
        " !git clone https://github.com/Wanita-8943/efficientnet_keras_transfer_learning\n",
        "%cd efficientnet_keras_transfer_learning/\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P7iy2f8n16p0",
        "outputId": "d3c56271-4e47-476a-b3e4-0f669417790b"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "Cloning into 'efficientnet_keras_transfer_learning'...\n",
            "remote: Enumerating objects: 837, done.\u001b[K\n",
            "remote: Counting objects: 100% (359/359), done.\u001b[K\n",
            "remote: Compressing objects: 100% (172/172), done.\u001b[K\n",
            "remote: Total 837 (delta 253), reused 248 (delta 187), pack-reused 478\u001b[K\n",
            "Receiving objects: 100% (837/837), 13.82 MiB | 16.98 MiB/s, done.\n",
            "Resolving deltas: 100% (493/493), done.\n",
            "/content/efficientnet_keras_transfer_learning\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Options: EfficientNetB0, EfficientNetB1, EfficientNetB2, EfficientNetB3\n",
        "# Higher the number, the more complex the model is.\n",
        "from efficientnet import EfficientNetB0 as Net\n",
        "from efficientnet import center_crop_and_resize, preprocess_input"
      ],
      "metadata": {
        "id": "tjZBRnfo3bN0"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# loading pretrained conv base model\n",
        "# โหลดโมเดล มาโดยตัด output ของโมเดลออก เเต่ยังใช้ input อันเดิม\n",
        "# เเละโหลด weight ของโมเดล มาด้วยที่ชื่อว่า imagenet\n",
        "conv_base = Net(weights='imagenet', include_top=False, input_shape=input_shape)"
      ],
      "metadata": {
        "id": "hNZAzbDp3lgA",
        "outputId": "632f5787-fc7a-46ed-c1d1-de1c88138c81",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
            "Instructions for updating:\n",
            "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://github.com/qubvel/efficientnet/releases/download/v0.0.1/efficientnet-b0_imagenet_1000_notop.h5\n",
            "16717576/16717576 [==============================] - 4s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = models.Sequential()\n",
        "model.add(conv_base)\n",
        "model.add(layers.GlobalMaxPooling2D(name=\"gap\"))\n",
        "# model.add(layers.Flatten(name=\"flatten\"))\n",
        "if dropout_rate > 0:\n",
        "    model.add(layers.Dropout(dropout_rate, name=\"dropout_out\"))\n",
        "# model.add(layers.Dense(256, activation='relu', name=\"fc1\"))\n",
        "model.add(layers.Dense(2, activation='softmax', name=\"fc_out\"))\n",
        "model.add(layers.Dense(1))"
      ],
      "metadata": {
        "id": "yWNKfQUt5rga"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "NadBB12251jh",
        "outputId": "92b56af0-beae-4600-c845-d4a1d5e90d43",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " efficientnet-b0 (Functional  (None, 5, 5, 1280)       4049564   \n",
            " )                                                               \n",
            "                                                                 \n",
            " gap (GlobalMaxPooling2D)    (None, 1280)              0         \n",
            "                                                                 \n",
            " dropout_out (Dropout)       (None, 1280)              0         \n",
            "                                                                 \n",
            " fc_out (Dense)              (None, 2)                 2562      \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1)                 3         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4,052,129\n",
            "Trainable params: 4,010,113\n",
            "Non-trainable params: 42,016\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('This is the number of trainable layers '\n",
        "      'before freezing the conv base:', len(model.trainable_weights))\n",
        "\n",
        "conv_base.trainable = False\n",
        "\n",
        "print('This is the number of trainable layers '\n",
        "      'after freezing the conv base:', len(model.trainable_weights))"
      ],
      "metadata": {
        "id": "GepWq3yy53t5",
        "outputId": "bb0aa85a-2194-4cf4-85b2-b1fb95deb5f3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This is the number of trainable layers before freezing the conv base: 215\n",
            "This is the number of trainable layers after freezing the conv base: 4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "conv_base.summary() #ดู Summary"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iD76D6c_79py",
        "outputId": "32d42ba9-7aca-4a00-b861-e152e68b84f9"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"efficientnet-b0\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 150, 150, 3  0           []                               \n",
            "                                )]                                                                \n",
            "                                                                                                  \n",
            " conv2d (Conv2D)                (None, 75, 75, 32)   864         ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " batch_normalization (BatchNorm  (None, 75, 75, 32)  128         ['conv2d[0][0]']                 \n",
            " alization)                                                                                       \n",
            "                                                                                                  \n",
            " swish (Swish)                  (None, 75, 75, 32)   0           ['batch_normalization[0][0]']    \n",
            "                                                                                                  \n",
            " depthwise_conv2d (DepthwiseCon  (None, 75, 75, 32)  288         ['swish[0][0]']                  \n",
            " v2D)                                                                                             \n",
            "                                                                                                  \n",
            " batch_normalization_1 (BatchNo  (None, 75, 75, 32)  128         ['depthwise_conv2d[0][0]']       \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " swish_1 (Swish)                (None, 75, 75, 32)   0           ['batch_normalization_1[0][0]']  \n",
            "                                                                                                  \n",
            " lambda (Lambda)                (None, 1, 1, 32)     0           ['swish_1[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d_1 (Conv2D)              (None, 1, 1, 8)      264         ['lambda[0][0]']                 \n",
            "                                                                                                  \n",
            " swish_2 (Swish)                (None, 1, 1, 8)      0           ['conv2d_1[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_2 (Conv2D)              (None, 1, 1, 32)     288         ['swish_2[0][0]']                \n",
            "                                                                                                  \n",
            " activation (Activation)        (None, 1, 1, 32)     0           ['conv2d_2[0][0]']               \n",
            "                                                                                                  \n",
            " multiply (Multiply)            (None, 75, 75, 32)   0           ['activation[0][0]',             \n",
            "                                                                  'swish_1[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d_3 (Conv2D)              (None, 75, 75, 16)   512         ['multiply[0][0]']               \n",
            "                                                                                                  \n",
            " batch_normalization_2 (BatchNo  (None, 75, 75, 16)  64          ['conv2d_3[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv2d_4 (Conv2D)              (None, 75, 75, 96)   1536        ['batch_normalization_2[0][0]']  \n",
            "                                                                                                  \n",
            " batch_normalization_3 (BatchNo  (None, 75, 75, 96)  384         ['conv2d_4[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " swish_3 (Swish)                (None, 75, 75, 96)   0           ['batch_normalization_3[0][0]']  \n",
            "                                                                                                  \n",
            " depthwise_conv2d_1 (DepthwiseC  (None, 38, 38, 96)  864         ['swish_3[0][0]']                \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_4 (BatchNo  (None, 38, 38, 96)  384         ['depthwise_conv2d_1[0][0]']     \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " swish_4 (Swish)                (None, 38, 38, 96)   0           ['batch_normalization_4[0][0]']  \n",
            "                                                                                                  \n",
            " lambda_1 (Lambda)              (None, 1, 1, 96)     0           ['swish_4[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d_5 (Conv2D)              (None, 1, 1, 4)      388         ['lambda_1[0][0]']               \n",
            "                                                                                                  \n",
            " swish_5 (Swish)                (None, 1, 1, 4)      0           ['conv2d_5[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_6 (Conv2D)              (None, 1, 1, 96)     480         ['swish_5[0][0]']                \n",
            "                                                                                                  \n",
            " activation_1 (Activation)      (None, 1, 1, 96)     0           ['conv2d_6[0][0]']               \n",
            "                                                                                                  \n",
            " multiply_1 (Multiply)          (None, 38, 38, 96)   0           ['activation_1[0][0]',           \n",
            "                                                                  'swish_4[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d_7 (Conv2D)              (None, 38, 38, 24)   2304        ['multiply_1[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_5 (BatchNo  (None, 38, 38, 24)  96          ['conv2d_7[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv2d_8 (Conv2D)              (None, 38, 38, 144)  3456        ['batch_normalization_5[0][0]']  \n",
            "                                                                                                  \n",
            " batch_normalization_6 (BatchNo  (None, 38, 38, 144)  576        ['conv2d_8[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " swish_6 (Swish)                (None, 38, 38, 144)  0           ['batch_normalization_6[0][0]']  \n",
            "                                                                                                  \n",
            " depthwise_conv2d_2 (DepthwiseC  (None, 38, 38, 144)  1296       ['swish_6[0][0]']                \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_7 (BatchNo  (None, 38, 38, 144)  576        ['depthwise_conv2d_2[0][0]']     \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " swish_7 (Swish)                (None, 38, 38, 144)  0           ['batch_normalization_7[0][0]']  \n",
            "                                                                                                  \n",
            " lambda_2 (Lambda)              (None, 1, 1, 144)    0           ['swish_7[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d_9 (Conv2D)              (None, 1, 1, 6)      870         ['lambda_2[0][0]']               \n",
            "                                                                                                  \n",
            " swish_8 (Swish)                (None, 1, 1, 6)      0           ['conv2d_9[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_10 (Conv2D)             (None, 1, 1, 144)    1008        ['swish_8[0][0]']                \n",
            "                                                                                                  \n",
            " activation_2 (Activation)      (None, 1, 1, 144)    0           ['conv2d_10[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_2 (Multiply)          (None, 38, 38, 144)  0           ['activation_2[0][0]',           \n",
            "                                                                  'swish_7[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d_11 (Conv2D)             (None, 38, 38, 24)   3456        ['multiply_2[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_8 (BatchNo  (None, 38, 38, 24)  96          ['conv2d_11[0][0]']              \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " drop_connect (DropConnect)     (None, 38, 38, 24)   0           ['batch_normalization_8[0][0]']  \n",
            "                                                                                                  \n",
            " add (Add)                      (None, 38, 38, 24)   0           ['drop_connect[0][0]',           \n",
            "                                                                  'batch_normalization_5[0][0]']  \n",
            "                                                                                                  \n",
            " conv2d_12 (Conv2D)             (None, 38, 38, 144)  3456        ['add[0][0]']                    \n",
            "                                                                                                  \n",
            " batch_normalization_9 (BatchNo  (None, 38, 38, 144)  576        ['conv2d_12[0][0]']              \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " swish_9 (Swish)                (None, 38, 38, 144)  0           ['batch_normalization_9[0][0]']  \n",
            "                                                                                                  \n",
            " depthwise_conv2d_3 (DepthwiseC  (None, 19, 19, 144)  3600       ['swish_9[0][0]']                \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_10 (BatchN  (None, 19, 19, 144)  576        ['depthwise_conv2d_3[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_10 (Swish)               (None, 19, 19, 144)  0           ['batch_normalization_10[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_3 (Lambda)              (None, 1, 1, 144)    0           ['swish_10[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_13 (Conv2D)             (None, 1, 1, 6)      870         ['lambda_3[0][0]']               \n",
            "                                                                                                  \n",
            " swish_11 (Swish)               (None, 1, 1, 6)      0           ['conv2d_13[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_14 (Conv2D)             (None, 1, 1, 144)    1008        ['swish_11[0][0]']               \n",
            "                                                                                                  \n",
            " activation_3 (Activation)      (None, 1, 1, 144)    0           ['conv2d_14[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_3 (Multiply)          (None, 19, 19, 144)  0           ['activation_3[0][0]',           \n",
            "                                                                  'swish_10[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_15 (Conv2D)             (None, 19, 19, 40)   5760        ['multiply_3[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_11 (BatchN  (None, 19, 19, 40)  160         ['conv2d_15[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_16 (Conv2D)             (None, 19, 19, 240)  9600        ['batch_normalization_11[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_12 (BatchN  (None, 19, 19, 240)  960        ['conv2d_16[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_12 (Swish)               (None, 19, 19, 240)  0           ['batch_normalization_12[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_4 (DepthwiseC  (None, 19, 19, 240)  6000       ['swish_12[0][0]']               \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_13 (BatchN  (None, 19, 19, 240)  960        ['depthwise_conv2d_4[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_13 (Swish)               (None, 19, 19, 240)  0           ['batch_normalization_13[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_4 (Lambda)              (None, 1, 1, 240)    0           ['swish_13[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_17 (Conv2D)             (None, 1, 1, 10)     2410        ['lambda_4[0][0]']               \n",
            "                                                                                                  \n",
            " swish_14 (Swish)               (None, 1, 1, 10)     0           ['conv2d_17[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_18 (Conv2D)             (None, 1, 1, 240)    2640        ['swish_14[0][0]']               \n",
            "                                                                                                  \n",
            " activation_4 (Activation)      (None, 1, 1, 240)    0           ['conv2d_18[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_4 (Multiply)          (None, 19, 19, 240)  0           ['activation_4[0][0]',           \n",
            "                                                                  'swish_13[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_19 (Conv2D)             (None, 19, 19, 40)   9600        ['multiply_4[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_14 (BatchN  (None, 19, 19, 40)  160         ['conv2d_19[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_1 (DropConnect)   (None, 19, 19, 40)   0           ['batch_normalization_14[0][0]'] \n",
            "                                                                                                  \n",
            " add_1 (Add)                    (None, 19, 19, 40)   0           ['drop_connect_1[0][0]',         \n",
            "                                                                  'batch_normalization_11[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_20 (Conv2D)             (None, 19, 19, 240)  9600        ['add_1[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_15 (BatchN  (None, 19, 19, 240)  960        ['conv2d_20[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_15 (Swish)               (None, 19, 19, 240)  0           ['batch_normalization_15[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_5 (DepthwiseC  (None, 10, 10, 240)  2160       ['swish_15[0][0]']               \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_16 (BatchN  (None, 10, 10, 240)  960        ['depthwise_conv2d_5[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_16 (Swish)               (None, 10, 10, 240)  0           ['batch_normalization_16[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_5 (Lambda)              (None, 1, 1, 240)    0           ['swish_16[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_21 (Conv2D)             (None, 1, 1, 10)     2410        ['lambda_5[0][0]']               \n",
            "                                                                                                  \n",
            " swish_17 (Swish)               (None, 1, 1, 10)     0           ['conv2d_21[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_22 (Conv2D)             (None, 1, 1, 240)    2640        ['swish_17[0][0]']               \n",
            "                                                                                                  \n",
            " activation_5 (Activation)      (None, 1, 1, 240)    0           ['conv2d_22[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_5 (Multiply)          (None, 10, 10, 240)  0           ['activation_5[0][0]',           \n",
            "                                                                  'swish_16[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_23 (Conv2D)             (None, 10, 10, 80)   19200       ['multiply_5[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_17 (BatchN  (None, 10, 10, 80)  320         ['conv2d_23[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_24 (Conv2D)             (None, 10, 10, 480)  38400       ['batch_normalization_17[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_18 (BatchN  (None, 10, 10, 480)  1920       ['conv2d_24[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_18 (Swish)               (None, 10, 10, 480)  0           ['batch_normalization_18[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_6 (DepthwiseC  (None, 10, 10, 480)  4320       ['swish_18[0][0]']               \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_19 (BatchN  (None, 10, 10, 480)  1920       ['depthwise_conv2d_6[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_19 (Swish)               (None, 10, 10, 480)  0           ['batch_normalization_19[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_6 (Lambda)              (None, 1, 1, 480)    0           ['swish_19[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_25 (Conv2D)             (None, 1, 1, 20)     9620        ['lambda_6[0][0]']               \n",
            "                                                                                                  \n",
            " swish_20 (Swish)               (None, 1, 1, 20)     0           ['conv2d_25[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_26 (Conv2D)             (None, 1, 1, 480)    10080       ['swish_20[0][0]']               \n",
            "                                                                                                  \n",
            " activation_6 (Activation)      (None, 1, 1, 480)    0           ['conv2d_26[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_6 (Multiply)          (None, 10, 10, 480)  0           ['activation_6[0][0]',           \n",
            "                                                                  'swish_19[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_27 (Conv2D)             (None, 10, 10, 80)   38400       ['multiply_6[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_20 (BatchN  (None, 10, 10, 80)  320         ['conv2d_27[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_2 (DropConnect)   (None, 10, 10, 80)   0           ['batch_normalization_20[0][0]'] \n",
            "                                                                                                  \n",
            " add_2 (Add)                    (None, 10, 10, 80)   0           ['drop_connect_2[0][0]',         \n",
            "                                                                  'batch_normalization_17[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_28 (Conv2D)             (None, 10, 10, 480)  38400       ['add_2[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_21 (BatchN  (None, 10, 10, 480)  1920       ['conv2d_28[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_21 (Swish)               (None, 10, 10, 480)  0           ['batch_normalization_21[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_7 (DepthwiseC  (None, 10, 10, 480)  4320       ['swish_21[0][0]']               \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_22 (BatchN  (None, 10, 10, 480)  1920       ['depthwise_conv2d_7[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_22 (Swish)               (None, 10, 10, 480)  0           ['batch_normalization_22[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_7 (Lambda)              (None, 1, 1, 480)    0           ['swish_22[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_29 (Conv2D)             (None, 1, 1, 20)     9620        ['lambda_7[0][0]']               \n",
            "                                                                                                  \n",
            " swish_23 (Swish)               (None, 1, 1, 20)     0           ['conv2d_29[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_30 (Conv2D)             (None, 1, 1, 480)    10080       ['swish_23[0][0]']               \n",
            "                                                                                                  \n",
            " activation_7 (Activation)      (None, 1, 1, 480)    0           ['conv2d_30[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_7 (Multiply)          (None, 10, 10, 480)  0           ['activation_7[0][0]',           \n",
            "                                                                  'swish_22[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_31 (Conv2D)             (None, 10, 10, 80)   38400       ['multiply_7[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_23 (BatchN  (None, 10, 10, 80)  320         ['conv2d_31[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_3 (DropConnect)   (None, 10, 10, 80)   0           ['batch_normalization_23[0][0]'] \n",
            "                                                                                                  \n",
            " add_3 (Add)                    (None, 10, 10, 80)   0           ['drop_connect_3[0][0]',         \n",
            "                                                                  'add_2[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_32 (Conv2D)             (None, 10, 10, 480)  38400       ['add_3[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_24 (BatchN  (None, 10, 10, 480)  1920       ['conv2d_32[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_24 (Swish)               (None, 10, 10, 480)  0           ['batch_normalization_24[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_8 (DepthwiseC  (None, 10, 10, 480)  12000      ['swish_24[0][0]']               \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_25 (BatchN  (None, 10, 10, 480)  1920       ['depthwise_conv2d_8[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_25 (Swish)               (None, 10, 10, 480)  0           ['batch_normalization_25[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_8 (Lambda)              (None, 1, 1, 480)    0           ['swish_25[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_33 (Conv2D)             (None, 1, 1, 20)     9620        ['lambda_8[0][0]']               \n",
            "                                                                                                  \n",
            " swish_26 (Swish)               (None, 1, 1, 20)     0           ['conv2d_33[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_34 (Conv2D)             (None, 1, 1, 480)    10080       ['swish_26[0][0]']               \n",
            "                                                                                                  \n",
            " activation_8 (Activation)      (None, 1, 1, 480)    0           ['conv2d_34[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_8 (Multiply)          (None, 10, 10, 480)  0           ['activation_8[0][0]',           \n",
            "                                                                  'swish_25[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_35 (Conv2D)             (None, 10, 10, 112)  53760       ['multiply_8[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_26 (BatchN  (None, 10, 10, 112)  448        ['conv2d_35[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_36 (Conv2D)             (None, 10, 10, 672)  75264       ['batch_normalization_26[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_27 (BatchN  (None, 10, 10, 672)  2688       ['conv2d_36[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_27 (Swish)               (None, 10, 10, 672)  0           ['batch_normalization_27[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_9 (DepthwiseC  (None, 10, 10, 672)  16800      ['swish_27[0][0]']               \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_28 (BatchN  (None, 10, 10, 672)  2688       ['depthwise_conv2d_9[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_28 (Swish)               (None, 10, 10, 672)  0           ['batch_normalization_28[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_9 (Lambda)              (None, 1, 1, 672)    0           ['swish_28[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_37 (Conv2D)             (None, 1, 1, 28)     18844       ['lambda_9[0][0]']               \n",
            "                                                                                                  \n",
            " swish_29 (Swish)               (None, 1, 1, 28)     0           ['conv2d_37[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_38 (Conv2D)             (None, 1, 1, 672)    19488       ['swish_29[0][0]']               \n",
            "                                                                                                  \n",
            " activation_9 (Activation)      (None, 1, 1, 672)    0           ['conv2d_38[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_9 (Multiply)          (None, 10, 10, 672)  0           ['activation_9[0][0]',           \n",
            "                                                                  'swish_28[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_39 (Conv2D)             (None, 10, 10, 112)  75264       ['multiply_9[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_29 (BatchN  (None, 10, 10, 112)  448        ['conv2d_39[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_4 (DropConnect)   (None, 10, 10, 112)  0           ['batch_normalization_29[0][0]'] \n",
            "                                                                                                  \n",
            " add_4 (Add)                    (None, 10, 10, 112)  0           ['drop_connect_4[0][0]',         \n",
            "                                                                  'batch_normalization_26[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_40 (Conv2D)             (None, 10, 10, 672)  75264       ['add_4[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_30 (BatchN  (None, 10, 10, 672)  2688       ['conv2d_40[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_30 (Swish)               (None, 10, 10, 672)  0           ['batch_normalization_30[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_10 (Depthwise  (None, 10, 10, 672)  16800      ['swish_30[0][0]']               \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_31 (BatchN  (None, 10, 10, 672)  2688       ['depthwise_conv2d_10[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_31 (Swish)               (None, 10, 10, 672)  0           ['batch_normalization_31[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_10 (Lambda)             (None, 1, 1, 672)    0           ['swish_31[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_41 (Conv2D)             (None, 1, 1, 28)     18844       ['lambda_10[0][0]']              \n",
            "                                                                                                  \n",
            " swish_32 (Swish)               (None, 1, 1, 28)     0           ['conv2d_41[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_42 (Conv2D)             (None, 1, 1, 672)    19488       ['swish_32[0][0]']               \n",
            "                                                                                                  \n",
            " activation_10 (Activation)     (None, 1, 1, 672)    0           ['conv2d_42[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_10 (Multiply)         (None, 10, 10, 672)  0           ['activation_10[0][0]',          \n",
            "                                                                  'swish_31[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_43 (Conv2D)             (None, 10, 10, 112)  75264       ['multiply_10[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_32 (BatchN  (None, 10, 10, 112)  448        ['conv2d_43[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_5 (DropConnect)   (None, 10, 10, 112)  0           ['batch_normalization_32[0][0]'] \n",
            "                                                                                                  \n",
            " add_5 (Add)                    (None, 10, 10, 112)  0           ['drop_connect_5[0][0]',         \n",
            "                                                                  'add_4[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_44 (Conv2D)             (None, 10, 10, 672)  75264       ['add_5[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_33 (BatchN  (None, 10, 10, 672)  2688       ['conv2d_44[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_33 (Swish)               (None, 10, 10, 672)  0           ['batch_normalization_33[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_11 (Depthwise  (None, 5, 5, 672)   16800       ['swish_33[0][0]']               \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_34 (BatchN  (None, 5, 5, 672)   2688        ['depthwise_conv2d_11[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_34 (Swish)               (None, 5, 5, 672)    0           ['batch_normalization_34[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_11 (Lambda)             (None, 1, 1, 672)    0           ['swish_34[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_45 (Conv2D)             (None, 1, 1, 28)     18844       ['lambda_11[0][0]']              \n",
            "                                                                                                  \n",
            " swish_35 (Swish)               (None, 1, 1, 28)     0           ['conv2d_45[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_46 (Conv2D)             (None, 1, 1, 672)    19488       ['swish_35[0][0]']               \n",
            "                                                                                                  \n",
            " activation_11 (Activation)     (None, 1, 1, 672)    0           ['conv2d_46[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_11 (Multiply)         (None, 5, 5, 672)    0           ['activation_11[0][0]',          \n",
            "                                                                  'swish_34[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_47 (Conv2D)             (None, 5, 5, 192)    129024      ['multiply_11[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_35 (BatchN  (None, 5, 5, 192)   768         ['conv2d_47[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_48 (Conv2D)             (None, 5, 5, 1152)   221184      ['batch_normalization_35[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_36 (BatchN  (None, 5, 5, 1152)  4608        ['conv2d_48[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_36 (Swish)               (None, 5, 5, 1152)   0           ['batch_normalization_36[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_12 (Depthwise  (None, 5, 5, 1152)  28800       ['swish_36[0][0]']               \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_37 (BatchN  (None, 5, 5, 1152)  4608        ['depthwise_conv2d_12[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_37 (Swish)               (None, 5, 5, 1152)   0           ['batch_normalization_37[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_12 (Lambda)             (None, 1, 1, 1152)   0           ['swish_37[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_49 (Conv2D)             (None, 1, 1, 48)     55344       ['lambda_12[0][0]']              \n",
            "                                                                                                  \n",
            " swish_38 (Swish)               (None, 1, 1, 48)     0           ['conv2d_49[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_50 (Conv2D)             (None, 1, 1, 1152)   56448       ['swish_38[0][0]']               \n",
            "                                                                                                  \n",
            " activation_12 (Activation)     (None, 1, 1, 1152)   0           ['conv2d_50[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_12 (Multiply)         (None, 5, 5, 1152)   0           ['activation_12[0][0]',          \n",
            "                                                                  'swish_37[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_51 (Conv2D)             (None, 5, 5, 192)    221184      ['multiply_12[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_38 (BatchN  (None, 5, 5, 192)   768         ['conv2d_51[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_6 (DropConnect)   (None, 5, 5, 192)    0           ['batch_normalization_38[0][0]'] \n",
            "                                                                                                  \n",
            " add_6 (Add)                    (None, 5, 5, 192)    0           ['drop_connect_6[0][0]',         \n",
            "                                                                  'batch_normalization_35[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_52 (Conv2D)             (None, 5, 5, 1152)   221184      ['add_6[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_39 (BatchN  (None, 5, 5, 1152)  4608        ['conv2d_52[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_39 (Swish)               (None, 5, 5, 1152)   0           ['batch_normalization_39[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_13 (Depthwise  (None, 5, 5, 1152)  28800       ['swish_39[0][0]']               \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_40 (BatchN  (None, 5, 5, 1152)  4608        ['depthwise_conv2d_13[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_40 (Swish)               (None, 5, 5, 1152)   0           ['batch_normalization_40[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_13 (Lambda)             (None, 1, 1, 1152)   0           ['swish_40[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_53 (Conv2D)             (None, 1, 1, 48)     55344       ['lambda_13[0][0]']              \n",
            "                                                                                                  \n",
            " swish_41 (Swish)               (None, 1, 1, 48)     0           ['conv2d_53[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_54 (Conv2D)             (None, 1, 1, 1152)   56448       ['swish_41[0][0]']               \n",
            "                                                                                                  \n",
            " activation_13 (Activation)     (None, 1, 1, 1152)   0           ['conv2d_54[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_13 (Multiply)         (None, 5, 5, 1152)   0           ['activation_13[0][0]',          \n",
            "                                                                  'swish_40[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_55 (Conv2D)             (None, 5, 5, 192)    221184      ['multiply_13[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_41 (BatchN  (None, 5, 5, 192)   768         ['conv2d_55[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_7 (DropConnect)   (None, 5, 5, 192)    0           ['batch_normalization_41[0][0]'] \n",
            "                                                                                                  \n",
            " add_7 (Add)                    (None, 5, 5, 192)    0           ['drop_connect_7[0][0]',         \n",
            "                                                                  'add_6[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_56 (Conv2D)             (None, 5, 5, 1152)   221184      ['add_7[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_42 (BatchN  (None, 5, 5, 1152)  4608        ['conv2d_56[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_42 (Swish)               (None, 5, 5, 1152)   0           ['batch_normalization_42[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_14 (Depthwise  (None, 5, 5, 1152)  28800       ['swish_42[0][0]']               \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_43 (BatchN  (None, 5, 5, 1152)  4608        ['depthwise_conv2d_14[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_43 (Swish)               (None, 5, 5, 1152)   0           ['batch_normalization_43[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_14 (Lambda)             (None, 1, 1, 1152)   0           ['swish_43[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_57 (Conv2D)             (None, 1, 1, 48)     55344       ['lambda_14[0][0]']              \n",
            "                                                                                                  \n",
            " swish_44 (Swish)               (None, 1, 1, 48)     0           ['conv2d_57[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_58 (Conv2D)             (None, 1, 1, 1152)   56448       ['swish_44[0][0]']               \n",
            "                                                                                                  \n",
            " activation_14 (Activation)     (None, 1, 1, 1152)   0           ['conv2d_58[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_14 (Multiply)         (None, 5, 5, 1152)   0           ['activation_14[0][0]',          \n",
            "                                                                  'swish_43[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_59 (Conv2D)             (None, 5, 5, 192)    221184      ['multiply_14[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_44 (BatchN  (None, 5, 5, 192)   768         ['conv2d_59[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_8 (DropConnect)   (None, 5, 5, 192)    0           ['batch_normalization_44[0][0]'] \n",
            "                                                                                                  \n",
            " add_8 (Add)                    (None, 5, 5, 192)    0           ['drop_connect_8[0][0]',         \n",
            "                                                                  'add_7[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_60 (Conv2D)             (None, 5, 5, 1152)   221184      ['add_8[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_45 (BatchN  (None, 5, 5, 1152)  4608        ['conv2d_60[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_45 (Swish)               (None, 5, 5, 1152)   0           ['batch_normalization_45[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_15 (Depthwise  (None, 5, 5, 1152)  10368       ['swish_45[0][0]']               \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_46 (BatchN  (None, 5, 5, 1152)  4608        ['depthwise_conv2d_15[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_46 (Swish)               (None, 5, 5, 1152)   0           ['batch_normalization_46[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_15 (Lambda)             (None, 1, 1, 1152)   0           ['swish_46[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_61 (Conv2D)             (None, 1, 1, 48)     55344       ['lambda_15[0][0]']              \n",
            "                                                                                                  \n",
            " swish_47 (Swish)               (None, 1, 1, 48)     0           ['conv2d_61[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_62 (Conv2D)             (None, 1, 1, 1152)   56448       ['swish_47[0][0]']               \n",
            "                                                                                                  \n",
            " activation_15 (Activation)     (None, 1, 1, 1152)   0           ['conv2d_62[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_15 (Multiply)         (None, 5, 5, 1152)   0           ['activation_15[0][0]',          \n",
            "                                                                  'swish_46[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_63 (Conv2D)             (None, 5, 5, 320)    368640      ['multiply_15[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_47 (BatchN  (None, 5, 5, 320)   1280        ['conv2d_63[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_64 (Conv2D)             (None, 5, 5, 1280)   409600      ['batch_normalization_47[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_48 (BatchN  (None, 5, 5, 1280)  5120        ['conv2d_64[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_48 (Swish)               (None, 5, 5, 1280)   0           ['batch_normalization_48[0][0]'] \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 4,049,564\n",
            "Trainable params: 0\n",
            "Non-trainable params: 4,049,564\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#สร้างโฟลเดอร์ Train Valodation และ Test"
      ],
      "metadata": {
        "id": "J36J9EAE7qSB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv (r'/content/drive/MyDrive/cut_panoramic/Data/New_Data_Gender.csv')\n",
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "skoKhKJDngAZ",
        "outputId": "4f18a2af-b2f7-482d-9793-210c6589cef5"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      Fig_Age  Fig_Person_Sex  Age(year) Class  Class_Re       Filename  \\\n",
              "0           1               1          7  Y07F         0         V1.jpg   \n",
              "1           2               1          7  Y07F         0    Flip_V1.jpg   \n",
              "2           3               2          7  Y07F         0         V2.jpg   \n",
              "3           4               2          7  Y07F         0    Flip_V2.jpg   \n",
              "4           5               3          7  Y07F         0         V3.jpg   \n",
              "...       ...             ...        ...   ...       ...            ...   \n",
              "4745      121              77         25  Y25M         1  Flip_J463.jpg   \n",
              "4746      122              78         25  Y25M         1       J464.jpg   \n",
              "4747      123              78         25  Y25M         1  Flip_J464.jpg   \n",
              "4748      124              79         25  Y25M         1       J465.jpg   \n",
              "4749      125              79         25  Y25M         1  Flip_J465.jpg   \n",
              "\n",
              "                                          Path_filename     Sex Floder  \n",
              "0     /content/drive/My Drive/TVT_Gender/train/Femal...  Female   Both  \n",
              "1     /content/drive/My Drive/TVT_Gender/train/Femal...  Female   Both  \n",
              "2     /content/drive/My Drive/TVT_Gender/train/Femal...  Female   Both  \n",
              "3     /content/drive/My Drive/TVT_Gender/train/Femal...  Female   Both  \n",
              "4     /content/drive/My Drive/TVT_Gender/train/Femal...  Female   Both  \n",
              "...                                                 ...     ...    ...  \n",
              "4745  /content/drive/My Drive/TVT_Gender/test/Male/F...    Male   Both  \n",
              "4746  /content/drive/My Drive/TVT_Gender/test/Male/J...    Male   Both  \n",
              "4747  /content/drive/My Drive/TVT_Gender/test/Male/F...    Male   Both  \n",
              "4748  /content/drive/My Drive/TVT_Gender/test/Male/J...    Male   Both  \n",
              "4749  /content/drive/My Drive/TVT_Gender/test/Male/F...    Male   Both  \n",
              "\n",
              "[4750 rows x 9 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-913c1df7-f2d6-4059-a85b-399e0ec41b54\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Fig_Age</th>\n",
              "      <th>Fig_Person_Sex</th>\n",
              "      <th>Age(year)</th>\n",
              "      <th>Class</th>\n",
              "      <th>Class_Re</th>\n",
              "      <th>Filename</th>\n",
              "      <th>Path_filename</th>\n",
              "      <th>Sex</th>\n",
              "      <th>Floder</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>Y07F</td>\n",
              "      <td>0</td>\n",
              "      <td>V1.jpg</td>\n",
              "      <td>/content/drive/My Drive/TVT_Gender/train/Femal...</td>\n",
              "      <td>Female</td>\n",
              "      <td>Both</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>Y07F</td>\n",
              "      <td>0</td>\n",
              "      <td>Flip_V1.jpg</td>\n",
              "      <td>/content/drive/My Drive/TVT_Gender/train/Femal...</td>\n",
              "      <td>Female</td>\n",
              "      <td>Both</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>7</td>\n",
              "      <td>Y07F</td>\n",
              "      <td>0</td>\n",
              "      <td>V2.jpg</td>\n",
              "      <td>/content/drive/My Drive/TVT_Gender/train/Femal...</td>\n",
              "      <td>Female</td>\n",
              "      <td>Both</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>7</td>\n",
              "      <td>Y07F</td>\n",
              "      <td>0</td>\n",
              "      <td>Flip_V2.jpg</td>\n",
              "      <td>/content/drive/My Drive/TVT_Gender/train/Femal...</td>\n",
              "      <td>Female</td>\n",
              "      <td>Both</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>7</td>\n",
              "      <td>Y07F</td>\n",
              "      <td>0</td>\n",
              "      <td>V3.jpg</td>\n",
              "      <td>/content/drive/My Drive/TVT_Gender/train/Femal...</td>\n",
              "      <td>Female</td>\n",
              "      <td>Both</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4745</th>\n",
              "      <td>121</td>\n",
              "      <td>77</td>\n",
              "      <td>25</td>\n",
              "      <td>Y25M</td>\n",
              "      <td>1</td>\n",
              "      <td>Flip_J463.jpg</td>\n",
              "      <td>/content/drive/My Drive/TVT_Gender/test/Male/F...</td>\n",
              "      <td>Male</td>\n",
              "      <td>Both</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4746</th>\n",
              "      <td>122</td>\n",
              "      <td>78</td>\n",
              "      <td>25</td>\n",
              "      <td>Y25M</td>\n",
              "      <td>1</td>\n",
              "      <td>J464.jpg</td>\n",
              "      <td>/content/drive/My Drive/TVT_Gender/test/Male/J...</td>\n",
              "      <td>Male</td>\n",
              "      <td>Both</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4747</th>\n",
              "      <td>123</td>\n",
              "      <td>78</td>\n",
              "      <td>25</td>\n",
              "      <td>Y25M</td>\n",
              "      <td>1</td>\n",
              "      <td>Flip_J464.jpg</td>\n",
              "      <td>/content/drive/My Drive/TVT_Gender/test/Male/F...</td>\n",
              "      <td>Male</td>\n",
              "      <td>Both</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4748</th>\n",
              "      <td>124</td>\n",
              "      <td>79</td>\n",
              "      <td>25</td>\n",
              "      <td>Y25M</td>\n",
              "      <td>1</td>\n",
              "      <td>J465.jpg</td>\n",
              "      <td>/content/drive/My Drive/TVT_Gender/test/Male/J...</td>\n",
              "      <td>Male</td>\n",
              "      <td>Both</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4749</th>\n",
              "      <td>125</td>\n",
              "      <td>79</td>\n",
              "      <td>25</td>\n",
              "      <td>Y25M</td>\n",
              "      <td>1</td>\n",
              "      <td>Flip_J465.jpg</td>\n",
              "      <td>/content/drive/My Drive/TVT_Gender/test/Male/F...</td>\n",
              "      <td>Male</td>\n",
              "      <td>Both</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4750 rows × 9 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-913c1df7-f2d6-4059-a85b-399e0ec41b54')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-913c1df7-f2d6-4059-a85b-399e0ec41b54 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-913c1df7-f2d6-4059-a85b-399e0ec41b54');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train = df[df['Fig_Age'].between(1,75)]\n",
        "val = df[df['Fig_Age'].between(76,100)]"
      ],
      "metadata": {
        "id": "Z1zBw01Gl8Ac"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DATA_PATH = \"/content/drive/My Drive/TVT_Gender\"\n",
        "os.chdir(DATA_PATH)\n",
        "train_dir = os.path.join(DATA_PATH, 'train')\n",
        "print(train_dir)\n",
        "validation_dir = os.path.join(DATA_PATH, 'validation')\n",
        "print(validation_dir)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QL0g-8iOnMC4",
        "outputId": "a280e97b-5238-45f5-9be7-b312b3bb8e48"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/My Drive/TVT_Gender/train\n",
            "/content/drive/My Drive/TVT_Gender/validation\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "#Train"
      ],
      "metadata": {
        "id": "bWEnlTSwazL5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train ด้วย ImageDataGenerator ของ Keras ซึ่งจะเพิ่มข้อมูลเสริมระหว่างการฝึกเพื่อลดโอกาสเกิด overfitting\n",
        "#overfitting เกิดจากข้อมูลที่ซับซ้อนกันเกินไป\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "train_datagen = ImageDataGenerator(\n",
        "      rescale=1./255, #โมเดลส่วนใหญ่ต้องใช้ RGB ในช่วง 0–1\n",
        "      rotation_range=40,\n",
        "      width_shift_range=0.2,\n",
        "      height_shift_range=0.2,\n",
        "      shear_range=0.2,\n",
        "      zoom_range=0.2,\n",
        "      horizontal_flip=True,\n",
        "      fill_mode='nearest')\n",
        "\n",
        "# Note that the validation data should not be augmented!\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)"
      ],
      "metadata": {
        "id": "xGPrsn9no_pa"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_generator = train_datagen.flow_from_dataframe(\n",
        "        dataframe = train,\n",
        "        directory = train_dir,\n",
        "        x_col = 'Path_filename',\n",
        "        y_col = 'Class_Re',\n",
        "        class_mode = 'other',\n",
        "        target_size=(height, width),\n",
        "        batch_size=batch_size)\n",
        "\n",
        "validation_generator = test_datagen.flow_from_dataframe(\n",
        "        dataframe = val,\n",
        "        directory = validation_dir,\n",
        "        x_col = 'Path_filename',\n",
        "        y_col = 'Class_Re',\n",
        "        class_mode = 'other',\n",
        "        target_size=(height, width),\n",
        "        batch_size=batch_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8nVlmAszntK_",
        "outputId": "3558cc6b-9e2f-4fbc-8fb7-d19c8a6fc763"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 2850 validated image filenames.\n",
            "Found 950 validated image filenames.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='mse',\n",
        "          optimizer=Adam(learning_rate=2e-3),\n",
        "          metrics=['mae'])\n",
        "history = model.fit_generator(\n",
        "      train_generator,\n",
        "      steps_per_epoch= NUM_TRAIN //batch_size,\n",
        "      epochs=epochs,\n",
        "      validation_data=validation_generator,\n",
        "      validation_steps= NUM_TEST //batch_size,\n",
        "      verbose=1,\n",
        "      use_multiprocessing=True,\n",
        "      workers=4)"
      ],
      "metadata": {
        "id": "N6qUmmF856ZE",
        "outputId": "bd93a5e7-0dd0-4933-8cfa-429746e80daa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-18-5cad5f8ae7ec>:4: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  history = model.fit_generator(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/250\n",
            "178/178 [==============================] - 641s 3s/step - loss: 0.3956 - mae: 0.5170 - val_loss: 0.2690 - val_mae: 0.5003\n",
            "Epoch 2/250\n",
            "178/178 [==============================] - 44s 242ms/step - loss: 0.2545 - mae: 0.5004 - val_loss: 0.2500 - val_mae: 0.5000\n",
            "Epoch 3/250\n",
            "178/178 [==============================] - 46s 254ms/step - loss: 0.2501 - mae: 0.5001 - val_loss: 0.2500 - val_mae: 0.5000\n",
            "Epoch 4/250\n",
            "178/178 [==============================] - 43s 240ms/step - loss: 0.2502 - mae: 0.5002 - val_loss: 0.2500 - val_mae: 0.5000\n",
            "Epoch 5/250\n",
            "178/178 [==============================] - 38s 206ms/step - loss: 0.2502 - mae: 0.5001 - val_loss: 0.2501 - val_mae: 0.5000\n",
            "Epoch 6/250\n",
            "178/178 [==============================] - 43s 235ms/step - loss: 0.2505 - mae: 0.5004 - val_loss: 0.2500 - val_mae: 0.5000\n",
            "Epoch 7/250\n",
            "178/178 [==============================] - 42s 231ms/step - loss: 0.2502 - mae: 0.5001 - val_loss: 0.2505 - val_mae: 0.5000\n",
            "Epoch 8/250\n",
            "178/178 [==============================] - 44s 242ms/step - loss: 0.2503 - mae: 0.5002 - val_loss: 0.2500 - val_mae: 0.5000\n",
            "Epoch 9/250\n",
            "178/178 [==============================] - 43s 240ms/step - loss: 0.2505 - mae: 0.5003 - val_loss: 0.2501 - val_mae: 0.5000\n",
            "Epoch 10/250\n",
            "178/178 [==============================] - 43s 240ms/step - loss: 0.2503 - mae: 0.5002 - val_loss: 0.2500 - val_mae: 0.5000\n",
            "Epoch 11/250\n",
            "178/178 [==============================] - 42s 231ms/step - loss: 0.2503 - mae: 0.5002 - val_loss: 0.2500 - val_mae: 0.5000\n",
            "Epoch 12/250\n",
            "178/178 [==============================] - 44s 241ms/step - loss: 0.2503 - mae: 0.5003 - val_loss: 0.2500 - val_mae: 0.5000\n",
            "Epoch 13/250\n",
            "178/178 [==============================] - 44s 242ms/step - loss: 0.2501 - mae: 0.5001 - val_loss: 0.2502 - val_mae: 0.5000\n",
            "Epoch 14/250\n",
            "178/178 [==============================] - 43s 240ms/step - loss: 0.2502 - mae: 0.5002 - val_loss: 0.2503 - val_mae: 0.5000\n",
            "Epoch 15/250\n",
            "178/178 [==============================] - 44s 242ms/step - loss: 0.2502 - mae: 0.5002 - val_loss: 0.2501 - val_mae: 0.5000\n",
            "Epoch 16/250\n",
            "178/178 [==============================] - 45s 250ms/step - loss: 0.2502 - mae: 0.5002 - val_loss: 0.2500 - val_mae: 0.5000\n",
            "Epoch 17/250\n",
            "178/178 [==============================] - 42s 233ms/step - loss: 0.2502 - mae: 0.5001 - val_loss: 0.2500 - val_mae: 0.5000\n",
            "Epoch 18/250\n",
            "178/178 [==============================] - 42s 234ms/step - loss: 0.2502 - mae: 0.5001 - val_loss: 0.2500 - val_mae: 0.5000\n",
            "Epoch 19/250\n",
            "178/178 [==============================] - 42s 232ms/step - loss: 0.2503 - mae: 0.5001 - val_loss: 0.2500 - val_mae: 0.5000\n",
            "Epoch 20/250\n",
            "178/178 [==============================] - 44s 244ms/step - loss: 0.2503 - mae: 0.5001 - val_loss: 0.2505 - val_mae: 0.5000\n",
            "Epoch 21/250\n",
            "178/178 [==============================] - 44s 243ms/step - loss: 0.2502 - mae: 0.5000 - val_loss: 0.2502 - val_mae: 0.4999\n",
            "Epoch 22/250\n",
            "178/178 [==============================] - 43s 237ms/step - loss: 0.2503 - mae: 0.5001 - val_loss: 0.2501 - val_mae: 0.5000\n",
            "Epoch 23/250\n",
            "178/178 [==============================] - 44s 243ms/step - loss: 0.2504 - mae: 0.5003 - val_loss: 0.2502 - val_mae: 0.5000\n",
            "Epoch 24/250\n",
            "178/178 [==============================] - 42s 233ms/step - loss: 0.2505 - mae: 0.5001 - val_loss: 0.2501 - val_mae: 0.5000\n",
            "Epoch 25/250\n",
            "178/178 [==============================] - 44s 244ms/step - loss: 0.2499 - mae: 0.4996 - val_loss: 0.2507 - val_mae: 0.5000\n",
            "Epoch 26/250\n",
            "178/178 [==============================] - 44s 243ms/step - loss: 0.2505 - mae: 0.5004 - val_loss: 0.2501 - val_mae: 0.5000\n",
            "Epoch 27/250\n",
            "178/178 [==============================] - 43s 234ms/step - loss: 0.2502 - mae: 0.5002 - val_loss: 0.2500 - val_mae: 0.5000\n",
            "Epoch 28/250\n",
            "178/178 [==============================] - 43s 235ms/step - loss: 0.2504 - mae: 0.5002 - val_loss: 0.2502 - val_mae: 0.5000\n",
            "Epoch 29/250\n",
            "178/178 [==============================] - 42s 230ms/step - loss: 0.2507 - mae: 0.5005 - val_loss: 0.2500 - val_mae: 0.5000\n",
            "Epoch 30/250\n",
            "178/178 [==============================] - 42s 231ms/step - loss: 0.2503 - mae: 0.5002 - val_loss: 0.2501 - val_mae: 0.5000\n",
            "Epoch 31/250\n",
            "178/178 [==============================] - 45s 255ms/step - loss: 0.2504 - mae: 0.5002 - val_loss: 0.2503 - val_mae: 0.5001\n",
            "Epoch 32/250\n",
            "178/178 [==============================] - 44s 242ms/step - loss: 0.2504 - mae: 0.5001 - val_loss: 0.2500 - val_mae: 0.5000\n",
            "Epoch 33/250\n",
            "178/178 [==============================] - 44s 242ms/step - loss: 0.2503 - mae: 0.5002 - val_loss: 0.2500 - val_mae: 0.5000\n",
            "Epoch 34/250\n",
            "178/178 [==============================] - 43s 241ms/step - loss: 0.2504 - mae: 0.5003 - val_loss: 0.2501 - val_mae: 0.5000\n",
            "Epoch 35/250\n",
            "178/178 [==============================] - 44s 241ms/step - loss: 0.2505 - mae: 0.5004 - val_loss: 0.2500 - val_mae: 0.5000\n",
            "Epoch 36/250\n",
            "178/178 [==============================] - 43s 234ms/step - loss: 0.2504 - mae: 0.5004 - val_loss: 0.2500 - val_mae: 0.5000\n",
            "Epoch 37/250\n",
            "178/178 [==============================] - 43s 239ms/step - loss: 0.2504 - mae: 0.5003 - val_loss: 0.2500 - val_mae: 0.5000\n",
            "Epoch 38/250\n",
            "178/178 [==============================] - 44s 245ms/step - loss: 0.2504 - mae: 0.5003 - val_loss: 0.2501 - val_mae: 0.5000\n",
            "Epoch 39/250\n",
            "178/178 [==============================] - 44s 243ms/step - loss: 0.2503 - mae: 0.5002 - val_loss: 0.2501 - val_mae: 0.5000\n",
            "Epoch 40/250\n",
            "178/178 [==============================] - 43s 241ms/step - loss: 0.2504 - mae: 0.5002 - val_loss: 0.2500 - val_mae: 0.5000\n",
            "Epoch 41/250\n",
            "178/178 [==============================] - 44s 241ms/step - loss: 0.2504 - mae: 0.5000 - val_loss: 0.2500 - val_mae: 0.5000\n",
            "Epoch 42/250\n",
            "178/178 [==============================] - 44s 241ms/step - loss: 0.2502 - mae: 0.4998 - val_loss: 0.2504 - val_mae: 0.5000\n",
            "Epoch 43/250\n",
            "178/178 [==============================] - 43s 238ms/step - loss: 0.2505 - mae: 0.5002 - val_loss: 0.2500 - val_mae: 0.5000\n",
            "Epoch 44/250\n",
            "178/178 [==============================] - 43s 232ms/step - loss: 0.2503 - mae: 0.5001 - val_loss: 0.2500 - val_mae: 0.5000\n",
            "Epoch 45/250\n",
            "178/178 [==============================] - 42s 233ms/step - loss: 0.2502 - mae: 0.4999 - val_loss: 0.2501 - val_mae: 0.4999\n",
            "Epoch 46/250\n",
            "178/178 [==============================] - 44s 243ms/step - loss: 0.2502 - mae: 0.5000 - val_loss: 0.2502 - val_mae: 0.5000\n",
            "Epoch 47/250\n",
            "178/178 [==============================] - 43s 239ms/step - loss: 0.2503 - mae: 0.5002 - val_loss: 0.2500 - val_mae: 0.5000\n",
            "Epoch 48/250\n",
            "178/178 [==============================] - 43s 234ms/step - loss: 0.2504 - mae: 0.5003 - val_loss: 0.2501 - val_mae: 0.5000\n",
            "Epoch 49/250\n",
            "178/178 [==============================] - 43s 232ms/step - loss: 0.2503 - mae: 0.5002 - val_loss: 0.2500 - val_mae: 0.5000\n",
            "Epoch 50/250\n",
            "178/178 [==============================] - 42s 229ms/step - loss: 0.2503 - mae: 0.5000 - val_loss: 0.2500 - val_mae: 0.5000\n",
            "Epoch 51/250\n",
            "178/178 [==============================] - 41s 229ms/step - loss: 0.2502 - mae: 0.5002 - val_loss: 0.2500 - val_mae: 0.5000\n",
            "Epoch 52/250\n",
            "178/178 [==============================] - 42s 233ms/step - loss: 0.2503 - mae: 0.5003 - val_loss: 0.2500 - val_mae: 0.5000\n",
            "Epoch 53/250\n",
            "178/178 [==============================] - 43s 240ms/step - loss: 0.2503 - mae: 0.5002 - val_loss: 0.2500 - val_mae: 0.5000\n",
            "Epoch 54/250\n",
            "178/178 [==============================] - 40s 220ms/step - loss: 0.2503 - mae: 0.5002 - val_loss: 0.2501 - val_mae: 0.5000\n",
            "Epoch 55/250\n",
            "178/178 [==============================] - 43s 241ms/step - loss: 0.2504 - mae: 0.5003 - val_loss: 0.2500 - val_mae: 0.5000\n",
            "Epoch 56/250\n",
            "178/178 [==============================] - 42s 231ms/step - loss: 0.2504 - mae: 0.5001 - val_loss: 0.2502 - val_mae: 0.5000\n",
            "Epoch 57/250\n",
            "178/178 [==============================] - 41s 230ms/step - loss: 0.2505 - mae: 0.5002 - val_loss: 0.2504 - val_mae: 0.5000\n",
            "Epoch 58/250\n",
            "178/178 [==============================] - 43s 240ms/step - loss: 0.2505 - mae: 0.5002 - val_loss: 0.2503 - val_mae: 0.5000\n",
            "Epoch 59/250\n",
            "178/178 [==============================] - 43s 241ms/step - loss: 0.2503 - mae: 0.5000 - val_loss: 0.2501 - val_mae: 0.5000\n",
            "Epoch 60/250\n",
            "178/178 [==============================] - 43s 240ms/step - loss: 0.2502 - mae: 0.5000 - val_loss: 0.2503 - val_mae: 0.5000\n",
            "Epoch 61/250\n",
            "178/178 [==============================] - 43s 237ms/step - loss: 0.2505 - mae: 0.5003 - val_loss: 0.2500 - val_mae: 0.5000\n",
            "Epoch 62/250\n",
            "178/178 [==============================] - 43s 235ms/step - loss: 0.2503 - mae: 0.5002 - val_loss: 0.2500 - val_mae: 0.5000\n",
            "Epoch 63/250\n",
            "178/178 [==============================] - 44s 243ms/step - loss: 0.2504 - mae: 0.5003 - val_loss: 0.2501 - val_mae: 0.5000\n",
            "Epoch 64/250\n",
            "178/178 [==============================] - 42s 232ms/step - loss: 0.2503 - mae: 0.5000 - val_loss: 0.2500 - val_mae: 0.5000\n",
            "Epoch 65/250\n",
            "178/178 [==============================] - 42s 231ms/step - loss: 0.2504 - mae: 0.5002 - val_loss: 0.2502 - val_mae: 0.5000\n",
            "Epoch 66/250\n",
            "178/178 [==============================] - 43s 237ms/step - loss: 0.2502 - mae: 0.4999 - val_loss: 0.2503 - val_mae: 0.5000\n",
            "Epoch 67/250\n",
            "178/178 [==============================] - 43s 238ms/step - loss: 0.2503 - mae: 0.5001 - val_loss: 0.2503 - val_mae: 0.5000\n",
            "Epoch 68/250\n",
            "178/178 [==============================] - 43s 240ms/step - loss: 0.2503 - mae: 0.5000 - val_loss: 0.2502 - val_mae: 0.4999\n",
            "Epoch 69/250\n",
            "178/178 [==============================] - 40s 219ms/step - loss: 0.2502 - mae: 0.4999 - val_loss: 0.2503 - val_mae: 0.5000\n",
            "Epoch 70/250\n",
            "178/178 [==============================] - 45s 251ms/step - loss: 0.2503 - mae: 0.5002 - val_loss: 0.2503 - val_mae: 0.5000\n",
            "Epoch 71/250\n",
            "178/178 [==============================] - 43s 241ms/step - loss: 0.2498 - mae: 0.4989 - val_loss: 0.2504 - val_mae: 0.5000\n",
            "Epoch 72/250\n",
            "178/178 [==============================] - 39s 217ms/step - loss: 0.2502 - mae: 0.5001 - val_loss: 0.2500 - val_mae: 0.5000\n",
            "Epoch 73/250\n",
            "178/178 [==============================] - 43s 239ms/step - loss: 0.2504 - mae: 0.5003 - val_loss: 0.2500 - val_mae: 0.5000\n",
            "Epoch 74/250\n",
            "178/178 [==============================] - 43s 239ms/step - loss: 0.2502 - mae: 0.5001 - val_loss: 0.2505 - val_mae: 0.5000\n",
            "Epoch 75/250\n",
            "178/178 [==============================] - 43s 240ms/step - loss: 0.2504 - mae: 0.5002 - val_loss: 0.2501 - val_mae: 0.5000\n",
            "Epoch 76/250\n",
            "178/178 [==============================] - 45s 248ms/step - loss: 0.2503 - mae: 0.5001 - val_loss: 0.2501 - val_mae: 0.5000\n",
            "Epoch 77/250\n",
            "178/178 [==============================] - 42s 229ms/step - loss: 0.2503 - mae: 0.5000 - val_loss: 0.2502 - val_mae: 0.5000\n",
            "Epoch 78/250\n",
            "178/178 [==============================] - 41s 229ms/step - loss: 0.2502 - mae: 0.4998 - val_loss: 0.2501 - val_mae: 0.5000\n",
            "Epoch 79/250\n",
            "178/178 [==============================] - 41s 229ms/step - loss: 0.2501 - mae: 0.4994 - val_loss: 0.2501 - val_mae: 0.5000\n",
            "Epoch 80/250\n",
            "178/178 [==============================] - 42s 230ms/step - loss: 0.2503 - mae: 0.5003 - val_loss: 0.2500 - val_mae: 0.5000\n",
            "Epoch 81/250\n",
            "178/178 [==============================] - 42s 234ms/step - loss: 0.2502 - mae: 0.4999 - val_loss: 0.2500 - val_mae: 0.5000\n",
            "Epoch 82/250\n",
            "178/178 [==============================] - 43s 241ms/step - loss: 0.2504 - mae: 0.5003 - val_loss: 0.2500 - val_mae: 0.5000\n",
            "Epoch 83/250\n",
            "178/178 [==============================] - 40s 223ms/step - loss: 0.2505 - mae: 0.5003 - val_loss: 0.2500 - val_mae: 0.5000\n",
            "Epoch 84/250\n",
            "178/178 [==============================] - 43s 240ms/step - loss: 0.2503 - mae: 0.5002 - val_loss: 0.2501 - val_mae: 0.5000\n",
            "Epoch 85/250\n",
            "178/178 [==============================] - 43s 240ms/step - loss: 0.2502 - mae: 0.5001 - val_loss: 0.2500 - val_mae: 0.5000\n",
            "Epoch 86/250\n",
            "178/178 [==============================] - 43s 240ms/step - loss: 0.2504 - mae: 0.5002 - val_loss: 0.2500 - val_mae: 0.5000\n",
            "Epoch 87/250\n",
            "178/178 [==============================] - 43s 235ms/step - loss: 0.2505 - mae: 0.5004 - val_loss: 0.2501 - val_mae: 0.5000\n",
            "Epoch 88/250\n",
            "178/178 [==============================] - 42s 230ms/step - loss: 0.2504 - mae: 0.5003 - val_loss: 0.2500 - val_mae: 0.5000\n",
            "Epoch 89/250\n",
            "178/178 [==============================] - 42s 232ms/step - loss: 0.2504 - mae: 0.5003 - val_loss: 0.2500 - val_mae: 0.5000\n",
            "Epoch 90/250\n",
            "178/178 [==============================] - 41s 229ms/step - loss: 0.2504 - mae: 0.5001 - val_loss: 0.2501 - val_mae: 0.5000\n",
            "Epoch 91/250\n",
            "178/178 [==============================] - 43s 237ms/step - loss: 0.2504 - mae: 0.5003 - val_loss: 0.2501 - val_mae: 0.5000\n",
            "Epoch 92/250\n",
            "178/178 [==============================] - 43s 237ms/step - loss: 0.2503 - mae: 0.5002 - val_loss: 0.2504 - val_mae: 0.5000\n",
            "Epoch 93/250\n",
            "178/178 [==============================] - 43s 237ms/step - loss: 0.2504 - mae: 0.5003 - val_loss: 0.2500 - val_mae: 0.5000\n",
            "Epoch 94/250\n",
            "178/178 [==============================] - 43s 240ms/step - loss: 0.2504 - mae: 0.5003 - val_loss: 0.2500 - val_mae: 0.5000\n",
            "Epoch 95/250\n",
            "178/178 [==============================] - 43s 235ms/step - loss: 0.2502 - mae: 0.5001 - val_loss: 0.2503 - val_mae: 0.5001\n",
            "Epoch 96/250\n",
            "178/178 [==============================] - 42s 232ms/step - loss: 0.2504 - mae: 0.5003 - val_loss: 0.2500 - val_mae: 0.5000\n",
            "Epoch 97/250\n",
            "178/178 [==============================] - 41s 227ms/step - loss: 0.2501 - mae: 0.5000 - val_loss: 0.2502 - val_mae: 0.5000\n",
            "Epoch 98/250\n",
            "178/178 [==============================] - 43s 239ms/step - loss: 0.2503 - mae: 0.5002 - val_loss: 0.2500 - val_mae: 0.5000\n",
            "Epoch 99/250\n",
            "178/178 [==============================] - 43s 241ms/step - loss: 0.2502 - mae: 0.5001 - val_loss: 0.2505 - val_mae: 0.5000\n",
            "Epoch 100/250\n",
            "178/178 [==============================] - 42s 231ms/step - loss: 0.2505 - mae: 0.5004 - val_loss: 0.2501 - val_mae: 0.5000\n",
            "Epoch 101/250\n",
            "178/178 [==============================] - 45s 248ms/step - loss: 0.2503 - mae: 0.5002 - val_loss: 0.2508 - val_mae: 0.5001\n",
            "Epoch 102/250\n",
            "178/178 [==============================] - 43s 238ms/step - loss: 0.2503 - mae: 0.5000 - val_loss: 0.2501 - val_mae: 0.5000\n",
            "Epoch 103/250\n",
            "178/178 [==============================] - 44s 242ms/step - loss: 0.2505 - mae: 0.5002 - val_loss: 0.2506 - val_mae: 0.4999\n",
            "Epoch 104/250\n",
            "178/178 [==============================] - 44s 240ms/step - loss: 0.2506 - mae: 0.5003 - val_loss: 0.2500 - val_mae: 0.5000\n",
            "Epoch 105/250\n",
            "178/178 [==============================] - 42s 232ms/step - loss: 0.2504 - mae: 0.5003 - val_loss: 0.2500 - val_mae: 0.5000\n",
            "Epoch 106/250\n",
            "178/178 [==============================] - 44s 246ms/step - loss: 0.2504 - mae: 0.5002 - val_loss: 0.2501 - val_mae: 0.5000\n",
            "Epoch 107/250\n",
            "178/178 [==============================] - 43s 241ms/step - loss: 0.2502 - mae: 0.5002 - val_loss: 0.2500 - val_mae: 0.5000\n",
            "Epoch 108/250\n",
            "178/178 [==============================] - 43s 238ms/step - loss: 0.2504 - mae: 0.5002 - val_loss: 0.2501 - val_mae: 0.5000\n",
            "Epoch 109/250\n",
            "178/178 [==============================] - 42s 231ms/step - loss: 0.2503 - mae: 0.5002 - val_loss: 0.2501 - val_mae: 0.5000\n",
            "Epoch 110/250\n",
            "178/178 [==============================] - 41s 228ms/step - loss: 0.2504 - mae: 0.5004 - val_loss: 0.2503 - val_mae: 0.5000\n",
            "Epoch 111/250\n",
            "178/178 [==============================] - 45s 248ms/step - loss: 0.2502 - mae: 0.5001 - val_loss: 0.2507 - val_mae: 0.5001\n",
            "Epoch 112/250\n",
            "178/178 [==============================] - 43s 240ms/step - loss: 0.2503 - mae: 0.4998 - val_loss: 0.2504 - val_mae: 0.4999\n",
            "Epoch 113/250\n",
            "178/178 [==============================] - 43s 240ms/step - loss: 0.2505 - mae: 0.5001 - val_loss: 0.2502 - val_mae: 0.4999\n",
            "Epoch 114/250\n",
            "178/178 [==============================] - 42s 231ms/step - loss: 0.2503 - mae: 0.5002 - val_loss: 0.2500 - val_mae: 0.5000\n",
            "Epoch 115/250\n",
            "178/178 [==============================] - 42s 228ms/step - loss: 0.2502 - mae: 0.5002 - val_loss: 0.2500 - val_mae: 0.5000\n",
            "Epoch 116/250\n",
            "178/178 [==============================] - 42s 228ms/step - loss: 0.2499 - mae: 0.4997 - val_loss: 0.2504 - val_mae: 0.5000\n",
            "Epoch 117/250\n",
            "178/178 [==============================] - 43s 239ms/step - loss: 0.2504 - mae: 0.5003 - val_loss: 0.2502 - val_mae: 0.4999\n",
            "Epoch 118/250\n",
            "178/178 [==============================] - 44s 244ms/step - loss: 0.2502 - mae: 0.5000 - val_loss: 0.2500 - val_mae: 0.5000\n",
            "Epoch 119/250\n",
            "178/178 [==============================] - 44s 246ms/step - loss: 0.2503 - mae: 0.5003 - val_loss: 0.2501 - val_mae: 0.5000\n",
            "Epoch 120/250\n",
            "178/178 [==============================] - 44s 243ms/step - loss: 0.2503 - mae: 0.5001 - val_loss: 0.2504 - val_mae: 0.5000\n",
            "Epoch 121/250\n",
            "178/178 [==============================] - 44s 241ms/step - loss: 0.2502 - mae: 0.5000 - val_loss: 0.2502 - val_mae: 0.5000\n",
            "Epoch 122/250\n",
            "178/178 [==============================] - 43s 240ms/step - loss: 0.2503 - mae: 0.5002 - val_loss: 0.2501 - val_mae: 0.5000\n",
            "Epoch 123/250\n",
            "178/178 [==============================] - 41s 230ms/step - loss: 0.2502 - mae: 0.4999 - val_loss: 0.2504 - val_mae: 0.5000\n",
            "Epoch 124/250\n",
            "178/178 [==============================] - 43s 240ms/step - loss: 0.2503 - mae: 0.5001 - val_loss: 0.2500 - val_mae: 0.5000\n",
            "Epoch 125/250\n",
            "178/178 [==============================] - 44s 241ms/step - loss: 0.2504 - mae: 0.5004 - val_loss: 0.2500 - val_mae: 0.5000\n",
            "Epoch 126/250\n",
            "178/178 [==============================] - 43s 240ms/step - loss: 0.2504 - mae: 0.5003 - val_loss: 0.2501 - val_mae: 0.5000\n",
            "Epoch 127/250\n",
            "178/178 [==============================] - 43s 240ms/step - loss: 0.2503 - mae: 0.5000 - val_loss: 0.2505 - val_mae: 0.5000\n",
            "Epoch 128/250\n",
            "178/178 [==============================] - 45s 251ms/step - loss: 0.2504 - mae: 0.5002 - val_loss: 0.2500 - val_mae: 0.5000\n",
            "Epoch 129/250\n",
            "178/178 [==============================] - 43s 234ms/step - loss: 0.2503 - mae: 0.5002 - val_loss: 0.2500 - val_mae: 0.5000\n",
            "Epoch 130/250\n",
            "178/178 [==============================] - 42s 230ms/step - loss: 0.2505 - mae: 0.5002 - val_loss: 0.2500 - val_mae: 0.5000\n",
            "Epoch 131/250\n",
            "178/178 [==============================] - 42s 233ms/step - loss: 0.2502 - mae: 0.5001 - val_loss: 0.2501 - val_mae: 0.5000\n",
            "Epoch 132/250\n",
            "178/178 [==============================] - 43s 239ms/step - loss: 0.2502 - mae: 0.4996 - val_loss: 0.2500 - val_mae: 0.5000\n",
            "Epoch 133/250\n",
            "178/178 [==============================] - 43s 241ms/step - loss: 0.2502 - mae: 0.5002 - val_loss: 0.2501 - val_mae: 0.5000\n",
            "Epoch 134/250\n",
            "178/178 [==============================] - 45s 250ms/step - loss: 0.2503 - mae: 0.5001 - val_loss: 0.2500 - val_mae: 0.5000\n",
            "Epoch 135/250\n",
            "178/178 [==============================] - 42s 232ms/step - loss: 0.2504 - mae: 0.5003 - val_loss: 0.2500 - val_mae: 0.5000\n",
            "Epoch 136/250\n",
            "178/178 [==============================] - 42s 230ms/step - loss: 0.2506 - mae: 0.5003 - val_loss: 0.2500 - val_mae: 0.5000\n",
            "Epoch 137/250\n",
            "178/178 [==============================] - 43s 237ms/step - loss: 0.2503 - mae: 0.5003 - val_loss: 0.2500 - val_mae: 0.5000\n",
            "Epoch 138/250\n",
            "178/178 [==============================] - 43s 237ms/step - loss: 0.2502 - mae: 0.5000 - val_loss: 0.2505 - val_mae: 0.5000\n",
            "Epoch 139/250\n",
            "178/178 [==============================] - 45s 250ms/step - loss: 0.2503 - mae: 0.5001 - val_loss: 0.2501 - val_mae: 0.5000\n",
            "Epoch 140/250\n",
            "178/178 [==============================] - 43s 236ms/step - loss: 0.2500 - mae: 0.4997 - val_loss: 0.2510 - val_mae: 0.4999\n",
            "Epoch 141/250\n",
            "178/178 [==============================] - 43s 235ms/step - loss: 0.2507 - mae: 0.5004 - val_loss: 0.2502 - val_mae: 0.5000\n",
            "Epoch 142/250\n",
            "178/178 [==============================] - 42s 228ms/step - loss: 0.2503 - mae: 0.5002 - val_loss: 0.2500 - val_mae: 0.5000\n",
            "Epoch 143/250\n",
            "178/178 [==============================] - 43s 237ms/step - loss: 0.2503 - mae: 0.5003 - val_loss: 0.2500 - val_mae: 0.5000\n",
            "Epoch 144/250\n",
            "178/178 [==============================] - 43s 238ms/step - loss: 0.2502 - mae: 0.5000 - val_loss: 0.2505 - val_mae: 0.5000\n",
            "Epoch 145/250\n",
            "178/178 [==============================] - 43s 240ms/step - loss: 0.2503 - mae: 0.4997 - val_loss: 0.2502 - val_mae: 0.5000\n",
            "Epoch 146/250\n",
            "178/178 [==============================] - 45s 249ms/step - loss: 0.2503 - mae: 0.5000 - val_loss: 0.2500 - val_mae: 0.5000\n",
            "Epoch 147/250\n",
            "178/178 [==============================] - 43s 239ms/step - loss: 0.2501 - mae: 0.4998 - val_loss: 0.2500 - val_mae: 0.5000\n",
            "Epoch 148/250\n",
            "178/178 [==============================] - 43s 241ms/step - loss: 0.2505 - mae: 0.5004 - val_loss: 0.2500 - val_mae: 0.5000\n",
            "Epoch 149/250\n",
            "178/178 [==============================] - 43s 241ms/step - loss: 0.2502 - mae: 0.5001 - val_loss: 0.2502 - val_mae: 0.5000\n",
            "Epoch 150/250\n",
            "178/178 [==============================] - 42s 230ms/step - loss: 0.2504 - mae: 0.5002 - val_loss: 0.2500 - val_mae: 0.5000\n",
            "Epoch 151/250\n",
            "178/178 [==============================] - 41s 229ms/step - loss: 0.2502 - mae: 0.5001 - val_loss: 0.2501 - val_mae: 0.5000\n",
            "Epoch 152/250\n",
            "178/178 [==============================] - 39s 214ms/step - loss: 0.2503 - mae: 0.5002 - val_loss: 0.2500 - val_mae: 0.5000\n",
            "Epoch 153/250\n",
            "178/178 [==============================] - 42s 229ms/step - loss: 0.2502 - mae: 0.5001 - val_loss: 0.2500 - val_mae: 0.5000\n",
            "Epoch 154/250\n",
            "178/178 [==============================] - 43s 239ms/step - loss: 0.2503 - mae: 0.5002 - val_loss: 0.2500 - val_mae: 0.5000\n",
            "Epoch 155/250\n",
            "178/178 [==============================] - 45s 252ms/step - loss: 0.2504 - mae: 0.5002 - val_loss: 0.2500 - val_mae: 0.5000\n",
            "Epoch 156/250\n",
            "178/178 [==============================] - 43s 234ms/step - loss: 0.2503 - mae: 0.5002 - val_loss: 0.2501 - val_mae: 0.5000\n",
            "Epoch 157/250\n",
            "178/178 [==============================] - 42s 236ms/step - loss: 0.2501 - mae: 0.5000 - val_loss: 0.2502 - val_mae: 0.5000\n",
            "Epoch 158/250\n",
            "178/178 [==============================] - 41s 229ms/step - loss: 0.2503 - mae: 0.5002 - val_loss: 0.2502 - val_mae: 0.5000\n",
            "Epoch 159/250\n",
            "178/178 [==============================] - 44s 241ms/step - loss: 0.2504 - mae: 0.5002 - val_loss: 0.2502 - val_mae: 0.5000\n",
            "Epoch 160/250\n",
            "178/178 [==============================] - 43s 240ms/step - loss: 0.2501 - mae: 0.4998 - val_loss: 0.2501 - val_mae: 0.5000\n",
            "Epoch 161/250\n",
            "178/178 [==============================] - 45s 251ms/step - loss: 0.2502 - mae: 0.5002 - val_loss: 0.2502 - val_mae: 0.5000\n",
            "Epoch 162/250\n",
            "178/178 [==============================] - 44s 242ms/step - loss: 0.2503 - mae: 0.5002 - val_loss: 0.2501 - val_mae: 0.5000\n",
            "Epoch 163/250\n",
            "178/178 [==============================] - 44s 244ms/step - loss: 0.2501 - mae: 0.4999 - val_loss: 0.2503 - val_mae: 0.4999\n",
            "Epoch 164/250\n",
            "178/178 [==============================] - 42s 232ms/step - loss: 0.2504 - mae: 0.5003 - val_loss: 0.2500 - val_mae: 0.5000\n",
            "Epoch 165/250\n",
            "178/178 [==============================] - 41s 229ms/step - loss: 0.2502 - mae: 0.5002 - val_loss: 0.2500 - val_mae: 0.5000\n",
            "Epoch 166/250\n",
            "178/178 [==============================] - 43s 239ms/step - loss: 0.2505 - mae: 0.5004 - val_loss: 0.2500 - val_mae: 0.5000\n",
            "Epoch 167/250\n",
            "178/178 [==============================] - 45s 252ms/step - loss: 0.2502 - mae: 0.4999 - val_loss: 0.2501 - val_mae: 0.5000\n",
            "Epoch 168/250\n",
            "178/178 [==============================] - 43s 241ms/step - loss: 0.2505 - mae: 0.5004 - val_loss: 0.2500 - val_mae: 0.5000\n",
            "Epoch 169/250\n",
            "178/178 [==============================] - 43s 235ms/step - loss: 0.2502 - mae: 0.5001 - val_loss: 0.2503 - val_mae: 0.5000\n",
            "Epoch 170/250\n",
            "178/178 [==============================] - 41s 226ms/step - loss: 0.2501 - mae: 0.4999 - val_loss: 0.2500 - val_mae: 0.5000\n",
            "Epoch 171/250\n",
            "178/178 [==============================] - 43s 238ms/step - loss: 0.2502 - mae: 0.5001 - val_loss: 0.2500 - val_mae: 0.5000\n",
            "Epoch 172/250\n",
            "178/178 [==============================] - 41s 230ms/step - loss: 0.2503 - mae: 0.5002 - val_loss: 0.2502 - val_mae: 0.5000\n",
            "Epoch 173/250\n",
            "178/178 [==============================] - 41s 226ms/step - loss: 0.2503 - mae: 0.5001 - val_loss: 0.2500 - val_mae: 0.5000\n",
            "Epoch 174/250\n",
            "178/178 [==============================] - 41s 227ms/step - loss: 0.2502 - mae: 0.5001 - val_loss: 0.2500 - val_mae: 0.5000\n",
            "Epoch 175/250\n",
            "178/178 [==============================] - 41s 230ms/step - loss: 0.2504 - mae: 0.5003 - val_loss: 0.2500 - val_mae: 0.5000\n",
            "Epoch 176/250\n",
            "178/178 [==============================] - 41s 230ms/step - loss: 0.2503 - mae: 0.5002 - val_loss: 0.2501 - val_mae: 0.5000\n",
            "Epoch 177/250\n",
            "178/178 [==============================] - 42s 231ms/step - loss: 0.2504 - mae: 0.5003 - val_loss: 0.2501 - val_mae: 0.4999\n",
            "Epoch 178/250\n",
            "178/178 [==============================] - 46s 253ms/step - loss: 0.2502 - mae: 0.5000 - val_loss: 0.2512 - val_mae: 0.5001\n",
            "Epoch 179/250\n",
            "178/178 [==============================] - 43s 241ms/step - loss: 0.2503 - mae: 0.5000 - val_loss: 0.2506 - val_mae: 0.5000\n",
            "Epoch 180/250\n",
            "178/178 [==============================] - 44s 243ms/step - loss: 0.2507 - mae: 0.5005 - val_loss: 0.2501 - val_mae: 0.5000\n",
            "Epoch 181/250\n",
            "178/178 [==============================] - 44s 243ms/step - loss: 0.2504 - mae: 0.5002 - val_loss: 0.2500 - val_mae: 0.5000\n",
            "Epoch 182/250\n",
            "178/178 [==============================] - 43s 232ms/step - loss: 0.2502 - mae: 0.5002 - val_loss: 0.2501 - val_mae: 0.5000\n",
            "Epoch 183/250\n",
            "178/178 [==============================] - 42s 231ms/step - loss: 0.2502 - mae: 0.5001 - val_loss: 0.2501 - val_mae: 0.5000\n",
            "Epoch 184/250\n",
            "178/178 [==============================] - 42s 231ms/step - loss: 0.2506 - mae: 0.5002 - val_loss: 0.2502 - val_mae: 0.5000\n",
            "Epoch 185/250\n",
            "178/178 [==============================] - 44s 243ms/step - loss: 0.2505 - mae: 0.5002 - val_loss: 0.2504 - val_mae: 0.5000\n",
            "Epoch 186/250\n",
            "178/178 [==============================] - 43s 241ms/step - loss: 0.2504 - mae: 0.5002 - val_loss: 0.2500 - val_mae: 0.5000\n",
            "Epoch 187/250\n",
            "178/178 [==============================] - 44s 241ms/step - loss: 0.2503 - mae: 0.5003 - val_loss: 0.2501 - val_mae: 0.5000\n",
            "Epoch 188/250\n",
            "178/178 [==============================] - 43s 233ms/step - loss: 0.2500 - mae: 0.4999 - val_loss: 0.2504 - val_mae: 0.4999\n",
            "Epoch 189/250\n",
            "178/178 [==============================] - 42s 230ms/step - loss: 0.2505 - mae: 0.5004 - val_loss: 0.2500 - val_mae: 0.5000\n",
            "Epoch 190/250\n",
            "178/178 [==============================] - 42s 230ms/step - loss: 0.2503 - mae: 0.5002 - val_loss: 0.2500 - val_mae: 0.5000\n",
            "Epoch 191/250\n",
            "178/178 [==============================] - 44s 242ms/step - loss: 0.2502 - mae: 0.5001 - val_loss: 0.2500 - val_mae: 0.5000\n",
            "Epoch 192/250\n",
            "178/178 [==============================] - 43s 238ms/step - loss: 0.2504 - mae: 0.5003 - val_loss: 0.2502 - val_mae: 0.5000\n",
            "Epoch 193/250\n",
            "178/178 [==============================] - 43s 234ms/step - loss: 0.2504 - mae: 0.5000 - val_loss: 0.2501 - val_mae: 0.5000\n",
            "Epoch 194/250\n",
            "178/178 [==============================] - 40s 219ms/step - loss: 0.2503 - mae: 0.5003 - val_loss: 0.2500 - val_mae: 0.5000\n",
            "Epoch 195/250\n",
            "178/178 [==============================] - 43s 238ms/step - loss: 0.2503 - mae: 0.5003 - val_loss: 0.2500 - val_mae: 0.5000\n",
            "Epoch 196/250\n",
            "178/178 [==============================] - 43s 233ms/step - loss: 0.2504 - mae: 0.5003 - val_loss: 0.2502 - val_mae: 0.5000\n",
            "Epoch 197/250\n",
            "178/178 [==============================] - 42s 232ms/step - loss: 0.2504 - mae: 0.5003 - val_loss: 0.2500 - val_mae: 0.5000\n",
            "Epoch 198/250\n",
            "178/178 [==============================] - 41s 229ms/step - loss: 0.2503 - mae: 0.5002 - val_loss: 0.2501 - val_mae: 0.5000\n",
            "Epoch 199/250\n",
            "178/178 [==============================] - 44s 241ms/step - loss: 0.2503 - mae: 0.5001 - val_loss: 0.2503 - val_mae: 0.5001\n",
            "Epoch 200/250\n",
            "178/178 [==============================] - 44s 241ms/step - loss: 0.2502 - mae: 0.5001 - val_loss: 0.2500 - val_mae: 0.5000\n",
            "Epoch 201/250\n",
            "178/178 [==============================] - 43s 241ms/step - loss: 0.2502 - mae: 0.5001 - val_loss: 0.2501 - val_mae: 0.5000\n",
            "Epoch 202/250\n",
            "178/178 [==============================] - 44s 241ms/step - loss: 0.2501 - mae: 0.5000 - val_loss: 0.2501 - val_mae: 0.5000\n",
            "Epoch 203/250\n",
            "178/178 [==============================] - 42s 231ms/step - loss: 0.2504 - mae: 0.5001 - val_loss: 0.2502 - val_mae: 0.5000\n",
            "Epoch 204/250\n",
            "178/178 [==============================] - 42s 230ms/step - loss: 0.2503 - mae: 0.5001 - val_loss: 0.2500 - val_mae: 0.5000\n",
            "Epoch 205/250\n",
            "178/178 [==============================] - 42s 231ms/step - loss: 0.2503 - mae: 0.5002 - val_loss: 0.2501 - val_mae: 0.5000\n",
            "Epoch 206/250\n",
            "178/178 [==============================] - 44s 242ms/step - loss: 0.2504 - mae: 0.5003 - val_loss: 0.2500 - val_mae: 0.5000\n",
            "Epoch 207/250\n",
            "178/178 [==============================] - 43s 241ms/step - loss: 0.2503 - mae: 0.5002 - val_loss: 0.2500 - val_mae: 0.5000\n",
            "Epoch 208/250\n",
            "178/178 [==============================] - 43s 237ms/step - loss: 0.2502 - mae: 0.5001 - val_loss: 0.2500 - val_mae: 0.5000\n",
            "Epoch 209/250\n",
            "178/178 [==============================] - 42s 231ms/step - loss: 0.2501 - mae: 0.5000 - val_loss: 0.2505 - val_mae: 0.5000\n",
            "Epoch 210/250\n",
            "178/178 [==============================] - 50s 278ms/step - loss: 0.2503 - mae: 0.5001 - val_loss: 0.2504 - val_mae: 0.5000\n",
            "Epoch 211/250\n",
            "178/178 [==============================] - 44s 240ms/step - loss: 0.2504 - mae: 0.5002 - val_loss: 0.2500 - val_mae: 0.5000\n",
            "Epoch 212/250\n",
            "178/178 [==============================] - 40s 218ms/step - loss: 0.2503 - mae: 0.5002 - val_loss: 0.2500 - val_mae: 0.5000\n",
            "Epoch 213/250\n",
            "178/178 [==============================] - 43s 239ms/step - loss: 0.2503 - mae: 0.5002 - val_loss: 0.2505 - val_mae: 0.5000\n",
            "Epoch 214/250\n",
            "178/178 [==============================] - 42s 231ms/step - loss: 0.2506 - mae: 0.5006 - val_loss: 0.2500 - val_mae: 0.5000\n",
            "Epoch 215/250\n",
            "178/178 [==============================] - 44s 241ms/step - loss: 0.2503 - mae: 0.5002 - val_loss: 0.2502 - val_mae: 0.5000\n",
            "Epoch 216/250\n",
            "178/178 [==============================] - 43s 240ms/step - loss: 0.2504 - mae: 0.5003 - val_loss: 0.2500 - val_mae: 0.5000\n",
            "Epoch 217/250\n",
            "178/178 [==============================] - 40s 220ms/step - loss: 0.2503 - mae: 0.5002 - val_loss: 0.2501 - val_mae: 0.5000\n",
            "Epoch 218/250\n",
            "178/178 [==============================] - 44s 242ms/step - loss: 0.2503 - mae: 0.5000 - val_loss: 0.2504 - val_mae: 0.5000\n",
            "Epoch 219/250\n",
            "178/178 [==============================] - 43s 241ms/step - loss: 0.2503 - mae: 0.5001 - val_loss: 0.2500 - val_mae: 0.5000\n",
            "Epoch 220/250\n",
            "178/178 [==============================] - 44s 242ms/step - loss: 0.2502 - mae: 0.5001 - val_loss: 0.2500 - val_mae: 0.5000\n",
            "Epoch 221/250\n",
            "178/178 [==============================] - 43s 234ms/step - loss: 0.2505 - mae: 0.5003 - val_loss: 0.2502 - val_mae: 0.5000\n",
            "Epoch 222/250\n",
            "178/178 [==============================] - 41s 229ms/step - loss: 0.2501 - mae: 0.4998 - val_loss: 0.2506 - val_mae: 0.5001\n",
            "Epoch 223/250\n",
            "178/178 [==============================] - 44s 241ms/step - loss: 0.2506 - mae: 0.5003 - val_loss: 0.2501 - val_mae: 0.5000\n",
            "Epoch 224/250\n",
            "178/178 [==============================] - 43s 240ms/step - loss: 0.2503 - mae: 0.5001 - val_loss: 0.2505 - val_mae: 0.5000\n",
            "Epoch 225/250\n",
            "178/178 [==============================] - 45s 251ms/step - loss: 0.2505 - mae: 0.5003 - val_loss: 0.2500 - val_mae: 0.5000\n",
            "Epoch 226/250\n",
            "178/178 [==============================] - 43s 233ms/step - loss: 0.2503 - mae: 0.5002 - val_loss: 0.2502 - val_mae: 0.5001\n",
            "Epoch 227/250\n",
            "178/178 [==============================] - 42s 231ms/step - loss: 0.2503 - mae: 0.5002 - val_loss: 0.2500 - val_mae: 0.5000\n",
            "Epoch 228/250\n",
            "178/178 [==============================] - 42s 233ms/step - loss: 0.2503 - mae: 0.5003 - val_loss: 0.2501 - val_mae: 0.5000\n",
            "Epoch 229/250\n",
            "178/178 [==============================] - 42s 233ms/step - loss: 0.2502 - mae: 0.5002 - val_loss: 0.2501 - val_mae: 0.5000\n",
            "Epoch 230/250\n",
            "178/178 [==============================] - 40s 221ms/step - loss: 0.2505 - mae: 0.5001 - val_loss: 0.2501 - val_mae: 0.4999\n",
            "Epoch 231/250\n",
            "178/178 [==============================] - 45s 246ms/step - loss: 0.2503 - mae: 0.5002 - val_loss: 0.2504 - val_mae: 0.5000\n",
            "Epoch 232/250\n",
            "178/178 [==============================] - 43s 242ms/step - loss: 0.2502 - mae: 0.5002 - val_loss: 0.2501 - val_mae: 0.5001\n",
            "Epoch 233/250\n",
            "178/178 [==============================] - 44s 242ms/step - loss: 0.2505 - mae: 0.5001 - val_loss: 0.2500 - val_mae: 0.5000\n",
            "Epoch 234/250\n",
            "178/178 [==============================] - 43s 236ms/step - loss: 0.2502 - mae: 0.5002 - val_loss: 0.2501 - val_mae: 0.5000\n",
            "Epoch 235/250\n",
            "178/178 [==============================] - 43s 234ms/step - loss: 0.2503 - mae: 0.5000 - val_loss: 0.2500 - val_mae: 0.5000\n",
            "Epoch 236/250\n",
            "178/178 [==============================] - 42s 233ms/step - loss: 0.2505 - mae: 0.5004 - val_loss: 0.2500 - val_mae: 0.5000\n",
            "Epoch 237/250\n",
            "178/178 [==============================] - 43s 237ms/step - loss: 0.2503 - mae: 0.5002 - val_loss: 0.2500 - val_mae: 0.5000\n",
            "Epoch 238/250\n",
            "178/178 [==============================] - 44s 243ms/step - loss: 0.2501 - mae: 0.5000 - val_loss: 0.2505 - val_mae: 0.5001\n",
            "Epoch 239/250\n",
            "178/178 [==============================] - 44s 241ms/step - loss: 0.2503 - mae: 0.5002 - val_loss: 0.2500 - val_mae: 0.5000\n",
            "Epoch 240/250\n",
            "178/178 [==============================] - 44s 241ms/step - loss: 0.2504 - mae: 0.5001 - val_loss: 0.2500 - val_mae: 0.5000\n",
            "Epoch 241/250\n",
            "178/178 [==============================] - 43s 232ms/step - loss: 0.2504 - mae: 0.5003 - val_loss: 0.2500 - val_mae: 0.5000\n",
            "Epoch 242/250\n",
            "178/178 [==============================] - 42s 231ms/step - loss: 0.2503 - mae: 0.5003 - val_loss: 0.2500 - val_mae: 0.5000\n",
            "Epoch 243/250\n",
            "178/178 [==============================] - 44s 241ms/step - loss: 0.2505 - mae: 0.5003 - val_loss: 0.2500 - val_mae: 0.5000\n",
            "Epoch 244/250\n",
            "178/178 [==============================] - 40s 219ms/step - loss: 0.2504 - mae: 0.5003 - val_loss: 0.2501 - val_mae: 0.5000\n",
            "Epoch 245/250\n",
            "178/178 [==============================] - 42s 231ms/step - loss: 0.2504 - mae: 0.5003 - val_loss: 0.2500 - val_mae: 0.5000\n",
            "Epoch 246/250\n",
            "178/178 [==============================] - 44s 242ms/step - loss: 0.2505 - mae: 0.5004 - val_loss: 0.2501 - val_mae: 0.5000\n",
            "Epoch 247/250\n",
            "178/178 [==============================] - 40s 220ms/step - loss: 0.2503 - mae: 0.5000 - val_loss: 0.2501 - val_mae: 0.5000\n",
            "Epoch 248/250\n",
            "178/178 [==============================] - 44s 243ms/step - loss: 0.2505 - mae: 0.5004 - val_loss: 0.2500 - val_mae: 0.5000\n",
            "Epoch 249/250\n",
            "178/178 [==============================] - 44s 241ms/step - loss: 0.2503 - mae: 0.5000 - val_loss: 0.2503 - val_mae: 0.5000\n",
            "Epoch 250/250\n",
            "178/178 [==============================] - 44s 246ms/step - loss: 0.2501 - mae: 0.4996 - val_loss: 0.2502 - val_mae: 0.5000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "mae = history.history['mae']\n",
        "val_mae = history.history['val_mae']\n",
        "\n",
        "\n",
        "epochs_x = range(len(loss))\n",
        "\n",
        "\n",
        "plt.plot(epochs_x, mae, 'go', label='Training MAE')\n",
        "plt.plot(epochs_x, val_mae, 'k', label='Validation MAE')\n",
        "plt.title('Training and validation MeanAbsoluteError')\n",
        "plt.legend()\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(epochs_x, loss, 'go', label='Training loss')\n",
        "plt.plot(epochs_x, val_loss, 'k', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Y3K89-CM-dfg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545
        },
        "outputId": "3ba5e5a1-8446-4214-ea11-5a3872c145ed"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "epochs_x"
      ],
      "metadata": {
        "id": "N_sP_ZmSY-Jv",
        "outputId": "ddd21d4b-39ce-40fa-e193-020145a39165",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "range(0, 250)"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Download the model\n"
      ],
      "metadata": {
        "id": "R19IJQSYoW7J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "os.makedirs('/content/drive/My Drive/cut_panoramic/Model', exist_ok=True)\n",
        "model.save('/content/drive/My Drive/cut_panoramic/Model/1G_2e-3_16_0.2_Gender_250.h5')"
      ],
      "metadata": {
        "id": "Zed4TdFcG2iJ"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "n5YxZ-5QjQ0-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# from google.colab import files\n",
        "# files.download('/content/drive/My Drive/cut_panoramic/Model/1.1_รอบแรก_Flimpano_Male125_250.h5')"
      ],
      "metadata": {
        "id": "P5eMxm1NV-oY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "wY_pDlxkRwxS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}