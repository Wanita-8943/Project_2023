{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Wanita-8943/Project_2023/blob/main/%E0%B8%A3%E0%B8%AD%E0%B8%9A%E0%B8%97%E0%B8%B5%E0%B9%884_Train_Male125_250_New_Unfreez.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "KKSs7cyoPHcD"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import shutil"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7LoeZxmVPMxp",
        "outputId": "4a44ca0c-33c4-48d9-a736-d755e4f0bc50"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import models\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import optimizers\n",
        "import os\n",
        "import glob\n",
        "import shutil\n",
        "import sys\n",
        "import numpy as np\n",
        "from skimage.io import imread\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import Image\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "1pX9g1HxPM2f"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 16\n",
        "width = 150\n",
        "height = 150\n",
        "epochs = 250\n",
        "NUM_TRAIN = 1425\n",
        "NUM_TEST = 475\n",
        "dropout_rate = 0.2\n",
        "input_shape = (height, width, 3)"
      ],
      "metadata": {
        "id": "eSFtvGyvPM6O"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#ดึงข้อมูลใน Github มาใช้\n",
        "import os\n",
        "%cd /content\n",
        "if not os.path.isdir(\"efficientnet_keras_transfer_learning\"):\n",
        " !git clone https://github.com/Wanita-8943/efficientnet_keras_transfer_learning\n",
        "%cd efficientnet_keras_transfer_learning/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lb4K4CsMPNAW",
        "outputId": "83fddb27-7d56-47bf-e696-09d73f75c618"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "Cloning into 'efficientnet_keras_transfer_learning'...\n",
            "remote: Enumerating objects: 837, done.\u001b[K\n",
            "remote: Counting objects: 100% (359/359), done.\u001b[K\n",
            "remote: Compressing objects: 100% (124/124), done.\u001b[K\n",
            "remote: Total 837 (delta 255), reused 328 (delta 235), pack-reused 478\u001b[K\n",
            "Receiving objects: 100% (837/837), 13.82 MiB | 27.47 MiB/s, done.\n",
            "Resolving deltas: 100% (495/495), done.\n",
            "/content/efficientnet_keras_transfer_learning\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Options: EfficientNetB0, EfficientNetB1, EfficientNetB2, EfficientNetB3\n",
        "# Higher the number, the more complex the model is.\n",
        "from efficientnet import EfficientNetB0 as Net\n",
        "from efficientnet import center_crop_and_resize, preprocess_input"
      ],
      "metadata": {
        "id": "eyBg0dLKPND3"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# loading pretrained conv base model\n",
        "# โหลดโมเดล มาโดยตัด output ของโมเดลออก เเต่ยังใช้ input อันเดิม\n",
        "# เเละโหลด weight ของโมเดล มาด้วยที่ชื่อว่า imagenet\n",
        "conv_base = Net(weights='imagenet', include_top=False, input_shape=input_shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DoxI-q8-1giK",
        "outputId": "0f96f6b0-4ebc-46dc-8f86-6df36084b86c"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
            "Instructions for updating:\n",
            "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://github.com/qubvel/efficientnet/releases/download/v0.0.1/efficientnet-b0_imagenet_1000_notop.h5\n",
            "16717576/16717576 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "conv_base.summary() #ดู Summary"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "od4Lp6dD1lWK",
        "outputId": "77bde083-3e01-46f8-ae39-777b84b620fa"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"efficientnet-b0\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 150, 150, 3  0           []                               \n",
            "                                )]                                                                \n",
            "                                                                                                  \n",
            " conv2d (Conv2D)                (None, 75, 75, 32)   864         ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " batch_normalization (BatchNorm  (None, 75, 75, 32)  128         ['conv2d[0][0]']                 \n",
            " alization)                                                                                       \n",
            "                                                                                                  \n",
            " swish (Swish)                  (None, 75, 75, 32)   0           ['batch_normalization[0][0]']    \n",
            "                                                                                                  \n",
            " depthwise_conv2d (DepthwiseCon  (None, 75, 75, 32)  288         ['swish[0][0]']                  \n",
            " v2D)                                                                                             \n",
            "                                                                                                  \n",
            " batch_normalization_1 (BatchNo  (None, 75, 75, 32)  128         ['depthwise_conv2d[0][0]']       \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " swish_1 (Swish)                (None, 75, 75, 32)   0           ['batch_normalization_1[0][0]']  \n",
            "                                                                                                  \n",
            " lambda (Lambda)                (None, 1, 1, 32)     0           ['swish_1[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d_1 (Conv2D)              (None, 1, 1, 8)      264         ['lambda[0][0]']                 \n",
            "                                                                                                  \n",
            " swish_2 (Swish)                (None, 1, 1, 8)      0           ['conv2d_1[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_2 (Conv2D)              (None, 1, 1, 32)     288         ['swish_2[0][0]']                \n",
            "                                                                                                  \n",
            " activation (Activation)        (None, 1, 1, 32)     0           ['conv2d_2[0][0]']               \n",
            "                                                                                                  \n",
            " multiply (Multiply)            (None, 75, 75, 32)   0           ['activation[0][0]',             \n",
            "                                                                  'swish_1[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d_3 (Conv2D)              (None, 75, 75, 16)   512         ['multiply[0][0]']               \n",
            "                                                                                                  \n",
            " batch_normalization_2 (BatchNo  (None, 75, 75, 16)  64          ['conv2d_3[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv2d_4 (Conv2D)              (None, 75, 75, 96)   1536        ['batch_normalization_2[0][0]']  \n",
            "                                                                                                  \n",
            " batch_normalization_3 (BatchNo  (None, 75, 75, 96)  384         ['conv2d_4[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " swish_3 (Swish)                (None, 75, 75, 96)   0           ['batch_normalization_3[0][0]']  \n",
            "                                                                                                  \n",
            " depthwise_conv2d_1 (DepthwiseC  (None, 38, 38, 96)  864         ['swish_3[0][0]']                \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_4 (BatchNo  (None, 38, 38, 96)  384         ['depthwise_conv2d_1[0][0]']     \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " swish_4 (Swish)                (None, 38, 38, 96)   0           ['batch_normalization_4[0][0]']  \n",
            "                                                                                                  \n",
            " lambda_1 (Lambda)              (None, 1, 1, 96)     0           ['swish_4[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d_5 (Conv2D)              (None, 1, 1, 4)      388         ['lambda_1[0][0]']               \n",
            "                                                                                                  \n",
            " swish_5 (Swish)                (None, 1, 1, 4)      0           ['conv2d_5[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_6 (Conv2D)              (None, 1, 1, 96)     480         ['swish_5[0][0]']                \n",
            "                                                                                                  \n",
            " activation_1 (Activation)      (None, 1, 1, 96)     0           ['conv2d_6[0][0]']               \n",
            "                                                                                                  \n",
            " multiply_1 (Multiply)          (None, 38, 38, 96)   0           ['activation_1[0][0]',           \n",
            "                                                                  'swish_4[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d_7 (Conv2D)              (None, 38, 38, 24)   2304        ['multiply_1[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_5 (BatchNo  (None, 38, 38, 24)  96          ['conv2d_7[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv2d_8 (Conv2D)              (None, 38, 38, 144)  3456        ['batch_normalization_5[0][0]']  \n",
            "                                                                                                  \n",
            " batch_normalization_6 (BatchNo  (None, 38, 38, 144)  576        ['conv2d_8[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " swish_6 (Swish)                (None, 38, 38, 144)  0           ['batch_normalization_6[0][0]']  \n",
            "                                                                                                  \n",
            " depthwise_conv2d_2 (DepthwiseC  (None, 38, 38, 144)  1296       ['swish_6[0][0]']                \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_7 (BatchNo  (None, 38, 38, 144)  576        ['depthwise_conv2d_2[0][0]']     \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " swish_7 (Swish)                (None, 38, 38, 144)  0           ['batch_normalization_7[0][0]']  \n",
            "                                                                                                  \n",
            " lambda_2 (Lambda)              (None, 1, 1, 144)    0           ['swish_7[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d_9 (Conv2D)              (None, 1, 1, 6)      870         ['lambda_2[0][0]']               \n",
            "                                                                                                  \n",
            " swish_8 (Swish)                (None, 1, 1, 6)      0           ['conv2d_9[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_10 (Conv2D)             (None, 1, 1, 144)    1008        ['swish_8[0][0]']                \n",
            "                                                                                                  \n",
            " activation_2 (Activation)      (None, 1, 1, 144)    0           ['conv2d_10[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_2 (Multiply)          (None, 38, 38, 144)  0           ['activation_2[0][0]',           \n",
            "                                                                  'swish_7[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d_11 (Conv2D)             (None, 38, 38, 24)   3456        ['multiply_2[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_8 (BatchNo  (None, 38, 38, 24)  96          ['conv2d_11[0][0]']              \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " drop_connect (DropConnect)     (None, 38, 38, 24)   0           ['batch_normalization_8[0][0]']  \n",
            "                                                                                                  \n",
            " add (Add)                      (None, 38, 38, 24)   0           ['drop_connect[0][0]',           \n",
            "                                                                  'batch_normalization_5[0][0]']  \n",
            "                                                                                                  \n",
            " conv2d_12 (Conv2D)             (None, 38, 38, 144)  3456        ['add[0][0]']                    \n",
            "                                                                                                  \n",
            " batch_normalization_9 (BatchNo  (None, 38, 38, 144)  576        ['conv2d_12[0][0]']              \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " swish_9 (Swish)                (None, 38, 38, 144)  0           ['batch_normalization_9[0][0]']  \n",
            "                                                                                                  \n",
            " depthwise_conv2d_3 (DepthwiseC  (None, 19, 19, 144)  3600       ['swish_9[0][0]']                \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_10 (BatchN  (None, 19, 19, 144)  576        ['depthwise_conv2d_3[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_10 (Swish)               (None, 19, 19, 144)  0           ['batch_normalization_10[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_3 (Lambda)              (None, 1, 1, 144)    0           ['swish_10[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_13 (Conv2D)             (None, 1, 1, 6)      870         ['lambda_3[0][0]']               \n",
            "                                                                                                  \n",
            " swish_11 (Swish)               (None, 1, 1, 6)      0           ['conv2d_13[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_14 (Conv2D)             (None, 1, 1, 144)    1008        ['swish_11[0][0]']               \n",
            "                                                                                                  \n",
            " activation_3 (Activation)      (None, 1, 1, 144)    0           ['conv2d_14[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_3 (Multiply)          (None, 19, 19, 144)  0           ['activation_3[0][0]',           \n",
            "                                                                  'swish_10[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_15 (Conv2D)             (None, 19, 19, 40)   5760        ['multiply_3[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_11 (BatchN  (None, 19, 19, 40)  160         ['conv2d_15[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_16 (Conv2D)             (None, 19, 19, 240)  9600        ['batch_normalization_11[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_12 (BatchN  (None, 19, 19, 240)  960        ['conv2d_16[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_12 (Swish)               (None, 19, 19, 240)  0           ['batch_normalization_12[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_4 (DepthwiseC  (None, 19, 19, 240)  6000       ['swish_12[0][0]']               \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_13 (BatchN  (None, 19, 19, 240)  960        ['depthwise_conv2d_4[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_13 (Swish)               (None, 19, 19, 240)  0           ['batch_normalization_13[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_4 (Lambda)              (None, 1, 1, 240)    0           ['swish_13[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_17 (Conv2D)             (None, 1, 1, 10)     2410        ['lambda_4[0][0]']               \n",
            "                                                                                                  \n",
            " swish_14 (Swish)               (None, 1, 1, 10)     0           ['conv2d_17[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_18 (Conv2D)             (None, 1, 1, 240)    2640        ['swish_14[0][0]']               \n",
            "                                                                                                  \n",
            " activation_4 (Activation)      (None, 1, 1, 240)    0           ['conv2d_18[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_4 (Multiply)          (None, 19, 19, 240)  0           ['activation_4[0][0]',           \n",
            "                                                                  'swish_13[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_19 (Conv2D)             (None, 19, 19, 40)   9600        ['multiply_4[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_14 (BatchN  (None, 19, 19, 40)  160         ['conv2d_19[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_1 (DropConnect)   (None, 19, 19, 40)   0           ['batch_normalization_14[0][0]'] \n",
            "                                                                                                  \n",
            " add_1 (Add)                    (None, 19, 19, 40)   0           ['drop_connect_1[0][0]',         \n",
            "                                                                  'batch_normalization_11[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_20 (Conv2D)             (None, 19, 19, 240)  9600        ['add_1[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_15 (BatchN  (None, 19, 19, 240)  960        ['conv2d_20[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_15 (Swish)               (None, 19, 19, 240)  0           ['batch_normalization_15[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_5 (DepthwiseC  (None, 10, 10, 240)  2160       ['swish_15[0][0]']               \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_16 (BatchN  (None, 10, 10, 240)  960        ['depthwise_conv2d_5[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_16 (Swish)               (None, 10, 10, 240)  0           ['batch_normalization_16[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_5 (Lambda)              (None, 1, 1, 240)    0           ['swish_16[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_21 (Conv2D)             (None, 1, 1, 10)     2410        ['lambda_5[0][0]']               \n",
            "                                                                                                  \n",
            " swish_17 (Swish)               (None, 1, 1, 10)     0           ['conv2d_21[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_22 (Conv2D)             (None, 1, 1, 240)    2640        ['swish_17[0][0]']               \n",
            "                                                                                                  \n",
            " activation_5 (Activation)      (None, 1, 1, 240)    0           ['conv2d_22[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_5 (Multiply)          (None, 10, 10, 240)  0           ['activation_5[0][0]',           \n",
            "                                                                  'swish_16[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_23 (Conv2D)             (None, 10, 10, 80)   19200       ['multiply_5[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_17 (BatchN  (None, 10, 10, 80)  320         ['conv2d_23[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_24 (Conv2D)             (None, 10, 10, 480)  38400       ['batch_normalization_17[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_18 (BatchN  (None, 10, 10, 480)  1920       ['conv2d_24[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_18 (Swish)               (None, 10, 10, 480)  0           ['batch_normalization_18[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_6 (DepthwiseC  (None, 10, 10, 480)  4320       ['swish_18[0][0]']               \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_19 (BatchN  (None, 10, 10, 480)  1920       ['depthwise_conv2d_6[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_19 (Swish)               (None, 10, 10, 480)  0           ['batch_normalization_19[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_6 (Lambda)              (None, 1, 1, 480)    0           ['swish_19[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_25 (Conv2D)             (None, 1, 1, 20)     9620        ['lambda_6[0][0]']               \n",
            "                                                                                                  \n",
            " swish_20 (Swish)               (None, 1, 1, 20)     0           ['conv2d_25[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_26 (Conv2D)             (None, 1, 1, 480)    10080       ['swish_20[0][0]']               \n",
            "                                                                                                  \n",
            " activation_6 (Activation)      (None, 1, 1, 480)    0           ['conv2d_26[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_6 (Multiply)          (None, 10, 10, 480)  0           ['activation_6[0][0]',           \n",
            "                                                                  'swish_19[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_27 (Conv2D)             (None, 10, 10, 80)   38400       ['multiply_6[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_20 (BatchN  (None, 10, 10, 80)  320         ['conv2d_27[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_2 (DropConnect)   (None, 10, 10, 80)   0           ['batch_normalization_20[0][0]'] \n",
            "                                                                                                  \n",
            " add_2 (Add)                    (None, 10, 10, 80)   0           ['drop_connect_2[0][0]',         \n",
            "                                                                  'batch_normalization_17[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_28 (Conv2D)             (None, 10, 10, 480)  38400       ['add_2[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_21 (BatchN  (None, 10, 10, 480)  1920       ['conv2d_28[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_21 (Swish)               (None, 10, 10, 480)  0           ['batch_normalization_21[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_7 (DepthwiseC  (None, 10, 10, 480)  4320       ['swish_21[0][0]']               \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_22 (BatchN  (None, 10, 10, 480)  1920       ['depthwise_conv2d_7[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_22 (Swish)               (None, 10, 10, 480)  0           ['batch_normalization_22[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_7 (Lambda)              (None, 1, 1, 480)    0           ['swish_22[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_29 (Conv2D)             (None, 1, 1, 20)     9620        ['lambda_7[0][0]']               \n",
            "                                                                                                  \n",
            " swish_23 (Swish)               (None, 1, 1, 20)     0           ['conv2d_29[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_30 (Conv2D)             (None, 1, 1, 480)    10080       ['swish_23[0][0]']               \n",
            "                                                                                                  \n",
            " activation_7 (Activation)      (None, 1, 1, 480)    0           ['conv2d_30[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_7 (Multiply)          (None, 10, 10, 480)  0           ['activation_7[0][0]',           \n",
            "                                                                  'swish_22[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_31 (Conv2D)             (None, 10, 10, 80)   38400       ['multiply_7[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_23 (BatchN  (None, 10, 10, 80)  320         ['conv2d_31[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_3 (DropConnect)   (None, 10, 10, 80)   0           ['batch_normalization_23[0][0]'] \n",
            "                                                                                                  \n",
            " add_3 (Add)                    (None, 10, 10, 80)   0           ['drop_connect_3[0][0]',         \n",
            "                                                                  'add_2[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_32 (Conv2D)             (None, 10, 10, 480)  38400       ['add_3[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_24 (BatchN  (None, 10, 10, 480)  1920       ['conv2d_32[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_24 (Swish)               (None, 10, 10, 480)  0           ['batch_normalization_24[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_8 (DepthwiseC  (None, 10, 10, 480)  12000      ['swish_24[0][0]']               \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_25 (BatchN  (None, 10, 10, 480)  1920       ['depthwise_conv2d_8[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_25 (Swish)               (None, 10, 10, 480)  0           ['batch_normalization_25[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_8 (Lambda)              (None, 1, 1, 480)    0           ['swish_25[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_33 (Conv2D)             (None, 1, 1, 20)     9620        ['lambda_8[0][0]']               \n",
            "                                                                                                  \n",
            " swish_26 (Swish)               (None, 1, 1, 20)     0           ['conv2d_33[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_34 (Conv2D)             (None, 1, 1, 480)    10080       ['swish_26[0][0]']               \n",
            "                                                                                                  \n",
            " activation_8 (Activation)      (None, 1, 1, 480)    0           ['conv2d_34[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_8 (Multiply)          (None, 10, 10, 480)  0           ['activation_8[0][0]',           \n",
            "                                                                  'swish_25[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_35 (Conv2D)             (None, 10, 10, 112)  53760       ['multiply_8[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_26 (BatchN  (None, 10, 10, 112)  448        ['conv2d_35[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_36 (Conv2D)             (None, 10, 10, 672)  75264       ['batch_normalization_26[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_27 (BatchN  (None, 10, 10, 672)  2688       ['conv2d_36[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_27 (Swish)               (None, 10, 10, 672)  0           ['batch_normalization_27[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_9 (DepthwiseC  (None, 10, 10, 672)  16800      ['swish_27[0][0]']               \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_28 (BatchN  (None, 10, 10, 672)  2688       ['depthwise_conv2d_9[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_28 (Swish)               (None, 10, 10, 672)  0           ['batch_normalization_28[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_9 (Lambda)              (None, 1, 1, 672)    0           ['swish_28[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_37 (Conv2D)             (None, 1, 1, 28)     18844       ['lambda_9[0][0]']               \n",
            "                                                                                                  \n",
            " swish_29 (Swish)               (None, 1, 1, 28)     0           ['conv2d_37[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_38 (Conv2D)             (None, 1, 1, 672)    19488       ['swish_29[0][0]']               \n",
            "                                                                                                  \n",
            " activation_9 (Activation)      (None, 1, 1, 672)    0           ['conv2d_38[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_9 (Multiply)          (None, 10, 10, 672)  0           ['activation_9[0][0]',           \n",
            "                                                                  'swish_28[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_39 (Conv2D)             (None, 10, 10, 112)  75264       ['multiply_9[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_29 (BatchN  (None, 10, 10, 112)  448        ['conv2d_39[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_4 (DropConnect)   (None, 10, 10, 112)  0           ['batch_normalization_29[0][0]'] \n",
            "                                                                                                  \n",
            " add_4 (Add)                    (None, 10, 10, 112)  0           ['drop_connect_4[0][0]',         \n",
            "                                                                  'batch_normalization_26[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_40 (Conv2D)             (None, 10, 10, 672)  75264       ['add_4[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_30 (BatchN  (None, 10, 10, 672)  2688       ['conv2d_40[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_30 (Swish)               (None, 10, 10, 672)  0           ['batch_normalization_30[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_10 (Depthwise  (None, 10, 10, 672)  16800      ['swish_30[0][0]']               \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_31 (BatchN  (None, 10, 10, 672)  2688       ['depthwise_conv2d_10[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_31 (Swish)               (None, 10, 10, 672)  0           ['batch_normalization_31[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_10 (Lambda)             (None, 1, 1, 672)    0           ['swish_31[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_41 (Conv2D)             (None, 1, 1, 28)     18844       ['lambda_10[0][0]']              \n",
            "                                                                                                  \n",
            " swish_32 (Swish)               (None, 1, 1, 28)     0           ['conv2d_41[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_42 (Conv2D)             (None, 1, 1, 672)    19488       ['swish_32[0][0]']               \n",
            "                                                                                                  \n",
            " activation_10 (Activation)     (None, 1, 1, 672)    0           ['conv2d_42[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_10 (Multiply)         (None, 10, 10, 672)  0           ['activation_10[0][0]',          \n",
            "                                                                  'swish_31[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_43 (Conv2D)             (None, 10, 10, 112)  75264       ['multiply_10[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_32 (BatchN  (None, 10, 10, 112)  448        ['conv2d_43[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_5 (DropConnect)   (None, 10, 10, 112)  0           ['batch_normalization_32[0][0]'] \n",
            "                                                                                                  \n",
            " add_5 (Add)                    (None, 10, 10, 112)  0           ['drop_connect_5[0][0]',         \n",
            "                                                                  'add_4[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_44 (Conv2D)             (None, 10, 10, 672)  75264       ['add_5[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_33 (BatchN  (None, 10, 10, 672)  2688       ['conv2d_44[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_33 (Swish)               (None, 10, 10, 672)  0           ['batch_normalization_33[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_11 (Depthwise  (None, 5, 5, 672)   16800       ['swish_33[0][0]']               \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_34 (BatchN  (None, 5, 5, 672)   2688        ['depthwise_conv2d_11[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_34 (Swish)               (None, 5, 5, 672)    0           ['batch_normalization_34[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_11 (Lambda)             (None, 1, 1, 672)    0           ['swish_34[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_45 (Conv2D)             (None, 1, 1, 28)     18844       ['lambda_11[0][0]']              \n",
            "                                                                                                  \n",
            " swish_35 (Swish)               (None, 1, 1, 28)     0           ['conv2d_45[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_46 (Conv2D)             (None, 1, 1, 672)    19488       ['swish_35[0][0]']               \n",
            "                                                                                                  \n",
            " activation_11 (Activation)     (None, 1, 1, 672)    0           ['conv2d_46[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_11 (Multiply)         (None, 5, 5, 672)    0           ['activation_11[0][0]',          \n",
            "                                                                  'swish_34[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_47 (Conv2D)             (None, 5, 5, 192)    129024      ['multiply_11[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_35 (BatchN  (None, 5, 5, 192)   768         ['conv2d_47[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_48 (Conv2D)             (None, 5, 5, 1152)   221184      ['batch_normalization_35[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_36 (BatchN  (None, 5, 5, 1152)  4608        ['conv2d_48[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_36 (Swish)               (None, 5, 5, 1152)   0           ['batch_normalization_36[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_12 (Depthwise  (None, 5, 5, 1152)  28800       ['swish_36[0][0]']               \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_37 (BatchN  (None, 5, 5, 1152)  4608        ['depthwise_conv2d_12[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_37 (Swish)               (None, 5, 5, 1152)   0           ['batch_normalization_37[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_12 (Lambda)             (None, 1, 1, 1152)   0           ['swish_37[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_49 (Conv2D)             (None, 1, 1, 48)     55344       ['lambda_12[0][0]']              \n",
            "                                                                                                  \n",
            " swish_38 (Swish)               (None, 1, 1, 48)     0           ['conv2d_49[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_50 (Conv2D)             (None, 1, 1, 1152)   56448       ['swish_38[0][0]']               \n",
            "                                                                                                  \n",
            " activation_12 (Activation)     (None, 1, 1, 1152)   0           ['conv2d_50[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_12 (Multiply)         (None, 5, 5, 1152)   0           ['activation_12[0][0]',          \n",
            "                                                                  'swish_37[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_51 (Conv2D)             (None, 5, 5, 192)    221184      ['multiply_12[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_38 (BatchN  (None, 5, 5, 192)   768         ['conv2d_51[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_6 (DropConnect)   (None, 5, 5, 192)    0           ['batch_normalization_38[0][0]'] \n",
            "                                                                                                  \n",
            " add_6 (Add)                    (None, 5, 5, 192)    0           ['drop_connect_6[0][0]',         \n",
            "                                                                  'batch_normalization_35[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_52 (Conv2D)             (None, 5, 5, 1152)   221184      ['add_6[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_39 (BatchN  (None, 5, 5, 1152)  4608        ['conv2d_52[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_39 (Swish)               (None, 5, 5, 1152)   0           ['batch_normalization_39[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_13 (Depthwise  (None, 5, 5, 1152)  28800       ['swish_39[0][0]']               \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_40 (BatchN  (None, 5, 5, 1152)  4608        ['depthwise_conv2d_13[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_40 (Swish)               (None, 5, 5, 1152)   0           ['batch_normalization_40[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_13 (Lambda)             (None, 1, 1, 1152)   0           ['swish_40[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_53 (Conv2D)             (None, 1, 1, 48)     55344       ['lambda_13[0][0]']              \n",
            "                                                                                                  \n",
            " swish_41 (Swish)               (None, 1, 1, 48)     0           ['conv2d_53[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_54 (Conv2D)             (None, 1, 1, 1152)   56448       ['swish_41[0][0]']               \n",
            "                                                                                                  \n",
            " activation_13 (Activation)     (None, 1, 1, 1152)   0           ['conv2d_54[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_13 (Multiply)         (None, 5, 5, 1152)   0           ['activation_13[0][0]',          \n",
            "                                                                  'swish_40[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_55 (Conv2D)             (None, 5, 5, 192)    221184      ['multiply_13[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_41 (BatchN  (None, 5, 5, 192)   768         ['conv2d_55[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_7 (DropConnect)   (None, 5, 5, 192)    0           ['batch_normalization_41[0][0]'] \n",
            "                                                                                                  \n",
            " add_7 (Add)                    (None, 5, 5, 192)    0           ['drop_connect_7[0][0]',         \n",
            "                                                                  'add_6[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_56 (Conv2D)             (None, 5, 5, 1152)   221184      ['add_7[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_42 (BatchN  (None, 5, 5, 1152)  4608        ['conv2d_56[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_42 (Swish)               (None, 5, 5, 1152)   0           ['batch_normalization_42[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_14 (Depthwise  (None, 5, 5, 1152)  28800       ['swish_42[0][0]']               \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_43 (BatchN  (None, 5, 5, 1152)  4608        ['depthwise_conv2d_14[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_43 (Swish)               (None, 5, 5, 1152)   0           ['batch_normalization_43[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_14 (Lambda)             (None, 1, 1, 1152)   0           ['swish_43[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_57 (Conv2D)             (None, 1, 1, 48)     55344       ['lambda_14[0][0]']              \n",
            "                                                                                                  \n",
            " swish_44 (Swish)               (None, 1, 1, 48)     0           ['conv2d_57[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_58 (Conv2D)             (None, 1, 1, 1152)   56448       ['swish_44[0][0]']               \n",
            "                                                                                                  \n",
            " activation_14 (Activation)     (None, 1, 1, 1152)   0           ['conv2d_58[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_14 (Multiply)         (None, 5, 5, 1152)   0           ['activation_14[0][0]',          \n",
            "                                                                  'swish_43[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_59 (Conv2D)             (None, 5, 5, 192)    221184      ['multiply_14[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_44 (BatchN  (None, 5, 5, 192)   768         ['conv2d_59[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_8 (DropConnect)   (None, 5, 5, 192)    0           ['batch_normalization_44[0][0]'] \n",
            "                                                                                                  \n",
            " add_8 (Add)                    (None, 5, 5, 192)    0           ['drop_connect_8[0][0]',         \n",
            "                                                                  'add_7[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_60 (Conv2D)             (None, 5, 5, 1152)   221184      ['add_8[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_45 (BatchN  (None, 5, 5, 1152)  4608        ['conv2d_60[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_45 (Swish)               (None, 5, 5, 1152)   0           ['batch_normalization_45[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_15 (Depthwise  (None, 5, 5, 1152)  10368       ['swish_45[0][0]']               \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_46 (BatchN  (None, 5, 5, 1152)  4608        ['depthwise_conv2d_15[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_46 (Swish)               (None, 5, 5, 1152)   0           ['batch_normalization_46[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_15 (Lambda)             (None, 1, 1, 1152)   0           ['swish_46[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_61 (Conv2D)             (None, 1, 1, 48)     55344       ['lambda_15[0][0]']              \n",
            "                                                                                                  \n",
            " swish_47 (Swish)               (None, 1, 1, 48)     0           ['conv2d_61[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_62 (Conv2D)             (None, 1, 1, 1152)   56448       ['swish_47[0][0]']               \n",
            "                                                                                                  \n",
            " activation_15 (Activation)     (None, 1, 1, 1152)   0           ['conv2d_62[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_15 (Multiply)         (None, 5, 5, 1152)   0           ['activation_15[0][0]',          \n",
            "                                                                  'swish_46[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_63 (Conv2D)             (None, 5, 5, 320)    368640      ['multiply_15[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_47 (BatchN  (None, 5, 5, 320)   1280        ['conv2d_63[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_64 (Conv2D)             (None, 5, 5, 1280)   409600      ['batch_normalization_47[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_48 (BatchN  (None, 5, 5, 1280)  5120        ['conv2d_64[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_48 (Swish)               (None, 5, 5, 1280)   0           ['batch_normalization_48[0][0]'] \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 4,049,564\n",
            "Trainable params: 4,007,548\n",
            "Non-trainable params: 42,016\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "base_dir = '/content/drive/MyDrive/TVT_Male125'\n",
        "os.makedirs(base_dir, exist_ok=True)\n",
        "\n",
        "# Directories for our training,\n",
        "# validation and test splits\n",
        "train_dir = os.path.join(base_dir, 'train')\n",
        "os.makedirs(train_dir, exist_ok=True)\n",
        "validation_dir = os.path.join(base_dir, 'validation')\n",
        "os.makedirs(validation_dir, exist_ok=True)\n",
        "test_dir = os.path.join(base_dir, 'test')\n",
        "os.makedirs(test_dir, exist_ok=True)"
      ],
      "metadata": {
        "id": "Jwpq_-KvPef8"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#load model"
      ],
      "metadata": {
        "id": "od-ZSNm5PoGy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.append('/content/drive/MyDrive/cut_panoramic/Model/Classification/Male/33_รอบที่3_Flimpano_Male125_250.h5')\n",
        "\n",
        "from efficientnet.layers import Swish, DropConnect\n",
        "from efficientnet.model import ConvKernalInitializer\n",
        "from tensorflow.keras.utils import get_custom_objects\n",
        "\n",
        "get_custom_objects().update({\n",
        "    'ConvKernalInitializer': ConvKernalInitializer,\n",
        "    'Swish': Swish,\n",
        "    'DropConnect':DropConnect\n",
        "})"
      ],
      "metadata": {
        "id": "n5iPL5MNPkhE"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#load model \n",
        "from tensorflow.keras.models import load_model\n",
        "model = load_model('/content/drive/MyDrive/cut_panoramic/Model/Classification/Male/33_รอบที่3_Flimpano_Male125_250.h5')\n",
        "height = width = model.input_shape[1]"
      ],
      "metadata": {
        "id": "plYz49xMPkly"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z6IOPBflFbvc",
        "outputId": "a9293c7b-492b-4069-a62b-b8ea311bd4b8"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " efficientnet-b0 (Functional  (None, 5, 5, 1280)       4049564   \n",
            " )                                                               \n",
            "                                                                 \n",
            " gap (GlobalMaxPooling2D)    (None, 1280)              0         \n",
            "                                                                 \n",
            " dropout_out (Dropout)       (None, 1280)              0         \n",
            "                                                                 \n",
            " fc_out (Dense)              (None, 19)                24339     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4,073,903\n",
            "Trainable params: 24,339\n",
            "Non-trainable params: 4,049,564\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train ด้วย ImageDataGenerator ของ Keras ซึ่งจะเพิ่มข้อมูลเสริมระหว่างการฝึกเพื่อลดโอกาสเกิด overfitting\n",
        "#overfitting เกิดจากข้อมูลที่ซับซ้อนกันเกินไป\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "train_datagen = ImageDataGenerator(\n",
        "      rescale=1./255, #โมเดลส่วนใหญ่ต้องใช้ RGB ในช่วง 0–1\n",
        "      rotation_range=40,\n",
        "      width_shift_range=0.2,\n",
        "      height_shift_range=0.2,\n",
        "      shear_range=0.2,\n",
        "      zoom_range=0.2,\n",
        "      horizontal_flip=True,\n",
        "      fill_mode='nearest')\n",
        "\n",
        "# Note that the validation data should not be augmented!\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "        # This is the target directory #ไดเรกเป้าหมาย\n",
        "        train_dir,\n",
        "        # รูปภาพทั้งหมดจะถูกปรับขนาดตามความสูงและความกว้างของเป้าหมาย\n",
        "        target_size=(height, width),\n",
        "        batch_size=batch_size,\n",
        "        # Since we use categorical_crossentropy loss, we need categorical labels\n",
        "        #เนื่องจากเราใช้ categorical_crossentropy loss เราจึงต้องมีป้ายกำกับตามหมวดหมู่\n",
        "        class_mode='categorical')\n",
        "\n",
        "validation_generator = test_datagen.flow_from_directory( #การดึงภาพจาก Directory มาเข้าโมเดล \n",
        "        validation_dir,\n",
        "        target_size=(height, width),\n",
        "        batch_size=batch_size,\n",
        "        class_mode='categorical')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KBMZbdr2Pgw4",
        "outputId": "8bfa2df2-920b-429e-c457-70f5d76ada4d"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1425 images belonging to 19 classes.\n",
            "Found 475 images belonging to 19 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# multiply_16\n",
        "# set 'multiply_16' and following layers trainable\n",
        "model.trainable = True\n",
        "\n",
        "set_trainable = False\n",
        "for layer in conv_base.layers:\n",
        "    if layer.name == 'multiply_16':\n",
        "        set_trainable = True\n",
        "    if set_trainable:\n",
        "        layer.trainable = True\n",
        "    else:\n",
        "        layer.trainable = False  "
      ],
      "metadata": {
        "id": "2SmWJJlZ0K0g"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gqOZnbxjGmFY",
        "outputId": "0a040cb9-8b03-4c14-ebb0-83134e86a1d9"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " efficientnet-b0 (Functional  (None, 5, 5, 1280)       4049564   \n",
            " )                                                               \n",
            "                                                                 \n",
            " gap (GlobalMaxPooling2D)    (None, 1280)              0         \n",
            "                                                                 \n",
            " dropout_out (Dropout)       (None, 1280)              0         \n",
            "                                                                 \n",
            " fc_out (Dense)              (None, 19)                24339     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4,073,903\n",
            "Trainable params: 4,031,887\n",
            "Non-trainable params: 42,016\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit_generator(\n",
        "      train_generator,\n",
        "      steps_per_epoch= NUM_TRAIN //batch_size,\n",
        "      epochs=epochs,\n",
        "      validation_data=validation_generator,\n",
        "      validation_steps= NUM_TEST //batch_size,\n",
        "      verbose=1,\n",
        "      use_multiprocessing=True,\n",
        "      workers=4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C9Cf1dwyP1PD",
        "outputId": "5e9df762-71fb-458a-af2a-858f8e785a47"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-16-caa7b37242a8>:1: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  history = model.fit_generator(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/250\n",
            "89/89 [==============================] - 109s 1s/step - loss: 2.2052 - acc: 0.2441 - val_loss: 2.6984 - val_acc: 0.1595\n",
            "Epoch 2/250\n",
            "89/89 [==============================] - 25s 280ms/step - loss: 2.2149 - acc: 0.2676 - val_loss: 2.7020 - val_acc: 0.1638\n",
            "Epoch 3/250\n",
            "89/89 [==============================] - 25s 275ms/step - loss: 2.2056 - acc: 0.2406 - val_loss: 2.6742 - val_acc: 0.1616\n",
            "Epoch 4/250\n",
            "89/89 [==============================] - 25s 270ms/step - loss: 2.2109 - acc: 0.2555 - val_loss: 2.6908 - val_acc: 0.1552\n",
            "Epoch 5/250\n",
            "89/89 [==============================] - 20s 219ms/step - loss: 2.2263 - acc: 0.2626 - val_loss: 2.7002 - val_acc: 0.1616\n",
            "Epoch 6/250\n",
            "89/89 [==============================] - 27s 296ms/step - loss: 2.2066 - acc: 0.2420 - val_loss: 2.6720 - val_acc: 0.1573\n",
            "Epoch 7/250\n",
            "89/89 [==============================] - 25s 277ms/step - loss: 2.1905 - acc: 0.2569 - val_loss: 2.6860 - val_acc: 0.1573\n",
            "Epoch 8/250\n",
            "89/89 [==============================] - 25s 274ms/step - loss: 2.2260 - acc: 0.2498 - val_loss: 2.6957 - val_acc: 0.1659\n",
            "Epoch 9/250\n",
            "89/89 [==============================] - 26s 290ms/step - loss: 2.1904 - acc: 0.2605 - val_loss: 2.7033 - val_acc: 0.1616\n",
            "Epoch 10/250\n",
            "89/89 [==============================] - 26s 281ms/step - loss: 2.1834 - acc: 0.2754 - val_loss: 2.6959 - val_acc: 0.1681\n",
            "Epoch 11/250\n",
            "89/89 [==============================] - 25s 275ms/step - loss: 2.1678 - acc: 0.2768 - val_loss: 2.6924 - val_acc: 0.1659\n",
            "Epoch 12/250\n",
            "89/89 [==============================] - 25s 276ms/step - loss: 2.2377 - acc: 0.2534 - val_loss: 2.7187 - val_acc: 0.1509\n",
            "Epoch 13/250\n",
            "89/89 [==============================] - 26s 283ms/step - loss: 2.1767 - acc: 0.2768 - val_loss: 2.7163 - val_acc: 0.1573\n",
            "Epoch 14/250\n",
            "89/89 [==============================] - 25s 276ms/step - loss: 2.1812 - acc: 0.2647 - val_loss: 2.6934 - val_acc: 0.1638\n",
            "Epoch 15/250\n",
            "89/89 [==============================] - 25s 276ms/step - loss: 2.1721 - acc: 0.2654 - val_loss: 2.6898 - val_acc: 0.1659\n",
            "Epoch 16/250\n",
            "89/89 [==============================] - 25s 273ms/step - loss: 2.2030 - acc: 0.2697 - val_loss: 2.6811 - val_acc: 0.1638\n",
            "Epoch 17/250\n",
            "89/89 [==============================] - 25s 281ms/step - loss: 2.1832 - acc: 0.2754 - val_loss: 2.7099 - val_acc: 0.1595\n",
            "Epoch 18/250\n",
            "89/89 [==============================] - 25s 274ms/step - loss: 2.2098 - acc: 0.2527 - val_loss: 2.6955 - val_acc: 0.1638\n",
            "Epoch 19/250\n",
            "89/89 [==============================] - 27s 296ms/step - loss: 2.2437 - acc: 0.2534 - val_loss: 2.6815 - val_acc: 0.1616\n",
            "Epoch 20/250\n",
            "89/89 [==============================] - 27s 299ms/step - loss: 2.1991 - acc: 0.2612 - val_loss: 2.6852 - val_acc: 0.1681\n",
            "Epoch 21/250\n",
            "89/89 [==============================] - 25s 276ms/step - loss: 2.1920 - acc: 0.2548 - val_loss: 2.6849 - val_acc: 0.1638\n",
            "Epoch 22/250\n",
            "89/89 [==============================] - 21s 226ms/step - loss: 2.2201 - acc: 0.2512 - val_loss: 2.7081 - val_acc: 0.1552\n",
            "Epoch 23/250\n",
            "89/89 [==============================] - 27s 294ms/step - loss: 2.2398 - acc: 0.2300 - val_loss: 2.6813 - val_acc: 0.1595\n",
            "Epoch 24/250\n",
            "89/89 [==============================] - 25s 279ms/step - loss: 2.2218 - acc: 0.2498 - val_loss: 2.7038 - val_acc: 0.1530\n",
            "Epoch 25/250\n",
            "89/89 [==============================] - 20s 219ms/step - loss: 2.2183 - acc: 0.2605 - val_loss: 2.6972 - val_acc: 0.1616\n",
            "Epoch 26/250\n",
            "89/89 [==============================] - 27s 295ms/step - loss: 2.1832 - acc: 0.2718 - val_loss: 2.6723 - val_acc: 0.1681\n",
            "Epoch 27/250\n",
            "89/89 [==============================] - 27s 292ms/step - loss: 2.2580 - acc: 0.2413 - val_loss: 2.6684 - val_acc: 0.1638\n",
            "Epoch 28/250\n",
            "89/89 [==============================] - 25s 278ms/step - loss: 2.2554 - acc: 0.2498 - val_loss: 2.6565 - val_acc: 0.1659\n",
            "Epoch 29/250\n",
            "89/89 [==============================] - 25s 273ms/step - loss: 2.2120 - acc: 0.2548 - val_loss: 2.6603 - val_acc: 0.1552\n",
            "Epoch 30/250\n",
            "89/89 [==============================] - 25s 279ms/step - loss: 2.1925 - acc: 0.2747 - val_loss: 2.6894 - val_acc: 0.1509\n",
            "Epoch 31/250\n",
            "89/89 [==============================] - 26s 281ms/step - loss: 2.2085 - acc: 0.2612 - val_loss: 2.6887 - val_acc: 0.1616\n",
            "Epoch 32/250\n",
            "89/89 [==============================] - 25s 272ms/step - loss: 2.2043 - acc: 0.2498 - val_loss: 2.7135 - val_acc: 0.1659\n",
            "Epoch 33/250\n",
            "89/89 [==============================] - 26s 283ms/step - loss: 2.2183 - acc: 0.2505 - val_loss: 2.6809 - val_acc: 0.1638\n",
            "Epoch 34/250\n",
            "89/89 [==============================] - 25s 276ms/step - loss: 2.2174 - acc: 0.2541 - val_loss: 2.7056 - val_acc: 0.1509\n",
            "Epoch 35/250\n",
            "89/89 [==============================] - 26s 286ms/step - loss: 2.1739 - acc: 0.2704 - val_loss: 2.6718 - val_acc: 0.1638\n",
            "Epoch 36/250\n",
            "89/89 [==============================] - 27s 293ms/step - loss: 2.2153 - acc: 0.2498 - val_loss: 2.7099 - val_acc: 0.1552\n",
            "Epoch 37/250\n",
            "89/89 [==============================] - 26s 287ms/step - loss: 2.2308 - acc: 0.2583 - val_loss: 2.6878 - val_acc: 0.1638\n",
            "Epoch 38/250\n",
            "89/89 [==============================] - 26s 286ms/step - loss: 2.2058 - acc: 0.2740 - val_loss: 2.6865 - val_acc: 0.1509\n",
            "Epoch 39/250\n",
            "89/89 [==============================] - 27s 297ms/step - loss: 2.1765 - acc: 0.2456 - val_loss: 2.6779 - val_acc: 0.1638\n",
            "Epoch 40/250\n",
            "89/89 [==============================] - 26s 281ms/step - loss: 2.2139 - acc: 0.2541 - val_loss: 2.6690 - val_acc: 0.1530\n",
            "Epoch 41/250\n",
            "89/89 [==============================] - 27s 298ms/step - loss: 2.1919 - acc: 0.2512 - val_loss: 2.6848 - val_acc: 0.1509\n",
            "Epoch 42/250\n",
            "89/89 [==============================] - 26s 283ms/step - loss: 2.1736 - acc: 0.2555 - val_loss: 2.6954 - val_acc: 0.1552\n",
            "Epoch 43/250\n",
            "89/89 [==============================] - 29s 323ms/step - loss: 2.2352 - acc: 0.2399 - val_loss: 2.6964 - val_acc: 0.1530\n",
            "Epoch 44/250\n",
            "89/89 [==============================] - 26s 286ms/step - loss: 2.1836 - acc: 0.2498 - val_loss: 2.6996 - val_acc: 0.1573\n",
            "Epoch 45/250\n",
            "89/89 [==============================] - 27s 295ms/step - loss: 2.1624 - acc: 0.2612 - val_loss: 2.6849 - val_acc: 0.1659\n",
            "Epoch 46/250\n",
            "89/89 [==============================] - 25s 274ms/step - loss: 2.2113 - acc: 0.2399 - val_loss: 2.6860 - val_acc: 0.1573\n",
            "Epoch 47/250\n",
            "89/89 [==============================] - 26s 287ms/step - loss: 2.2325 - acc: 0.2548 - val_loss: 2.6838 - val_acc: 0.1530\n",
            "Epoch 48/250\n",
            "89/89 [==============================] - 26s 285ms/step - loss: 2.2040 - acc: 0.2605 - val_loss: 2.6774 - val_acc: 0.1595\n",
            "Epoch 49/250\n",
            "89/89 [==============================] - 27s 297ms/step - loss: 2.1924 - acc: 0.2598 - val_loss: 2.6810 - val_acc: 0.1573\n",
            "Epoch 50/250\n",
            "89/89 [==============================] - 26s 284ms/step - loss: 2.1767 - acc: 0.2406 - val_loss: 2.6982 - val_acc: 0.1552\n",
            "Epoch 51/250\n",
            "89/89 [==============================] - 26s 288ms/step - loss: 2.2151 - acc: 0.2491 - val_loss: 2.6925 - val_acc: 0.1595\n",
            "Epoch 52/250\n",
            "89/89 [==============================] - 25s 278ms/step - loss: 2.1842 - acc: 0.2605 - val_loss: 2.7030 - val_acc: 0.1530\n",
            "Epoch 53/250\n",
            "89/89 [==============================] - 25s 279ms/step - loss: 2.2188 - acc: 0.2498 - val_loss: 2.6867 - val_acc: 0.1595\n",
            "Epoch 54/250\n",
            "89/89 [==============================] - 25s 280ms/step - loss: 2.2217 - acc: 0.2449 - val_loss: 2.6824 - val_acc: 0.1616\n",
            "Epoch 55/250\n",
            "89/89 [==============================] - 25s 279ms/step - loss: 2.1692 - acc: 0.2619 - val_loss: 2.6804 - val_acc: 0.1681\n",
            "Epoch 56/250\n",
            "89/89 [==============================] - 25s 274ms/step - loss: 2.1840 - acc: 0.2576 - val_loss: 2.6918 - val_acc: 0.1573\n",
            "Epoch 57/250\n",
            "89/89 [==============================] - 20s 218ms/step - loss: 2.2018 - acc: 0.2406 - val_loss: 2.6984 - val_acc: 0.1573\n",
            "Epoch 58/250\n",
            "89/89 [==============================] - 27s 294ms/step - loss: 2.2080 - acc: 0.2605 - val_loss: 2.6516 - val_acc: 0.1616\n",
            "Epoch 59/250\n",
            "89/89 [==============================] - 22s 238ms/step - loss: 2.2193 - acc: 0.2562 - val_loss: 2.6656 - val_acc: 0.1659\n",
            "Epoch 60/250\n",
            "89/89 [==============================] - 27s 292ms/step - loss: 2.1849 - acc: 0.2704 - val_loss: 2.6928 - val_acc: 0.1466\n",
            "Epoch 61/250\n",
            "89/89 [==============================] - 28s 303ms/step - loss: 2.1775 - acc: 0.2576 - val_loss: 2.6861 - val_acc: 0.1616\n",
            "Epoch 62/250\n",
            "89/89 [==============================] - 27s 300ms/step - loss: 2.2090 - acc: 0.2548 - val_loss: 2.6893 - val_acc: 0.1595\n",
            "Epoch 63/250\n",
            "89/89 [==============================] - 27s 303ms/step - loss: 2.1457 - acc: 0.2775 - val_loss: 2.6876 - val_acc: 0.1616\n",
            "Epoch 64/250\n",
            "89/89 [==============================] - 27s 293ms/step - loss: 2.1702 - acc: 0.2704 - val_loss: 2.6880 - val_acc: 0.1530\n",
            "Epoch 65/250\n",
            "89/89 [==============================] - 29s 319ms/step - loss: 2.1915 - acc: 0.2598 - val_loss: 2.7046 - val_acc: 0.1487\n",
            "Epoch 66/250\n",
            "89/89 [==============================] - 27s 292ms/step - loss: 2.1864 - acc: 0.2676 - val_loss: 2.6904 - val_acc: 0.1638\n",
            "Epoch 67/250\n",
            "89/89 [==============================] - 20s 221ms/step - loss: 2.1787 - acc: 0.2683 - val_loss: 2.7201 - val_acc: 0.1530\n",
            "Epoch 68/250\n",
            "89/89 [==============================] - 26s 282ms/step - loss: 2.1970 - acc: 0.2534 - val_loss: 2.6926 - val_acc: 0.1616\n",
            "Epoch 69/250\n",
            "89/89 [==============================] - 25s 273ms/step - loss: 2.2654 - acc: 0.2548 - val_loss: 2.7187 - val_acc: 0.1530\n",
            "Epoch 70/250\n",
            "89/89 [==============================] - 27s 295ms/step - loss: 2.1823 - acc: 0.2569 - val_loss: 2.7265 - val_acc: 0.1530\n",
            "Epoch 71/250\n",
            "89/89 [==============================] - 25s 278ms/step - loss: 2.1761 - acc: 0.2569 - val_loss: 2.6827 - val_acc: 0.1638\n",
            "Epoch 72/250\n",
            "89/89 [==============================] - 20s 218ms/step - loss: 2.1483 - acc: 0.2661 - val_loss: 2.6845 - val_acc: 0.1595\n",
            "Epoch 73/250\n",
            "89/89 [==============================] - 26s 285ms/step - loss: 2.1967 - acc: 0.2562 - val_loss: 2.6983 - val_acc: 0.1552\n",
            "Epoch 74/250\n",
            "89/89 [==============================] - 20s 219ms/step - loss: 2.1904 - acc: 0.2839 - val_loss: 2.7007 - val_acc: 0.1487\n",
            "Epoch 75/250\n",
            "89/89 [==============================] - 26s 282ms/step - loss: 2.1979 - acc: 0.2576 - val_loss: 2.6925 - val_acc: 0.1616\n",
            "Epoch 76/250\n",
            "89/89 [==============================] - 29s 314ms/step - loss: 2.2087 - acc: 0.2498 - val_loss: 2.6844 - val_acc: 0.1595\n",
            "Epoch 77/250\n",
            "89/89 [==============================] - 27s 293ms/step - loss: 2.1739 - acc: 0.2562 - val_loss: 2.6690 - val_acc: 0.1530\n",
            "Epoch 78/250\n",
            "89/89 [==============================] - 27s 294ms/step - loss: 2.1861 - acc: 0.2612 - val_loss: 2.7030 - val_acc: 0.1487\n",
            "Epoch 79/250\n",
            "89/89 [==============================] - 27s 300ms/step - loss: 2.2038 - acc: 0.2520 - val_loss: 2.7054 - val_acc: 0.1422\n",
            "Epoch 80/250\n",
            "89/89 [==============================] - 21s 230ms/step - loss: 2.1931 - acc: 0.2647 - val_loss: 2.6887 - val_acc: 0.1509\n",
            "Epoch 81/250\n",
            "89/89 [==============================] - 28s 297ms/step - loss: 2.2070 - acc: 0.2605 - val_loss: 2.6894 - val_acc: 0.1573\n",
            "Epoch 82/250\n",
            "89/89 [==============================] - 25s 272ms/step - loss: 2.1942 - acc: 0.2612 - val_loss: 2.6827 - val_acc: 0.1573\n",
            "Epoch 83/250\n",
            "89/89 [==============================] - 22s 239ms/step - loss: 2.2250 - acc: 0.2569 - val_loss: 2.7116 - val_acc: 0.1530\n",
            "Epoch 84/250\n",
            "89/89 [==============================] - 27s 291ms/step - loss: 2.2047 - acc: 0.2725 - val_loss: 2.6994 - val_acc: 0.1595\n",
            "Epoch 85/250\n",
            "89/89 [==============================] - 27s 306ms/step - loss: 2.1951 - acc: 0.2541 - val_loss: 2.6778 - val_acc: 0.1552\n",
            "Epoch 86/250\n",
            "89/89 [==============================] - 26s 291ms/step - loss: 2.1784 - acc: 0.2704 - val_loss: 2.6795 - val_acc: 0.1552\n",
            "Epoch 87/250\n",
            "89/89 [==============================] - 27s 293ms/step - loss: 2.1763 - acc: 0.2647 - val_loss: 2.6641 - val_acc: 0.1616\n",
            "Epoch 88/250\n",
            "89/89 [==============================] - 25s 272ms/step - loss: 2.1675 - acc: 0.2619 - val_loss: 2.6933 - val_acc: 0.1573\n",
            "Epoch 89/250\n",
            "89/89 [==============================] - 25s 271ms/step - loss: 2.1393 - acc: 0.2740 - val_loss: 2.6926 - val_acc: 0.1573\n",
            "Epoch 90/250\n",
            "89/89 [==============================] - 25s 274ms/step - loss: 2.1922 - acc: 0.2754 - val_loss: 2.7032 - val_acc: 0.1573\n",
            "Epoch 91/250\n",
            "89/89 [==============================] - 26s 275ms/step - loss: 2.1611 - acc: 0.2796 - val_loss: 2.6731 - val_acc: 0.1638\n",
            "Epoch 92/250\n",
            "89/89 [==============================] - 26s 283ms/step - loss: 2.2309 - acc: 0.2583 - val_loss: 2.6926 - val_acc: 0.1530\n",
            "Epoch 93/250\n",
            "89/89 [==============================] - 29s 324ms/step - loss: 2.1993 - acc: 0.2683 - val_loss: 2.6954 - val_acc: 0.1573\n",
            "Epoch 94/250\n",
            "89/89 [==============================] - 25s 273ms/step - loss: 2.1618 - acc: 0.2598 - val_loss: 2.7247 - val_acc: 0.1487\n",
            "Epoch 95/250\n",
            "89/89 [==============================] - 25s 275ms/step - loss: 2.1989 - acc: 0.2669 - val_loss: 2.6651 - val_acc: 0.1616\n",
            "Epoch 96/250\n",
            "89/89 [==============================] - 25s 271ms/step - loss: 2.1858 - acc: 0.2775 - val_loss: 2.7048 - val_acc: 0.1530\n",
            "Epoch 97/250\n",
            "89/89 [==============================] - 25s 273ms/step - loss: 2.1760 - acc: 0.2669 - val_loss: 2.7123 - val_acc: 0.1638\n",
            "Epoch 98/250\n",
            "89/89 [==============================] - 27s 286ms/step - loss: 2.1623 - acc: 0.2569 - val_loss: 2.6994 - val_acc: 0.1595\n",
            "Epoch 99/250\n",
            "89/89 [==============================] - 27s 288ms/step - loss: 2.2065 - acc: 0.2661 - val_loss: 2.6944 - val_acc: 0.1595\n",
            "Epoch 100/250\n",
            "89/89 [==============================] - 26s 280ms/step - loss: 2.1712 - acc: 0.2697 - val_loss: 2.6785 - val_acc: 0.1616\n",
            "Epoch 101/250\n",
            "89/89 [==============================] - 26s 277ms/step - loss: 2.1352 - acc: 0.2669 - val_loss: 2.7041 - val_acc: 0.1573\n",
            "Epoch 102/250\n",
            "89/89 [==============================] - 27s 290ms/step - loss: 2.1795 - acc: 0.2598 - val_loss: 2.7385 - val_acc: 0.1552\n",
            "Epoch 103/250\n",
            "89/89 [==============================] - 29s 321ms/step - loss: 2.1518 - acc: 0.2775 - val_loss: 2.7162 - val_acc: 0.1616\n",
            "Epoch 104/250\n",
            "89/89 [==============================] - 26s 285ms/step - loss: 2.2120 - acc: 0.2576 - val_loss: 2.7237 - val_acc: 0.1466\n",
            "Epoch 105/250\n",
            "89/89 [==============================] - 25s 276ms/step - loss: 2.1238 - acc: 0.2782 - val_loss: 2.7152 - val_acc: 0.1509\n",
            "Epoch 106/250\n",
            "89/89 [==============================] - 26s 289ms/step - loss: 2.1884 - acc: 0.2562 - val_loss: 2.7163 - val_acc: 0.1573\n",
            "Epoch 107/250\n",
            "89/89 [==============================] - 26s 291ms/step - loss: 2.1738 - acc: 0.2704 - val_loss: 2.7188 - val_acc: 0.1595\n",
            "Epoch 108/250\n",
            "89/89 [==============================] - 28s 308ms/step - loss: 2.1924 - acc: 0.2676 - val_loss: 2.7012 - val_acc: 0.1616\n",
            "Epoch 109/250\n",
            "89/89 [==============================] - 20s 220ms/step - loss: 2.1545 - acc: 0.2661 - val_loss: 2.6964 - val_acc: 0.1659\n",
            "Epoch 110/250\n",
            "89/89 [==============================] - 26s 279ms/step - loss: 2.1774 - acc: 0.2406 - val_loss: 2.7242 - val_acc: 0.1573\n",
            "Epoch 111/250\n",
            "89/89 [==============================] - 27s 297ms/step - loss: 2.1510 - acc: 0.2782 - val_loss: 2.7264 - val_acc: 0.1573\n",
            "Epoch 112/250\n",
            "89/89 [==============================] - 27s 298ms/step - loss: 2.1682 - acc: 0.2740 - val_loss: 2.7287 - val_acc: 0.1616\n",
            "Epoch 113/250\n",
            "89/89 [==============================] - 25s 279ms/step - loss: 2.1466 - acc: 0.2867 - val_loss: 2.7279 - val_acc: 0.1595\n",
            "Epoch 114/250\n",
            "89/89 [==============================] - 27s 295ms/step - loss: 2.1913 - acc: 0.2669 - val_loss: 2.7122 - val_acc: 0.1616\n",
            "Epoch 115/250\n",
            "89/89 [==============================] - 20s 219ms/step - loss: 2.1980 - acc: 0.2441 - val_loss: 2.7343 - val_acc: 0.1509\n",
            "Epoch 116/250\n",
            "89/89 [==============================] - 27s 293ms/step - loss: 2.1771 - acc: 0.2527 - val_loss: 2.7240 - val_acc: 0.1616\n",
            "Epoch 117/250\n",
            "89/89 [==============================] - 25s 278ms/step - loss: 2.1696 - acc: 0.2768 - val_loss: 2.7140 - val_acc: 0.1552\n",
            "Epoch 118/250\n",
            "89/89 [==============================] - 20s 222ms/step - loss: 2.1690 - acc: 0.2633 - val_loss: 2.7003 - val_acc: 0.1616\n",
            "Epoch 119/250\n",
            "89/89 [==============================] - 27s 299ms/step - loss: 2.1626 - acc: 0.2640 - val_loss: 2.6880 - val_acc: 0.1638\n",
            "Epoch 120/250\n",
            "89/89 [==============================] - 27s 299ms/step - loss: 2.2484 - acc: 0.2427 - val_loss: 2.7139 - val_acc: 0.1573\n",
            "Epoch 121/250\n",
            "89/89 [==============================] - 27s 298ms/step - loss: 2.1245 - acc: 0.2881 - val_loss: 2.7105 - val_acc: 0.1595\n",
            "Epoch 122/250\n",
            "89/89 [==============================] - 27s 298ms/step - loss: 2.1511 - acc: 0.2605 - val_loss: 2.7082 - val_acc: 0.1573\n",
            "Epoch 123/250\n",
            "89/89 [==============================] - 26s 285ms/step - loss: 2.1854 - acc: 0.2796 - val_loss: 2.7281 - val_acc: 0.1595\n",
            "Epoch 124/250\n",
            "89/89 [==============================] - 25s 277ms/step - loss: 2.1991 - acc: 0.2534 - val_loss: 2.7264 - val_acc: 0.1595\n",
            "Epoch 125/250\n",
            "89/89 [==============================] - 26s 291ms/step - loss: 2.2009 - acc: 0.2562 - val_loss: 2.7420 - val_acc: 0.1509\n",
            "Epoch 126/250\n",
            "89/89 [==============================] - 26s 289ms/step - loss: 2.1478 - acc: 0.2598 - val_loss: 2.7351 - val_acc: 0.1530\n",
            "Epoch 127/250\n",
            "89/89 [==============================] - 27s 292ms/step - loss: 2.1755 - acc: 0.2661 - val_loss: 2.7161 - val_acc: 0.1595\n",
            "Epoch 128/250\n",
            "89/89 [==============================] - 27s 294ms/step - loss: 2.1699 - acc: 0.2633 - val_loss: 2.7143 - val_acc: 0.1573\n",
            "Epoch 129/250\n",
            "89/89 [==============================] - 28s 304ms/step - loss: 2.1717 - acc: 0.2576 - val_loss: 2.7301 - val_acc: 0.1530\n",
            "Epoch 130/250\n",
            "89/89 [==============================] - 25s 275ms/step - loss: 2.1439 - acc: 0.2860 - val_loss: 2.7255 - val_acc: 0.1552\n",
            "Epoch 131/250\n",
            "89/89 [==============================] - 26s 287ms/step - loss: 2.1517 - acc: 0.2747 - val_loss: 2.7238 - val_acc: 0.1573\n",
            "Epoch 132/250\n",
            "89/89 [==============================] - 20s 218ms/step - loss: 2.1349 - acc: 0.2889 - val_loss: 2.7259 - val_acc: 0.1595\n",
            "Epoch 133/250\n",
            "89/89 [==============================] - 27s 295ms/step - loss: 2.1830 - acc: 0.2718 - val_loss: 2.7305 - val_acc: 0.1573\n",
            "Epoch 134/250\n",
            "89/89 [==============================] - 29s 316ms/step - loss: 2.1552 - acc: 0.2740 - val_loss: 2.7668 - val_acc: 0.1422\n",
            "Epoch 135/250\n",
            "89/89 [==============================] - 27s 291ms/step - loss: 2.1396 - acc: 0.2605 - val_loss: 2.7371 - val_acc: 0.1595\n",
            "Epoch 136/250\n",
            "89/89 [==============================] - 27s 299ms/step - loss: 2.2387 - acc: 0.2562 - val_loss: 2.7304 - val_acc: 0.1595\n",
            "Epoch 137/250\n",
            "89/89 [==============================] - 27s 299ms/step - loss: 2.1879 - acc: 0.2583 - val_loss: 2.7214 - val_acc: 0.1595\n",
            "Epoch 138/250\n",
            "89/89 [==============================] - 27s 300ms/step - loss: 2.1929 - acc: 0.2385 - val_loss: 2.7299 - val_acc: 0.1487\n",
            "Epoch 139/250\n",
            "89/89 [==============================] - 29s 315ms/step - loss: 2.1823 - acc: 0.2661 - val_loss: 2.7116 - val_acc: 0.1638\n",
            "Epoch 140/250\n",
            "89/89 [==============================] - 25s 277ms/step - loss: 2.1437 - acc: 0.2782 - val_loss: 2.7332 - val_acc: 0.1638\n",
            "Epoch 141/250\n",
            "89/89 [==============================] - 25s 277ms/step - loss: 2.1911 - acc: 0.2747 - val_loss: 2.7372 - val_acc: 0.1487\n",
            "Epoch 142/250\n",
            "89/89 [==============================] - 26s 283ms/step - loss: 2.1859 - acc: 0.2498 - val_loss: 2.6999 - val_acc: 0.1573\n",
            "Epoch 143/250\n",
            "89/89 [==============================] - 25s 278ms/step - loss: 2.1763 - acc: 0.2654 - val_loss: 2.7502 - val_acc: 0.1530\n",
            "Epoch 144/250\n",
            "89/89 [==============================] - 27s 299ms/step - loss: 2.2221 - acc: 0.2562 - val_loss: 2.7133 - val_acc: 0.1595\n",
            "Epoch 145/250\n",
            "89/89 [==============================] - 25s 277ms/step - loss: 2.1641 - acc: 0.2619 - val_loss: 2.7232 - val_acc: 0.1616\n",
            "Epoch 146/250\n",
            "89/89 [==============================] - 25s 275ms/step - loss: 2.1102 - acc: 0.2858 - val_loss: 2.7282 - val_acc: 0.1595\n",
            "Epoch 147/250\n",
            "89/89 [==============================] - 21s 227ms/step - loss: 2.1390 - acc: 0.2697 - val_loss: 2.7243 - val_acc: 0.1638\n",
            "Epoch 148/250\n",
            "89/89 [==============================] - 26s 277ms/step - loss: 2.1576 - acc: 0.2626 - val_loss: 2.7176 - val_acc: 0.1552\n",
            "Epoch 149/250\n",
            "89/89 [==============================] - 25s 276ms/step - loss: 2.1455 - acc: 0.2825 - val_loss: 2.7215 - val_acc: 0.1659\n",
            "Epoch 150/250\n",
            "89/89 [==============================] - 26s 279ms/step - loss: 2.1861 - acc: 0.2747 - val_loss: 2.7190 - val_acc: 0.1509\n",
            "Epoch 151/250\n",
            "89/89 [==============================] - 20s 223ms/step - loss: 2.1975 - acc: 0.2349 - val_loss: 2.6881 - val_acc: 0.1638\n",
            "Epoch 152/250\n",
            "89/89 [==============================] - 25s 277ms/step - loss: 2.1718 - acc: 0.2704 - val_loss: 2.7074 - val_acc: 0.1552\n",
            "Epoch 153/250\n",
            "89/89 [==============================] - 27s 299ms/step - loss: 2.1645 - acc: 0.2740 - val_loss: 2.7082 - val_acc: 0.1616\n",
            "Epoch 154/250\n",
            "89/89 [==============================] - 25s 277ms/step - loss: 2.1665 - acc: 0.2661 - val_loss: 2.7090 - val_acc: 0.1530\n",
            "Epoch 155/250\n",
            "89/89 [==============================] - 25s 273ms/step - loss: 2.1369 - acc: 0.2661 - val_loss: 2.7357 - val_acc: 0.1595\n",
            "Epoch 156/250\n",
            "89/89 [==============================] - 25s 279ms/step - loss: 2.1434 - acc: 0.2562 - val_loss: 2.7299 - val_acc: 0.1573\n",
            "Epoch 157/250\n",
            "89/89 [==============================] - 26s 277ms/step - loss: 2.1280 - acc: 0.2711 - val_loss: 2.7064 - val_acc: 0.1681\n",
            "Epoch 158/250\n",
            "89/89 [==============================] - 21s 221ms/step - loss: 2.1089 - acc: 0.2853 - val_loss: 2.7216 - val_acc: 0.1595\n",
            "Epoch 159/250\n",
            "89/89 [==============================] - 25s 279ms/step - loss: 2.1155 - acc: 0.2853 - val_loss: 2.7309 - val_acc: 0.1509\n",
            "Epoch 160/250\n",
            "89/89 [==============================] - 25s 278ms/step - loss: 2.1408 - acc: 0.2725 - val_loss: 2.7212 - val_acc: 0.1552\n",
            "Epoch 161/250\n",
            "89/89 [==============================] - 21s 225ms/step - loss: 2.1222 - acc: 0.2747 - val_loss: 2.7011 - val_acc: 0.1552\n",
            "Epoch 162/250\n",
            "89/89 [==============================] - 22s 239ms/step - loss: 2.1729 - acc: 0.2732 - val_loss: 2.7185 - val_acc: 0.1595\n",
            "Epoch 163/250\n",
            "89/89 [==============================] - 27s 287ms/step - loss: 2.1607 - acc: 0.2541 - val_loss: 2.7259 - val_acc: 0.1509\n",
            "Epoch 164/250\n",
            "89/89 [==============================] - 26s 279ms/step - loss: 2.1223 - acc: 0.2683 - val_loss: 2.7369 - val_acc: 0.1552\n",
            "Epoch 165/250\n",
            "89/89 [==============================] - 25s 275ms/step - loss: 2.1877 - acc: 0.2690 - val_loss: 2.7150 - val_acc: 0.1595\n",
            "Epoch 166/250\n",
            "89/89 [==============================] - 26s 283ms/step - loss: 2.1594 - acc: 0.2676 - val_loss: 2.7513 - val_acc: 0.1509\n",
            "Epoch 167/250\n",
            "89/89 [==============================] - 27s 296ms/step - loss: 2.1427 - acc: 0.2789 - val_loss: 2.7410 - val_acc: 0.1552\n",
            "Epoch 168/250\n",
            "89/89 [==============================] - 25s 277ms/step - loss: 2.1364 - acc: 0.2874 - val_loss: 2.7158 - val_acc: 0.1595\n",
            "Epoch 169/250\n",
            "89/89 [==============================] - 26s 278ms/step - loss: 2.1435 - acc: 0.2796 - val_loss: 2.7292 - val_acc: 0.1595\n",
            "Epoch 170/250\n",
            "89/89 [==============================] - 20s 224ms/step - loss: 2.1022 - acc: 0.2725 - val_loss: 2.7309 - val_acc: 0.1595\n",
            "Epoch 171/250\n",
            "89/89 [==============================] - 28s 304ms/step - loss: 2.1596 - acc: 0.2569 - val_loss: 2.7236 - val_acc: 0.1552\n",
            "Epoch 172/250\n",
            "89/89 [==============================] - 25s 277ms/step - loss: 2.1461 - acc: 0.2811 - val_loss: 2.7314 - val_acc: 0.1530\n",
            "Epoch 173/250\n",
            "89/89 [==============================] - 26s 289ms/step - loss: 2.1531 - acc: 0.2676 - val_loss: 2.7268 - val_acc: 0.1552\n",
            "Epoch 174/250\n",
            "89/89 [==============================] - 25s 275ms/step - loss: 2.1519 - acc: 0.2711 - val_loss: 2.6996 - val_acc: 0.1552\n",
            "Epoch 175/250\n",
            "89/89 [==============================] - 25s 277ms/step - loss: 2.1315 - acc: 0.2747 - val_loss: 2.7369 - val_acc: 0.1552\n",
            "Epoch 176/250\n",
            "89/89 [==============================] - 27s 300ms/step - loss: 2.1362 - acc: 0.2740 - val_loss: 2.7330 - val_acc: 0.1573\n",
            "Epoch 177/250\n",
            "89/89 [==============================] - 21s 225ms/step - loss: 2.1811 - acc: 0.2626 - val_loss: 2.7412 - val_acc: 0.1552\n",
            "Epoch 178/250\n",
            "89/89 [==============================] - 27s 290ms/step - loss: 2.1323 - acc: 0.2690 - val_loss: 2.7351 - val_acc: 0.1552\n",
            "Epoch 179/250\n",
            "89/89 [==============================] - 27s 300ms/step - loss: 2.0953 - acc: 0.2945 - val_loss: 2.7042 - val_acc: 0.1616\n",
            "Epoch 180/250\n",
            "89/89 [==============================] - 28s 303ms/step - loss: 2.1725 - acc: 0.2633 - val_loss: 2.7273 - val_acc: 0.1595\n",
            "Epoch 181/250\n",
            "89/89 [==============================] - 28s 307ms/step - loss: 2.1997 - acc: 0.2520 - val_loss: 2.7396 - val_acc: 0.1552\n",
            "Epoch 182/250\n",
            "89/89 [==============================] - 27s 292ms/step - loss: 2.1294 - acc: 0.2654 - val_loss: 2.7549 - val_acc: 0.1509\n",
            "Epoch 183/250\n",
            "89/89 [==============================] - 27s 296ms/step - loss: 2.1295 - acc: 0.2640 - val_loss: 2.7310 - val_acc: 0.1616\n",
            "Epoch 184/250\n",
            "89/89 [==============================] - 27s 294ms/step - loss: 2.1654 - acc: 0.2690 - val_loss: 2.7116 - val_acc: 0.1530\n",
            "Epoch 185/250\n",
            "89/89 [==============================] - 27s 301ms/step - loss: 2.1660 - acc: 0.2661 - val_loss: 2.7218 - val_acc: 0.1530\n",
            "Epoch 186/250\n",
            "89/89 [==============================] - 29s 324ms/step - loss: 2.1543 - acc: 0.2576 - val_loss: 2.7407 - val_acc: 0.1509\n",
            "Epoch 187/250\n",
            "89/89 [==============================] - 26s 281ms/step - loss: 2.1577 - acc: 0.2654 - val_loss: 2.7305 - val_acc: 0.1616\n",
            "Epoch 188/250\n",
            "89/89 [==============================] - 26s 290ms/step - loss: 2.1427 - acc: 0.2796 - val_loss: 2.7039 - val_acc: 0.1595\n",
            "Epoch 189/250\n",
            "89/89 [==============================] - 27s 302ms/step - loss: 2.1711 - acc: 0.2612 - val_loss: 2.7475 - val_acc: 0.1595\n",
            "Epoch 190/250\n",
            "89/89 [==============================] - 26s 286ms/step - loss: 2.1415 - acc: 0.2654 - val_loss: 2.7127 - val_acc: 0.1595\n",
            "Epoch 191/250\n",
            "89/89 [==============================] - 26s 282ms/step - loss: 2.1088 - acc: 0.2782 - val_loss: 2.7299 - val_acc: 0.1595\n",
            "Epoch 192/250\n",
            "89/89 [==============================] - 26s 281ms/step - loss: 2.1493 - acc: 0.2917 - val_loss: 2.7208 - val_acc: 0.1638\n",
            "Epoch 193/250\n",
            "89/89 [==============================] - 25s 277ms/step - loss: 2.1313 - acc: 0.2626 - val_loss: 2.7401 - val_acc: 0.1616\n",
            "Epoch 194/250\n",
            "89/89 [==============================] - 26s 279ms/step - loss: 2.1614 - acc: 0.2598 - val_loss: 2.7347 - val_acc: 0.1573\n",
            "Epoch 195/250\n",
            "89/89 [==============================] - 25s 278ms/step - loss: 2.1134 - acc: 0.2874 - val_loss: 2.7372 - val_acc: 0.1573\n",
            "Epoch 196/250\n",
            "89/89 [==============================] - 25s 276ms/step - loss: 2.1449 - acc: 0.2860 - val_loss: 2.7404 - val_acc: 0.1552\n",
            "Epoch 197/250\n",
            "89/89 [==============================] - 26s 282ms/step - loss: 2.1528 - acc: 0.2832 - val_loss: 2.7177 - val_acc: 0.1595\n",
            "Epoch 198/250\n",
            "89/89 [==============================] - 25s 276ms/step - loss: 2.1666 - acc: 0.2690 - val_loss: 2.7091 - val_acc: 0.1595\n",
            "Epoch 199/250\n",
            "89/89 [==============================] - 21s 224ms/step - loss: 2.1599 - acc: 0.2576 - val_loss: 2.7463 - val_acc: 0.1616\n",
            "Epoch 200/250\n",
            "89/89 [==============================] - 22s 240ms/step - loss: 2.1571 - acc: 0.2782 - val_loss: 2.7213 - val_acc: 0.1595\n",
            "Epoch 201/250\n",
            "89/89 [==============================] - 25s 280ms/step - loss: 2.1664 - acc: 0.2470 - val_loss: 2.7339 - val_acc: 0.1573\n",
            "Epoch 202/250\n",
            "89/89 [==============================] - 26s 289ms/step - loss: 2.1863 - acc: 0.2527 - val_loss: 2.7515 - val_acc: 0.1595\n",
            "Epoch 203/250\n",
            "89/89 [==============================] - 25s 280ms/step - loss: 2.1177 - acc: 0.2874 - val_loss: 2.7492 - val_acc: 0.1552\n",
            "Epoch 204/250\n",
            "89/89 [==============================] - 27s 293ms/step - loss: 2.1605 - acc: 0.2740 - val_loss: 2.7879 - val_acc: 0.1573\n",
            "Epoch 205/250\n",
            "89/89 [==============================] - 27s 291ms/step - loss: 2.2088 - acc: 0.2683 - val_loss: 2.7347 - val_acc: 0.1573\n",
            "Epoch 206/250\n",
            "89/89 [==============================] - 29s 315ms/step - loss: 2.1227 - acc: 0.2818 - val_loss: 2.7589 - val_acc: 0.1595\n",
            "Epoch 207/250\n",
            "89/89 [==============================] - 27s 295ms/step - loss: 2.1533 - acc: 0.2768 - val_loss: 2.7488 - val_acc: 0.1595\n",
            "Epoch 208/250\n",
            "89/89 [==============================] - 26s 283ms/step - loss: 2.1276 - acc: 0.2889 - val_loss: 2.7366 - val_acc: 0.1681\n",
            "Epoch 209/250\n",
            "89/89 [==============================] - 27s 296ms/step - loss: 2.1964 - acc: 0.2598 - val_loss: 2.7553 - val_acc: 0.1573\n",
            "Epoch 210/250\n",
            "89/89 [==============================] - 27s 301ms/step - loss: 2.2091 - acc: 0.2605 - val_loss: 2.7549 - val_acc: 0.1616\n",
            "Epoch 211/250\n",
            "89/89 [==============================] - 29s 317ms/step - loss: 2.1730 - acc: 0.2768 - val_loss: 2.7364 - val_acc: 0.1573\n",
            "Epoch 212/250\n",
            "89/89 [==============================] - 25s 278ms/step - loss: 2.1289 - acc: 0.2740 - val_loss: 2.7220 - val_acc: 0.1530\n",
            "Epoch 213/250\n",
            "89/89 [==============================] - 26s 292ms/step - loss: 2.1235 - acc: 0.2803 - val_loss: 2.7599 - val_acc: 0.1616\n",
            "Epoch 214/250\n",
            "89/89 [==============================] - 26s 283ms/step - loss: 2.1456 - acc: 0.2917 - val_loss: 2.7252 - val_acc: 0.1659\n",
            "Epoch 215/250\n",
            "89/89 [==============================] - 25s 278ms/step - loss: 2.1960 - acc: 0.2583 - val_loss: 2.7275 - val_acc: 0.1595\n",
            "Epoch 216/250\n",
            "89/89 [==============================] - 28s 315ms/step - loss: 2.1608 - acc: 0.2612 - val_loss: 2.7308 - val_acc: 0.1509\n",
            "Epoch 217/250\n",
            "89/89 [==============================] - 25s 276ms/step - loss: 2.1406 - acc: 0.2860 - val_loss: 2.7635 - val_acc: 0.1552\n",
            "Epoch 218/250\n",
            "89/89 [==============================] - 26s 289ms/step - loss: 2.1331 - acc: 0.2782 - val_loss: 2.7599 - val_acc: 0.1616\n",
            "Epoch 219/250\n",
            "89/89 [==============================] - 26s 283ms/step - loss: 2.1387 - acc: 0.2789 - val_loss: 2.7331 - val_acc: 0.1616\n",
            "Epoch 220/250\n",
            "89/89 [==============================] - 26s 290ms/step - loss: 2.1620 - acc: 0.2527 - val_loss: 2.7133 - val_acc: 0.1616\n",
            "Epoch 221/250\n",
            "89/89 [==============================] - 27s 299ms/step - loss: 2.1227 - acc: 0.2768 - val_loss: 2.7505 - val_acc: 0.1573\n",
            "Epoch 222/250\n",
            "89/89 [==============================] - 21s 226ms/step - loss: 2.1264 - acc: 0.2811 - val_loss: 2.7385 - val_acc: 0.1616\n",
            "Epoch 223/250\n",
            "89/89 [==============================] - 27s 281ms/step - loss: 2.1185 - acc: 0.2881 - val_loss: 2.7632 - val_acc: 0.1659\n",
            "Epoch 224/250\n",
            "89/89 [==============================] - 21s 225ms/step - loss: 2.1437 - acc: 0.2761 - val_loss: 2.7287 - val_acc: 0.1595\n",
            "Epoch 225/250\n",
            "89/89 [==============================] - 26s 279ms/step - loss: 2.1738 - acc: 0.2761 - val_loss: 2.7496 - val_acc: 0.1616\n",
            "Epoch 226/250\n",
            "89/89 [==============================] - 25s 279ms/step - loss: 2.1436 - acc: 0.2782 - val_loss: 2.7391 - val_acc: 0.1681\n",
            "Epoch 227/250\n",
            "89/89 [==============================] - 21s 229ms/step - loss: 2.1784 - acc: 0.2498 - val_loss: 2.7620 - val_acc: 0.1595\n",
            "Epoch 228/250\n",
            "89/89 [==============================] - 27s 282ms/step - loss: 2.1186 - acc: 0.2924 - val_loss: 2.7520 - val_acc: 0.1573\n",
            "Epoch 229/250\n",
            "89/89 [==============================] - 27s 295ms/step - loss: 2.1222 - acc: 0.2775 - val_loss: 2.7591 - val_acc: 0.1616\n",
            "Epoch 230/250\n",
            "89/89 [==============================] - 27s 301ms/step - loss: 2.1582 - acc: 0.2626 - val_loss: 2.7650 - val_acc: 0.1659\n",
            "Epoch 231/250\n",
            "89/89 [==============================] - 28s 313ms/step - loss: 2.1476 - acc: 0.2697 - val_loss: 2.7374 - val_acc: 0.1595\n",
            "Epoch 232/250\n",
            "89/89 [==============================] - 21s 225ms/step - loss: 2.1296 - acc: 0.2683 - val_loss: 2.7754 - val_acc: 0.1487\n",
            "Epoch 233/250\n",
            "89/89 [==============================] - 27s 297ms/step - loss: 2.1320 - acc: 0.2697 - val_loss: 2.7785 - val_acc: 0.1659\n",
            "Epoch 234/250\n",
            "89/89 [==============================] - 20s 222ms/step - loss: 2.1762 - acc: 0.2619 - val_loss: 2.7401 - val_acc: 0.1638\n",
            "Epoch 235/250\n",
            "89/89 [==============================] - 27s 287ms/step - loss: 2.1774 - acc: 0.2683 - val_loss: 2.7619 - val_acc: 0.1595\n",
            "Epoch 236/250\n",
            "89/89 [==============================] - 28s 298ms/step - loss: 2.1726 - acc: 0.2562 - val_loss: 2.7437 - val_acc: 0.1638\n",
            "Epoch 237/250\n",
            "89/89 [==============================] - 26s 283ms/step - loss: 2.1488 - acc: 0.2775 - val_loss: 2.7741 - val_acc: 0.1638\n",
            "Epoch 238/250\n",
            "89/89 [==============================] - 27s 292ms/step - loss: 2.1368 - acc: 0.2697 - val_loss: 2.7751 - val_acc: 0.1595\n",
            "Epoch 239/250\n",
            "89/89 [==============================] - 27s 299ms/step - loss: 2.1800 - acc: 0.2654 - val_loss: 2.7500 - val_acc: 0.1595\n",
            "Epoch 240/250\n",
            "89/89 [==============================] - 27s 298ms/step - loss: 2.0718 - acc: 0.2896 - val_loss: 2.7560 - val_acc: 0.1616\n",
            "Epoch 241/250\n",
            "89/89 [==============================] - 27s 296ms/step - loss: 2.1276 - acc: 0.2704 - val_loss: 2.7576 - val_acc: 0.1595\n",
            "Epoch 242/250\n",
            "89/89 [==============================] - 26s 279ms/step - loss: 2.1653 - acc: 0.2768 - val_loss: 2.7681 - val_acc: 0.1552\n",
            "Epoch 243/250\n",
            "89/89 [==============================] - 27s 295ms/step - loss: 2.1360 - acc: 0.2832 - val_loss: 2.7808 - val_acc: 0.1616\n",
            "Epoch 244/250\n",
            "89/89 [==============================] - 26s 281ms/step - loss: 2.1211 - acc: 0.2740 - val_loss: 2.7308 - val_acc: 0.1638\n",
            "Epoch 245/250\n",
            "89/89 [==============================] - 25s 275ms/step - loss: 2.1504 - acc: 0.2725 - val_loss: 2.7659 - val_acc: 0.1595\n",
            "Epoch 246/250\n",
            "89/89 [==============================] - 29s 323ms/step - loss: 2.1627 - acc: 0.2590 - val_loss: 2.7657 - val_acc: 0.1595\n",
            "Epoch 247/250\n",
            "89/89 [==============================] - 26s 288ms/step - loss: 2.1591 - acc: 0.2640 - val_loss: 2.7693 - val_acc: 0.1595\n",
            "Epoch 248/250\n",
            "89/89 [==============================] - 26s 285ms/step - loss: 2.1514 - acc: 0.2803 - val_loss: 2.7561 - val_acc: 0.1638\n",
            "Epoch 249/250\n",
            "89/89 [==============================] - 25s 278ms/step - loss: 2.1246 - acc: 0.2704 - val_loss: 2.7340 - val_acc: 0.1659\n",
            "Epoch 250/250\n",
            "89/89 [==============================] - 25s 279ms/step - loss: 2.1018 - acc: 0.2881 - val_loss: 2.7512 - val_acc: 0.1659\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "acc = history.history['acc']\n",
        "val_acc = history.history['val_acc']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs_x = range(len(acc))\n",
        "\n",
        "plt.plot(epochs_x, acc, 'co', label='Training acc')\n",
        "plt.plot(epochs_x, val_acc, 'k', label='Validation acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.figure()\n",
        "\n",
        "plt.plot(epochs_x, loss, 'co', label='Training loss')\n",
        "plt.plot(epochs_x, val_loss, 'k', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "kwylTJpTP5XI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545
        },
        "outputId": "f9c19b78-e2fd-459a-ea7f-ceee66d35640"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Download the model"
      ],
      "metadata": {
        "id": "lD-vKaoHQAFd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "os.makedirs('/content/drive/My Drive/cut_panoramic/Model/Classification', exist_ok=True)\n",
        "model.save('/content/drive/My Drive/cut_panoramic/Model/Classification/Male/44_รอบที่4_Flimpano_Male125_250_New_Unfreez.h5')"
      ],
      "metadata": {
        "id": "74dL7-HLP_Sh"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from google.colab import files\n",
        "# files.download('/content/drive/My Drive/cut_panoramic/Model/33_รอบที่3_Flimpano_Male125_250.h5')"
      ],
      "metadata": {
        "id": "qcPW-brHQDpc"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "P4pe9URV1vBB"
      },
      "execution_count": 19,
      "outputs": []
    }
  ]
}