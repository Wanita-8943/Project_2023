{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Wanita-8943/Project_2023/blob/main/%E0%B8%A3%E0%B8%AD%E0%B8%9A%E0%B8%97%E0%B8%B5%E0%B9%884_Train_Female125_250_Unfreez.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "KKSs7cyoPHcD"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import shutil"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7LoeZxmVPMxp",
        "outputId": "95e7d652-4ca1-47fd-8b25-99107d143948"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import models\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import optimizers\n",
        "import os\n",
        "import glob\n",
        "import shutil\n",
        "import sys\n",
        "import numpy as np\n",
        "from skimage.io import imread\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import Image\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "1pX9g1HxPM2f"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 16\n",
        "width = 150\n",
        "height = 150\n",
        "epochs = 250\n",
        "NUM_TRAIN = 1425\n",
        "NUM_TEST = 475\n",
        "dropout_rate = 0.2\n",
        "input_shape = (height, width, 3)"
      ],
      "metadata": {
        "id": "eSFtvGyvPM6O"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#ดึงข้อมูลใน Github มาใช้\n",
        "import os\n",
        "%cd /content\n",
        "if not os.path.isdir(\"efficientnet_keras_transfer_learning\"):\n",
        " !git clone https://github.com/Wanita-8943/efficientnet_keras_transfer_learning\n",
        "%cd efficientnet_keras_transfer_learning/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lb4K4CsMPNAW",
        "outputId": "2fe12fca-08b8-4e2e-95af-cb69b136438b"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "Cloning into 'efficientnet_keras_transfer_learning'...\n",
            "remote: Enumerating objects: 834, done.\u001b[K\n",
            "remote: Counting objects: 100% (356/356), done.\u001b[K\n",
            "remote: Compressing objects: 100% (169/169), done.\u001b[K\n",
            "remote: Total 834 (delta 251), reused 248 (delta 187), pack-reused 478\u001b[K\n",
            "Receiving objects: 100% (834/834), 13.77 MiB | 28.42 MiB/s, done.\n",
            "Resolving deltas: 100% (491/491), done.\n",
            "/content/efficientnet_keras_transfer_learning\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Options: EfficientNetB0, EfficientNetB1, EfficientNetB2, EfficientNetB3\n",
        "# Higher the number, the more complex the model is.\n",
        "from efficientnet import EfficientNetB0 as Net\n",
        "from efficientnet import center_crop_and_resize, preprocess_input"
      ],
      "metadata": {
        "id": "eyBg0dLKPND3"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# loading pretrained conv base model\n",
        "# โหลดโมเดล มาโดยตัด output ของโมเดลออก เเต่ยังใช้ input อันเดิม\n",
        "# เเละโหลด weight ของโมเดล มาด้วยที่ชื่อว่า imagenet\n",
        "conv_base = Net(weights='imagenet', include_top=False, input_shape=input_shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gDL19Uuf1joi",
        "outputId": "713e8240-59ef-46cd-8e2e-acbd4dd27c94"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://github.com/qubvel/efficientnet/releases/download/v0.0.1/efficientnet-b0_imagenet_1000_notop.h5\n",
            "16717576/16717576 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "conv_base.summary() #ดู Summary"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o1n_e8lG1l4p",
        "outputId": "8cafd3f0-a24b-44a8-f854-78ae5dd4af66"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"efficientnet-b0\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 150, 150, 3  0           []                               \n",
            "                                )]                                                                \n",
            "                                                                                                  \n",
            " conv2d (Conv2D)                (None, 75, 75, 32)   864         ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " batch_normalization (BatchNorm  (None, 75, 75, 32)  128         ['conv2d[0][0]']                 \n",
            " alization)                                                                                       \n",
            "                                                                                                  \n",
            " swish (Swish)                  (None, 75, 75, 32)   0           ['batch_normalization[0][0]']    \n",
            "                                                                                                  \n",
            " depthwise_conv2d (DepthwiseCon  (None, 75, 75, 32)  288         ['swish[0][0]']                  \n",
            " v2D)                                                                                             \n",
            "                                                                                                  \n",
            " batch_normalization_1 (BatchNo  (None, 75, 75, 32)  128         ['depthwise_conv2d[0][0]']       \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " swish_1 (Swish)                (None, 75, 75, 32)   0           ['batch_normalization_1[0][0]']  \n",
            "                                                                                                  \n",
            " lambda (Lambda)                (None, 1, 1, 32)     0           ['swish_1[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d_1 (Conv2D)              (None, 1, 1, 8)      264         ['lambda[0][0]']                 \n",
            "                                                                                                  \n",
            " swish_2 (Swish)                (None, 1, 1, 8)      0           ['conv2d_1[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_2 (Conv2D)              (None, 1, 1, 32)     288         ['swish_2[0][0]']                \n",
            "                                                                                                  \n",
            " activation (Activation)        (None, 1, 1, 32)     0           ['conv2d_2[0][0]']               \n",
            "                                                                                                  \n",
            " multiply (Multiply)            (None, 75, 75, 32)   0           ['activation[0][0]',             \n",
            "                                                                  'swish_1[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d_3 (Conv2D)              (None, 75, 75, 16)   512         ['multiply[0][0]']               \n",
            "                                                                                                  \n",
            " batch_normalization_2 (BatchNo  (None, 75, 75, 16)  64          ['conv2d_3[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv2d_4 (Conv2D)              (None, 75, 75, 96)   1536        ['batch_normalization_2[0][0]']  \n",
            "                                                                                                  \n",
            " batch_normalization_3 (BatchNo  (None, 75, 75, 96)  384         ['conv2d_4[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " swish_3 (Swish)                (None, 75, 75, 96)   0           ['batch_normalization_3[0][0]']  \n",
            "                                                                                                  \n",
            " depthwise_conv2d_1 (DepthwiseC  (None, 38, 38, 96)  864         ['swish_3[0][0]']                \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_4 (BatchNo  (None, 38, 38, 96)  384         ['depthwise_conv2d_1[0][0]']     \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " swish_4 (Swish)                (None, 38, 38, 96)   0           ['batch_normalization_4[0][0]']  \n",
            "                                                                                                  \n",
            " lambda_1 (Lambda)              (None, 1, 1, 96)     0           ['swish_4[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d_5 (Conv2D)              (None, 1, 1, 4)      388         ['lambda_1[0][0]']               \n",
            "                                                                                                  \n",
            " swish_5 (Swish)                (None, 1, 1, 4)      0           ['conv2d_5[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_6 (Conv2D)              (None, 1, 1, 96)     480         ['swish_5[0][0]']                \n",
            "                                                                                                  \n",
            " activation_1 (Activation)      (None, 1, 1, 96)     0           ['conv2d_6[0][0]']               \n",
            "                                                                                                  \n",
            " multiply_1 (Multiply)          (None, 38, 38, 96)   0           ['activation_1[0][0]',           \n",
            "                                                                  'swish_4[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d_7 (Conv2D)              (None, 38, 38, 24)   2304        ['multiply_1[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_5 (BatchNo  (None, 38, 38, 24)  96          ['conv2d_7[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv2d_8 (Conv2D)              (None, 38, 38, 144)  3456        ['batch_normalization_5[0][0]']  \n",
            "                                                                                                  \n",
            " batch_normalization_6 (BatchNo  (None, 38, 38, 144)  576        ['conv2d_8[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " swish_6 (Swish)                (None, 38, 38, 144)  0           ['batch_normalization_6[0][0]']  \n",
            "                                                                                                  \n",
            " depthwise_conv2d_2 (DepthwiseC  (None, 38, 38, 144)  1296       ['swish_6[0][0]']                \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_7 (BatchNo  (None, 38, 38, 144)  576        ['depthwise_conv2d_2[0][0]']     \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " swish_7 (Swish)                (None, 38, 38, 144)  0           ['batch_normalization_7[0][0]']  \n",
            "                                                                                                  \n",
            " lambda_2 (Lambda)              (None, 1, 1, 144)    0           ['swish_7[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d_9 (Conv2D)              (None, 1, 1, 6)      870         ['lambda_2[0][0]']               \n",
            "                                                                                                  \n",
            " swish_8 (Swish)                (None, 1, 1, 6)      0           ['conv2d_9[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_10 (Conv2D)             (None, 1, 1, 144)    1008        ['swish_8[0][0]']                \n",
            "                                                                                                  \n",
            " activation_2 (Activation)      (None, 1, 1, 144)    0           ['conv2d_10[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_2 (Multiply)          (None, 38, 38, 144)  0           ['activation_2[0][0]',           \n",
            "                                                                  'swish_7[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d_11 (Conv2D)             (None, 38, 38, 24)   3456        ['multiply_2[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_8 (BatchNo  (None, 38, 38, 24)  96          ['conv2d_11[0][0]']              \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " drop_connect (DropConnect)     (None, 38, 38, 24)   0           ['batch_normalization_8[0][0]']  \n",
            "                                                                                                  \n",
            " add (Add)                      (None, 38, 38, 24)   0           ['drop_connect[0][0]',           \n",
            "                                                                  'batch_normalization_5[0][0]']  \n",
            "                                                                                                  \n",
            " conv2d_12 (Conv2D)             (None, 38, 38, 144)  3456        ['add[0][0]']                    \n",
            "                                                                                                  \n",
            " batch_normalization_9 (BatchNo  (None, 38, 38, 144)  576        ['conv2d_12[0][0]']              \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " swish_9 (Swish)                (None, 38, 38, 144)  0           ['batch_normalization_9[0][0]']  \n",
            "                                                                                                  \n",
            " depthwise_conv2d_3 (DepthwiseC  (None, 19, 19, 144)  3600       ['swish_9[0][0]']                \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_10 (BatchN  (None, 19, 19, 144)  576        ['depthwise_conv2d_3[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_10 (Swish)               (None, 19, 19, 144)  0           ['batch_normalization_10[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_3 (Lambda)              (None, 1, 1, 144)    0           ['swish_10[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_13 (Conv2D)             (None, 1, 1, 6)      870         ['lambda_3[0][0]']               \n",
            "                                                                                                  \n",
            " swish_11 (Swish)               (None, 1, 1, 6)      0           ['conv2d_13[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_14 (Conv2D)             (None, 1, 1, 144)    1008        ['swish_11[0][0]']               \n",
            "                                                                                                  \n",
            " activation_3 (Activation)      (None, 1, 1, 144)    0           ['conv2d_14[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_3 (Multiply)          (None, 19, 19, 144)  0           ['activation_3[0][0]',           \n",
            "                                                                  'swish_10[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_15 (Conv2D)             (None, 19, 19, 40)   5760        ['multiply_3[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_11 (BatchN  (None, 19, 19, 40)  160         ['conv2d_15[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_16 (Conv2D)             (None, 19, 19, 240)  9600        ['batch_normalization_11[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_12 (BatchN  (None, 19, 19, 240)  960        ['conv2d_16[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_12 (Swish)               (None, 19, 19, 240)  0           ['batch_normalization_12[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_4 (DepthwiseC  (None, 19, 19, 240)  6000       ['swish_12[0][0]']               \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_13 (BatchN  (None, 19, 19, 240)  960        ['depthwise_conv2d_4[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_13 (Swish)               (None, 19, 19, 240)  0           ['batch_normalization_13[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_4 (Lambda)              (None, 1, 1, 240)    0           ['swish_13[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_17 (Conv2D)             (None, 1, 1, 10)     2410        ['lambda_4[0][0]']               \n",
            "                                                                                                  \n",
            " swish_14 (Swish)               (None, 1, 1, 10)     0           ['conv2d_17[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_18 (Conv2D)             (None, 1, 1, 240)    2640        ['swish_14[0][0]']               \n",
            "                                                                                                  \n",
            " activation_4 (Activation)      (None, 1, 1, 240)    0           ['conv2d_18[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_4 (Multiply)          (None, 19, 19, 240)  0           ['activation_4[0][0]',           \n",
            "                                                                  'swish_13[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_19 (Conv2D)             (None, 19, 19, 40)   9600        ['multiply_4[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_14 (BatchN  (None, 19, 19, 40)  160         ['conv2d_19[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_1 (DropConnect)   (None, 19, 19, 40)   0           ['batch_normalization_14[0][0]'] \n",
            "                                                                                                  \n",
            " add_1 (Add)                    (None, 19, 19, 40)   0           ['drop_connect_1[0][0]',         \n",
            "                                                                  'batch_normalization_11[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_20 (Conv2D)             (None, 19, 19, 240)  9600        ['add_1[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_15 (BatchN  (None, 19, 19, 240)  960        ['conv2d_20[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_15 (Swish)               (None, 19, 19, 240)  0           ['batch_normalization_15[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_5 (DepthwiseC  (None, 10, 10, 240)  2160       ['swish_15[0][0]']               \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_16 (BatchN  (None, 10, 10, 240)  960        ['depthwise_conv2d_5[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_16 (Swish)               (None, 10, 10, 240)  0           ['batch_normalization_16[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_5 (Lambda)              (None, 1, 1, 240)    0           ['swish_16[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_21 (Conv2D)             (None, 1, 1, 10)     2410        ['lambda_5[0][0]']               \n",
            "                                                                                                  \n",
            " swish_17 (Swish)               (None, 1, 1, 10)     0           ['conv2d_21[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_22 (Conv2D)             (None, 1, 1, 240)    2640        ['swish_17[0][0]']               \n",
            "                                                                                                  \n",
            " activation_5 (Activation)      (None, 1, 1, 240)    0           ['conv2d_22[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_5 (Multiply)          (None, 10, 10, 240)  0           ['activation_5[0][0]',           \n",
            "                                                                  'swish_16[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_23 (Conv2D)             (None, 10, 10, 80)   19200       ['multiply_5[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_17 (BatchN  (None, 10, 10, 80)  320         ['conv2d_23[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_24 (Conv2D)             (None, 10, 10, 480)  38400       ['batch_normalization_17[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_18 (BatchN  (None, 10, 10, 480)  1920       ['conv2d_24[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_18 (Swish)               (None, 10, 10, 480)  0           ['batch_normalization_18[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_6 (DepthwiseC  (None, 10, 10, 480)  4320       ['swish_18[0][0]']               \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_19 (BatchN  (None, 10, 10, 480)  1920       ['depthwise_conv2d_6[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_19 (Swish)               (None, 10, 10, 480)  0           ['batch_normalization_19[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_6 (Lambda)              (None, 1, 1, 480)    0           ['swish_19[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_25 (Conv2D)             (None, 1, 1, 20)     9620        ['lambda_6[0][0]']               \n",
            "                                                                                                  \n",
            " swish_20 (Swish)               (None, 1, 1, 20)     0           ['conv2d_25[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_26 (Conv2D)             (None, 1, 1, 480)    10080       ['swish_20[0][0]']               \n",
            "                                                                                                  \n",
            " activation_6 (Activation)      (None, 1, 1, 480)    0           ['conv2d_26[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_6 (Multiply)          (None, 10, 10, 480)  0           ['activation_6[0][0]',           \n",
            "                                                                  'swish_19[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_27 (Conv2D)             (None, 10, 10, 80)   38400       ['multiply_6[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_20 (BatchN  (None, 10, 10, 80)  320         ['conv2d_27[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_2 (DropConnect)   (None, 10, 10, 80)   0           ['batch_normalization_20[0][0]'] \n",
            "                                                                                                  \n",
            " add_2 (Add)                    (None, 10, 10, 80)   0           ['drop_connect_2[0][0]',         \n",
            "                                                                  'batch_normalization_17[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_28 (Conv2D)             (None, 10, 10, 480)  38400       ['add_2[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_21 (BatchN  (None, 10, 10, 480)  1920       ['conv2d_28[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_21 (Swish)               (None, 10, 10, 480)  0           ['batch_normalization_21[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_7 (DepthwiseC  (None, 10, 10, 480)  4320       ['swish_21[0][0]']               \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_22 (BatchN  (None, 10, 10, 480)  1920       ['depthwise_conv2d_7[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_22 (Swish)               (None, 10, 10, 480)  0           ['batch_normalization_22[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_7 (Lambda)              (None, 1, 1, 480)    0           ['swish_22[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_29 (Conv2D)             (None, 1, 1, 20)     9620        ['lambda_7[0][0]']               \n",
            "                                                                                                  \n",
            " swish_23 (Swish)               (None, 1, 1, 20)     0           ['conv2d_29[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_30 (Conv2D)             (None, 1, 1, 480)    10080       ['swish_23[0][0]']               \n",
            "                                                                                                  \n",
            " activation_7 (Activation)      (None, 1, 1, 480)    0           ['conv2d_30[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_7 (Multiply)          (None, 10, 10, 480)  0           ['activation_7[0][0]',           \n",
            "                                                                  'swish_22[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_31 (Conv2D)             (None, 10, 10, 80)   38400       ['multiply_7[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_23 (BatchN  (None, 10, 10, 80)  320         ['conv2d_31[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_3 (DropConnect)   (None, 10, 10, 80)   0           ['batch_normalization_23[0][0]'] \n",
            "                                                                                                  \n",
            " add_3 (Add)                    (None, 10, 10, 80)   0           ['drop_connect_3[0][0]',         \n",
            "                                                                  'add_2[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_32 (Conv2D)             (None, 10, 10, 480)  38400       ['add_3[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_24 (BatchN  (None, 10, 10, 480)  1920       ['conv2d_32[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_24 (Swish)               (None, 10, 10, 480)  0           ['batch_normalization_24[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_8 (DepthwiseC  (None, 10, 10, 480)  12000      ['swish_24[0][0]']               \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_25 (BatchN  (None, 10, 10, 480)  1920       ['depthwise_conv2d_8[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_25 (Swish)               (None, 10, 10, 480)  0           ['batch_normalization_25[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_8 (Lambda)              (None, 1, 1, 480)    0           ['swish_25[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_33 (Conv2D)             (None, 1, 1, 20)     9620        ['lambda_8[0][0]']               \n",
            "                                                                                                  \n",
            " swish_26 (Swish)               (None, 1, 1, 20)     0           ['conv2d_33[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_34 (Conv2D)             (None, 1, 1, 480)    10080       ['swish_26[0][0]']               \n",
            "                                                                                                  \n",
            " activation_8 (Activation)      (None, 1, 1, 480)    0           ['conv2d_34[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_8 (Multiply)          (None, 10, 10, 480)  0           ['activation_8[0][0]',           \n",
            "                                                                  'swish_25[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_35 (Conv2D)             (None, 10, 10, 112)  53760       ['multiply_8[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_26 (BatchN  (None, 10, 10, 112)  448        ['conv2d_35[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_36 (Conv2D)             (None, 10, 10, 672)  75264       ['batch_normalization_26[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_27 (BatchN  (None, 10, 10, 672)  2688       ['conv2d_36[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_27 (Swish)               (None, 10, 10, 672)  0           ['batch_normalization_27[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_9 (DepthwiseC  (None, 10, 10, 672)  16800      ['swish_27[0][0]']               \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_28 (BatchN  (None, 10, 10, 672)  2688       ['depthwise_conv2d_9[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_28 (Swish)               (None, 10, 10, 672)  0           ['batch_normalization_28[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_9 (Lambda)              (None, 1, 1, 672)    0           ['swish_28[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_37 (Conv2D)             (None, 1, 1, 28)     18844       ['lambda_9[0][0]']               \n",
            "                                                                                                  \n",
            " swish_29 (Swish)               (None, 1, 1, 28)     0           ['conv2d_37[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_38 (Conv2D)             (None, 1, 1, 672)    19488       ['swish_29[0][0]']               \n",
            "                                                                                                  \n",
            " activation_9 (Activation)      (None, 1, 1, 672)    0           ['conv2d_38[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_9 (Multiply)          (None, 10, 10, 672)  0           ['activation_9[0][0]',           \n",
            "                                                                  'swish_28[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_39 (Conv2D)             (None, 10, 10, 112)  75264       ['multiply_9[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_29 (BatchN  (None, 10, 10, 112)  448        ['conv2d_39[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_4 (DropConnect)   (None, 10, 10, 112)  0           ['batch_normalization_29[0][0]'] \n",
            "                                                                                                  \n",
            " add_4 (Add)                    (None, 10, 10, 112)  0           ['drop_connect_4[0][0]',         \n",
            "                                                                  'batch_normalization_26[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_40 (Conv2D)             (None, 10, 10, 672)  75264       ['add_4[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_30 (BatchN  (None, 10, 10, 672)  2688       ['conv2d_40[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_30 (Swish)               (None, 10, 10, 672)  0           ['batch_normalization_30[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_10 (Depthwise  (None, 10, 10, 672)  16800      ['swish_30[0][0]']               \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_31 (BatchN  (None, 10, 10, 672)  2688       ['depthwise_conv2d_10[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_31 (Swish)               (None, 10, 10, 672)  0           ['batch_normalization_31[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_10 (Lambda)             (None, 1, 1, 672)    0           ['swish_31[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_41 (Conv2D)             (None, 1, 1, 28)     18844       ['lambda_10[0][0]']              \n",
            "                                                                                                  \n",
            " swish_32 (Swish)               (None, 1, 1, 28)     0           ['conv2d_41[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_42 (Conv2D)             (None, 1, 1, 672)    19488       ['swish_32[0][0]']               \n",
            "                                                                                                  \n",
            " activation_10 (Activation)     (None, 1, 1, 672)    0           ['conv2d_42[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_10 (Multiply)         (None, 10, 10, 672)  0           ['activation_10[0][0]',          \n",
            "                                                                  'swish_31[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_43 (Conv2D)             (None, 10, 10, 112)  75264       ['multiply_10[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_32 (BatchN  (None, 10, 10, 112)  448        ['conv2d_43[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_5 (DropConnect)   (None, 10, 10, 112)  0           ['batch_normalization_32[0][0]'] \n",
            "                                                                                                  \n",
            " add_5 (Add)                    (None, 10, 10, 112)  0           ['drop_connect_5[0][0]',         \n",
            "                                                                  'add_4[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_44 (Conv2D)             (None, 10, 10, 672)  75264       ['add_5[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_33 (BatchN  (None, 10, 10, 672)  2688       ['conv2d_44[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_33 (Swish)               (None, 10, 10, 672)  0           ['batch_normalization_33[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_11 (Depthwise  (None, 5, 5, 672)   16800       ['swish_33[0][0]']               \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_34 (BatchN  (None, 5, 5, 672)   2688        ['depthwise_conv2d_11[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_34 (Swish)               (None, 5, 5, 672)    0           ['batch_normalization_34[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_11 (Lambda)             (None, 1, 1, 672)    0           ['swish_34[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_45 (Conv2D)             (None, 1, 1, 28)     18844       ['lambda_11[0][0]']              \n",
            "                                                                                                  \n",
            " swish_35 (Swish)               (None, 1, 1, 28)     0           ['conv2d_45[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_46 (Conv2D)             (None, 1, 1, 672)    19488       ['swish_35[0][0]']               \n",
            "                                                                                                  \n",
            " activation_11 (Activation)     (None, 1, 1, 672)    0           ['conv2d_46[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_11 (Multiply)         (None, 5, 5, 672)    0           ['activation_11[0][0]',          \n",
            "                                                                  'swish_34[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_47 (Conv2D)             (None, 5, 5, 192)    129024      ['multiply_11[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_35 (BatchN  (None, 5, 5, 192)   768         ['conv2d_47[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_48 (Conv2D)             (None, 5, 5, 1152)   221184      ['batch_normalization_35[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_36 (BatchN  (None, 5, 5, 1152)  4608        ['conv2d_48[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_36 (Swish)               (None, 5, 5, 1152)   0           ['batch_normalization_36[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_12 (Depthwise  (None, 5, 5, 1152)  28800       ['swish_36[0][0]']               \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_37 (BatchN  (None, 5, 5, 1152)  4608        ['depthwise_conv2d_12[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_37 (Swish)               (None, 5, 5, 1152)   0           ['batch_normalization_37[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_12 (Lambda)             (None, 1, 1, 1152)   0           ['swish_37[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_49 (Conv2D)             (None, 1, 1, 48)     55344       ['lambda_12[0][0]']              \n",
            "                                                                                                  \n",
            " swish_38 (Swish)               (None, 1, 1, 48)     0           ['conv2d_49[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_50 (Conv2D)             (None, 1, 1, 1152)   56448       ['swish_38[0][0]']               \n",
            "                                                                                                  \n",
            " activation_12 (Activation)     (None, 1, 1, 1152)   0           ['conv2d_50[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_12 (Multiply)         (None, 5, 5, 1152)   0           ['activation_12[0][0]',          \n",
            "                                                                  'swish_37[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_51 (Conv2D)             (None, 5, 5, 192)    221184      ['multiply_12[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_38 (BatchN  (None, 5, 5, 192)   768         ['conv2d_51[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_6 (DropConnect)   (None, 5, 5, 192)    0           ['batch_normalization_38[0][0]'] \n",
            "                                                                                                  \n",
            " add_6 (Add)                    (None, 5, 5, 192)    0           ['drop_connect_6[0][0]',         \n",
            "                                                                  'batch_normalization_35[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_52 (Conv2D)             (None, 5, 5, 1152)   221184      ['add_6[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_39 (BatchN  (None, 5, 5, 1152)  4608        ['conv2d_52[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_39 (Swish)               (None, 5, 5, 1152)   0           ['batch_normalization_39[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_13 (Depthwise  (None, 5, 5, 1152)  28800       ['swish_39[0][0]']               \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_40 (BatchN  (None, 5, 5, 1152)  4608        ['depthwise_conv2d_13[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_40 (Swish)               (None, 5, 5, 1152)   0           ['batch_normalization_40[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_13 (Lambda)             (None, 1, 1, 1152)   0           ['swish_40[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_53 (Conv2D)             (None, 1, 1, 48)     55344       ['lambda_13[0][0]']              \n",
            "                                                                                                  \n",
            " swish_41 (Swish)               (None, 1, 1, 48)     0           ['conv2d_53[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_54 (Conv2D)             (None, 1, 1, 1152)   56448       ['swish_41[0][0]']               \n",
            "                                                                                                  \n",
            " activation_13 (Activation)     (None, 1, 1, 1152)   0           ['conv2d_54[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_13 (Multiply)         (None, 5, 5, 1152)   0           ['activation_13[0][0]',          \n",
            "                                                                  'swish_40[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_55 (Conv2D)             (None, 5, 5, 192)    221184      ['multiply_13[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_41 (BatchN  (None, 5, 5, 192)   768         ['conv2d_55[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_7 (DropConnect)   (None, 5, 5, 192)    0           ['batch_normalization_41[0][0]'] \n",
            "                                                                                                  \n",
            " add_7 (Add)                    (None, 5, 5, 192)    0           ['drop_connect_7[0][0]',         \n",
            "                                                                  'add_6[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_56 (Conv2D)             (None, 5, 5, 1152)   221184      ['add_7[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_42 (BatchN  (None, 5, 5, 1152)  4608        ['conv2d_56[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_42 (Swish)               (None, 5, 5, 1152)   0           ['batch_normalization_42[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_14 (Depthwise  (None, 5, 5, 1152)  28800       ['swish_42[0][0]']               \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_43 (BatchN  (None, 5, 5, 1152)  4608        ['depthwise_conv2d_14[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_43 (Swish)               (None, 5, 5, 1152)   0           ['batch_normalization_43[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_14 (Lambda)             (None, 1, 1, 1152)   0           ['swish_43[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_57 (Conv2D)             (None, 1, 1, 48)     55344       ['lambda_14[0][0]']              \n",
            "                                                                                                  \n",
            " swish_44 (Swish)               (None, 1, 1, 48)     0           ['conv2d_57[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_58 (Conv2D)             (None, 1, 1, 1152)   56448       ['swish_44[0][0]']               \n",
            "                                                                                                  \n",
            " activation_14 (Activation)     (None, 1, 1, 1152)   0           ['conv2d_58[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_14 (Multiply)         (None, 5, 5, 1152)   0           ['activation_14[0][0]',          \n",
            "                                                                  'swish_43[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_59 (Conv2D)             (None, 5, 5, 192)    221184      ['multiply_14[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_44 (BatchN  (None, 5, 5, 192)   768         ['conv2d_59[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_8 (DropConnect)   (None, 5, 5, 192)    0           ['batch_normalization_44[0][0]'] \n",
            "                                                                                                  \n",
            " add_8 (Add)                    (None, 5, 5, 192)    0           ['drop_connect_8[0][0]',         \n",
            "                                                                  'add_7[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_60 (Conv2D)             (None, 5, 5, 1152)   221184      ['add_8[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_45 (BatchN  (None, 5, 5, 1152)  4608        ['conv2d_60[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_45 (Swish)               (None, 5, 5, 1152)   0           ['batch_normalization_45[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_15 (Depthwise  (None, 5, 5, 1152)  10368       ['swish_45[0][0]']               \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_46 (BatchN  (None, 5, 5, 1152)  4608        ['depthwise_conv2d_15[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_46 (Swish)               (None, 5, 5, 1152)   0           ['batch_normalization_46[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_15 (Lambda)             (None, 1, 1, 1152)   0           ['swish_46[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_61 (Conv2D)             (None, 1, 1, 48)     55344       ['lambda_15[0][0]']              \n",
            "                                                                                                  \n",
            " swish_47 (Swish)               (None, 1, 1, 48)     0           ['conv2d_61[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_62 (Conv2D)             (None, 1, 1, 1152)   56448       ['swish_47[0][0]']               \n",
            "                                                                                                  \n",
            " activation_15 (Activation)     (None, 1, 1, 1152)   0           ['conv2d_62[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_15 (Multiply)         (None, 5, 5, 1152)   0           ['activation_15[0][0]',          \n",
            "                                                                  'swish_46[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_63 (Conv2D)             (None, 5, 5, 320)    368640      ['multiply_15[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_47 (BatchN  (None, 5, 5, 320)   1280        ['conv2d_63[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_64 (Conv2D)             (None, 5, 5, 1280)   409600      ['batch_normalization_47[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_48 (BatchN  (None, 5, 5, 1280)  5120        ['conv2d_64[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_48 (Swish)               (None, 5, 5, 1280)   0           ['batch_normalization_48[0][0]'] \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 4,049,564\n",
            "Trainable params: 4,007,548\n",
            "Non-trainable params: 42,016\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "base_dir = '/content/drive/MyDrive/TVT_Female125'\n",
        "os.makedirs(base_dir, exist_ok=True)\n",
        "\n",
        "# Directories for our training,\n",
        "# validation and test splits\n",
        "train_dir = os.path.join(base_dir, 'train')\n",
        "os.makedirs(train_dir, exist_ok=True)\n",
        "validation_dir = os.path.join(base_dir, 'validation')\n",
        "os.makedirs(validation_dir, exist_ok=True)\n",
        "test_dir = os.path.join(base_dir, 'test')\n",
        "os.makedirs(test_dir, exist_ok=True)"
      ],
      "metadata": {
        "id": "Jwpq_-KvPef8"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#load model"
      ],
      "metadata": {
        "id": "od-ZSNm5PoGy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.append('/content/drive/MyDrive/cut_panoramic/Model/Classification/33_รอบที่3_Flimpano_Female125_250.h5')\n",
        "\n",
        "from efficientnet.layers import Swish, DropConnect\n",
        "from efficientnet.model import ConvKernalInitializer\n",
        "from tensorflow.keras.utils import get_custom_objects\n",
        "\n",
        "get_custom_objects().update({\n",
        "    'ConvKernalInitializer': ConvKernalInitializer,\n",
        "    'Swish': Swish,\n",
        "    'DropConnect':DropConnect\n",
        "})"
      ],
      "metadata": {
        "id": "n5iPL5MNPkhE"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#load model \n",
        "from tensorflow.keras.models import load_model\n",
        "model = load_model('/content/drive/MyDrive/cut_panoramic/Model/Classification/33_รอบที่3_Flimpano_Female125_250.h5')\n",
        "height = width = model.input_shape[1]"
      ],
      "metadata": {
        "id": "plYz49xMPkly"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z6IOPBflFbvc",
        "outputId": "7d0905af-4d30-471c-cde0-f08dbd6f6dc1"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " efficientnet-b0 (Functional  (None, 5, 5, 1280)       4049564   \n",
            " )                                                               \n",
            "                                                                 \n",
            " gap (GlobalMaxPooling2D)    (None, 1280)              0         \n",
            "                                                                 \n",
            " dropout_out (Dropout)       (None, 1280)              0         \n",
            "                                                                 \n",
            " fc_out (Dense)              (None, 19)                24339     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4,073,903\n",
            "Trainable params: 24,339\n",
            "Non-trainable params: 4,049,564\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train ด้วย ImageDataGenerator ของ Keras ซึ่งจะเพิ่มข้อมูลเสริมระหว่างการฝึกเพื่อลดโอกาสเกิด overfitting\n",
        "#overfitting เกิดจากข้อมูลที่ซับซ้อนกันเกินไป\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "train_datagen = ImageDataGenerator(\n",
        "      rescale=1./255, #โมเดลส่วนใหญ่ต้องใช้ RGB ในช่วง 0–1\n",
        "      rotation_range=40,\n",
        "      width_shift_range=0.2,\n",
        "      height_shift_range=0.2,\n",
        "      shear_range=0.2,\n",
        "      zoom_range=0.2,\n",
        "      horizontal_flip=True,\n",
        "      fill_mode='nearest')\n",
        "\n",
        "# Note that the validation data should not be augmented!\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "        # This is the target directory #ไดเรกเป้าหมาย\n",
        "        train_dir,\n",
        "        # รูปภาพทั้งหมดจะถูกปรับขนาดตามความสูงและความกว้างของเป้าหมาย\n",
        "        target_size=(height, width),\n",
        "        batch_size=batch_size,\n",
        "        # Since we use categorical_crossentropy loss, we need categorical labels\n",
        "        #เนื่องจากเราใช้ categorical_crossentropy loss เราจึงต้องมีป้ายกำกับตามหมวดหมู่\n",
        "        class_mode='categorical')\n",
        "\n",
        "validation_generator = test_datagen.flow_from_directory( #การดึงภาพจาก Directory มาเข้าโมเดล \n",
        "        validation_dir,\n",
        "        target_size=(height, width),\n",
        "        batch_size=batch_size,\n",
        "        class_mode='categorical')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KBMZbdr2Pgw4",
        "outputId": "8ac45cef-3040-4054-8732-a7eb5cd0de5e"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1425 images belonging to 19 classes.\n",
            "Found 475 images belonging to 19 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# multiply_16\n",
        "# set 'multiply_16' and following layers trainable\n",
        "conv_base.trainable = True\n",
        "\n",
        "set_trainable = False\n",
        "for layer in conv_base.layers:\n",
        "    if layer.name == 'multiply_16':\n",
        "        set_trainable = True\n",
        "    if set_trainable:\n",
        "        layer.trainable = True\n",
        "    else:\n",
        "        layer.trainable = False"
      ],
      "metadata": {
        "id": "wSz_e8hR0Fiv"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit_generator(\n",
        "      train_generator,\n",
        "      steps_per_epoch= NUM_TRAIN //batch_size,\n",
        "      epochs=epochs,\n",
        "      validation_data=validation_generator,\n",
        "      validation_steps= NUM_TEST //batch_size,\n",
        "      verbose=1,\n",
        "      use_multiprocessing=True,\n",
        "      workers=4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C9Cf1dwyP1PD",
        "outputId": "3f910c6f-eb21-4d46-d235-492d3ff44674"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-21-caa7b37242a8>:1: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  history = model.fit_generator(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/250\n",
            "89/89 [==============================] - 127s 1s/step - loss: 2.3370 - acc: 0.2335 - val_loss: 2.7461 - val_acc: 0.1810\n",
            "Epoch 2/250\n",
            "89/89 [==============================] - 27s 299ms/step - loss: 2.2760 - acc: 0.2449 - val_loss: 2.7421 - val_acc: 0.1853\n",
            "Epoch 3/250\n",
            "89/89 [==============================] - 26s 290ms/step - loss: 2.2937 - acc: 0.2505 - val_loss: 2.7346 - val_acc: 0.1746\n",
            "Epoch 4/250\n",
            "89/89 [==============================] - 26s 286ms/step - loss: 2.2565 - acc: 0.2598 - val_loss: 2.7153 - val_acc: 0.1789\n",
            "Epoch 5/250\n",
            "89/89 [==============================] - 27s 293ms/step - loss: 2.3144 - acc: 0.2363 - val_loss: 2.7168 - val_acc: 0.1810\n",
            "Epoch 6/250\n",
            "89/89 [==============================] - 26s 286ms/step - loss: 2.2593 - acc: 0.2370 - val_loss: 2.7168 - val_acc: 0.1810\n",
            "Epoch 7/250\n",
            "89/89 [==============================] - 25s 271ms/step - loss: 2.2722 - acc: 0.2434 - val_loss: 2.6829 - val_acc: 0.1810\n",
            "Epoch 8/250\n",
            "89/89 [==============================] - 25s 271ms/step - loss: 2.2725 - acc: 0.2356 - val_loss: 2.6960 - val_acc: 0.1789\n",
            "Epoch 9/250\n",
            "89/89 [==============================] - 24s 267ms/step - loss: 2.2343 - acc: 0.2498 - val_loss: 2.7248 - val_acc: 0.1746\n",
            "Epoch 10/250\n",
            "89/89 [==============================] - 26s 285ms/step - loss: 2.2290 - acc: 0.2640 - val_loss: 2.7265 - val_acc: 0.1767\n",
            "Epoch 11/250\n",
            "89/89 [==============================] - 26s 282ms/step - loss: 2.2570 - acc: 0.2505 - val_loss: 2.7309 - val_acc: 0.1810\n",
            "Epoch 12/250\n",
            "89/89 [==============================] - 21s 230ms/step - loss: 2.2900 - acc: 0.2456 - val_loss: 2.7298 - val_acc: 0.1767\n",
            "Epoch 13/250\n",
            "89/89 [==============================] - 31s 334ms/step - loss: 2.2726 - acc: 0.2463 - val_loss: 2.7236 - val_acc: 0.1789\n",
            "Epoch 14/250\n",
            "89/89 [==============================] - 28s 304ms/step - loss: 2.2715 - acc: 0.2498 - val_loss: 2.7490 - val_acc: 0.1767\n",
            "Epoch 15/250\n",
            "89/89 [==============================] - 27s 304ms/step - loss: 2.2300 - acc: 0.2661 - val_loss: 2.7508 - val_acc: 0.1832\n",
            "Epoch 16/250\n",
            "89/89 [==============================] - 27s 294ms/step - loss: 2.2266 - acc: 0.2555 - val_loss: 2.7192 - val_acc: 0.1789\n",
            "Epoch 17/250\n",
            "89/89 [==============================] - 28s 305ms/step - loss: 2.2780 - acc: 0.2484 - val_loss: 2.7109 - val_acc: 0.1789\n",
            "Epoch 18/250\n",
            "89/89 [==============================] - 28s 304ms/step - loss: 2.2354 - acc: 0.2427 - val_loss: 2.7257 - val_acc: 0.1681\n",
            "Epoch 19/250\n",
            "89/89 [==============================] - 26s 287ms/step - loss: 2.2408 - acc: 0.2619 - val_loss: 2.7369 - val_acc: 0.1810\n",
            "Epoch 20/250\n",
            "89/89 [==============================] - 28s 305ms/step - loss: 2.2947 - acc: 0.2420 - val_loss: 2.7233 - val_acc: 0.1724\n",
            "Epoch 21/250\n",
            "89/89 [==============================] - 21s 231ms/step - loss: 2.2519 - acc: 0.2470 - val_loss: 2.7543 - val_acc: 0.1724\n",
            "Epoch 22/250\n",
            "89/89 [==============================] - 27s 293ms/step - loss: 2.2477 - acc: 0.2555 - val_loss: 2.7252 - val_acc: 0.1681\n",
            "Epoch 23/250\n",
            "89/89 [==============================] - 27s 302ms/step - loss: 2.2580 - acc: 0.2385 - val_loss: 2.7538 - val_acc: 0.1746\n",
            "Epoch 24/250\n",
            "89/89 [==============================] - 27s 293ms/step - loss: 2.2592 - acc: 0.2512 - val_loss: 2.7449 - val_acc: 0.1789\n",
            "Epoch 25/250\n",
            "89/89 [==============================] - 27s 302ms/step - loss: 2.2545 - acc: 0.2498 - val_loss: 2.7422 - val_acc: 0.1767\n",
            "Epoch 26/250\n",
            "89/89 [==============================] - 27s 295ms/step - loss: 2.2217 - acc: 0.2527 - val_loss: 2.7269 - val_acc: 0.1832\n",
            "Epoch 27/250\n",
            "89/89 [==============================] - 29s 325ms/step - loss: 2.2536 - acc: 0.2413 - val_loss: 2.7351 - val_acc: 0.1789\n",
            "Epoch 28/250\n",
            "89/89 [==============================] - 27s 295ms/step - loss: 2.2564 - acc: 0.2704 - val_loss: 2.7367 - val_acc: 0.1832\n",
            "Epoch 29/250\n",
            "89/89 [==============================] - 28s 302ms/step - loss: 2.2016 - acc: 0.2647 - val_loss: 2.7513 - val_acc: 0.1810\n",
            "Epoch 30/250\n",
            "89/89 [==============================] - 27s 292ms/step - loss: 2.2762 - acc: 0.2590 - val_loss: 2.7437 - val_acc: 0.1832\n",
            "Epoch 31/250\n",
            "89/89 [==============================] - 27s 300ms/step - loss: 2.2371 - acc: 0.2541 - val_loss: 2.7100 - val_acc: 0.1789\n",
            "Epoch 32/250\n",
            "89/89 [==============================] - 27s 297ms/step - loss: 2.2279 - acc: 0.2548 - val_loss: 2.7349 - val_acc: 0.1810\n",
            "Epoch 33/250\n",
            "89/89 [==============================] - 28s 305ms/step - loss: 2.2525 - acc: 0.2534 - val_loss: 2.7513 - val_acc: 0.1746\n",
            "Epoch 34/250\n",
            "89/89 [==============================] - 29s 316ms/step - loss: 2.2349 - acc: 0.2647 - val_loss: 2.7545 - val_acc: 0.1767\n",
            "Epoch 35/250\n",
            "89/89 [==============================] - 26s 288ms/step - loss: 2.2179 - acc: 0.2732 - val_loss: 2.7162 - val_acc: 0.1875\n",
            "Epoch 36/250\n",
            "89/89 [==============================] - 26s 283ms/step - loss: 2.2642 - acc: 0.2314 - val_loss: 2.7388 - val_acc: 0.1789\n",
            "Epoch 37/250\n",
            "89/89 [==============================] - 25s 270ms/step - loss: 2.2627 - acc: 0.2548 - val_loss: 2.7218 - val_acc: 0.1789\n",
            "Epoch 38/250\n",
            "89/89 [==============================] - 24s 269ms/step - loss: 2.2660 - acc: 0.2449 - val_loss: 2.7350 - val_acc: 0.1832\n",
            "Epoch 39/250\n",
            "89/89 [==============================] - 26s 285ms/step - loss: 2.2667 - acc: 0.2576 - val_loss: 2.7358 - val_acc: 0.1875\n",
            "Epoch 40/250\n",
            "89/89 [==============================] - 20s 216ms/step - loss: 2.2489 - acc: 0.2576 - val_loss: 2.7072 - val_acc: 0.1832\n",
            "Epoch 41/250\n",
            "89/89 [==============================] - 26s 276ms/step - loss: 2.2062 - acc: 0.2626 - val_loss: 2.7306 - val_acc: 0.1767\n",
            "Epoch 42/250\n",
            "89/89 [==============================] - 20s 215ms/step - loss: 2.2359 - acc: 0.2527 - val_loss: 2.7228 - val_acc: 0.1659\n",
            "Epoch 43/250\n",
            "89/89 [==============================] - 26s 282ms/step - loss: 2.2659 - acc: 0.2477 - val_loss: 2.7326 - val_acc: 0.1681\n",
            "Epoch 44/250\n",
            "89/89 [==============================] - 24s 267ms/step - loss: 2.2644 - acc: 0.2456 - val_loss: 2.7430 - val_acc: 0.1681\n",
            "Epoch 45/250\n",
            "89/89 [==============================] - 20s 215ms/step - loss: 2.2159 - acc: 0.2633 - val_loss: 2.7136 - val_acc: 0.1789\n",
            "Epoch 46/250\n",
            "89/89 [==============================] - 26s 290ms/step - loss: 2.2481 - acc: 0.2676 - val_loss: 2.7206 - val_acc: 0.1767\n",
            "Epoch 47/250\n",
            "89/89 [==============================] - 26s 285ms/step - loss: 2.2395 - acc: 0.2704 - val_loss: 2.7460 - val_acc: 0.1659\n",
            "Epoch 48/250\n",
            "89/89 [==============================] - 26s 288ms/step - loss: 2.2643 - acc: 0.2491 - val_loss: 2.7094 - val_acc: 0.1724\n",
            "Epoch 49/250\n",
            "89/89 [==============================] - 24s 267ms/step - loss: 2.2139 - acc: 0.2654 - val_loss: 2.7311 - val_acc: 0.1724\n",
            "Epoch 50/250\n",
            "89/89 [==============================] - 27s 292ms/step - loss: 2.2408 - acc: 0.2583 - val_loss: 2.7348 - val_acc: 0.1681\n",
            "Epoch 51/250\n",
            "89/89 [==============================] - 25s 270ms/step - loss: 2.2650 - acc: 0.2427 - val_loss: 2.7106 - val_acc: 0.1832\n",
            "Epoch 52/250\n",
            "89/89 [==============================] - 25s 271ms/step - loss: 2.2569 - acc: 0.2562 - val_loss: 2.7107 - val_acc: 0.1767\n",
            "Epoch 53/250\n",
            "89/89 [==============================] - 25s 270ms/step - loss: 2.2552 - acc: 0.2406 - val_loss: 2.7419 - val_acc: 0.1724\n",
            "Epoch 54/250\n",
            "89/89 [==============================] - 25s 271ms/step - loss: 2.2273 - acc: 0.2654 - val_loss: 2.7517 - val_acc: 0.1832\n",
            "Epoch 55/250\n",
            "89/89 [==============================] - 20s 215ms/step - loss: 2.2403 - acc: 0.2598 - val_loss: 2.7252 - val_acc: 0.1767\n",
            "Epoch 56/250\n",
            "89/89 [==============================] - 26s 287ms/step - loss: 2.2584 - acc: 0.2576 - val_loss: 2.7321 - val_acc: 0.1918\n",
            "Epoch 57/250\n",
            "89/89 [==============================] - 24s 268ms/step - loss: 2.2482 - acc: 0.2640 - val_loss: 2.7558 - val_acc: 0.1746\n",
            "Epoch 58/250\n",
            "89/89 [==============================] - 25s 273ms/step - loss: 2.2519 - acc: 0.2451 - val_loss: 2.7403 - val_acc: 0.1681\n",
            "Epoch 59/250\n",
            "89/89 [==============================] - 25s 270ms/step - loss: 2.2279 - acc: 0.2676 - val_loss: 2.7374 - val_acc: 0.1789\n",
            "Epoch 60/250\n",
            "89/89 [==============================] - 26s 291ms/step - loss: 2.2201 - acc: 0.2661 - val_loss: 2.7391 - val_acc: 0.1746\n",
            "Epoch 61/250\n",
            "89/89 [==============================] - 27s 293ms/step - loss: 2.2188 - acc: 0.2590 - val_loss: 2.7342 - val_acc: 0.1724\n",
            "Epoch 62/250\n",
            "89/89 [==============================] - 25s 270ms/step - loss: 2.2202 - acc: 0.2818 - val_loss: 2.7322 - val_acc: 0.1746\n",
            "Epoch 63/250\n",
            "89/89 [==============================] - 22s 237ms/step - loss: 2.2720 - acc: 0.2576 - val_loss: 2.7401 - val_acc: 0.1767\n",
            "Epoch 64/250\n",
            "89/89 [==============================] - 26s 288ms/step - loss: 2.2110 - acc: 0.2725 - val_loss: 2.7348 - val_acc: 0.1724\n",
            "Epoch 65/250\n",
            "89/89 [==============================] - 26s 286ms/step - loss: 2.2597 - acc: 0.2576 - val_loss: 2.7485 - val_acc: 0.1810\n",
            "Epoch 66/250\n",
            "89/89 [==============================] - 26s 289ms/step - loss: 2.2208 - acc: 0.2527 - val_loss: 2.7176 - val_acc: 0.1724\n",
            "Epoch 67/250\n",
            "89/89 [==============================] - 26s 287ms/step - loss: 2.2723 - acc: 0.2392 - val_loss: 2.7294 - val_acc: 0.1659\n",
            "Epoch 68/250\n",
            "89/89 [==============================] - 25s 271ms/step - loss: 2.2463 - acc: 0.2562 - val_loss: 2.7486 - val_acc: 0.1703\n",
            "Epoch 69/250\n",
            "89/89 [==============================] - 26s 289ms/step - loss: 2.2574 - acc: 0.2520 - val_loss: 2.7525 - val_acc: 0.1746\n",
            "Epoch 70/250\n",
            "89/89 [==============================] - 26s 291ms/step - loss: 2.2915 - acc: 0.2335 - val_loss: 2.7474 - val_acc: 0.1746\n",
            "Epoch 71/250\n",
            "89/89 [==============================] - 27s 295ms/step - loss: 2.2816 - acc: 0.2449 - val_loss: 2.7683 - val_acc: 0.1724\n",
            "Epoch 72/250\n",
            "89/89 [==============================] - 25s 270ms/step - loss: 2.2488 - acc: 0.2477 - val_loss: 2.7887 - val_acc: 0.1616\n",
            "Epoch 73/250\n",
            "89/89 [==============================] - 25s 271ms/step - loss: 2.2363 - acc: 0.2711 - val_loss: 2.7366 - val_acc: 0.1659\n",
            "Epoch 74/250\n",
            "89/89 [==============================] - 25s 280ms/step - loss: 2.1974 - acc: 0.2555 - val_loss: 2.7577 - val_acc: 0.1681\n",
            "Epoch 75/250\n",
            "89/89 [==============================] - 25s 270ms/step - loss: 2.2101 - acc: 0.2498 - val_loss: 2.7313 - val_acc: 0.1789\n",
            "Epoch 76/250\n",
            "89/89 [==============================] - 26s 281ms/step - loss: 2.2251 - acc: 0.2619 - val_loss: 2.7254 - val_acc: 0.1789\n",
            "Epoch 77/250\n",
            "89/89 [==============================] - 25s 272ms/step - loss: 2.2363 - acc: 0.2541 - val_loss: 2.7474 - val_acc: 0.1853\n",
            "Epoch 78/250\n",
            "89/89 [==============================] - 22s 237ms/step - loss: 2.2575 - acc: 0.2491 - val_loss: 2.7521 - val_acc: 0.1724\n",
            "Epoch 79/250\n",
            "89/89 [==============================] - 25s 270ms/step - loss: 2.2340 - acc: 0.2562 - val_loss: 2.7642 - val_acc: 0.1703\n",
            "Epoch 80/250\n",
            "89/89 [==============================] - 25s 272ms/step - loss: 2.2927 - acc: 0.2569 - val_loss: 2.7601 - val_acc: 0.1616\n",
            "Epoch 81/250\n",
            "89/89 [==============================] - 20s 216ms/step - loss: 2.2146 - acc: 0.2647 - val_loss: 2.7254 - val_acc: 0.1767\n",
            "Epoch 82/250\n",
            "89/89 [==============================] - 22s 239ms/step - loss: 2.2216 - acc: 0.2661 - val_loss: 2.7279 - val_acc: 0.1703\n",
            "Epoch 83/250\n",
            "89/89 [==============================] - 26s 289ms/step - loss: 2.2091 - acc: 0.2541 - val_loss: 2.7262 - val_acc: 0.1703\n",
            "Epoch 84/250\n",
            "89/89 [==============================] - 27s 296ms/step - loss: 2.2701 - acc: 0.2527 - val_loss: 2.7348 - val_acc: 0.1724\n",
            "Epoch 85/250\n",
            "89/89 [==============================] - 27s 293ms/step - loss: 2.2222 - acc: 0.2676 - val_loss: 2.7503 - val_acc: 0.1767\n",
            "Epoch 86/250\n",
            "89/89 [==============================] - 20s 222ms/step - loss: 2.2182 - acc: 0.2661 - val_loss: 2.7408 - val_acc: 0.1724\n",
            "Epoch 87/250\n",
            "89/89 [==============================] - 26s 270ms/step - loss: 2.2549 - acc: 0.2548 - val_loss: 2.7256 - val_acc: 0.1767\n",
            "Epoch 88/250\n",
            "89/89 [==============================] - 25s 270ms/step - loss: 2.2505 - acc: 0.2605 - val_loss: 2.7646 - val_acc: 0.1616\n",
            "Epoch 89/250\n",
            "89/89 [==============================] - 26s 277ms/step - loss: 2.2387 - acc: 0.2619 - val_loss: 2.7238 - val_acc: 0.1767\n",
            "Epoch 90/250\n",
            "89/89 [==============================] - 25s 271ms/step - loss: 2.2762 - acc: 0.2555 - val_loss: 2.7222 - val_acc: 0.1746\n",
            "Epoch 91/250\n",
            "89/89 [==============================] - 20s 217ms/step - loss: 2.1881 - acc: 0.2718 - val_loss: 2.7160 - val_acc: 0.1746\n",
            "Epoch 92/250\n",
            "89/89 [==============================] - 28s 310ms/step - loss: 2.2644 - acc: 0.2420 - val_loss: 2.7302 - val_acc: 0.1681\n",
            "Epoch 93/250\n",
            "89/89 [==============================] - 27s 293ms/step - loss: 2.2288 - acc: 0.2444 - val_loss: 2.7534 - val_acc: 0.1681\n",
            "Epoch 94/250\n",
            "89/89 [==============================] - 26s 291ms/step - loss: 2.2339 - acc: 0.2768 - val_loss: 2.7544 - val_acc: 0.1810\n",
            "Epoch 95/250\n",
            "89/89 [==============================] - 27s 292ms/step - loss: 2.2674 - acc: 0.2413 - val_loss: 2.7455 - val_acc: 0.1703\n",
            "Epoch 96/250\n",
            "89/89 [==============================] - 25s 275ms/step - loss: 2.2344 - acc: 0.2576 - val_loss: 2.7389 - val_acc: 0.1746\n",
            "Epoch 97/250\n",
            "89/89 [==============================] - 25s 272ms/step - loss: 2.2533 - acc: 0.2498 - val_loss: 2.7268 - val_acc: 0.1789\n",
            "Epoch 98/250\n",
            "89/89 [==============================] - 25s 271ms/step - loss: 2.2259 - acc: 0.2605 - val_loss: 2.7127 - val_acc: 0.1810\n",
            "Epoch 99/250\n",
            "89/89 [==============================] - 26s 284ms/step - loss: 2.2087 - acc: 0.2704 - val_loss: 2.7119 - val_acc: 0.1832\n",
            "Epoch 100/250\n",
            "89/89 [==============================] - 24s 265ms/step - loss: 2.2530 - acc: 0.2449 - val_loss: 2.7380 - val_acc: 0.1832\n",
            "Epoch 101/250\n",
            "89/89 [==============================] - 20s 212ms/step - loss: 2.2503 - acc: 0.2534 - val_loss: 2.7060 - val_acc: 0.1832\n",
            "Epoch 102/250\n",
            "89/89 [==============================] - 25s 272ms/step - loss: 2.2277 - acc: 0.2626 - val_loss: 2.7173 - val_acc: 0.1810\n",
            "Epoch 103/250\n",
            "89/89 [==============================] - 24s 268ms/step - loss: 2.2335 - acc: 0.2512 - val_loss: 2.7594 - val_acc: 0.1724\n",
            "Epoch 104/250\n",
            "89/89 [==============================] - 26s 275ms/step - loss: 2.2420 - acc: 0.2548 - val_loss: 2.7308 - val_acc: 0.1703\n",
            "Epoch 105/250\n",
            "89/89 [==============================] - 25s 271ms/step - loss: 2.2304 - acc: 0.2661 - val_loss: 2.7182 - val_acc: 0.1767\n",
            "Epoch 106/250\n",
            "89/89 [==============================] - 26s 277ms/step - loss: 2.2148 - acc: 0.2661 - val_loss: 2.7248 - val_acc: 0.1746\n",
            "Epoch 107/250\n",
            "89/89 [==============================] - 24s 266ms/step - loss: 2.2093 - acc: 0.2740 - val_loss: 2.7429 - val_acc: 0.1703\n",
            "Epoch 108/250\n",
            "89/89 [==============================] - 24s 269ms/step - loss: 2.2057 - acc: 0.2683 - val_loss: 2.7341 - val_acc: 0.1681\n",
            "Epoch 109/250\n",
            "89/89 [==============================] - 25s 271ms/step - loss: 2.2665 - acc: 0.2498 - val_loss: 2.7589 - val_acc: 0.1703\n",
            "Epoch 110/250\n",
            "89/89 [==============================] - 25s 272ms/step - loss: 2.2541 - acc: 0.2512 - val_loss: 2.7264 - val_acc: 0.1703\n",
            "Epoch 111/250\n",
            "89/89 [==============================] - 25s 269ms/step - loss: 2.1974 - acc: 0.2598 - val_loss: 2.7119 - val_acc: 0.1746\n",
            "Epoch 112/250\n",
            "89/89 [==============================] - 25s 270ms/step - loss: 2.2139 - acc: 0.2697 - val_loss: 2.7247 - val_acc: 0.1767\n",
            "Epoch 113/250\n",
            "89/89 [==============================] - 22s 232ms/step - loss: 2.2194 - acc: 0.2704 - val_loss: 2.7159 - val_acc: 0.1853\n",
            "Epoch 114/250\n",
            "89/89 [==============================] - 28s 302ms/step - loss: 2.2119 - acc: 0.2590 - val_loss: 2.7353 - val_acc: 0.1875\n",
            "Epoch 115/250\n",
            "89/89 [==============================] - 26s 288ms/step - loss: 2.2418 - acc: 0.2541 - val_loss: 2.7138 - val_acc: 0.1810\n",
            "Epoch 116/250\n",
            "89/89 [==============================] - 26s 290ms/step - loss: 2.2244 - acc: 0.2619 - val_loss: 2.7498 - val_acc: 0.1810\n",
            "Epoch 117/250\n",
            "89/89 [==============================] - 27s 295ms/step - loss: 2.2575 - acc: 0.2626 - val_loss: 2.7053 - val_acc: 0.1918\n",
            "Epoch 118/250\n",
            "89/89 [==============================] - 26s 285ms/step - loss: 2.2043 - acc: 0.2718 - val_loss: 2.7685 - val_acc: 0.1789\n",
            "Epoch 119/250\n",
            "89/89 [==============================] - 27s 297ms/step - loss: 2.2500 - acc: 0.2647 - val_loss: 2.7330 - val_acc: 0.1724\n",
            "Epoch 120/250\n",
            "89/89 [==============================] - 25s 277ms/step - loss: 2.2293 - acc: 0.2612 - val_loss: 2.7503 - val_acc: 0.1681\n",
            "Epoch 121/250\n",
            "89/89 [==============================] - 27s 295ms/step - loss: 2.1948 - acc: 0.2754 - val_loss: 2.7565 - val_acc: 0.1810\n",
            "Epoch 122/250\n",
            "89/89 [==============================] - 25s 272ms/step - loss: 2.2312 - acc: 0.2605 - val_loss: 2.7300 - val_acc: 0.1789\n",
            "Epoch 123/250\n",
            "89/89 [==============================] - 25s 271ms/step - loss: 2.2276 - acc: 0.2598 - val_loss: 2.7293 - val_acc: 0.1659\n",
            "Epoch 124/250\n",
            "89/89 [==============================] - 27s 294ms/step - loss: 2.2363 - acc: 0.2548 - val_loss: 2.7378 - val_acc: 0.1853\n",
            "Epoch 125/250\n",
            "89/89 [==============================] - 26s 286ms/step - loss: 2.1998 - acc: 0.2690 - val_loss: 2.7137 - val_acc: 0.1810\n",
            "Epoch 126/250\n",
            "89/89 [==============================] - 25s 272ms/step - loss: 2.2259 - acc: 0.2541 - val_loss: 2.7543 - val_acc: 0.1746\n",
            "Epoch 127/250\n",
            "89/89 [==============================] - 29s 321ms/step - loss: 2.2335 - acc: 0.2583 - val_loss: 2.7449 - val_acc: 0.1789\n",
            "Epoch 128/250\n",
            "89/89 [==============================] - 26s 290ms/step - loss: 2.1840 - acc: 0.2633 - val_loss: 2.7432 - val_acc: 0.1789\n",
            "Epoch 129/250\n",
            "89/89 [==============================] - 28s 303ms/step - loss: 2.2261 - acc: 0.2562 - val_loss: 2.7706 - val_acc: 0.1789\n",
            "Epoch 130/250\n",
            "89/89 [==============================] - 26s 291ms/step - loss: 2.2739 - acc: 0.2534 - val_loss: 2.7512 - val_acc: 0.1746\n",
            "Epoch 131/250\n",
            "89/89 [==============================] - 26s 281ms/step - loss: 2.1756 - acc: 0.2796 - val_loss: 2.7433 - val_acc: 0.1810\n",
            "Epoch 132/250\n",
            "89/89 [==============================] - 27s 297ms/step - loss: 2.2424 - acc: 0.2569 - val_loss: 2.7499 - val_acc: 0.1767\n",
            "Epoch 133/250\n",
            "89/89 [==============================] - 27s 292ms/step - loss: 2.2306 - acc: 0.2761 - val_loss: 2.7574 - val_acc: 0.1746\n",
            "Epoch 134/250\n",
            "89/89 [==============================] - 26s 283ms/step - loss: 2.2096 - acc: 0.2704 - val_loss: 2.7456 - val_acc: 0.1767\n",
            "Epoch 135/250\n",
            "89/89 [==============================] - 27s 299ms/step - loss: 2.2165 - acc: 0.2704 - val_loss: 2.7410 - val_acc: 0.1875\n",
            "Epoch 136/250\n",
            "89/89 [==============================] - 26s 289ms/step - loss: 2.2344 - acc: 0.2640 - val_loss: 2.7400 - val_acc: 0.1832\n",
            "Epoch 137/250\n",
            "89/89 [==============================] - 23s 249ms/step - loss: 2.1639 - acc: 0.2711 - val_loss: 2.7425 - val_acc: 0.1789\n",
            "Epoch 138/250\n",
            "89/89 [==============================] - 25s 277ms/step - loss: 2.2271 - acc: 0.2782 - val_loss: 2.7466 - val_acc: 0.1767\n",
            "Epoch 139/250\n",
            "89/89 [==============================] - 26s 277ms/step - loss: 2.1607 - acc: 0.2598 - val_loss: 2.7136 - val_acc: 0.1746\n",
            "Epoch 140/250\n",
            "89/89 [==============================] - 27s 292ms/step - loss: 2.2124 - acc: 0.2633 - val_loss: 2.7499 - val_acc: 0.1767\n",
            "Epoch 141/250\n",
            "89/89 [==============================] - 25s 279ms/step - loss: 2.2169 - acc: 0.2732 - val_loss: 2.7380 - val_acc: 0.1832\n",
            "Epoch 142/250\n",
            "89/89 [==============================] - 25s 278ms/step - loss: 2.2177 - acc: 0.2576 - val_loss: 2.7342 - val_acc: 0.1767\n",
            "Epoch 143/250\n",
            "89/89 [==============================] - 26s 287ms/step - loss: 2.2690 - acc: 0.2534 - val_loss: 2.7249 - val_acc: 0.1897\n",
            "Epoch 144/250\n",
            "89/89 [==============================] - 27s 293ms/step - loss: 2.2251 - acc: 0.2527 - val_loss: 2.7349 - val_acc: 0.1832\n",
            "Epoch 145/250\n",
            "89/89 [==============================] - 27s 296ms/step - loss: 2.2407 - acc: 0.2423 - val_loss: 2.7254 - val_acc: 0.1961\n",
            "Epoch 146/250\n",
            "89/89 [==============================] - 23s 249ms/step - loss: 2.2348 - acc: 0.2576 - val_loss: 2.7335 - val_acc: 0.1746\n",
            "Epoch 147/250\n",
            "89/89 [==============================] - 27s 284ms/step - loss: 2.2060 - acc: 0.2796 - val_loss: 2.7471 - val_acc: 0.1810\n",
            "Epoch 148/250\n",
            "89/89 [==============================] - 25s 277ms/step - loss: 2.2327 - acc: 0.2704 - val_loss: 2.7375 - val_acc: 0.1767\n",
            "Epoch 149/250\n",
            "89/89 [==============================] - 25s 278ms/step - loss: 2.2041 - acc: 0.2740 - val_loss: 2.7148 - val_acc: 0.1767\n",
            "Epoch 150/250\n",
            "89/89 [==============================] - 25s 275ms/step - loss: 2.2104 - acc: 0.2676 - val_loss: 2.7488 - val_acc: 0.1897\n",
            "Epoch 151/250\n",
            "89/89 [==============================] - 25s 278ms/step - loss: 2.2266 - acc: 0.2590 - val_loss: 2.7495 - val_acc: 0.1875\n",
            "Epoch 152/250\n",
            "89/89 [==============================] - 26s 289ms/step - loss: 2.2037 - acc: 0.2541 - val_loss: 2.7316 - val_acc: 0.1940\n",
            "Epoch 153/250\n",
            "89/89 [==============================] - 28s 298ms/step - loss: 2.2348 - acc: 0.2583 - val_loss: 2.7293 - val_acc: 0.1961\n",
            "Epoch 154/250\n",
            "89/89 [==============================] - 26s 284ms/step - loss: 2.2387 - acc: 0.2562 - val_loss: 2.7191 - val_acc: 0.1875\n",
            "Epoch 155/250\n",
            "89/89 [==============================] - 25s 278ms/step - loss: 2.2159 - acc: 0.2732 - val_loss: 2.7290 - val_acc: 0.1875\n",
            "Epoch 156/250\n",
            "89/89 [==============================] - 26s 290ms/step - loss: 2.2641 - acc: 0.2498 - val_loss: 2.7380 - val_acc: 0.1832\n",
            "Epoch 157/250\n",
            "89/89 [==============================] - 27s 295ms/step - loss: 2.1996 - acc: 0.2740 - val_loss: 2.7730 - val_acc: 0.1767\n",
            "Epoch 158/250\n",
            "89/89 [==============================] - 27s 298ms/step - loss: 2.2176 - acc: 0.2697 - val_loss: 2.7713 - val_acc: 0.1832\n",
            "Epoch 159/250\n",
            "89/89 [==============================] - 29s 317ms/step - loss: 2.2141 - acc: 0.2569 - val_loss: 2.7538 - val_acc: 0.1897\n",
            "Epoch 160/250\n",
            "89/89 [==============================] - 27s 296ms/step - loss: 2.2349 - acc: 0.2569 - val_loss: 2.7688 - val_acc: 0.1832\n",
            "Epoch 161/250\n",
            "89/89 [==============================] - 27s 297ms/step - loss: 2.1868 - acc: 0.2782 - val_loss: 2.7673 - val_acc: 0.1897\n",
            "Epoch 162/250\n",
            "89/89 [==============================] - 26s 285ms/step - loss: 2.2480 - acc: 0.2441 - val_loss: 2.7913 - val_acc: 0.1746\n",
            "Epoch 163/250\n",
            "89/89 [==============================] - 25s 277ms/step - loss: 2.2153 - acc: 0.2541 - val_loss: 2.7446 - val_acc: 0.1875\n",
            "Epoch 164/250\n",
            "89/89 [==============================] - 27s 296ms/step - loss: 2.2414 - acc: 0.2477 - val_loss: 2.7644 - val_acc: 0.1853\n",
            "Epoch 165/250\n",
            "89/89 [==============================] - 26s 281ms/step - loss: 2.2394 - acc: 0.2598 - val_loss: 2.7353 - val_acc: 0.1875\n",
            "Epoch 166/250\n",
            "89/89 [==============================] - 28s 307ms/step - loss: 2.1913 - acc: 0.2732 - val_loss: 2.7571 - val_acc: 0.1789\n",
            "Epoch 167/250\n",
            "89/89 [==============================] - 25s 278ms/step - loss: 2.2305 - acc: 0.2661 - val_loss: 2.7561 - val_acc: 0.1789\n",
            "Epoch 168/250\n",
            "89/89 [==============================] - 26s 281ms/step - loss: 2.2401 - acc: 0.2590 - val_loss: 2.7619 - val_acc: 0.1853\n",
            "Epoch 169/250\n",
            "89/89 [==============================] - 25s 278ms/step - loss: 2.2313 - acc: 0.2654 - val_loss: 2.7531 - val_acc: 0.1810\n",
            "Epoch 170/250\n",
            "89/89 [==============================] - 21s 225ms/step - loss: 2.2072 - acc: 0.2711 - val_loss: 2.7538 - val_acc: 0.1767\n",
            "Epoch 171/250\n",
            "89/89 [==============================] - 28s 304ms/step - loss: 2.2101 - acc: 0.2491 - val_loss: 2.7675 - val_acc: 0.1724\n",
            "Epoch 172/250\n",
            "89/89 [==============================] - 28s 305ms/step - loss: 2.1947 - acc: 0.2626 - val_loss: 2.7485 - val_acc: 0.2004\n",
            "Epoch 173/250\n",
            "89/89 [==============================] - 22s 244ms/step - loss: 2.2072 - acc: 0.2740 - val_loss: 2.7913 - val_acc: 0.1832\n",
            "Epoch 174/250\n",
            "89/89 [==============================] - 26s 280ms/step - loss: 2.1526 - acc: 0.2740 - val_loss: 2.7498 - val_acc: 0.1853\n",
            "Epoch 175/250\n",
            "89/89 [==============================] - 26s 281ms/step - loss: 2.1583 - acc: 0.2931 - val_loss: 2.7547 - val_acc: 0.1897\n",
            "Epoch 176/250\n",
            "89/89 [==============================] - 26s 281ms/step - loss: 2.2340 - acc: 0.2598 - val_loss: 2.7484 - val_acc: 0.1832\n",
            "Epoch 177/250\n",
            "89/89 [==============================] - 26s 280ms/step - loss: 2.2193 - acc: 0.2690 - val_loss: 2.7396 - val_acc: 0.1940\n",
            "Epoch 178/250\n",
            "89/89 [==============================] - 26s 283ms/step - loss: 2.2297 - acc: 0.2683 - val_loss: 2.7493 - val_acc: 0.1853\n",
            "Epoch 179/250\n",
            "89/89 [==============================] - 27s 296ms/step - loss: 2.2076 - acc: 0.2697 - val_loss: 2.7560 - val_acc: 0.1832\n",
            "Epoch 180/250\n",
            "89/89 [==============================] - 26s 281ms/step - loss: 2.2049 - acc: 0.2789 - val_loss: 2.7233 - val_acc: 0.1897\n",
            "Epoch 181/250\n",
            "89/89 [==============================] - 26s 280ms/step - loss: 2.2133 - acc: 0.2697 - val_loss: 2.7456 - val_acc: 0.1918\n",
            "Epoch 182/250\n",
            "89/89 [==============================] - 25s 275ms/step - loss: 2.2071 - acc: 0.2704 - val_loss: 2.7575 - val_acc: 0.1897\n",
            "Epoch 183/250\n",
            "89/89 [==============================] - 25s 280ms/step - loss: 2.2017 - acc: 0.2683 - val_loss: 2.7847 - val_acc: 0.1767\n",
            "Epoch 184/250\n",
            "89/89 [==============================] - 20s 222ms/step - loss: 2.2150 - acc: 0.2484 - val_loss: 2.7479 - val_acc: 0.1767\n",
            "Epoch 185/250\n",
            "89/89 [==============================] - 27s 301ms/step - loss: 2.2032 - acc: 0.2761 - val_loss: 2.7412 - val_acc: 0.1789\n",
            "Epoch 186/250\n",
            "89/89 [==============================] - 27s 296ms/step - loss: 2.2371 - acc: 0.2612 - val_loss: 2.7420 - val_acc: 0.1810\n",
            "Epoch 187/250\n",
            "89/89 [==============================] - 27s 300ms/step - loss: 2.2325 - acc: 0.2512 - val_loss: 2.7616 - val_acc: 0.1810\n",
            "Epoch 188/250\n",
            "89/89 [==============================] - 27s 302ms/step - loss: 2.2362 - acc: 0.2640 - val_loss: 2.7452 - val_acc: 0.1767\n",
            "Epoch 189/250\n",
            "89/89 [==============================] - 30s 325ms/step - loss: 2.2014 - acc: 0.2683 - val_loss: 2.7357 - val_acc: 0.1832\n",
            "Epoch 190/250\n",
            "89/89 [==============================] - 26s 288ms/step - loss: 2.2335 - acc: 0.2598 - val_loss: 2.7356 - val_acc: 0.1875\n",
            "Epoch 191/250\n",
            "89/89 [==============================] - 28s 302ms/step - loss: 2.2059 - acc: 0.2811 - val_loss: 2.7228 - val_acc: 0.1810\n",
            "Epoch 192/250\n",
            "89/89 [==============================] - 28s 304ms/step - loss: 2.2310 - acc: 0.2598 - val_loss: 2.7557 - val_acc: 0.1832\n",
            "Epoch 193/250\n",
            "89/89 [==============================] - 27s 295ms/step - loss: 2.2125 - acc: 0.2633 - val_loss: 2.7322 - val_acc: 0.1875\n",
            "Epoch 194/250\n",
            "89/89 [==============================] - 26s 284ms/step - loss: 2.1874 - acc: 0.2867 - val_loss: 2.7649 - val_acc: 0.1832\n",
            "Epoch 195/250\n",
            "89/89 [==============================] - 27s 294ms/step - loss: 2.1730 - acc: 0.2576 - val_loss: 2.7545 - val_acc: 0.1832\n",
            "Epoch 196/250\n",
            "89/89 [==============================] - 30s 327ms/step - loss: 2.1880 - acc: 0.2683 - val_loss: 2.7632 - val_acc: 0.1810\n",
            "Epoch 197/250\n",
            "89/89 [==============================] - 26s 282ms/step - loss: 2.1904 - acc: 0.2676 - val_loss: 2.7501 - val_acc: 0.1810\n",
            "Epoch 198/250\n",
            "89/89 [==============================] - 26s 289ms/step - loss: 2.2083 - acc: 0.2612 - val_loss: 2.7357 - val_acc: 0.1875\n",
            "Epoch 199/250\n",
            "89/89 [==============================] - 21s 227ms/step - loss: 2.2479 - acc: 0.2498 - val_loss: 2.7428 - val_acc: 0.1897\n",
            "Epoch 200/250\n",
            "89/89 [==============================] - 26s 284ms/step - loss: 2.1976 - acc: 0.2605 - val_loss: 2.7420 - val_acc: 0.1897\n",
            "Epoch 201/250\n",
            "89/89 [==============================] - 26s 283ms/step - loss: 2.2301 - acc: 0.2754 - val_loss: 2.7459 - val_acc: 0.1853\n",
            "Epoch 202/250\n",
            "89/89 [==============================] - 27s 298ms/step - loss: 2.2120 - acc: 0.2626 - val_loss: 2.7292 - val_acc: 0.1810\n",
            "Epoch 203/250\n",
            "89/89 [==============================] - 26s 285ms/step - loss: 2.2120 - acc: 0.2562 - val_loss: 2.7504 - val_acc: 0.1810\n",
            "Epoch 204/250\n",
            "89/89 [==============================] - 27s 293ms/step - loss: 2.2425 - acc: 0.2633 - val_loss: 2.7185 - val_acc: 0.1875\n",
            "Epoch 205/250\n",
            "89/89 [==============================] - 26s 285ms/step - loss: 2.1732 - acc: 0.2690 - val_loss: 2.7772 - val_acc: 0.1983\n",
            "Epoch 206/250\n",
            "89/89 [==============================] - 25s 278ms/step - loss: 2.1843 - acc: 0.2825 - val_loss: 2.7573 - val_acc: 0.1875\n",
            "Epoch 207/250\n",
            "89/89 [==============================] - 20s 223ms/step - loss: 2.2494 - acc: 0.2477 - val_loss: 2.7456 - val_acc: 0.1810\n",
            "Epoch 208/250\n",
            "89/89 [==============================] - 27s 300ms/step - loss: 2.2421 - acc: 0.2406 - val_loss: 2.7533 - val_acc: 0.1767\n",
            "Epoch 209/250\n",
            "89/89 [==============================] - 27s 304ms/step - loss: 2.2626 - acc: 0.2477 - val_loss: 2.7296 - val_acc: 0.1853\n",
            "Epoch 210/250\n",
            "89/89 [==============================] - 27s 304ms/step - loss: 2.2201 - acc: 0.2569 - val_loss: 2.7640 - val_acc: 0.1810\n",
            "Epoch 211/250\n",
            "89/89 [==============================] - 30s 328ms/step - loss: 2.2011 - acc: 0.2747 - val_loss: 2.7690 - val_acc: 0.1810\n",
            "Epoch 212/250\n",
            "89/89 [==============================] - 27s 295ms/step - loss: 2.1826 - acc: 0.2661 - val_loss: 2.7577 - val_acc: 0.1853\n",
            "Epoch 213/250\n",
            "89/89 [==============================] - 26s 288ms/step - loss: 2.1798 - acc: 0.2789 - val_loss: 2.7819 - val_acc: 0.1832\n",
            "Epoch 214/250\n",
            "89/89 [==============================] - 26s 287ms/step - loss: 2.2240 - acc: 0.2683 - val_loss: 2.7876 - val_acc: 0.1789\n",
            "Epoch 215/250\n",
            "89/89 [==============================] - 26s 286ms/step - loss: 2.2232 - acc: 0.2640 - val_loss: 2.7598 - val_acc: 0.1875\n",
            "Epoch 216/250\n",
            "89/89 [==============================] - 26s 282ms/step - loss: 2.1662 - acc: 0.2534 - val_loss: 2.7965 - val_acc: 0.1875\n",
            "Epoch 217/250\n",
            "89/89 [==============================] - 26s 288ms/step - loss: 2.2150 - acc: 0.2498 - val_loss: 2.7807 - val_acc: 0.1918\n",
            "Epoch 218/250\n",
            "89/89 [==============================] - 27s 297ms/step - loss: 2.1559 - acc: 0.2690 - val_loss: 2.7777 - val_acc: 0.1853\n",
            "Epoch 219/250\n",
            "89/89 [==============================] - 26s 288ms/step - loss: 2.2252 - acc: 0.2456 - val_loss: 2.7654 - val_acc: 0.1918\n",
            "Epoch 220/250\n",
            "89/89 [==============================] - 26s 287ms/step - loss: 2.1820 - acc: 0.2669 - val_loss: 2.7516 - val_acc: 0.1940\n",
            "Epoch 221/250\n",
            "89/89 [==============================] - 27s 297ms/step - loss: 2.1966 - acc: 0.2725 - val_loss: 2.7523 - val_acc: 0.1940\n",
            "Epoch 222/250\n",
            "89/89 [==============================] - 27s 301ms/step - loss: 2.2179 - acc: 0.2619 - val_loss: 2.7461 - val_acc: 0.1853\n",
            "Epoch 223/250\n",
            "89/89 [==============================] - 26s 290ms/step - loss: 2.2168 - acc: 0.2640 - val_loss: 2.7582 - val_acc: 0.1875\n",
            "Epoch 224/250\n",
            "89/89 [==============================] - 27s 298ms/step - loss: 2.1966 - acc: 0.2661 - val_loss: 2.7430 - val_acc: 0.1853\n",
            "Epoch 225/250\n",
            "89/89 [==============================] - 29s 322ms/step - loss: 2.2170 - acc: 0.2541 - val_loss: 2.7608 - val_acc: 0.1940\n",
            "Epoch 226/250\n",
            "89/89 [==============================] - 27s 296ms/step - loss: 2.1808 - acc: 0.2754 - val_loss: 2.7707 - val_acc: 0.1853\n",
            "Epoch 227/250\n",
            "89/89 [==============================] - 26s 285ms/step - loss: 2.1810 - acc: 0.2740 - val_loss: 2.7406 - val_acc: 0.1897\n",
            "Epoch 228/250\n",
            "89/89 [==============================] - 27s 301ms/step - loss: 2.1981 - acc: 0.2562 - val_loss: 2.7691 - val_acc: 0.1810\n",
            "Epoch 229/250\n",
            "89/89 [==============================] - 22s 241ms/step - loss: 2.2215 - acc: 0.2633 - val_loss: 2.7561 - val_acc: 0.1853\n",
            "Epoch 230/250\n",
            "89/89 [==============================] - 26s 277ms/step - loss: 2.2034 - acc: 0.2732 - val_loss: 2.7620 - val_acc: 0.1832\n",
            "Epoch 231/250\n",
            "89/89 [==============================] - 25s 278ms/step - loss: 2.1928 - acc: 0.2633 - val_loss: 2.7742 - val_acc: 0.1789\n",
            "Epoch 232/250\n",
            "89/89 [==============================] - 28s 309ms/step - loss: 2.2174 - acc: 0.2697 - val_loss: 2.7788 - val_acc: 0.1832\n",
            "Epoch 233/250\n",
            "89/89 [==============================] - 25s 275ms/step - loss: 2.1919 - acc: 0.2725 - val_loss: 2.7699 - val_acc: 0.1832\n",
            "Epoch 234/250\n",
            "89/89 [==============================] - 25s 277ms/step - loss: 2.1585 - acc: 0.2768 - val_loss: 2.7952 - val_acc: 0.1810\n",
            "Epoch 235/250\n",
            "89/89 [==============================] - 21s 226ms/step - loss: 2.1875 - acc: 0.2803 - val_loss: 2.7598 - val_acc: 0.1875\n",
            "Epoch 236/250\n",
            "89/89 [==============================] - 22s 246ms/step - loss: 2.2034 - acc: 0.2598 - val_loss: 2.7631 - val_acc: 0.1832\n",
            "Epoch 237/250\n",
            "89/89 [==============================] - 27s 294ms/step - loss: 2.1992 - acc: 0.2633 - val_loss: 2.7691 - val_acc: 0.1853\n",
            "Epoch 238/250\n",
            "89/89 [==============================] - 26s 283ms/step - loss: 2.1831 - acc: 0.2598 - val_loss: 2.7531 - val_acc: 0.1940\n",
            "Epoch 239/250\n",
            "89/89 [==============================] - 28s 312ms/step - loss: 2.1707 - acc: 0.2846 - val_loss: 2.7631 - val_acc: 0.1832\n",
            "Epoch 240/250\n",
            "89/89 [==============================] - 25s 277ms/step - loss: 2.2606 - acc: 0.2505 - val_loss: 2.7484 - val_acc: 0.1832\n",
            "Epoch 241/250\n",
            "89/89 [==============================] - 27s 301ms/step - loss: 2.1854 - acc: 0.2647 - val_loss: 2.7583 - val_acc: 0.1832\n",
            "Epoch 242/250\n",
            "89/89 [==============================] - 27s 301ms/step - loss: 2.2174 - acc: 0.2704 - val_loss: 2.7609 - val_acc: 0.1832\n",
            "Epoch 243/250\n",
            "89/89 [==============================] - 26s 283ms/step - loss: 2.1873 - acc: 0.2654 - val_loss: 2.7451 - val_acc: 0.1897\n",
            "Epoch 244/250\n",
            "89/89 [==============================] - 27s 297ms/step - loss: 2.1736 - acc: 0.2881 - val_loss: 2.7497 - val_acc: 0.1875\n",
            "Epoch 245/250\n",
            "89/89 [==============================] - 29s 316ms/step - loss: 2.1602 - acc: 0.2740 - val_loss: 2.7173 - val_acc: 0.1961\n",
            "Epoch 246/250\n",
            "89/89 [==============================] - 21s 224ms/step - loss: 2.2191 - acc: 0.2747 - val_loss: 2.7379 - val_acc: 0.1853\n",
            "Epoch 247/250\n",
            "89/89 [==============================] - 27s 301ms/step - loss: 2.1956 - acc: 0.2612 - val_loss: 2.7306 - val_acc: 0.1853\n",
            "Epoch 248/250\n",
            "89/89 [==============================] - 27s 297ms/step - loss: 2.2170 - acc: 0.2626 - val_loss: 2.7271 - val_acc: 0.1897\n",
            "Epoch 249/250\n",
            "89/89 [==============================] - 27s 293ms/step - loss: 2.1982 - acc: 0.2669 - val_loss: 2.7431 - val_acc: 0.1832\n",
            "Epoch 250/250\n",
            "89/89 [==============================] - 27s 302ms/step - loss: 2.1601 - acc: 0.2711 - val_loss: 2.7399 - val_acc: 0.1875\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "acc = history.history['acc']\n",
        "val_acc = history.history['val_acc']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs_x = range(len(acc))\n",
        "\n",
        "plt.plot(epochs_x, acc, 'mo', label='Training acc')\n",
        "plt.plot(epochs_x, val_acc, 'k', label='Validation acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.figure()\n",
        "\n",
        "plt.plot(epochs_x, loss, 'mo', label='Training loss')\n",
        "plt.plot(epochs_x, val_loss, 'k', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "kwylTJpTP5XI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545
        },
        "outputId": "b3a0d95b-1c21-4206-cbf2-264fb2bb24fa"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Download the model"
      ],
      "metadata": {
        "id": "lD-vKaoHQAFd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "os.makedirs('/content/drive/My Drive/cut_panoramic/Model/Classification', exist_ok=True)\n",
        "model.save('/content/drive/My Drive/cut_panoramic/Model/Classification/44_รอบที่4_Flimpano_Female125_250_Unfreez.h5')"
      ],
      "metadata": {
        "id": "74dL7-HLP_Sh"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from google.colab import files\n",
        "# files.download('/content/drive/My Drive/cut_panoramic/Model/33_รอบที่3_Flimpano_Female125_250.h5')"
      ],
      "metadata": {
        "id": "qcPW-brHQDpc"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "05eOFn2Y1wRs"
      },
      "execution_count": 24,
      "outputs": []
    }
  ]
}