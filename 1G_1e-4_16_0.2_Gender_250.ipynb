{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Wanita-8943/Project_2023/blob/main/1G_1e-4_16_0.2_Gender_250.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#เรียกใช้ CSV"
      ],
      "metadata": {
        "id": "ow7eWoNw6U-c"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "z8o_VVNXzcL8"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import shutil"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1_2Fe8u81d5r",
        "outputId": "360a6300-04f1-488f-ec2e-fb248b128bae"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Imports"
      ],
      "metadata": {
        "id": "5qxePnnn7TGW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import models\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import optimizers\n",
        "import os\n",
        "import glob\n",
        "import shutil\n",
        "import sys\n",
        "import numpy as np\n",
        "from skimage.io import imread\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import Image\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "D-hCRloc3t39"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras import backend as K"
      ],
      "metadata": {
        "id": "YZWXwjXeGxZP"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#กำหนดค่าพารามิเตอร์\n"
      ],
      "metadata": {
        "id": "RooqSdBc7QHC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 16\n",
        "width = 150\n",
        "height = 150\n",
        "epochs = 250\n",
        "NUM_TRAIN = 2850\n",
        "NUM_TEST = 950\n",
        "dropout_rate = 0.2\n",
        "input_shape = (height, width, 3)"
      ],
      "metadata": {
        "id": "thDb7U9B3xOo"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Clone efficientnet repo\n"
      ],
      "metadata": {
        "id": "pumGmy6f3eSW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#ดึงข้อมูลใน Github มาใช้\n",
        "import os\n",
        "%cd /content\n",
        "if not os.path.isdir(\"efficientnet_keras_transfer_learning\"):\n",
        " !git clone https://github.com/Wanita-8943/efficientnet_keras_transfer_learning\n",
        "%cd efficientnet_keras_transfer_learning/\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P7iy2f8n16p0",
        "outputId": "033434aa-444c-457a-effd-ecb0356c8248"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "Cloning into 'efficientnet_keras_transfer_learning'...\n",
            "remote: Enumerating objects: 837, done.\u001b[K\n",
            "remote: Counting objects: 100% (359/359), done.\u001b[K\n",
            "remote: Compressing objects: 100% (124/124), done.\u001b[K\n",
            "remote: Total 837 (delta 255), reused 328 (delta 235), pack-reused 478\u001b[K\n",
            "Receiving objects: 100% (837/837), 13.82 MiB | 19.96 MiB/s, done.\n",
            "Resolving deltas: 100% (495/495), done.\n",
            "/content/efficientnet_keras_transfer_learning\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Options: EfficientNetB0, EfficientNetB1, EfficientNetB2, EfficientNetB3\n",
        "# Higher the number, the more complex the model is.\n",
        "from efficientnet import EfficientNetB0 as Net\n",
        "from efficientnet import center_crop_and_resize, preprocess_input"
      ],
      "metadata": {
        "id": "tjZBRnfo3bN0"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# loading pretrained conv base model\n",
        "# โหลดโมเดล มาโดยตัด output ของโมเดลออก เเต่ยังใช้ input อันเดิม\n",
        "# เเละโหลด weight ของโมเดล มาด้วยที่ชื่อว่า imagenet\n",
        "conv_base = Net(weights='imagenet', include_top=False, input_shape=input_shape)"
      ],
      "metadata": {
        "id": "hNZAzbDp3lgA",
        "outputId": "ec1b88aa-77c5-49df-aeea-7e7a2c44011b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
            "Instructions for updating:\n",
            "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://github.com/qubvel/efficientnet/releases/download/v0.0.1/efficientnet-b0_imagenet_1000_notop.h5\n",
            "16717576/16717576 [==============================] - 1s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = models.Sequential()\n",
        "model.add(conv_base)\n",
        "model.add(layers.GlobalMaxPooling2D(name=\"gap\"))\n",
        "# model.add(layers.Flatten(name=\"flatten\"))\n",
        "if dropout_rate > 0:\n",
        "    model.add(layers.Dropout(dropout_rate, name=\"dropout_out\"))\n",
        "# model.add(layers.Dense(256, activation='relu', name=\"fc1\"))\n",
        "model.add(layers.Dense(2, activation='softmax', name=\"fc_out\"))\n",
        "model.add(layers.Dense(1))"
      ],
      "metadata": {
        "id": "yWNKfQUt5rga"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "NadBB12251jh",
        "outputId": "5fce6635-07cc-4c9e-9ce0-535e36dbed5a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " efficientnet-b0 (Functional  (None, 5, 5, 1280)       4049564   \n",
            " )                                                               \n",
            "                                                                 \n",
            " gap (GlobalMaxPooling2D)    (None, 1280)              0         \n",
            "                                                                 \n",
            " dropout_out (Dropout)       (None, 1280)              0         \n",
            "                                                                 \n",
            " fc_out (Dense)              (None, 2)                 2562      \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1)                 3         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4,052,129\n",
            "Trainable params: 4,010,113\n",
            "Non-trainable params: 42,016\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('This is the number of trainable layers '\n",
        "      'before freezing the conv base:', len(model.trainable_weights))\n",
        "\n",
        "conv_base.trainable = False\n",
        "\n",
        "print('This is the number of trainable layers '\n",
        "      'after freezing the conv base:', len(model.trainable_weights))"
      ],
      "metadata": {
        "id": "GepWq3yy53t5",
        "outputId": "dce09856-eac1-4475-807e-f981f426163b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This is the number of trainable layers before freezing the conv base: 215\n",
            "This is the number of trainable layers after freezing the conv base: 4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "conv_base.summary() #ดู Summary"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iD76D6c_79py",
        "outputId": "efa13f82-5d27-4f2b-89e4-14689b84fc2d"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"efficientnet-b0\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 150, 150, 3  0           []                               \n",
            "                                )]                                                                \n",
            "                                                                                                  \n",
            " conv2d (Conv2D)                (None, 75, 75, 32)   864         ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " batch_normalization (BatchNorm  (None, 75, 75, 32)  128         ['conv2d[0][0]']                 \n",
            " alization)                                                                                       \n",
            "                                                                                                  \n",
            " swish (Swish)                  (None, 75, 75, 32)   0           ['batch_normalization[0][0]']    \n",
            "                                                                                                  \n",
            " depthwise_conv2d (DepthwiseCon  (None, 75, 75, 32)  288         ['swish[0][0]']                  \n",
            " v2D)                                                                                             \n",
            "                                                                                                  \n",
            " batch_normalization_1 (BatchNo  (None, 75, 75, 32)  128         ['depthwise_conv2d[0][0]']       \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " swish_1 (Swish)                (None, 75, 75, 32)   0           ['batch_normalization_1[0][0]']  \n",
            "                                                                                                  \n",
            " lambda (Lambda)                (None, 1, 1, 32)     0           ['swish_1[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d_1 (Conv2D)              (None, 1, 1, 8)      264         ['lambda[0][0]']                 \n",
            "                                                                                                  \n",
            " swish_2 (Swish)                (None, 1, 1, 8)      0           ['conv2d_1[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_2 (Conv2D)              (None, 1, 1, 32)     288         ['swish_2[0][0]']                \n",
            "                                                                                                  \n",
            " activation (Activation)        (None, 1, 1, 32)     0           ['conv2d_2[0][0]']               \n",
            "                                                                                                  \n",
            " multiply (Multiply)            (None, 75, 75, 32)   0           ['activation[0][0]',             \n",
            "                                                                  'swish_1[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d_3 (Conv2D)              (None, 75, 75, 16)   512         ['multiply[0][0]']               \n",
            "                                                                                                  \n",
            " batch_normalization_2 (BatchNo  (None, 75, 75, 16)  64          ['conv2d_3[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv2d_4 (Conv2D)              (None, 75, 75, 96)   1536        ['batch_normalization_2[0][0]']  \n",
            "                                                                                                  \n",
            " batch_normalization_3 (BatchNo  (None, 75, 75, 96)  384         ['conv2d_4[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " swish_3 (Swish)                (None, 75, 75, 96)   0           ['batch_normalization_3[0][0]']  \n",
            "                                                                                                  \n",
            " depthwise_conv2d_1 (DepthwiseC  (None, 38, 38, 96)  864         ['swish_3[0][0]']                \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_4 (BatchNo  (None, 38, 38, 96)  384         ['depthwise_conv2d_1[0][0]']     \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " swish_4 (Swish)                (None, 38, 38, 96)   0           ['batch_normalization_4[0][0]']  \n",
            "                                                                                                  \n",
            " lambda_1 (Lambda)              (None, 1, 1, 96)     0           ['swish_4[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d_5 (Conv2D)              (None, 1, 1, 4)      388         ['lambda_1[0][0]']               \n",
            "                                                                                                  \n",
            " swish_5 (Swish)                (None, 1, 1, 4)      0           ['conv2d_5[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_6 (Conv2D)              (None, 1, 1, 96)     480         ['swish_5[0][0]']                \n",
            "                                                                                                  \n",
            " activation_1 (Activation)      (None, 1, 1, 96)     0           ['conv2d_6[0][0]']               \n",
            "                                                                                                  \n",
            " multiply_1 (Multiply)          (None, 38, 38, 96)   0           ['activation_1[0][0]',           \n",
            "                                                                  'swish_4[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d_7 (Conv2D)              (None, 38, 38, 24)   2304        ['multiply_1[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_5 (BatchNo  (None, 38, 38, 24)  96          ['conv2d_7[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv2d_8 (Conv2D)              (None, 38, 38, 144)  3456        ['batch_normalization_5[0][0]']  \n",
            "                                                                                                  \n",
            " batch_normalization_6 (BatchNo  (None, 38, 38, 144)  576        ['conv2d_8[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " swish_6 (Swish)                (None, 38, 38, 144)  0           ['batch_normalization_6[0][0]']  \n",
            "                                                                                                  \n",
            " depthwise_conv2d_2 (DepthwiseC  (None, 38, 38, 144)  1296       ['swish_6[0][0]']                \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_7 (BatchNo  (None, 38, 38, 144)  576        ['depthwise_conv2d_2[0][0]']     \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " swish_7 (Swish)                (None, 38, 38, 144)  0           ['batch_normalization_7[0][0]']  \n",
            "                                                                                                  \n",
            " lambda_2 (Lambda)              (None, 1, 1, 144)    0           ['swish_7[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d_9 (Conv2D)              (None, 1, 1, 6)      870         ['lambda_2[0][0]']               \n",
            "                                                                                                  \n",
            " swish_8 (Swish)                (None, 1, 1, 6)      0           ['conv2d_9[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_10 (Conv2D)             (None, 1, 1, 144)    1008        ['swish_8[0][0]']                \n",
            "                                                                                                  \n",
            " activation_2 (Activation)      (None, 1, 1, 144)    0           ['conv2d_10[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_2 (Multiply)          (None, 38, 38, 144)  0           ['activation_2[0][0]',           \n",
            "                                                                  'swish_7[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d_11 (Conv2D)             (None, 38, 38, 24)   3456        ['multiply_2[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_8 (BatchNo  (None, 38, 38, 24)  96          ['conv2d_11[0][0]']              \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " drop_connect (DropConnect)     (None, 38, 38, 24)   0           ['batch_normalization_8[0][0]']  \n",
            "                                                                                                  \n",
            " add (Add)                      (None, 38, 38, 24)   0           ['drop_connect[0][0]',           \n",
            "                                                                  'batch_normalization_5[0][0]']  \n",
            "                                                                                                  \n",
            " conv2d_12 (Conv2D)             (None, 38, 38, 144)  3456        ['add[0][0]']                    \n",
            "                                                                                                  \n",
            " batch_normalization_9 (BatchNo  (None, 38, 38, 144)  576        ['conv2d_12[0][0]']              \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " swish_9 (Swish)                (None, 38, 38, 144)  0           ['batch_normalization_9[0][0]']  \n",
            "                                                                                                  \n",
            " depthwise_conv2d_3 (DepthwiseC  (None, 19, 19, 144)  3600       ['swish_9[0][0]']                \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_10 (BatchN  (None, 19, 19, 144)  576        ['depthwise_conv2d_3[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_10 (Swish)               (None, 19, 19, 144)  0           ['batch_normalization_10[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_3 (Lambda)              (None, 1, 1, 144)    0           ['swish_10[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_13 (Conv2D)             (None, 1, 1, 6)      870         ['lambda_3[0][0]']               \n",
            "                                                                                                  \n",
            " swish_11 (Swish)               (None, 1, 1, 6)      0           ['conv2d_13[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_14 (Conv2D)             (None, 1, 1, 144)    1008        ['swish_11[0][0]']               \n",
            "                                                                                                  \n",
            " activation_3 (Activation)      (None, 1, 1, 144)    0           ['conv2d_14[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_3 (Multiply)          (None, 19, 19, 144)  0           ['activation_3[0][0]',           \n",
            "                                                                  'swish_10[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_15 (Conv2D)             (None, 19, 19, 40)   5760        ['multiply_3[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_11 (BatchN  (None, 19, 19, 40)  160         ['conv2d_15[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_16 (Conv2D)             (None, 19, 19, 240)  9600        ['batch_normalization_11[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_12 (BatchN  (None, 19, 19, 240)  960        ['conv2d_16[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_12 (Swish)               (None, 19, 19, 240)  0           ['batch_normalization_12[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_4 (DepthwiseC  (None, 19, 19, 240)  6000       ['swish_12[0][0]']               \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_13 (BatchN  (None, 19, 19, 240)  960        ['depthwise_conv2d_4[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_13 (Swish)               (None, 19, 19, 240)  0           ['batch_normalization_13[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_4 (Lambda)              (None, 1, 1, 240)    0           ['swish_13[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_17 (Conv2D)             (None, 1, 1, 10)     2410        ['lambda_4[0][0]']               \n",
            "                                                                                                  \n",
            " swish_14 (Swish)               (None, 1, 1, 10)     0           ['conv2d_17[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_18 (Conv2D)             (None, 1, 1, 240)    2640        ['swish_14[0][0]']               \n",
            "                                                                                                  \n",
            " activation_4 (Activation)      (None, 1, 1, 240)    0           ['conv2d_18[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_4 (Multiply)          (None, 19, 19, 240)  0           ['activation_4[0][0]',           \n",
            "                                                                  'swish_13[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_19 (Conv2D)             (None, 19, 19, 40)   9600        ['multiply_4[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_14 (BatchN  (None, 19, 19, 40)  160         ['conv2d_19[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_1 (DropConnect)   (None, 19, 19, 40)   0           ['batch_normalization_14[0][0]'] \n",
            "                                                                                                  \n",
            " add_1 (Add)                    (None, 19, 19, 40)   0           ['drop_connect_1[0][0]',         \n",
            "                                                                  'batch_normalization_11[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_20 (Conv2D)             (None, 19, 19, 240)  9600        ['add_1[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_15 (BatchN  (None, 19, 19, 240)  960        ['conv2d_20[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_15 (Swish)               (None, 19, 19, 240)  0           ['batch_normalization_15[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_5 (DepthwiseC  (None, 10, 10, 240)  2160       ['swish_15[0][0]']               \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_16 (BatchN  (None, 10, 10, 240)  960        ['depthwise_conv2d_5[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_16 (Swish)               (None, 10, 10, 240)  0           ['batch_normalization_16[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_5 (Lambda)              (None, 1, 1, 240)    0           ['swish_16[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_21 (Conv2D)             (None, 1, 1, 10)     2410        ['lambda_5[0][0]']               \n",
            "                                                                                                  \n",
            " swish_17 (Swish)               (None, 1, 1, 10)     0           ['conv2d_21[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_22 (Conv2D)             (None, 1, 1, 240)    2640        ['swish_17[0][0]']               \n",
            "                                                                                                  \n",
            " activation_5 (Activation)      (None, 1, 1, 240)    0           ['conv2d_22[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_5 (Multiply)          (None, 10, 10, 240)  0           ['activation_5[0][0]',           \n",
            "                                                                  'swish_16[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_23 (Conv2D)             (None, 10, 10, 80)   19200       ['multiply_5[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_17 (BatchN  (None, 10, 10, 80)  320         ['conv2d_23[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_24 (Conv2D)             (None, 10, 10, 480)  38400       ['batch_normalization_17[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_18 (BatchN  (None, 10, 10, 480)  1920       ['conv2d_24[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_18 (Swish)               (None, 10, 10, 480)  0           ['batch_normalization_18[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_6 (DepthwiseC  (None, 10, 10, 480)  4320       ['swish_18[0][0]']               \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_19 (BatchN  (None, 10, 10, 480)  1920       ['depthwise_conv2d_6[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_19 (Swish)               (None, 10, 10, 480)  0           ['batch_normalization_19[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_6 (Lambda)              (None, 1, 1, 480)    0           ['swish_19[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_25 (Conv2D)             (None, 1, 1, 20)     9620        ['lambda_6[0][0]']               \n",
            "                                                                                                  \n",
            " swish_20 (Swish)               (None, 1, 1, 20)     0           ['conv2d_25[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_26 (Conv2D)             (None, 1, 1, 480)    10080       ['swish_20[0][0]']               \n",
            "                                                                                                  \n",
            " activation_6 (Activation)      (None, 1, 1, 480)    0           ['conv2d_26[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_6 (Multiply)          (None, 10, 10, 480)  0           ['activation_6[0][0]',           \n",
            "                                                                  'swish_19[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_27 (Conv2D)             (None, 10, 10, 80)   38400       ['multiply_6[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_20 (BatchN  (None, 10, 10, 80)  320         ['conv2d_27[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_2 (DropConnect)   (None, 10, 10, 80)   0           ['batch_normalization_20[0][0]'] \n",
            "                                                                                                  \n",
            " add_2 (Add)                    (None, 10, 10, 80)   0           ['drop_connect_2[0][0]',         \n",
            "                                                                  'batch_normalization_17[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_28 (Conv2D)             (None, 10, 10, 480)  38400       ['add_2[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_21 (BatchN  (None, 10, 10, 480)  1920       ['conv2d_28[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_21 (Swish)               (None, 10, 10, 480)  0           ['batch_normalization_21[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_7 (DepthwiseC  (None, 10, 10, 480)  4320       ['swish_21[0][0]']               \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_22 (BatchN  (None, 10, 10, 480)  1920       ['depthwise_conv2d_7[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_22 (Swish)               (None, 10, 10, 480)  0           ['batch_normalization_22[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_7 (Lambda)              (None, 1, 1, 480)    0           ['swish_22[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_29 (Conv2D)             (None, 1, 1, 20)     9620        ['lambda_7[0][0]']               \n",
            "                                                                                                  \n",
            " swish_23 (Swish)               (None, 1, 1, 20)     0           ['conv2d_29[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_30 (Conv2D)             (None, 1, 1, 480)    10080       ['swish_23[0][0]']               \n",
            "                                                                                                  \n",
            " activation_7 (Activation)      (None, 1, 1, 480)    0           ['conv2d_30[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_7 (Multiply)          (None, 10, 10, 480)  0           ['activation_7[0][0]',           \n",
            "                                                                  'swish_22[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_31 (Conv2D)             (None, 10, 10, 80)   38400       ['multiply_7[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_23 (BatchN  (None, 10, 10, 80)  320         ['conv2d_31[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_3 (DropConnect)   (None, 10, 10, 80)   0           ['batch_normalization_23[0][0]'] \n",
            "                                                                                                  \n",
            " add_3 (Add)                    (None, 10, 10, 80)   0           ['drop_connect_3[0][0]',         \n",
            "                                                                  'add_2[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_32 (Conv2D)             (None, 10, 10, 480)  38400       ['add_3[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_24 (BatchN  (None, 10, 10, 480)  1920       ['conv2d_32[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_24 (Swish)               (None, 10, 10, 480)  0           ['batch_normalization_24[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_8 (DepthwiseC  (None, 10, 10, 480)  12000      ['swish_24[0][0]']               \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_25 (BatchN  (None, 10, 10, 480)  1920       ['depthwise_conv2d_8[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_25 (Swish)               (None, 10, 10, 480)  0           ['batch_normalization_25[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_8 (Lambda)              (None, 1, 1, 480)    0           ['swish_25[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_33 (Conv2D)             (None, 1, 1, 20)     9620        ['lambda_8[0][0]']               \n",
            "                                                                                                  \n",
            " swish_26 (Swish)               (None, 1, 1, 20)     0           ['conv2d_33[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_34 (Conv2D)             (None, 1, 1, 480)    10080       ['swish_26[0][0]']               \n",
            "                                                                                                  \n",
            " activation_8 (Activation)      (None, 1, 1, 480)    0           ['conv2d_34[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_8 (Multiply)          (None, 10, 10, 480)  0           ['activation_8[0][0]',           \n",
            "                                                                  'swish_25[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_35 (Conv2D)             (None, 10, 10, 112)  53760       ['multiply_8[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_26 (BatchN  (None, 10, 10, 112)  448        ['conv2d_35[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_36 (Conv2D)             (None, 10, 10, 672)  75264       ['batch_normalization_26[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_27 (BatchN  (None, 10, 10, 672)  2688       ['conv2d_36[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_27 (Swish)               (None, 10, 10, 672)  0           ['batch_normalization_27[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_9 (DepthwiseC  (None, 10, 10, 672)  16800      ['swish_27[0][0]']               \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_28 (BatchN  (None, 10, 10, 672)  2688       ['depthwise_conv2d_9[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_28 (Swish)               (None, 10, 10, 672)  0           ['batch_normalization_28[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_9 (Lambda)              (None, 1, 1, 672)    0           ['swish_28[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_37 (Conv2D)             (None, 1, 1, 28)     18844       ['lambda_9[0][0]']               \n",
            "                                                                                                  \n",
            " swish_29 (Swish)               (None, 1, 1, 28)     0           ['conv2d_37[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_38 (Conv2D)             (None, 1, 1, 672)    19488       ['swish_29[0][0]']               \n",
            "                                                                                                  \n",
            " activation_9 (Activation)      (None, 1, 1, 672)    0           ['conv2d_38[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_9 (Multiply)          (None, 10, 10, 672)  0           ['activation_9[0][0]',           \n",
            "                                                                  'swish_28[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_39 (Conv2D)             (None, 10, 10, 112)  75264       ['multiply_9[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_29 (BatchN  (None, 10, 10, 112)  448        ['conv2d_39[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_4 (DropConnect)   (None, 10, 10, 112)  0           ['batch_normalization_29[0][0]'] \n",
            "                                                                                                  \n",
            " add_4 (Add)                    (None, 10, 10, 112)  0           ['drop_connect_4[0][0]',         \n",
            "                                                                  'batch_normalization_26[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_40 (Conv2D)             (None, 10, 10, 672)  75264       ['add_4[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_30 (BatchN  (None, 10, 10, 672)  2688       ['conv2d_40[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_30 (Swish)               (None, 10, 10, 672)  0           ['batch_normalization_30[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_10 (Depthwise  (None, 10, 10, 672)  16800      ['swish_30[0][0]']               \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_31 (BatchN  (None, 10, 10, 672)  2688       ['depthwise_conv2d_10[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_31 (Swish)               (None, 10, 10, 672)  0           ['batch_normalization_31[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_10 (Lambda)             (None, 1, 1, 672)    0           ['swish_31[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_41 (Conv2D)             (None, 1, 1, 28)     18844       ['lambda_10[0][0]']              \n",
            "                                                                                                  \n",
            " swish_32 (Swish)               (None, 1, 1, 28)     0           ['conv2d_41[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_42 (Conv2D)             (None, 1, 1, 672)    19488       ['swish_32[0][0]']               \n",
            "                                                                                                  \n",
            " activation_10 (Activation)     (None, 1, 1, 672)    0           ['conv2d_42[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_10 (Multiply)         (None, 10, 10, 672)  0           ['activation_10[0][0]',          \n",
            "                                                                  'swish_31[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_43 (Conv2D)             (None, 10, 10, 112)  75264       ['multiply_10[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_32 (BatchN  (None, 10, 10, 112)  448        ['conv2d_43[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_5 (DropConnect)   (None, 10, 10, 112)  0           ['batch_normalization_32[0][0]'] \n",
            "                                                                                                  \n",
            " add_5 (Add)                    (None, 10, 10, 112)  0           ['drop_connect_5[0][0]',         \n",
            "                                                                  'add_4[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_44 (Conv2D)             (None, 10, 10, 672)  75264       ['add_5[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_33 (BatchN  (None, 10, 10, 672)  2688       ['conv2d_44[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_33 (Swish)               (None, 10, 10, 672)  0           ['batch_normalization_33[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_11 (Depthwise  (None, 5, 5, 672)   16800       ['swish_33[0][0]']               \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_34 (BatchN  (None, 5, 5, 672)   2688        ['depthwise_conv2d_11[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_34 (Swish)               (None, 5, 5, 672)    0           ['batch_normalization_34[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_11 (Lambda)             (None, 1, 1, 672)    0           ['swish_34[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_45 (Conv2D)             (None, 1, 1, 28)     18844       ['lambda_11[0][0]']              \n",
            "                                                                                                  \n",
            " swish_35 (Swish)               (None, 1, 1, 28)     0           ['conv2d_45[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_46 (Conv2D)             (None, 1, 1, 672)    19488       ['swish_35[0][0]']               \n",
            "                                                                                                  \n",
            " activation_11 (Activation)     (None, 1, 1, 672)    0           ['conv2d_46[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_11 (Multiply)         (None, 5, 5, 672)    0           ['activation_11[0][0]',          \n",
            "                                                                  'swish_34[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_47 (Conv2D)             (None, 5, 5, 192)    129024      ['multiply_11[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_35 (BatchN  (None, 5, 5, 192)   768         ['conv2d_47[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_48 (Conv2D)             (None, 5, 5, 1152)   221184      ['batch_normalization_35[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_36 (BatchN  (None, 5, 5, 1152)  4608        ['conv2d_48[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_36 (Swish)               (None, 5, 5, 1152)   0           ['batch_normalization_36[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_12 (Depthwise  (None, 5, 5, 1152)  28800       ['swish_36[0][0]']               \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_37 (BatchN  (None, 5, 5, 1152)  4608        ['depthwise_conv2d_12[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_37 (Swish)               (None, 5, 5, 1152)   0           ['batch_normalization_37[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_12 (Lambda)             (None, 1, 1, 1152)   0           ['swish_37[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_49 (Conv2D)             (None, 1, 1, 48)     55344       ['lambda_12[0][0]']              \n",
            "                                                                                                  \n",
            " swish_38 (Swish)               (None, 1, 1, 48)     0           ['conv2d_49[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_50 (Conv2D)             (None, 1, 1, 1152)   56448       ['swish_38[0][0]']               \n",
            "                                                                                                  \n",
            " activation_12 (Activation)     (None, 1, 1, 1152)   0           ['conv2d_50[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_12 (Multiply)         (None, 5, 5, 1152)   0           ['activation_12[0][0]',          \n",
            "                                                                  'swish_37[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_51 (Conv2D)             (None, 5, 5, 192)    221184      ['multiply_12[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_38 (BatchN  (None, 5, 5, 192)   768         ['conv2d_51[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_6 (DropConnect)   (None, 5, 5, 192)    0           ['batch_normalization_38[0][0]'] \n",
            "                                                                                                  \n",
            " add_6 (Add)                    (None, 5, 5, 192)    0           ['drop_connect_6[0][0]',         \n",
            "                                                                  'batch_normalization_35[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_52 (Conv2D)             (None, 5, 5, 1152)   221184      ['add_6[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_39 (BatchN  (None, 5, 5, 1152)  4608        ['conv2d_52[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_39 (Swish)               (None, 5, 5, 1152)   0           ['batch_normalization_39[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_13 (Depthwise  (None, 5, 5, 1152)  28800       ['swish_39[0][0]']               \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_40 (BatchN  (None, 5, 5, 1152)  4608        ['depthwise_conv2d_13[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_40 (Swish)               (None, 5, 5, 1152)   0           ['batch_normalization_40[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_13 (Lambda)             (None, 1, 1, 1152)   0           ['swish_40[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_53 (Conv2D)             (None, 1, 1, 48)     55344       ['lambda_13[0][0]']              \n",
            "                                                                                                  \n",
            " swish_41 (Swish)               (None, 1, 1, 48)     0           ['conv2d_53[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_54 (Conv2D)             (None, 1, 1, 1152)   56448       ['swish_41[0][0]']               \n",
            "                                                                                                  \n",
            " activation_13 (Activation)     (None, 1, 1, 1152)   0           ['conv2d_54[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_13 (Multiply)         (None, 5, 5, 1152)   0           ['activation_13[0][0]',          \n",
            "                                                                  'swish_40[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_55 (Conv2D)             (None, 5, 5, 192)    221184      ['multiply_13[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_41 (BatchN  (None, 5, 5, 192)   768         ['conv2d_55[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_7 (DropConnect)   (None, 5, 5, 192)    0           ['batch_normalization_41[0][0]'] \n",
            "                                                                                                  \n",
            " add_7 (Add)                    (None, 5, 5, 192)    0           ['drop_connect_7[0][0]',         \n",
            "                                                                  'add_6[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_56 (Conv2D)             (None, 5, 5, 1152)   221184      ['add_7[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_42 (BatchN  (None, 5, 5, 1152)  4608        ['conv2d_56[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_42 (Swish)               (None, 5, 5, 1152)   0           ['batch_normalization_42[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_14 (Depthwise  (None, 5, 5, 1152)  28800       ['swish_42[0][0]']               \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_43 (BatchN  (None, 5, 5, 1152)  4608        ['depthwise_conv2d_14[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_43 (Swish)               (None, 5, 5, 1152)   0           ['batch_normalization_43[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_14 (Lambda)             (None, 1, 1, 1152)   0           ['swish_43[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_57 (Conv2D)             (None, 1, 1, 48)     55344       ['lambda_14[0][0]']              \n",
            "                                                                                                  \n",
            " swish_44 (Swish)               (None, 1, 1, 48)     0           ['conv2d_57[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_58 (Conv2D)             (None, 1, 1, 1152)   56448       ['swish_44[0][0]']               \n",
            "                                                                                                  \n",
            " activation_14 (Activation)     (None, 1, 1, 1152)   0           ['conv2d_58[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_14 (Multiply)         (None, 5, 5, 1152)   0           ['activation_14[0][0]',          \n",
            "                                                                  'swish_43[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_59 (Conv2D)             (None, 5, 5, 192)    221184      ['multiply_14[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_44 (BatchN  (None, 5, 5, 192)   768         ['conv2d_59[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_8 (DropConnect)   (None, 5, 5, 192)    0           ['batch_normalization_44[0][0]'] \n",
            "                                                                                                  \n",
            " add_8 (Add)                    (None, 5, 5, 192)    0           ['drop_connect_8[0][0]',         \n",
            "                                                                  'add_7[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_60 (Conv2D)             (None, 5, 5, 1152)   221184      ['add_8[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_45 (BatchN  (None, 5, 5, 1152)  4608        ['conv2d_60[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_45 (Swish)               (None, 5, 5, 1152)   0           ['batch_normalization_45[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_15 (Depthwise  (None, 5, 5, 1152)  10368       ['swish_45[0][0]']               \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_46 (BatchN  (None, 5, 5, 1152)  4608        ['depthwise_conv2d_15[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_46 (Swish)               (None, 5, 5, 1152)   0           ['batch_normalization_46[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_15 (Lambda)             (None, 1, 1, 1152)   0           ['swish_46[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_61 (Conv2D)             (None, 1, 1, 48)     55344       ['lambda_15[0][0]']              \n",
            "                                                                                                  \n",
            " swish_47 (Swish)               (None, 1, 1, 48)     0           ['conv2d_61[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_62 (Conv2D)             (None, 1, 1, 1152)   56448       ['swish_47[0][0]']               \n",
            "                                                                                                  \n",
            " activation_15 (Activation)     (None, 1, 1, 1152)   0           ['conv2d_62[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_15 (Multiply)         (None, 5, 5, 1152)   0           ['activation_15[0][0]',          \n",
            "                                                                  'swish_46[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_63 (Conv2D)             (None, 5, 5, 320)    368640      ['multiply_15[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_47 (BatchN  (None, 5, 5, 320)   1280        ['conv2d_63[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_64 (Conv2D)             (None, 5, 5, 1280)   409600      ['batch_normalization_47[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_48 (BatchN  (None, 5, 5, 1280)  5120        ['conv2d_64[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_48 (Swish)               (None, 5, 5, 1280)   0           ['batch_normalization_48[0][0]'] \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 4,049,564\n",
            "Trainable params: 0\n",
            "Non-trainable params: 4,049,564\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#สร้างโฟลเดอร์ Train Valodation และ Test"
      ],
      "metadata": {
        "id": "J36J9EAE7qSB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv (r'/content/drive/MyDrive/cut_panoramic/Data/New_Data_Gender.csv')\n",
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "skoKhKJDngAZ",
        "outputId": "c5b33cd5-6095-4f6d-a71d-6403f9a69e1b"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      Fig_Age  Fig_Person_Sex  Age(year) Class  Class_Re       Filename  \\\n",
              "0           1               1          7  Y07F         0         V1.jpg   \n",
              "1           2               1          7  Y07F         0    Flip_V1.jpg   \n",
              "2           3               2          7  Y07F         0         V2.jpg   \n",
              "3           4               2          7  Y07F         0    Flip_V2.jpg   \n",
              "4           5               3          7  Y07F         0         V3.jpg   \n",
              "...       ...             ...        ...   ...       ...            ...   \n",
              "4745      121              77         25  Y25M         1  Flip_J463.jpg   \n",
              "4746      122              78         25  Y25M         1       J464.jpg   \n",
              "4747      123              78         25  Y25M         1  Flip_J464.jpg   \n",
              "4748      124              79         25  Y25M         1       J465.jpg   \n",
              "4749      125              79         25  Y25M         1  Flip_J465.jpg   \n",
              "\n",
              "                                          Path_filename     Sex Floder  \n",
              "0     /content/drive/My Drive/TVT_Gender/train/Femal...  Female   Both  \n",
              "1     /content/drive/My Drive/TVT_Gender/train/Femal...  Female   Both  \n",
              "2     /content/drive/My Drive/TVT_Gender/train/Femal...  Female   Both  \n",
              "3     /content/drive/My Drive/TVT_Gender/train/Femal...  Female   Both  \n",
              "4     /content/drive/My Drive/TVT_Gender/train/Femal...  Female   Both  \n",
              "...                                                 ...     ...    ...  \n",
              "4745  /content/drive/My Drive/TVT_Gender/test/Male/F...    Male   Both  \n",
              "4746  /content/drive/My Drive/TVT_Gender/test/Male/J...    Male   Both  \n",
              "4747  /content/drive/My Drive/TVT_Gender/test/Male/F...    Male   Both  \n",
              "4748  /content/drive/My Drive/TVT_Gender/test/Male/J...    Male   Both  \n",
              "4749  /content/drive/My Drive/TVT_Gender/test/Male/F...    Male   Both  \n",
              "\n",
              "[4750 rows x 9 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a7a16db5-6fa4-4a43-aee3-6896d23b4796\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Fig_Age</th>\n",
              "      <th>Fig_Person_Sex</th>\n",
              "      <th>Age(year)</th>\n",
              "      <th>Class</th>\n",
              "      <th>Class_Re</th>\n",
              "      <th>Filename</th>\n",
              "      <th>Path_filename</th>\n",
              "      <th>Sex</th>\n",
              "      <th>Floder</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>Y07F</td>\n",
              "      <td>0</td>\n",
              "      <td>V1.jpg</td>\n",
              "      <td>/content/drive/My Drive/TVT_Gender/train/Femal...</td>\n",
              "      <td>Female</td>\n",
              "      <td>Both</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>Y07F</td>\n",
              "      <td>0</td>\n",
              "      <td>Flip_V1.jpg</td>\n",
              "      <td>/content/drive/My Drive/TVT_Gender/train/Femal...</td>\n",
              "      <td>Female</td>\n",
              "      <td>Both</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>7</td>\n",
              "      <td>Y07F</td>\n",
              "      <td>0</td>\n",
              "      <td>V2.jpg</td>\n",
              "      <td>/content/drive/My Drive/TVT_Gender/train/Femal...</td>\n",
              "      <td>Female</td>\n",
              "      <td>Both</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>7</td>\n",
              "      <td>Y07F</td>\n",
              "      <td>0</td>\n",
              "      <td>Flip_V2.jpg</td>\n",
              "      <td>/content/drive/My Drive/TVT_Gender/train/Femal...</td>\n",
              "      <td>Female</td>\n",
              "      <td>Both</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>7</td>\n",
              "      <td>Y07F</td>\n",
              "      <td>0</td>\n",
              "      <td>V3.jpg</td>\n",
              "      <td>/content/drive/My Drive/TVT_Gender/train/Femal...</td>\n",
              "      <td>Female</td>\n",
              "      <td>Both</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4745</th>\n",
              "      <td>121</td>\n",
              "      <td>77</td>\n",
              "      <td>25</td>\n",
              "      <td>Y25M</td>\n",
              "      <td>1</td>\n",
              "      <td>Flip_J463.jpg</td>\n",
              "      <td>/content/drive/My Drive/TVT_Gender/test/Male/F...</td>\n",
              "      <td>Male</td>\n",
              "      <td>Both</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4746</th>\n",
              "      <td>122</td>\n",
              "      <td>78</td>\n",
              "      <td>25</td>\n",
              "      <td>Y25M</td>\n",
              "      <td>1</td>\n",
              "      <td>J464.jpg</td>\n",
              "      <td>/content/drive/My Drive/TVT_Gender/test/Male/J...</td>\n",
              "      <td>Male</td>\n",
              "      <td>Both</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4747</th>\n",
              "      <td>123</td>\n",
              "      <td>78</td>\n",
              "      <td>25</td>\n",
              "      <td>Y25M</td>\n",
              "      <td>1</td>\n",
              "      <td>Flip_J464.jpg</td>\n",
              "      <td>/content/drive/My Drive/TVT_Gender/test/Male/F...</td>\n",
              "      <td>Male</td>\n",
              "      <td>Both</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4748</th>\n",
              "      <td>124</td>\n",
              "      <td>79</td>\n",
              "      <td>25</td>\n",
              "      <td>Y25M</td>\n",
              "      <td>1</td>\n",
              "      <td>J465.jpg</td>\n",
              "      <td>/content/drive/My Drive/TVT_Gender/test/Male/J...</td>\n",
              "      <td>Male</td>\n",
              "      <td>Both</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4749</th>\n",
              "      <td>125</td>\n",
              "      <td>79</td>\n",
              "      <td>25</td>\n",
              "      <td>Y25M</td>\n",
              "      <td>1</td>\n",
              "      <td>Flip_J465.jpg</td>\n",
              "      <td>/content/drive/My Drive/TVT_Gender/test/Male/F...</td>\n",
              "      <td>Male</td>\n",
              "      <td>Both</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4750 rows × 9 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a7a16db5-6fa4-4a43-aee3-6896d23b4796')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a7a16db5-6fa4-4a43-aee3-6896d23b4796 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a7a16db5-6fa4-4a43-aee3-6896d23b4796');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train = df[df['Fig_Age'].between(1,75)]\n",
        "val = df[df['Fig_Age'].between(76,100)]"
      ],
      "metadata": {
        "id": "Z1zBw01Gl8Ac"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DATA_PATH = \"/content/drive/My Drive/TVT_Gender\"\n",
        "os.chdir(DATA_PATH)\n",
        "train_dir = os.path.join(DATA_PATH, 'train')\n",
        "print(train_dir)\n",
        "validation_dir = os.path.join(DATA_PATH, 'validation')\n",
        "print(validation_dir)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QL0g-8iOnMC4",
        "outputId": "35897fc7-a0de-4c88-f411-88ca05f3d077"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/My Drive/TVT_Gender/train\n",
            "/content/drive/My Drive/TVT_Gender/validation\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "#Train"
      ],
      "metadata": {
        "id": "bWEnlTSwazL5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train ด้วย ImageDataGenerator ของ Keras ซึ่งจะเพิ่มข้อมูลเสริมระหว่างการฝึกเพื่อลดโอกาสเกิด overfitting\n",
        "#overfitting เกิดจากข้อมูลที่ซับซ้อนกันเกินไป\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "train_datagen = ImageDataGenerator(\n",
        "      rescale=1./255, #โมเดลส่วนใหญ่ต้องใช้ RGB ในช่วง 0–1\n",
        "      rotation_range=40,\n",
        "      width_shift_range=0.2,\n",
        "      height_shift_range=0.2,\n",
        "      shear_range=0.2,\n",
        "      zoom_range=0.2,\n",
        "      horizontal_flip=True,\n",
        "      fill_mode='nearest')\n",
        "\n",
        "# Note that the validation data should not be augmented!\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)"
      ],
      "metadata": {
        "id": "xGPrsn9no_pa"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_generator = train_datagen.flow_from_dataframe(\n",
        "        dataframe = train,\n",
        "        directory = train_dir,\n",
        "        x_col = 'Path_filename',\n",
        "        y_col = 'Class_Re',\n",
        "        class_mode = 'other',\n",
        "        target_size=(height, width),\n",
        "        batch_size=batch_size)\n",
        "\n",
        "validation_generator = test_datagen.flow_from_dataframe(\n",
        "        dataframe = val,\n",
        "        directory = validation_dir,\n",
        "        x_col = 'Path_filename',\n",
        "        y_col = 'Class_Re',\n",
        "        class_mode = 'other',\n",
        "        target_size=(height, width),\n",
        "        batch_size=batch_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8nVlmAszntK_",
        "outputId": "449f73dc-2497-4dc5-a9d5-5f8faf362156"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 2850 validated image filenames.\n",
            "Found 950 validated image filenames.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='mse',\n",
        "          optimizer=Adam(learning_rate=1e-4),\n",
        "          metrics=['mae'])\n",
        "history = model.fit_generator(\n",
        "      train_generator,\n",
        "      steps_per_epoch= NUM_TRAIN //batch_size,\n",
        "      epochs=epochs,\n",
        "      validation_data=validation_generator,\n",
        "      validation_steps= NUM_TEST //batch_size,\n",
        "      verbose=1,\n",
        "      use_multiprocessing=True,\n",
        "      workers=4)"
      ],
      "metadata": {
        "id": "N6qUmmF856ZE",
        "outputId": "0fcebf87-814a-40db-beed-a0bdd2eb4add",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-18-f59104fd3985>:4: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  history = model.fit_generator(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/250\n",
            "178/178 [==============================] - 379s 2s/step - loss: 1.8168 - mae: 1.2514 - val_loss: 1.7706 - val_mae: 1.2331\n",
            "Epoch 2/250\n",
            "178/178 [==============================] - 46s 254ms/step - loss: 1.7270 - mae: 1.2153 - val_loss: 1.6858 - val_mae: 1.1983\n",
            "Epoch 3/250\n",
            "178/178 [==============================] - 46s 257ms/step - loss: 1.6431 - mae: 1.1803 - val_loss: 1.6002 - val_mae: 1.1620\n",
            "Epoch 4/250\n",
            "178/178 [==============================] - 46s 257ms/step - loss: 1.5653 - mae: 1.1468 - val_loss: 1.5274 - val_mae: 1.1302\n",
            "Epoch 5/250\n",
            "178/178 [==============================] - 46s 256ms/step - loss: 1.4911 - mae: 1.1140 - val_loss: 1.4532 - val_mae: 1.0969\n",
            "Epoch 6/250\n",
            "178/178 [==============================] - 46s 249ms/step - loss: 1.4145 - mae: 1.0789 - val_loss: 1.3820 - val_mae: 1.0639\n",
            "Epoch 7/250\n",
            "178/178 [==============================] - 45s 251ms/step - loss: 1.3456 - mae: 1.0465 - val_loss: 1.3091 - val_mae: 1.0291\n",
            "Epoch 8/250\n",
            "178/178 [==============================] - 42s 233ms/step - loss: 1.2780 - mae: 1.0138 - val_loss: 1.2419 - val_mae: 0.9959\n",
            "Epoch 9/250\n",
            "178/178 [==============================] - 47s 259ms/step - loss: 1.2132 - mae: 0.9813 - val_loss: 1.1875 - val_mae: 0.9682\n",
            "Epoch 10/250\n",
            "178/178 [==============================] - 48s 264ms/step - loss: 1.1566 - mae: 0.9522 - val_loss: 1.1231 - val_mae: 0.9344\n",
            "Epoch 11/250\n",
            "178/178 [==============================] - 47s 260ms/step - loss: 1.0945 - mae: 0.9189 - val_loss: 1.0659 - val_mae: 0.9033\n",
            "Epoch 12/250\n",
            "178/178 [==============================] - 47s 261ms/step - loss: 1.0365 - mae: 0.8869 - val_loss: 1.0053 - val_mae: 0.8691\n",
            "Epoch 13/250\n",
            "178/178 [==============================] - 48s 266ms/step - loss: 0.9857 - mae: 0.8577 - val_loss: 0.9619 - val_mae: 0.8438\n",
            "Epoch 14/250\n",
            "178/178 [==============================] - 47s 260ms/step - loss: 0.9340 - mae: 0.8271 - val_loss: 0.9069 - val_mae: 0.8105\n",
            "Epoch 15/250\n",
            "178/178 [==============================] - 45s 247ms/step - loss: 0.8863 - mae: 0.7976 - val_loss: 0.8607 - val_mae: 0.7815\n",
            "Epoch 16/250\n",
            "178/178 [==============================] - 42s 232ms/step - loss: 0.8359 - mae: 0.7655 - val_loss: 0.8170 - val_mae: 0.7530\n",
            "Epoch 17/250\n",
            "178/178 [==============================] - 47s 258ms/step - loss: 0.7932 - mae: 0.7368 - val_loss: 0.7706 - val_mae: 0.7215\n",
            "Epoch 18/250\n",
            "178/178 [==============================] - 46s 258ms/step - loss: 0.7507 - mae: 0.7076 - val_loss: 0.7343 - val_mae: 0.6959\n",
            "Epoch 19/250\n",
            "178/178 [==============================] - 47s 259ms/step - loss: 0.7090 - mae: 0.6776 - val_loss: 0.6899 - val_mae: 0.6632\n",
            "Epoch 20/250\n",
            "178/178 [==============================] - 46s 257ms/step - loss: 0.6746 - mae: 0.6516 - val_loss: 0.6558 - val_mae: 0.6370\n",
            "Epoch 21/250\n",
            "178/178 [==============================] - 46s 249ms/step - loss: 0.6390 - mae: 0.6237 - val_loss: 0.6183 - val_mae: 0.6068\n",
            "Epoch 22/250\n",
            "178/178 [==============================] - 45s 248ms/step - loss: 0.6030 - mae: 0.5941 - val_loss: 0.5878 - val_mae: 0.5812\n",
            "Epoch 23/250\n",
            "178/178 [==============================] - 46s 257ms/step - loss: 0.5738 - mae: 0.5690 - val_loss: 0.5555 - val_mae: 0.5527\n",
            "Epoch 24/250\n",
            "178/178 [==============================] - 47s 259ms/step - loss: 0.5425 - mae: 0.5406 - val_loss: 0.5275 - val_mae: 0.5268\n",
            "Epoch 25/250\n",
            "178/178 [==============================] - 46s 258ms/step - loss: 0.5134 - mae: 0.5131 - val_loss: 0.4982 - val_mae: 0.4982\n",
            "Epoch 26/250\n",
            "178/178 [==============================] - 46s 257ms/step - loss: 0.4874 - mae: 0.4999 - val_loss: 0.4746 - val_mae: 0.5000\n",
            "Epoch 27/250\n",
            "178/178 [==============================] - 41s 222ms/step - loss: 0.4617 - mae: 0.4991 - val_loss: 0.4508 - val_mae: 0.5000\n",
            "Epoch 28/250\n",
            "178/178 [==============================] - 46s 256ms/step - loss: 0.4396 - mae: 0.4997 - val_loss: 0.4269 - val_mae: 0.4982\n",
            "Epoch 29/250\n",
            "178/178 [==============================] - 43s 237ms/step - loss: 0.4184 - mae: 0.5000 - val_loss: 0.4065 - val_mae: 0.4983\n",
            "Epoch 30/250\n",
            "178/178 [==============================] - 45s 248ms/step - loss: 0.3982 - mae: 0.4997 - val_loss: 0.3893 - val_mae: 0.5000\n",
            "Epoch 31/250\n",
            "178/178 [==============================] - 45s 249ms/step - loss: 0.3810 - mae: 0.4999 - val_loss: 0.3707 - val_mae: 0.4985\n",
            "Epoch 32/250\n",
            "178/178 [==============================] - 46s 258ms/step - loss: 0.3631 - mae: 0.4989 - val_loss: 0.3578 - val_mae: 0.5014\n",
            "Epoch 33/250\n",
            "178/178 [==============================] - 46s 257ms/step - loss: 0.3493 - mae: 0.5003 - val_loss: 0.3422 - val_mae: 0.5000\n",
            "Epoch 34/250\n",
            "178/178 [==============================] - 46s 257ms/step - loss: 0.3355 - mae: 0.4999 - val_loss: 0.3287 - val_mae: 0.4994\n",
            "Epoch 35/250\n",
            "178/178 [==============================] - 46s 257ms/step - loss: 0.3235 - mae: 0.5003 - val_loss: 0.3175 - val_mae: 0.5000\n",
            "Epoch 36/250\n",
            "178/178 [==============================] - 46s 255ms/step - loss: 0.3118 - mae: 0.4997 - val_loss: 0.3072 - val_mae: 0.5000\n",
            "Epoch 37/250\n",
            "178/178 [==============================] - 46s 249ms/step - loss: 0.3021 - mae: 0.4997 - val_loss: 0.2969 - val_mae: 0.4991\n",
            "Epoch 38/250\n",
            "178/178 [==============================] - 45s 248ms/step - loss: 0.2938 - mae: 0.5001 - val_loss: 0.2894 - val_mae: 0.4996\n",
            "Epoch 39/250\n",
            "178/178 [==============================] - 42s 231ms/step - loss: 0.2860 - mae: 0.4998 - val_loss: 0.2831 - val_mae: 0.5004\n",
            "Epoch 40/250\n",
            "178/178 [==============================] - 46s 256ms/step - loss: 0.2796 - mae: 0.5002 - val_loss: 0.2764 - val_mae: 0.5000\n",
            "Epoch 41/250\n",
            "178/178 [==============================] - 46s 258ms/step - loss: 0.2740 - mae: 0.5003 - val_loss: 0.2715 - val_mae: 0.5003\n",
            "Epoch 42/250\n",
            "178/178 [==============================] - 46s 258ms/step - loss: 0.2689 - mae: 0.4999 - val_loss: 0.2668 - val_mae: 0.5000\n",
            "Epoch 43/250\n",
            "178/178 [==============================] - 45s 247ms/step - loss: 0.2648 - mae: 0.5001 - val_loss: 0.2627 - val_mae: 0.4998\n",
            "Epoch 44/250\n",
            "178/178 [==============================] - 46s 256ms/step - loss: 0.2613 - mae: 0.4999 - val_loss: 0.2600 - val_mae: 0.5000\n",
            "Epoch 45/250\n",
            "178/178 [==============================] - 47s 260ms/step - loss: 0.2589 - mae: 0.5001 - val_loss: 0.2575 - val_mae: 0.5000\n",
            "Epoch 46/250\n",
            "178/178 [==============================] - 47s 260ms/step - loss: 0.2566 - mae: 0.5000 - val_loss: 0.2557 - val_mae: 0.5002\n",
            "Epoch 47/250\n",
            "178/178 [==============================] - 47s 259ms/step - loss: 0.2549 - mae: 0.5001 - val_loss: 0.2541 - val_mae: 0.5000\n",
            "Epoch 48/250\n",
            "178/178 [==============================] - 46s 252ms/step - loss: 0.2535 - mae: 0.5000 - val_loss: 0.2530 - val_mae: 0.5000\n",
            "Epoch 49/250\n",
            "178/178 [==============================] - 45s 247ms/step - loss: 0.2525 - mae: 0.4999 - val_loss: 0.2521 - val_mae: 0.5000\n",
            "Epoch 50/250\n",
            "178/178 [==============================] - 47s 260ms/step - loss: 0.2519 - mae: 0.5000 - val_loss: 0.2516 - val_mae: 0.5001\n",
            "Epoch 51/250\n",
            "178/178 [==============================] - 47s 259ms/step - loss: 0.2513 - mae: 0.5000 - val_loss: 0.2511 - val_mae: 0.5000\n",
            "Epoch 52/250\n",
            "178/178 [==============================] - 47s 258ms/step - loss: 0.2509 - mae: 0.5000 - val_loss: 0.2506 - val_mae: 0.4999\n",
            "Epoch 53/250\n",
            "178/178 [==============================] - 47s 257ms/step - loss: 0.2506 - mae: 0.5000 - val_loss: 0.2504 - val_mae: 0.5000\n",
            "Epoch 54/250\n",
            "178/178 [==============================] - 46s 251ms/step - loss: 0.2504 - mae: 0.5000 - val_loss: 0.2504 - val_mae: 0.5001\n",
            "Epoch 55/250\n",
            "178/178 [==============================] - 44s 246ms/step - loss: 0.2502 - mae: 0.5000 - val_loss: 0.2501 - val_mae: 0.5000\n",
            "Epoch 56/250\n",
            "178/178 [==============================] - 42s 234ms/step - loss: 0.2502 - mae: 0.5000 - val_loss: 0.2501 - val_mae: 0.5000\n",
            "Epoch 57/250\n",
            "178/178 [==============================] - 47s 260ms/step - loss: 0.2501 - mae: 0.5000 - val_loss: 0.2501 - val_mae: 0.5000\n",
            "Epoch 58/250\n",
            "178/178 [==============================] - 47s 261ms/step - loss: 0.2501 - mae: 0.5000 - val_loss: 0.2500 - val_mae: 0.5000\n",
            "Epoch 59/250\n",
            "178/178 [==============================] - 47s 259ms/step - loss: 0.2500 - mae: 0.5000 - val_loss: 0.2500 - val_mae: 0.5000\n",
            "Epoch 60/250\n",
            "178/178 [==============================] - 47s 256ms/step - loss: 0.2500 - mae: 0.5000 - val_loss: 0.2500 - val_mae: 0.5000\n",
            "Epoch 61/250\n",
            "178/178 [==============================] - 45s 249ms/step - loss: 0.2500 - mae: 0.5000 - val_loss: 0.2500 - val_mae: 0.5000\n",
            "Epoch 62/250\n",
            "178/178 [==============================] - 47s 259ms/step - loss: 0.2500 - mae: 0.5000 - val_loss: 0.2500 - val_mae: 0.5000\n",
            "Epoch 63/250\n",
            "178/178 [==============================] - 47s 259ms/step - loss: 0.2500 - mae: 0.5000 - val_loss: 0.2500 - val_mae: 0.5000\n",
            "Epoch 64/250\n",
            "178/178 [==============================] - 46s 257ms/step - loss: 0.2500 - mae: 0.5000 - val_loss: 0.2500 - val_mae: 0.5000\n",
            "Epoch 65/250\n",
            "178/178 [==============================] - 46s 253ms/step - loss: 0.2500 - mae: 0.5000 - val_loss: 0.2500 - val_mae: 0.5000\n",
            "Epoch 66/250\n",
            "178/178 [==============================] - 45s 247ms/step - loss: 0.2500 - mae: 0.5000 - val_loss: 0.2500 - val_mae: 0.5000\n",
            "Epoch 67/250\n",
            "178/178 [==============================] - 44s 242ms/step - loss: 0.2500 - mae: 0.5000 - val_loss: 0.2500 - val_mae: 0.5000\n",
            "Epoch 68/250\n",
            "178/178 [==============================] - 46s 254ms/step - loss: 0.2500 - mae: 0.5000 - val_loss: 0.2500 - val_mae: 0.5000\n",
            "Epoch 69/250\n",
            "178/178 [==============================] - 46s 253ms/step - loss: 0.2500 - mae: 0.5000 - val_loss: 0.2500 - val_mae: 0.5000\n",
            "Epoch 70/250\n",
            "178/178 [==============================] - 46s 255ms/step - loss: 0.2500 - mae: 0.5000 - val_loss: 0.2500 - val_mae: 0.5000\n",
            "Epoch 71/250\n",
            "178/178 [==============================] - 46s 254ms/step - loss: 0.2500 - mae: 0.5000 - val_loss: 0.2500 - val_mae: 0.5000\n",
            "Epoch 72/250\n",
            "178/178 [==============================] - 45s 245ms/step - loss: 0.2500 - mae: 0.5000 - val_loss: 0.2500 - val_mae: 0.5000\n",
            "Epoch 73/250\n",
            "178/178 [==============================] - 46s 256ms/step - loss: 0.2500 - mae: 0.5000 - val_loss: 0.2500 - val_mae: 0.5000\n",
            "Epoch 74/250\n",
            "178/178 [==============================] - 46s 255ms/step - loss: 0.2500 - mae: 0.5000 - val_loss: 0.2500 - val_mae: 0.5000\n",
            "Epoch 75/250\n",
            "178/178 [==============================] - 46s 254ms/step - loss: 0.2500 - mae: 0.5000 - val_loss: 0.2500 - val_mae: 0.5000\n",
            "Epoch 76/250\n",
            "178/178 [==============================] - 46s 255ms/step - loss: 0.2500 - mae: 0.5000 - val_loss: 0.2500 - val_mae: 0.5000\n",
            "Epoch 77/250\n",
            "178/178 [==============================] - 46s 255ms/step - loss: 0.2500 - mae: 0.5000 - val_loss: 0.2500 - val_mae: 0.5000\n",
            "Epoch 78/250\n",
            "178/178 [==============================] - 46s 249ms/step - loss: 0.2500 - mae: 0.5000 - val_loss: 0.2500 - val_mae: 0.5000\n",
            "Epoch 79/250\n",
            "178/178 [==============================] - 44s 244ms/step - loss: 0.2500 - mae: 0.5000 - val_loss: 0.2500 - val_mae: 0.5000\n",
            "Epoch 80/250\n",
            "178/178 [==============================] - 46s 255ms/step - loss: 0.2500 - mae: 0.5000 - val_loss: 0.2500 - val_mae: 0.5000\n",
            "Epoch 81/250\n",
            "178/178 [==============================] - 46s 254ms/step - loss: 0.2500 - mae: 0.5000 - val_loss: 0.2500 - val_mae: 0.5000\n",
            "Epoch 82/250\n",
            "178/178 [==============================] - 46s 255ms/step - loss: 0.2500 - mae: 0.5000 - val_loss: 0.2500 - val_mae: 0.5000\n",
            "Epoch 83/250\n",
            "178/178 [==============================] - 46s 253ms/step - loss: 0.2500 - mae: 0.5000 - val_loss: 0.2500 - val_mae: 0.5000\n",
            "Epoch 84/250\n",
            "178/178 [==============================] - 45s 247ms/step - loss: 0.2500 - mae: 0.5000 - val_loss: 0.2500 - val_mae: 0.5000\n",
            "Epoch 85/250\n",
            "178/178 [==============================] - 44s 245ms/step - loss: 0.2500 - mae: 0.5000 - val_loss: 0.2500 - val_mae: 0.5000\n",
            "Epoch 86/250\n",
            "178/178 [==============================] - 46s 254ms/step - loss: 0.2500 - mae: 0.5000 - val_loss: 0.2500 - val_mae: 0.5000\n",
            "Epoch 87/250\n",
            "178/178 [==============================] - 46s 255ms/step - loss: 0.2500 - mae: 0.5000 - val_loss: 0.2500 - val_mae: 0.5000\n",
            "Epoch 88/250\n",
            "178/178 [==============================] - 46s 253ms/step - loss: 0.2500 - mae: 0.5000 - val_loss: 0.2500 - val_mae: 0.5000\n",
            "Epoch 89/250\n",
            "178/178 [==============================] - 46s 253ms/step - loss: 0.2500 - mae: 0.5000 - val_loss: 0.2500 - val_mae: 0.5000\n",
            "Epoch 90/250\n",
            "178/178 [==============================] - 44s 242ms/step - loss: 0.2500 - mae: 0.5000 - val_loss: 0.2500 - val_mae: 0.5000\n",
            "Epoch 91/250\n",
            "178/178 [==============================] - 46s 254ms/step - loss: 0.2500 - mae: 0.5000 - val_loss: 0.2500 - val_mae: 0.5000\n",
            "Epoch 92/250\n",
            "178/178 [==============================] - 46s 253ms/step - loss: 0.2500 - mae: 0.5000 - val_loss: 0.2500 - val_mae: 0.5000\n",
            "Epoch 93/250\n",
            "178/178 [==============================] - 46s 254ms/step - loss: 0.2500 - mae: 0.5000 - val_loss: 0.2500 - val_mae: 0.5000\n",
            "Epoch 94/250\n",
            "178/178 [==============================] - 46s 255ms/step - loss: 0.2500 - mae: 0.5000 - val_loss: 0.2500 - val_mae: 0.5000\n",
            "Epoch 95/250\n",
            "178/178 [==============================] - 45s 244ms/step - loss: 0.2500 - mae: 0.5000 - val_loss: 0.2500 - val_mae: 0.5000\n",
            "Epoch 96/250\n",
            "178/178 [==============================] - 44s 245ms/step - loss: 0.2500 - mae: 0.5000 - val_loss: 0.2500 - val_mae: 0.5000\n",
            "Epoch 97/250\n",
            "178/178 [==============================] - 46s 257ms/step - loss: 0.2500 - mae: 0.5000 - val_loss: 0.2500 - val_mae: 0.5000\n",
            "Epoch 98/250\n",
            "178/178 [==============================] - 46s 255ms/step - loss: 0.2500 - mae: 0.5000 - val_loss: 0.2500 - val_mae: 0.5000\n",
            "Epoch 99/250\n",
            "178/178 [==============================] - 41s 229ms/step - loss: 0.2500 - mae: 0.5000 - val_loss: 0.2500 - val_mae: 0.5000\n",
            "Epoch 100/250\n",
            "178/178 [==============================] - 46s 254ms/step - loss: 0.2498 - mae: 0.4996 - val_loss: 0.2500 - val_mae: 0.5000\n",
            "Epoch 101/250\n",
            "178/178 [==============================] - 42s 232ms/step - loss: 0.2500 - mae: 0.5000 - val_loss: 0.2500 - val_mae: 0.5000\n",
            "Epoch 102/250\n",
            "178/178 [==============================] - 45s 245ms/step - loss: 0.2500 - mae: 0.5000 - val_loss: 0.2500 - val_mae: 0.5000\n",
            "Epoch 103/250\n",
            "178/178 [==============================] - 45s 251ms/step - loss: 0.2500 - mae: 0.5000 - val_loss: 0.2500 - val_mae: 0.5000\n",
            "Epoch 104/250\n",
            "178/178 [==============================] - 46s 255ms/step - loss: 0.2500 - mae: 0.5000 - val_loss: 0.2500 - val_mae: 0.5000\n",
            "Epoch 105/250\n",
            "178/178 [==============================] - 46s 256ms/step - loss: 0.2500 - mae: 0.5000 - val_loss: 0.2500 - val_mae: 0.5000\n",
            "Epoch 106/250\n",
            "178/178 [==============================] - 46s 256ms/step - loss: 0.2500 - mae: 0.5000 - val_loss: 0.2500 - val_mae: 0.5000\n",
            "Epoch 107/250\n",
            "178/178 [==============================] - 46s 252ms/step - loss: 0.2500 - mae: 0.5000 - val_loss: 0.2500 - val_mae: 0.5000\n",
            "Epoch 108/250\n",
            "178/178 [==============================] - 45s 246ms/step - loss: 0.2500 - mae: 0.5000 - val_loss: 0.2500 - val_mae: 0.5000\n",
            "Epoch 109/250\n",
            "178/178 [==============================] - 45s 249ms/step - loss: 0.2500 - mae: 0.5000 - val_loss: 0.2500 - val_mae: 0.5000\n",
            "Epoch 110/250\n",
            "178/178 [==============================] - 46s 255ms/step - loss: 0.2500 - mae: 0.5000 - val_loss: 0.2500 - val_mae: 0.5000\n",
            "Epoch 111/250\n",
            "178/178 [==============================] - 46s 255ms/step - loss: 0.2500 - mae: 0.5000 - val_loss: 0.2500 - val_mae: 0.5000\n",
            "Epoch 112/250\n",
            "178/178 [==============================] - 46s 256ms/step - loss: 0.2500 - mae: 0.4999 - val_loss: 0.2500 - val_mae: 0.5000\n",
            "Epoch 113/250\n",
            "178/178 [==============================] - 46s 254ms/step - loss: 0.2499 - mae: 0.4995 - val_loss: 0.2500 - val_mae: 0.5000\n",
            "Epoch 114/250\n",
            "178/178 [==============================] - 41s 224ms/step - loss: 0.2503 - mae: 0.5001 - val_loss: 0.2500 - val_mae: 0.5000\n",
            "Epoch 115/250\n",
            "178/178 [==============================] - 44s 242ms/step - loss: 0.2500 - mae: 0.5000 - val_loss: 0.2500 - val_mae: 0.5000\n",
            "Epoch 116/250\n",
            "178/178 [==============================] - 46s 256ms/step - loss: 0.2497 - mae: 0.4997 - val_loss: 0.2500 - val_mae: 0.5000\n",
            "Epoch 117/250\n",
            "178/178 [==============================] - 46s 255ms/step - loss: 0.2501 - mae: 0.4999 - val_loss: 0.2500 - val_mae: 0.5000\n",
            "Epoch 118/250\n",
            "178/178 [==============================] - 46s 254ms/step - loss: 0.2501 - mae: 0.5001 - val_loss: 0.2500 - val_mae: 0.5000\n",
            "Epoch 119/250\n",
            "178/178 [==============================] - 46s 251ms/step - loss: 0.2500 - mae: 0.4998 - val_loss: 0.2500 - val_mae: 0.5000\n",
            "Epoch 120/250\n",
            "178/178 [==============================] - 44s 243ms/step - loss: 0.2502 - mae: 0.5001 - val_loss: 0.2500 - val_mae: 0.5000\n",
            "Epoch 121/250\n",
            "178/178 [==============================] - 46s 256ms/step - loss: 0.2496 - mae: 0.4995 - val_loss: 0.2500 - val_mae: 0.5000\n",
            "Epoch 122/250\n",
            "178/178 [==============================] - 46s 255ms/step - loss: 0.2496 - mae: 0.4990 - val_loss: 0.2500 - val_mae: 0.5000\n",
            "Epoch 123/250\n",
            "178/178 [==============================] - 46s 255ms/step - loss: 0.2495 - mae: 0.4993 - val_loss: 0.2500 - val_mae: 0.4999\n",
            "Epoch 124/250\n",
            "178/178 [==============================] - 47s 259ms/step - loss: 0.2501 - mae: 0.4999 - val_loss: 0.2500 - val_mae: 0.5000\n",
            "Epoch 125/250\n",
            "178/178 [==============================] - 46s 249ms/step - loss: 0.2488 - mae: 0.4972 - val_loss: 0.2500 - val_mae: 0.5000\n",
            "Epoch 126/250\n",
            "178/178 [==============================] - 44s 243ms/step - loss: 0.2494 - mae: 0.4990 - val_loss: 0.2499 - val_mae: 0.4999\n",
            "Epoch 127/250\n",
            "178/178 [==============================] - 46s 256ms/step - loss: 0.2491 - mae: 0.4979 - val_loss: 0.2500 - val_mae: 0.5000\n",
            "Epoch 128/250\n",
            "178/178 [==============================] - 46s 256ms/step - loss: 0.2496 - mae: 0.4989 - val_loss: 0.2500 - val_mae: 0.5000\n",
            "Epoch 129/250\n",
            "178/178 [==============================] - 42s 234ms/step - loss: 0.2495 - mae: 0.4981 - val_loss: 0.2500 - val_mae: 0.5000\n",
            "Epoch 130/250\n",
            "178/178 [==============================] - 46s 255ms/step - loss: 0.2480 - mae: 0.4963 - val_loss: 0.2500 - val_mae: 0.4999\n",
            "Epoch 131/250\n",
            "178/178 [==============================] - 46s 256ms/step - loss: 0.2475 - mae: 0.4950 - val_loss: 0.2501 - val_mae: 0.4999\n",
            "Epoch 132/250\n",
            "178/178 [==============================] - 42s 232ms/step - loss: 0.2473 - mae: 0.4950 - val_loss: 0.2494 - val_mae: 0.4993\n",
            "Epoch 133/250\n",
            "178/178 [==============================] - 45s 247ms/step - loss: 0.2479 - mae: 0.4943 - val_loss: 0.2497 - val_mae: 0.4995\n",
            "Epoch 134/250\n",
            "178/178 [==============================] - 44s 247ms/step - loss: 0.2458 - mae: 0.4916 - val_loss: 0.2500 - val_mae: 0.4998\n",
            "Epoch 135/250\n",
            "178/178 [==============================] - 47s 260ms/step - loss: 0.2444 - mae: 0.4887 - val_loss: 0.2496 - val_mae: 0.4993\n",
            "Epoch 136/250\n",
            "178/178 [==============================] - 46s 258ms/step - loss: 0.2473 - mae: 0.4936 - val_loss: 0.2502 - val_mae: 0.4998\n",
            "Epoch 137/250\n",
            "178/178 [==============================] - 47s 258ms/step - loss: 0.2474 - mae: 0.4949 - val_loss: 0.2500 - val_mae: 0.4996\n",
            "Epoch 138/250\n",
            "178/178 [==============================] - 46s 258ms/step - loss: 0.2476 - mae: 0.4933 - val_loss: 0.2494 - val_mae: 0.4991\n",
            "Epoch 139/250\n",
            "178/178 [==============================] - 45s 247ms/step - loss: 0.2476 - mae: 0.4938 - val_loss: 0.2493 - val_mae: 0.4989\n",
            "Epoch 140/250\n",
            "178/178 [==============================] - 44s 244ms/step - loss: 0.2469 - mae: 0.4906 - val_loss: 0.2490 - val_mae: 0.4986\n",
            "Epoch 141/250\n",
            "178/178 [==============================] - 46s 255ms/step - loss: 0.2468 - mae: 0.4923 - val_loss: 0.2494 - val_mae: 0.4989\n",
            "Epoch 142/250\n",
            "178/178 [==============================] - 46s 257ms/step - loss: 0.2482 - mae: 0.4931 - val_loss: 0.2493 - val_mae: 0.4988\n",
            "Epoch 143/250\n",
            "178/178 [==============================] - 46s 257ms/step - loss: 0.2476 - mae: 0.4932 - val_loss: 0.2494 - val_mae: 0.4989\n",
            "Epoch 144/250\n",
            "178/178 [==============================] - 46s 255ms/step - loss: 0.2438 - mae: 0.4860 - val_loss: 0.2507 - val_mae: 0.4999\n",
            "Epoch 145/250\n",
            "178/178 [==============================] - 44s 245ms/step - loss: 0.2469 - mae: 0.4941 - val_loss: 0.2497 - val_mae: 0.4991\n",
            "Epoch 146/250\n",
            "178/178 [==============================] - 46s 256ms/step - loss: 0.2452 - mae: 0.4898 - val_loss: 0.2491 - val_mae: 0.4984\n",
            "Epoch 147/250\n",
            "178/178 [==============================] - 47s 258ms/step - loss: 0.2459 - mae: 0.4909 - val_loss: 0.2496 - val_mae: 0.4990\n",
            "Epoch 148/250\n",
            "178/178 [==============================] - 46s 256ms/step - loss: 0.2452 - mae: 0.4897 - val_loss: 0.2497 - val_mae: 0.4990\n",
            "Epoch 149/250\n",
            "178/178 [==============================] - 42s 229ms/step - loss: 0.2443 - mae: 0.4893 - val_loss: 0.2490 - val_mae: 0.4982\n",
            "Epoch 150/250\n",
            "178/178 [==============================] - 47s 259ms/step - loss: 0.2434 - mae: 0.4862 - val_loss: 0.2504 - val_mae: 0.4994\n",
            "Epoch 151/250\n",
            "178/178 [==============================] - 46s 256ms/step - loss: 0.2429 - mae: 0.4859 - val_loss: 0.2505 - val_mae: 0.4994\n",
            "Epoch 152/250\n",
            "178/178 [==============================] - 46s 250ms/step - loss: 0.2436 - mae: 0.4862 - val_loss: 0.2466 - val_mae: 0.4955\n",
            "Epoch 153/250\n",
            "178/178 [==============================] - 45s 252ms/step - loss: 0.2436 - mae: 0.4858 - val_loss: 0.2480 - val_mae: 0.4968\n",
            "Epoch 154/250\n",
            "178/178 [==============================] - 47s 259ms/step - loss: 0.2440 - mae: 0.4868 - val_loss: 0.2493 - val_mae: 0.4979\n",
            "Epoch 155/250\n",
            "178/178 [==============================] - 47s 258ms/step - loss: 0.2435 - mae: 0.4854 - val_loss: 0.2509 - val_mae: 0.4992\n",
            "Epoch 156/250\n",
            "178/178 [==============================] - 46s 256ms/step - loss: 0.2433 - mae: 0.4853 - val_loss: 0.2447 - val_mae: 0.4931\n",
            "Epoch 157/250\n",
            "178/178 [==============================] - 46s 252ms/step - loss: 0.2436 - mae: 0.4843 - val_loss: 0.2500 - val_mae: 0.4984\n",
            "Epoch 158/250\n",
            "178/178 [==============================] - 45s 246ms/step - loss: 0.2441 - mae: 0.4843 - val_loss: 0.2479 - val_mae: 0.4964\n",
            "Epoch 159/250\n",
            "178/178 [==============================] - 46s 254ms/step - loss: 0.2428 - mae: 0.4844 - val_loss: 0.2478 - val_mae: 0.4961\n",
            "Epoch 160/250\n",
            "178/178 [==============================] - 46s 258ms/step - loss: 0.2420 - mae: 0.4832 - val_loss: 0.2460 - val_mae: 0.4942\n",
            "Epoch 161/250\n",
            "178/178 [==============================] - 46s 256ms/step - loss: 0.2400 - mae: 0.4798 - val_loss: 0.2460 - val_mae: 0.4942\n",
            "Epoch 162/250\n",
            "178/178 [==============================] - 47s 259ms/step - loss: 0.2438 - mae: 0.4845 - val_loss: 0.2472 - val_mae: 0.4953\n",
            "Epoch 163/250\n",
            "178/178 [==============================] - 47s 258ms/step - loss: 0.2424 - mae: 0.4829 - val_loss: 0.2486 - val_mae: 0.4966\n",
            "Epoch 164/250\n",
            "178/178 [==============================] - 46s 256ms/step - loss: 0.2397 - mae: 0.4790 - val_loss: 0.2409 - val_mae: 0.4884\n",
            "Epoch 165/250\n",
            "178/178 [==============================] - 46s 250ms/step - loss: 0.2407 - mae: 0.4808 - val_loss: 0.2465 - val_mae: 0.4943\n",
            "Epoch 166/250\n",
            "178/178 [==============================] - 46s 255ms/step - loss: 0.2403 - mae: 0.4796 - val_loss: 0.2378 - val_mae: 0.4846\n",
            "Epoch 167/250\n",
            "178/178 [==============================] - 47s 258ms/step - loss: 0.2401 - mae: 0.4788 - val_loss: 0.2389 - val_mae: 0.4859\n",
            "Epoch 168/250\n",
            "178/178 [==============================] - 47s 258ms/step - loss: 0.2445 - mae: 0.4848 - val_loss: 0.2362 - val_mae: 0.4826\n",
            "Epoch 169/250\n",
            "178/178 [==============================] - 46s 256ms/step - loss: 0.2388 - mae: 0.4784 - val_loss: 0.2396 - val_mae: 0.4866\n",
            "Epoch 170/250\n",
            "178/178 [==============================] - 46s 257ms/step - loss: 0.2384 - mae: 0.4744 - val_loss: 0.2270 - val_mae: 0.4695\n",
            "Epoch 171/250\n",
            "178/178 [==============================] - 46s 249ms/step - loss: 0.2401 - mae: 0.4749 - val_loss: 0.2214 - val_mae: 0.4597\n",
            "Epoch 172/250\n",
            "178/178 [==============================] - 46s 252ms/step - loss: 0.2401 - mae: 0.4778 - val_loss: 0.2337 - val_mae: 0.4787\n",
            "Epoch 173/250\n",
            "178/178 [==============================] - 42s 233ms/step - loss: 0.2339 - mae: 0.4692 - val_loss: 0.2174 - val_mae: 0.4515\n",
            "Epoch 174/250\n",
            "178/178 [==============================] - 47s 258ms/step - loss: 0.2368 - mae: 0.4720 - val_loss: 0.2222 - val_mae: 0.4627\n",
            "Epoch 175/250\n",
            "178/178 [==============================] - 46s 257ms/step - loss: 0.2356 - mae: 0.4693 - val_loss: 0.2246 - val_mae: 0.4663\n",
            "Epoch 176/250\n",
            "178/178 [==============================] - 47s 260ms/step - loss: 0.2312 - mae: 0.4637 - val_loss: 0.2309 - val_mae: 0.4745\n",
            "Epoch 177/250\n",
            "178/178 [==============================] - 47s 260ms/step - loss: 0.2331 - mae: 0.4658 - val_loss: 0.2183 - val_mae: 0.4556\n",
            "Epoch 178/250\n",
            "178/178 [==============================] - 46s 257ms/step - loss: 0.2358 - mae: 0.4684 - val_loss: 0.2273 - val_mae: 0.4694\n",
            "Epoch 179/250\n",
            "178/178 [==============================] - 46s 254ms/step - loss: 0.2357 - mae: 0.4685 - val_loss: 0.2203 - val_mae: 0.4590\n",
            "Epoch 180/250\n",
            "178/178 [==============================] - 45s 247ms/step - loss: 0.2356 - mae: 0.4680 - val_loss: 0.2228 - val_mae: 0.4630\n",
            "Epoch 181/250\n",
            "178/178 [==============================] - 46s 254ms/step - loss: 0.2339 - mae: 0.4665 - val_loss: 0.2133 - val_mae: 0.4464\n",
            "Epoch 182/250\n",
            "178/178 [==============================] - 47s 258ms/step - loss: 0.2349 - mae: 0.4669 - val_loss: 0.2179 - val_mae: 0.4552\n",
            "Epoch 183/250\n",
            "178/178 [==============================] - 47s 258ms/step - loss: 0.2322 - mae: 0.4631 - val_loss: 0.2127 - val_mae: 0.4453\n",
            "Epoch 184/250\n",
            "178/178 [==============================] - 47s 259ms/step - loss: 0.2277 - mae: 0.4567 - val_loss: 0.2187 - val_mae: 0.4562\n",
            "Epoch 185/250\n",
            "178/178 [==============================] - 46s 254ms/step - loss: 0.2339 - mae: 0.4634 - val_loss: 0.2116 - val_mae: 0.4175\n",
            "Epoch 186/250\n",
            "178/178 [==============================] - 46s 249ms/step - loss: 0.2357 - mae: 0.4656 - val_loss: 0.2147 - val_mae: 0.4501\n",
            "Epoch 187/250\n",
            "178/178 [==============================] - 45s 250ms/step - loss: 0.2336 - mae: 0.4649 - val_loss: 0.2055 - val_mae: 0.4305\n",
            "Epoch 188/250\n",
            "178/178 [==============================] - 47s 259ms/step - loss: 0.2345 - mae: 0.4652 - val_loss: 0.2085 - val_mae: 0.4382\n",
            "Epoch 189/250\n",
            "178/178 [==============================] - 47s 260ms/step - loss: 0.2283 - mae: 0.4555 - val_loss: 0.2116 - val_mae: 0.4451\n",
            "Epoch 190/250\n",
            "178/178 [==============================] - 47s 258ms/step - loss: 0.2361 - mae: 0.4657 - val_loss: 0.2212 - val_mae: 0.4603\n",
            "Epoch 191/250\n",
            "178/178 [==============================] - 46s 257ms/step - loss: 0.2307 - mae: 0.4585 - val_loss: 0.2290 - val_mae: 0.4698\n",
            "Epoch 192/250\n",
            "178/178 [==============================] - 46s 251ms/step - loss: 0.2345 - mae: 0.4628 - val_loss: 0.2084 - val_mae: 0.4395\n",
            "Epoch 193/250\n",
            "178/178 [==============================] - 45s 251ms/step - loss: 0.2313 - mae: 0.4577 - val_loss: 0.2066 - val_mae: 0.4358\n",
            "Epoch 194/250\n",
            "178/178 [==============================] - 47s 259ms/step - loss: 0.2298 - mae: 0.4566 - val_loss: 0.2105 - val_mae: 0.4438\n",
            "Epoch 195/250\n",
            "178/178 [==============================] - 47s 259ms/step - loss: 0.2207 - mae: 0.4449 - val_loss: 0.1991 - val_mae: 0.4196\n",
            "Epoch 196/250\n",
            "178/178 [==============================] - 47s 260ms/step - loss: 0.2296 - mae: 0.4527 - val_loss: 0.2055 - val_mae: 0.4343\n",
            "Epoch 197/250\n",
            "178/178 [==============================] - 47s 258ms/step - loss: 0.2238 - mae: 0.4469 - val_loss: 0.1959 - val_mae: 0.4097\n",
            "Epoch 198/250\n",
            "178/178 [==============================] - 46s 252ms/step - loss: 0.2278 - mae: 0.4489 - val_loss: 0.1963 - val_mae: 0.4066\n",
            "Epoch 199/250\n",
            "178/178 [==============================] - 45s 249ms/step - loss: 0.2245 - mae: 0.4465 - val_loss: 0.1986 - val_mae: 0.4205\n",
            "Epoch 200/250\n",
            "178/178 [==============================] - 47s 259ms/step - loss: 0.2252 - mae: 0.4462 - val_loss: 0.1994 - val_mae: 0.4232\n",
            "Epoch 201/250\n",
            "178/178 [==============================] - 47s 258ms/step - loss: 0.2259 - mae: 0.4459 - val_loss: 0.1948 - val_mae: 0.4084\n",
            "Epoch 202/250\n",
            "178/178 [==============================] - 46s 256ms/step - loss: 0.2322 - mae: 0.4543 - val_loss: 0.2216 - val_mae: 0.4561\n",
            "Epoch 203/250\n",
            "178/178 [==============================] - 46s 250ms/step - loss: 0.2292 - mae: 0.4528 - val_loss: 0.1969 - val_mae: 0.4181\n",
            "Epoch 204/250\n",
            "178/178 [==============================] - 45s 250ms/step - loss: 0.2288 - mae: 0.4502 - val_loss: 0.1947 - val_mae: 0.4125\n",
            "Epoch 205/250\n",
            "178/178 [==============================] - 47s 258ms/step - loss: 0.2250 - mae: 0.4458 - val_loss: 0.2008 - val_mae: 0.4263\n",
            "Epoch 206/250\n",
            "178/178 [==============================] - 47s 259ms/step - loss: 0.2229 - mae: 0.4414 - val_loss: 0.1922 - val_mae: 0.4069\n",
            "Epoch 207/250\n",
            "178/178 [==============================] - 47s 259ms/step - loss: 0.2255 - mae: 0.4455 - val_loss: 0.1960 - val_mae: 0.4167\n",
            "Epoch 208/250\n",
            "178/178 [==============================] - 46s 257ms/step - loss: 0.2227 - mae: 0.4413 - val_loss: 0.1927 - val_mae: 0.4087\n",
            "Epoch 209/250\n",
            "178/178 [==============================] - 43s 235ms/step - loss: 0.2198 - mae: 0.4378 - val_loss: 0.2007 - val_mae: 0.4240\n",
            "Epoch 210/250\n",
            "178/178 [==============================] - 45s 245ms/step - loss: 0.2190 - mae: 0.4353 - val_loss: 0.1957 - val_mae: 0.3883\n",
            "Epoch 211/250\n",
            "178/178 [==============================] - 47s 258ms/step - loss: 0.2234 - mae: 0.4402 - val_loss: 0.1912 - val_mae: 0.3904\n",
            "Epoch 212/250\n",
            "178/178 [==============================] - 47s 259ms/step - loss: 0.2228 - mae: 0.4387 - val_loss: 0.1954 - val_mae: 0.3871\n",
            "Epoch 213/250\n",
            "178/178 [==============================] - 47s 259ms/step - loss: 0.2235 - mae: 0.4399 - val_loss: 0.1876 - val_mae: 0.3902\n",
            "Epoch 214/250\n",
            "178/178 [==============================] - 47s 261ms/step - loss: 0.2223 - mae: 0.4381 - val_loss: 0.1877 - val_mae: 0.3873\n",
            "Epoch 215/250\n",
            "178/178 [==============================] - 46s 256ms/step - loss: 0.2208 - mae: 0.4332 - val_loss: 0.1891 - val_mae: 0.4037\n",
            "Epoch 216/250\n",
            "178/178 [==============================] - 46s 252ms/step - loss: 0.2196 - mae: 0.4346 - val_loss: 0.1859 - val_mae: 0.3877\n",
            "Epoch 217/250\n",
            "178/178 [==============================] - 46s 255ms/step - loss: 0.2222 - mae: 0.4332 - val_loss: 0.1847 - val_mae: 0.3895\n",
            "Epoch 218/250\n",
            "178/178 [==============================] - 47s 261ms/step - loss: 0.2188 - mae: 0.4320 - val_loss: 0.1837 - val_mae: 0.3913\n",
            "Epoch 219/250\n",
            "178/178 [==============================] - 47s 261ms/step - loss: 0.2177 - mae: 0.4287 - val_loss: 0.1866 - val_mae: 0.3800\n",
            "Epoch 220/250\n",
            "178/178 [==============================] - 47s 259ms/step - loss: 0.2207 - mae: 0.4322 - val_loss: 0.1827 - val_mae: 0.3907\n",
            "Epoch 221/250\n",
            "178/178 [==============================] - 46s 253ms/step - loss: 0.2154 - mae: 0.4276 - val_loss: 0.1828 - val_mae: 0.3836\n",
            "Epoch 222/250\n",
            "178/178 [==============================] - 47s 257ms/step - loss: 0.2154 - mae: 0.4246 - val_loss: 0.1823 - val_mae: 0.3895\n",
            "Epoch 223/250\n",
            "178/178 [==============================] - 47s 260ms/step - loss: 0.2230 - mae: 0.4316 - val_loss: 0.1886 - val_mae: 0.4011\n",
            "Epoch 224/250\n",
            "178/178 [==============================] - 47s 259ms/step - loss: 0.2173 - mae: 0.4258 - val_loss: 0.1830 - val_mae: 0.3880\n",
            "Epoch 225/250\n",
            "178/178 [==============================] - 47s 262ms/step - loss: 0.2212 - mae: 0.4299 - val_loss: 0.1811 - val_mae: 0.3797\n",
            "Epoch 226/250\n",
            "178/178 [==============================] - 47s 259ms/step - loss: 0.2215 - mae: 0.4300 - val_loss: 0.1821 - val_mae: 0.3835\n",
            "Epoch 227/250\n",
            "178/178 [==============================] - 42s 233ms/step - loss: 0.2210 - mae: 0.4293 - val_loss: 0.1860 - val_mae: 0.3753\n",
            "Epoch 228/250\n",
            "178/178 [==============================] - 46s 250ms/step - loss: 0.2183 - mae: 0.4262 - val_loss: 0.1850 - val_mae: 0.3735\n",
            "Epoch 229/250\n",
            "178/178 [==============================] - 46s 256ms/step - loss: 0.2130 - mae: 0.4190 - val_loss: 0.2071 - val_mae: 0.3734\n",
            "Epoch 230/250\n",
            "178/178 [==============================] - 47s 258ms/step - loss: 0.2156 - mae: 0.4228 - val_loss: 0.2095 - val_mae: 0.3744\n",
            "Epoch 231/250\n",
            "178/178 [==============================] - 47s 259ms/step - loss: 0.2102 - mae: 0.4146 - val_loss: 0.1962 - val_mae: 0.3694\n",
            "Epoch 232/250\n",
            "178/178 [==============================] - 42s 233ms/step - loss: 0.2158 - mae: 0.4199 - val_loss: 0.1950 - val_mae: 0.3683\n",
            "Epoch 233/250\n",
            "178/178 [==============================] - 47s 259ms/step - loss: 0.2150 - mae: 0.4186 - val_loss: 0.1808 - val_mae: 0.3698\n",
            "Epoch 234/250\n",
            "178/178 [==============================] - 47s 259ms/step - loss: 0.2181 - mae: 0.4246 - val_loss: 0.2039 - val_mae: 0.3696\n",
            "Epoch 235/250\n",
            "178/178 [==============================] - 46s 249ms/step - loss: 0.2131 - mae: 0.4188 - val_loss: 0.1864 - val_mae: 0.3680\n",
            "Epoch 236/250\n",
            "178/178 [==============================] - 46s 253ms/step - loss: 0.2178 - mae: 0.4228 - val_loss: 0.1805 - val_mae: 0.3710\n",
            "Epoch 237/250\n",
            "178/178 [==============================] - 46s 257ms/step - loss: 0.2196 - mae: 0.4258 - val_loss: 0.1857 - val_mae: 0.3703\n",
            "Epoch 238/250\n",
            "178/178 [==============================] - 47s 260ms/step - loss: 0.2184 - mae: 0.4248 - val_loss: 0.1813 - val_mae: 0.3692\n",
            "Epoch 239/250\n",
            "178/178 [==============================] - 46s 256ms/step - loss: 0.2129 - mae: 0.4173 - val_loss: 0.1832 - val_mae: 0.3900\n",
            "Epoch 240/250\n",
            "178/178 [==============================] - 46s 251ms/step - loss: 0.2101 - mae: 0.4168 - val_loss: 0.1775 - val_mae: 0.3759\n",
            "Epoch 241/250\n",
            "178/178 [==============================] - 45s 251ms/step - loss: 0.2119 - mae: 0.4174 - val_loss: 0.1787 - val_mae: 0.3751\n",
            "Epoch 242/250\n",
            "178/178 [==============================] - 47s 260ms/step - loss: 0.2092 - mae: 0.4126 - val_loss: 0.1863 - val_mae: 0.3705\n",
            "Epoch 243/250\n",
            "178/178 [==============================] - 47s 259ms/step - loss: 0.2116 - mae: 0.4143 - val_loss: 0.1830 - val_mae: 0.3691\n",
            "Epoch 244/250\n",
            "178/178 [==============================] - 47s 260ms/step - loss: 0.2074 - mae: 0.4106 - val_loss: 0.1922 - val_mae: 0.3720\n",
            "Epoch 245/250\n",
            "178/178 [==============================] - 46s 257ms/step - loss: 0.2107 - mae: 0.4146 - val_loss: 0.1776 - val_mae: 0.3744\n",
            "Epoch 246/250\n",
            "178/178 [==============================] - 45s 247ms/step - loss: 0.2106 - mae: 0.4143 - val_loss: 0.1796 - val_mae: 0.3733\n",
            "Epoch 247/250\n",
            "178/178 [==============================] - 46s 256ms/step - loss: 0.2113 - mae: 0.4150 - val_loss: 0.1768 - val_mae: 0.3775\n",
            "Epoch 248/250\n",
            "178/178 [==============================] - 46s 257ms/step - loss: 0.2087 - mae: 0.4124 - val_loss: 0.1838 - val_mae: 0.3739\n",
            "Epoch 249/250\n",
            "178/178 [==============================] - 47s 259ms/step - loss: 0.2113 - mae: 0.4145 - val_loss: 0.1850 - val_mae: 0.3720\n",
            "Epoch 250/250\n",
            "178/178 [==============================] - 47s 258ms/step - loss: 0.2115 - mae: 0.4140 - val_loss: 0.1935 - val_mae: 0.3736\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "mae = history.history['mae']\n",
        "val_mae = history.history['val_mae']\n",
        "\n",
        "\n",
        "epochs_x = range(len(loss))\n",
        "\n",
        "\n",
        "plt.plot(epochs_x, mae, 'go', label='Training MAE')\n",
        "plt.plot(epochs_x, val_mae, 'k', label='Validation MAE')\n",
        "plt.title('Training and validation MeanAbsoluteError')\n",
        "plt.legend()\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(epochs_x, loss, 'go', label='Training loss')\n",
        "plt.plot(epochs_x, val_loss, 'k', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Y3K89-CM-dfg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545
        },
        "outputId": "2a24e325-c217-4784-9724-ece6482f6441"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAEICAYAAABPgw/pAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3de3wU1fn48c+ThIQEQoAQ5JoEWxGxyC1ivYNRCxbEC6IYVNSq4KXV71f9qvFWbfz24q9FWm/QUq2NoFbhKwVsBbVUUBSVgqggahIiFyGQcCcheX5/nNlls+RGsiHZ3ef9eu0rO2dmZ87sbJ49e+aZM6KqGGOMCX8xLV0BY4wxoWEB3RhjIoQFdGOMiRAW0I0xJkJYQDfGmAhhAd0YYyKEBfRmJiILReSaUC/bkkSkQETObYb1qoh833v+jIg80JBlG7GdHBH5Z2PrGc5EZLiIFDfDeht9PEzoWECvgYjsDnhUici+gOmcI1mXqo5S1edDvWykU9XJqvpoU9cjIplesIkLWHe+qp7f1HXXsK3h3rbmBJUP9MrfCfU266jLJG+blx+tbTbUkQZ/rwGxL+j/8g/NWcdwFVf/ItFHVdv7notIAfATVV0UvJyIxKnqwaNZN9PqbQVOFZFUVS3xyq4B1h3lelwDbAeuBl46yttuDmNq+h8MVtP/pIjEqmplQzd0pMu3JtZCPwK+n6si8j8ishn4s4h0EpG/i8hWEdnhPe8V8Jp3ROQn3vNJIvKuiDzuLfuNiIxq5LJ9RGSJiOwSkUUi8qSI/LWWejekjo+KyFJvff8UkS4B868SkUIRKRGR3Dren1NEZLOIxAaUXSwiq7znw0TkPREpFZFNIvIHEYmvZV3PicgvAqbv8l6zUUSuC1r2xyLyiYjsFJENIvJwwOwl3t9Sr2V3qu+9DXj9aSLyoYiUeX9Pa+h7U4NyYC5whff6WOByID+ozv1E5E0R2S4ia0VkfEP2J+AXxzUiUiQi24KPiYhkAGcDNwI/EpFuNby/93mvLZCAX50icoGIfObt67cicmfAvBtEZL1X59dFpEdNb0Dg59ib9r/fIuI7Hv/xjsflXvloEVnpfTaWichJdbzHgdua5B2b34lICfCw99l5WkQWiMgeYISInODVq1RE1ojIhQHrOGz5hmy7NbKAfuS6AZ2BDNw/TAzwZ286HdgH1PVz8BRgLdAF+DXwJxGRRiz7IvABkAo8DFxVxzYbUscrgWuBrkA8cCeAiPQHnvbW38PbXi9qoKrLgT3AOUHrfdF7Xgnc4e3PqUA2cHMd9carw0ivPucBxwHB/fd7cC3RjsCPgSkicpE37yzvb0dVba+q7wWtuzMwH5jm7dtvgfkikhq0D4e9N3X4i1cfgB8BnwIbA7bZDngT9750xQX/p7z3ur798TkDOB73Hj4oIicEzLsaWKGqrwKfA8HdhN1wx6AnriU/XUSO9+b9CbhJVZOBHwBveXU+B/hfYDzQHSgEZtfzPhxGVX3HY6B3PF4SkcHATOAm3DF4FnhdRBIauNpTgK+BY4A8r+xK73kysByYB/wT937fBuQH7HPw8u8SpiygH7kq4CFVPaCq+1S1RFVfVdW9qroL96E4u47XF6rqDO8n3fO4f45jjmRZEUkHTgYeVNVyVX0XeL22DTawjn9W1XWqug94GRjklY8D/q6qS1T1APCA9x7UZhYwAUBEkoELvDJU9SNVfV9VD6pqAe4ft673yme8V79PVXUP7gsscP/eUdXVqlqlqqu87TVkveAC5peq+oJXr1nAF8CYgGVqe29qpKrLgM5ewLgaF+ADjQYKVPXP3jY/AV4FLjuC/fm59/n7D/AfYGDAvKs59CX6Ioe+XAI94H2G/4X7QvP9QqgA+otIB1Xdoaofe+U5wExV/dj7HNyL61rKrOu9aKAbgWdVdbmqVnrnkQ4APwxYZq7XuvY9bgiYt1FVf++9l/u8sv9T1aWqWoU7Xu2BX3r/L28Bf8f7nAYvr6r7Q7BPLcIC+pHbGnjARSRJRJ4V1yWxE/cTv6MEdDsE2ex7oqp7vaftj3DZHsD2gDKADbVVuIF13BzwfG9AnXoErtsLqCXU7kXgEq91dQnwsaoWevXoK667Z7NXj8dwLcX6VKsDrnUYuH+niMjb4rqUyoDJDVyvb92FQWWFuNarT23vTV1eAG7F/XyfEzQvAzglMEDhAma3I9ifGuskIqcDfTjUen4RGCAigV9CO7zjGLi/vu6TS3FfwoUi8i8ROdUrr/Y+qepu3Ocg8H1qrAzgv4Pej94BdQK4SFU7BjxmBMyr6bMfWNYD2OAFd5/gY1zr/084sYB+5IKHp/xv3E/fU1S1A4d+4tfWjRIKm3AtwKSAst51LN+UOm4KXLe3zdTaFlbVz3D/LKOo3t0CruvmC+A4rx73NaYOuG6jQC/ifqH0VtUU4JmA9dY3nOhGXEAJlA5824B61eUFXHfSgqAvXnDB419BAaq9qk7x5te1P/W5xlt2pbjzPMsDyn06ed0+Pul4XUKq+qGqjsV1TczF/SKBoPfJe30qNb9Pe4DAz+ZhffhBNgB5Qe9HkvdrqSFqOsaBZRuB3iISGO+Cj3FEDDtrAb3pknF90qVef+xDzb1Br8W7AncCKN5rRY2p4yVNqePfgNEicoa4E5iPUP/n5kXgZ7gvjleC6rET2C0i/YApNby2Ji8Dk0Skv/eFElz/ZNwvlv0iMgz3ReKzFddFdGwt614A9BWRK0UkzjtJ1x/3k7zRVPUbXDdJTSeR/+5t8yoRaeM9Tg7oB69rf2olIm1xXSc34roZfI/bgCslIHUT+Ln32TkT1wX0ijedIyIpqlqBO1a+Vu0s4FoRGeT9+noMWO51nQVbifuVliQuPfH6oPlbqH48ZgCTvV8mIiLtxJ0YTm7IfjfActyvmLu993o47v/liM8BtHYW0JtuKpAIbAPeB944StvNwZ1YLAF+gUtNO1DLso2uo6quAW7BBelNwA6gvgtTfH2+b6nqtoDyO3HBaRfun7hB6XSqutDbh7eA9d7fQDcDj4jILuBBDrUqfV1VecBS7+d8YL8sXmrhaNyvmBLgbmB0UL0bRVXfVdWNNZTvAs7HnQzdiOs++RXgOwlY6/7U4yLcF/dfVHWz74E74RgHjPSW24w7jhtx2TeTVfULb95VQIHXJTYZ74SqupTBB3B9/ZuA73n1r8nvcNk+W3DnfvKD5j8MPO8dj/GqugK4AXeifgfuGE8Kes08qZ6HHtyNVStVLccF8FG4/4GngKsD9jliiNoNLiKCiLwEfKGqzf4LwRjTOlkLPUx5P9G/JyIxXlrfWFyfpzEmStmVouGrG/Aa7sRUMTDFS38zxkQp63IxxpgIYV0uxhgTIVqsy6VLly6amZnZUps3xpiw9NFHH21T1bSa5rVYQM/MzGTFihUttXljjAlLIhJ8ZbOfdbkYY0yEsIBujDERwgK6McZECMtDNyYKVFRUUFxczP79YTsybNRp27YtvXr1ok2bNg1+jQV0Y6JAcXExycnJZGZmIrXeT8W0FqpKSUkJxcXF9OnTp8GvC6sul/zV+WROzSTm5zFkTs0kf3XwmD/GmJrs37+f1NRUC+ZhQkRITU094l9UYdNCz1+dz43zbmRvhRtaurCskBvn3QhAzoDgO2wZY4JZMA8vjTleYdNCz12c6w/mPnsr9pK7uNZ7FhtjTFQJm4BeVFZ0ROXGmNahpKSEQYMGMWjQILp160bPnj390+Xl5XW+dsWKFfz0pz+tdxunnXZaSOr6zjvvICL88Y9/9JetXLkSEeHxxx/3lx08eJC0tDTuueeeaq8fPnw4xx9/vH//xo0bF5J6NVTYBPT0lOC7jtVdboxpvFCer0pNTWXlypWsXLmSyZMnc8cdd/in4+PjOXjwYK2vzcrKYtq0afVuY9myZY2uX7Af/OAHvPzyoXuKzJo1i4EDB1Zb5s0336Rv37688sorBA9wmJ+f79+/v/3tbyGrV0OETUDPy84jqU1StbKkNknkZee1UI2MiUy+81WFZYUo6j9fFcokhEmTJjF58mROOeUU7r77bj744ANOPfVUBg8ezGmnncbatWsB12IePXo0AA8//DDXXXcdw4cP59hjj60W6Nu3b+9ffvjw4YwbN45+/fqRk5PjD7gLFiygX79+DB06lJ/+9Kf+9QbLyMhg//79bNmyBVXljTfeYNSoUdWWmTVrFj/72c9IT0/nvffeC9n70lRhc1LUd+Lz7tl3s/GjjfQe0Zv/veB/7YSoMSFW1/mqUP6/FRcXs2zZMmJjY9m5cyf//ve/iYuLY9GiRdx33328+uqrh73miy++4O2332bXrl0cf/zxTJky5bA87U8++YQ1a9bQo0cPTj/9dJYuXUpWVhY33XQTS5YsoU+fPkyYMKHOuo0bN45XXnmFwYMHM2TIEBISEvzz9u/fz6JFi3j22WcpLS1l1qxZ1bp8cnJySExMBOC8887jN7/5TVPepiMSNgEdXFBP/DKRSx+7lNd+8RpZA7JaukrGRJyjdb7qsssuIzY2FoCysjKuueYavvzyS0SEioqKGl/z4x//mISEBBISEujatStbtmyhV69e1ZYZNmyYv2zQoEEUFBTQvn17jj32WH9O94QJE5g+fXqtdRs/fjyXX345X3zxBRMmTKjWpfP3v/+dESNGkJiYyKWXXsqjjz7K1KlT/fuSn59PVlbLxKaw6XLxOeEEd2P0kVNHWj66Mc3gaJ2vateunf/5Aw88wIgRI/j000+ZN29erfnXgS3l2NjYGvvfG7JMfbp160abNm148803yc7OrjZv1qxZLFq0iMzMTIYOHUpJSQlvvRV83/KWEXYB/YN9H0AMlBSVNFv/njHRrCXOV5WVldGzZ08AnnvuuZCv//jjj+frr7+moKAAgJdeeqne1zzyyCP86le/8re8AX/XUFFREQUFBRQUFPDkk08ya9askNe5McIuoD+05CHoDGw9VGb56MaETs6AHKaPmU5GSgaCkJGSwfQx05v1fNXdd9/Nvffey+DBgxvVoq5PYmIiTz31FCNHjmTo0KEkJyeTkpJS52tOO+00Lrroomplc+bM4Zxzzqn2K2Ds2LHMmzePAwcOAK4P3Ze2eO6554Z8X+rSYvcUzcrK0sbc4CLm5zHobIVtwK2HygWh6qGq0FXQmAjy+eef+7sro9Xu3btp3749qsott9zCcccdxx133NHS1apTTcdNRD5S1Ro76ettoYvITBH5TkQ+rWV+joisEpHVIrJMRAbWtFyopKekQxdgO1AZVG6MMbWYMWMGgwYN4sQTT6SsrIybbrqppasUcg3pcnkOGFnH/G+As1V1APAoUPup4xDIy84jvls8VOGCOpaPboypn++Cps8++4z8/HySkpLqf1GYqTegq+oS/KGzxvnLVHWHN/k+0Ku2ZUMhZ0AO9196v5vYxlHp3zPGmHAQ6pOi1wMLa5spIjeKyAoRWbF169baFqvX7T++HYC8k/IouL3AgrkxxhDCgC4iI3AB/X9qW0ZVp6tqlqpmpaWlNXpbycnJdD6mM4+99pjlohtjjCckV4qKyEnAH4FRqloSinXWJX91PqXJpVRtclktNja6McaEoIUuIunAa8BVqrqu6VWqX+7iXKpSq1zqopd1abnoxrReI0aM4B//+Ee1sqlTpzJlypRaXzN8+HB8qc0XXHABpaWlhy3z8MMPVxvWtiZz587ls88+808/+OCDLFq06EiqX6PWONRuQ9IWZwHvAceLSLGIXC8ik0VksrfIg0Aq8JSIrBSRI08uP0JFZUUudbEc2BlUboxpdSZMmMDs2bOrlc2ePbveQbJ8FixYQMeOHRu17eCA/sgjj4Tsgp/WNtRuQ7JcJqhqd1Vto6q9VPVPqvqMqj7jzf+JqnZS1UHeo9lHpfHnokO1K0YtF92Y1mncuHHMnz/ff0OLgoICNm7cyJlnnsmUKVPIysrixBNP5KGHHqrx9ZmZmWzbtg2AvLw8+vbtyxlnnOEfZhdcnvnJJ5/MwIEDufTSS9m7dy/Lli3j9ddf56677mLQoEF89dVXTJo0yR88Fy9ezODBgxkwYADXXXed/2rPzMxMHnroIYYMGcKAAQP44osvaqxXaxtqN6xGW/TJy87jhu9uYB/7XLfL9y0X3ZiGuv3221m5cmVI1zlo0CCmTp1a6/zOnTszbNgwFi5cyNixY5k9ezbjx49HRMjLy6Nz585UVlaSnZ3NqlWrOOmkk2pcz0cffcTs2bNZuXIlBw8eZMiQIQwdOhSASy65hBtuuAGA+++/nz/96U/cdtttXHjhhYwePfqwLo39+/czadIkFi9eTN++fbn66qt5+umnuf12l0XXpUsXPv74Y5566ikef/zxal0rgVrTULthN5YLeGNNXDGdmKQYy0U3JkwEdrsEdre8/PLLDBkyhMGDB7NmzZpq3SPB/v3vf3PxxReTlJREhw4duPDCC/3zPv30U84880wGDBhAfn4+a9asqbM+a9eupU+fPvTt2xeAa665hiVLlvjnX3LJJQAMHTrUP6hXTcaPH88rr7zCrFmzDutCCh5qd+7cuVRWHrrEPbDLJRTjpodlCx1g4kkTeWrgU8THx/PO7e+0dHWMCRt1taSb09ixY7njjjv4+OOP2bt3L0OHDuWbb77h8ccf58MPP6RTp05MmjSp1qFz6zNp0iTmzp3LwIEDee6553jnnXeaVF9fS7u+IXgDh9p94oknqo2dPmvWLN59910yMzMB/EPtnnfeeU2qW23CsoXuE98tnn9/9G/LRTcmDLRv354RI0Zw3XXX+VuyO3fupF27dqSkpLBlyxYWLqz1ukQAzjrrLObOncu+ffvYtWsX8+bN88/btWsX3bt3p6Kigvz8Q7EgOTmZXbt2Hbau448/noKCAtavXw/ACy+8wNlnn92ofWstQ+2GbQs9f3U+y/Yto2p3FeyFQiwX3ZjWbsKECVx88cX+rpeBAwcyePBg+vXrR+/evTn99NPrfP2QIUO4/PLLGThwIF27duXkk0/2z3v00Uc55ZRTSEtL45RTTvEH8SuuuIIbbriBadOmVcskadu2LX/+85+57LLLOHjwICeffDKTJ08+bJsNEdgv7lPbULt33313taF2fX3oXbp0aXI6ZdgNn+uTOTWTwg8L4UXgOsBLcMlIyaDg9oJQVNGYiGHD54ankA+f21r5c9HBZboElhtjTBQK24CenpIOHYFYLBfdGGMI44Cel51HUkKSa6V7LXTLRTemdi3VvWoapzHHK2wDuu++h0k9kmCr5aIbU5e2bdtSUlJiQT1MqColJSW0bdv2iF4Xtlku4IL6nFPn8OrKVyncWugfnMuCujHV9erVi+LiYppyHwJzdLVt25ZevY7sfkFhHdDzV+czb/s8N+JiCRTGW+qiMTVp06YNffr0aelqmGYWtl0u4IbRLe/sBvvxnRi1YXSNMdEqrAN6UVkRdAaEapkulrpojIlGYR3Q01PSXadRZyx10RgT9cI6oOdl55HUJgnSsNRFY0zUC+uA7ktd7NC7A5RAert0S100xkStsM5yAS+b5RqY+OZEFl6wkP79+7d0lYwxpkWEdQvdxxfEz/712TaUrjEmakVEQP+k4hMQ2Fa4DUUpLHP56BbUjTHRJCIC+iPLHoEUqo26aPnoxphoExEBvaisyGW6bK2h3BhjokREBPT0lPRDqYtVQeXGGBMlIiKg52XnEd89HiqBHa7M8tGNMdEmIgJ6zoAc7rv4PjdhQ+kaY6JURAR0gDvG3AFAx10dKSorIndxrmW5GGOiSsQE9HmF85AUobS41FIXjTFRKWICeu7iXDRVq2W6WOqiMSaaRExAr5a6WBVUbowxUSBiAro/dbEC2BlUbowxUSBiAnpedh4J3RPchNftYqmLxphoEjEBPWdADlOvmuomLHXRGBOFIiagA0w+czIdOneg/c72lrpojIk6YT8eeqD81fnsTtlN1bfurKgvdRGwlroxJuJFVAs9d3EuValVrg9dXZmlLhpjokW9AV1EZorIdyLyaS3zRUSmich6EVklIkNCX82G8acu7gd2B5UbY0yEa0gL/TlgZB3zRwHHeY8bgaebXq3G8acuQrULjCx10RgTDeoN6Kq6BNhexyJjgb+o8z7QUUS6h6qCRyIvO4/E7oluwrvZhaUuGmOiRSj60HsCGwKmi72yoy5nQA7Tr5xOTGKMpS4aY6LOUc1yEZEbcd0ypKc3TzfIxJMm8vTgp4mNjWXJ7UuaZRvGGNMahaKF/i3QO2C6l1d2GFWdrqpZqpqVlpZW0yIh0S69He9+8C7ykJA5NdNy0Y0xUSEUAf114Gov2+WHQJmqbgrBehslf3U+/yr/F3pAYTs2jK4xJmo0JG1xFvAecLyIFIvI9SIyWUQme4ssAL4G1gMzgJubrbYNkLs4l/Ku5W7C+1qxXHRjTDSotw9dVSfUM1+BW0JWoyby56LH4gL6gIByY4yJYBF1pSh4OeexwDHAxqByY4yJYBEX0POy80hqkwTdgc2AWi66MSY6RFxAzxmQw/Qx00nqleSGANgFiXGJLV0tY4xpdhEX0H0qu1S6J1uhZF+JZboYYyJeRAb03MW5HOh0wE14Y7pYposxJtJFZEAvKiuCdkAi1QbpskwXY0wki8iAnp6SDoJLX7RRF40xUSIiA7o/0yUN+A7LdDHGRIWIDOi+TJdO6Z1gP/SK6WWjLhpjIl5EBnRwQf2VW14B4PkznrdgboyJeBEb0AH69+8PwLg/jCPm5zE28qIxJqJFdEBfvHUxJMKODTtQ1EZeNMZEtIgO6Pe/dT90oVqmi+WjG2MiVUQHdP/Ii16mS7VyY4yJMBEd0NNT0qErsA/YE1RujDERJqIDel52HgndE9yE1+1i+ejGmEgV0QE9Z0AOv7nyN25iK2SkZFg+ujEmYkV0QAe4NftWkpKTaF/WnqKyInIX51qWizEmItV7C7pw9+KnL7K/036qvq0CDt00GrCWujEmokR8Cz13cS5VqVUu08VjqYvGmEgU8QG9qKzIZbrspVqmi6UuGmMiTcQH9PSUdJeLDjaUrjEmokV8QM/LzqNt97ZuwlIXjTERLOIDes6AHGZMnIEkiL8f3W4abYyJRBEf0AFEBOkusNFN202jjTGRKCoCeu7iXKp6VMFm4KArs0wXY0ykiYqAXlRWBL2ASlxQDyw3xpgIERUBPT0lHXp6E8VB5cYYEyGiIqDnZeeR1CUJkvEHdMt0McZEmqgI6L6bRidmJsJGG6TLGBOZoiKggwvqPzrtR7ADCrcV2iBdxpiIE/GDc/nkr85nQekCd+eiEihsY4N0GWMiS9S00HMX51LeqdxNeFeMWuqiMSaSRE1ALyorcjeMFqqN6WKpi8aYSBE1AT09Jd11MHXGBukyxkSkqAnoedl5JLVJciMv2iBdxpgI1KCALiIjRWStiKwXkXtqmJ8uIm+LyCciskpELgh9VZvGl7rYoVcH2A7p7dItddEYE1HqDegiEgs8CYwC+gMTRKR/0GL3Ay+r6mDgCuCpUFc0FHIG5PDs9c9CFVR8V8FVr11F5tRMS180xkSEhrTQhwHrVfVrVS0HZgNjg5ZRoIP3PAX/uIatz4akDQBs+nITivrvMWpB3RgT7hoS0HsCGwKmizk0MorPw8BEESkGFgC31bQiEblRRFaIyIqtW7fWtEiz+8P6P7iTowGDdFn6ojEmEoTqpOgE4DlV7QVcALwgIoetW1Wnq2qWqmalpaUdtpKjYcOuDXAM1QI6WPqiMSb8NSSgfwv0Dpju5ZUFuh54GUBV3wPa4rK+W530lHTohgvoGlRujDFhrCEB/UPgOBHpIyLxuJOerwctUwRkA4jICbiA3jJ9KvXIy86jTc82sB8oc2WWvmiMiQT1BnRVPQjcCvwD+ByXzbJGRB4RkQu9xf4buEFE/gPMAiapqta8xpaVMyCH3Mu8/vLNNvKiMSZySEvF3aysLF2xYkWLbHvPnj0kJyfT4fwO7Dx1J+kp6eRl51lQN8a0eiLykapm1TQvaq4UDTT367mQCmWFZZa6aIyJGFEZ0HMX56LHqKUuGmMiSlQG9KKyIpfpUgrsCyo3xpgwFZUB3Z+6CLAlqNwYY8JUVAb0vOw8Ensnugmv28VSF40x4S4qA3rOgBxmXDkDSRZ/QE+MS2zZShljTBNFZUD3kW4Cm9zzkn0llulijAlrURvQcxfnUnVMlbue9aArs0wXY0w4i9qA7s90qcLuMWqMiQhRG9CrZbpsDio3xpgwFLUBPS87j8RjEqENlulijIkIURvQcwbkMGPsDOJ7xNsgXcaYiBC1AR1cUD9z2JnIFqGwtJDcxbmW5WKMCVtxLV2BlpS/Op8l5UvQ/QqlUChukC7AWurGmLAT1S303MW5VKRVuAmvH91SF40x4SqqA3pRWRF0BYRqmS6WumiMCUdRHdDTU9IhHkjFUheNMWEvqgN6XnYeSW2SDt00GktdNMaEr6gO6DkDcpg+ZjodMztCGfSK62Wpi8aYsBXVAR1cUL9p9E0AFH9ZbKmLxpiwFfUBPX91PtMKp7mJzdj9RY0xYSvqA3ru4lz2JeyD9ljqojEmrEV9QPenKAacGK1WbowxYSLqA7o/RbEb1cZGt9RFY0y4ifqAXi11MWBs9N3lu60f3RgTVqJ6LBc4NGbLrTtupZRS1+3S/dAt6QKXMcaY1izqW+jgAnaH7h2qjY0OdnLUGBNeLKB7NuzaAMdQLaCDnRw1xoQPC+ge/y3pNgMaVG6MMWHAAronLzuP+J7xcAAodWU2rosxJpxYQPfkDMghd7zXX77JbklnjAk/FtAD3HnRnUiMkFKaQlFZkY3rYowJKxbQA8z5ag6kQllBGYrauC7GmLBiAT1A7uJctJta6qIxJixZQA9QVFbkMl12AnuDyo0xppWzgB7An7oIdks6Y0zYaVBAF5GRIrJWRNaLyD21LDNeRD4TkTUi8mJoq3l05GXnkdgr0U3YLemMMWGm3rFcRCQWeBI4DygGPhSR11X1s4BljgPuBU5X1R0i0rW5KtycfCmKVz15FbrJXV2UGJfYklUyxpgGa0gLfRiwXlW/VtVyYDYwNmiZG4AnVXUHgKp+F9pqHl0xPWPgW8ikc0UAABMDSURBVPfcN0iXZboYY1q7hgT0nsCGgOliryxQX6CviCwVkfdFZGRNKxKRG0VkhYis2Lp1a+Nq3MxyF+dS2aMStuM/MWqZLsaYcBCqk6JxwHHAcGACMENEOgYvpKrTVTVLVbPS0tJCtOnQKiorOvR1tTGo3BhjWrGGBPRvgd4B073wd0j4FQOvq2qFqn4DrMMF+LCTnpIOPbyJb4PKjTGmFWtIQP8QOE5E+ohIPHAF8HrQMnNxrXNEpAuuC+brENbzqMnLziMpOQnScF9TWKaLMSY81BvQVfUgcCvwD+Bz4GVVXSMij4jIhd5i/wBKROQz4G3gLlUtaa5KN6ecATlMHzOdhPQE1+WilulijAkPDboFnaouABYElT0Y8FyB//IeEaGqexV8BOyCErHb0RljWj+7UrQGuYtzqeha4SY2uT+W6WKMae0soNfAP6aLYJkuxpiwYQG9Bukp6RAPdMHfQveXG2NMK2UBvQZ52XkktUmC7vgDumW6GGNauwadFI02vhOft314GztW7SBmdwx72x/qQ7cTo8aY1sha6LXIGZDDLRfeAkDVxioAu4ORMaZVs4Beh+e3PO+eBPSjW7aLMaa1soBeh+IDxZBKtYAOlu1ijGmdLKDXIT0l3Z0Y3VhDuTHGtDIW0OuQl51Hm95t3D1G97gyy3YxxrRWFtDrkDMgh7suvctNeN0uNq6LMaa1soBej4x+Ge6JF9DtDkbGmNbKAno9HvvwMehEtX50y3QxxrRGdmFRPYrKitwNL4Ju6VFYVkjMz2NQ1F/Wrk07APZU7DmKNTRNlZqYyvgTx7PgywUUlRWRnpJOXnaeXUBmwo64kW+PvqysLF2xYkWLbPtIZE7NpHB+ISwC7gaSWrpGpqXFSAxVWkVGSoYFfnPUichHqppV0zxrodcjLzuPiR9PdBMfA+1wQf1Yb4ECIAHYAXyDa813Asq9RzyQAuwGynAjOMYAB7158d56DgKVQJW3TODD950b/Fdq+Wua9l7U9dpYqEqugkoorChk4oqJTIyb6G4oHov7j4oD2gQ8j8Md1zKQfYJ2VDp164SWK6W7SunZpScP/+hhfsAPqKysZMiQISQmupPvlZWVbN68mR49evirIGIH2tTMWugNIP8j8OsGLBiPC+LGNEUXoD+um68YOABnXXQWKZUpLF++nIsvvphu3bpx/vnn07dvXwoLC3nvvffYsGEDDzzwAG3btiUmJoaYGDtFFonqaqFbQG+AzKmZFC4pdC2tHsB2oBDXkuuNC+KxuNti7/Qe8biW+35cyzwZ6OC9pgq3Ll8rXrzXx3LoNHUVriWu1N0S9y1DwF9Tt6a8TxXALg61witxv67aBTwPfFR4f2OA9t5ypd7D9wttv/fo6i3/T28bx+A+X5XAJ972++BO0B+ouXrxJ8WTUpLC6PNHM3PmTPJX55O7ONfODUQQC+hNlL86n6teu6raCVBjmo3viyHBm1ZgKdAZ13IH9wXwJa6rpx3QC3jfe/hchRu6oiOuAdIVSIT28e3ZU77HAnyYsj70JsoZkMPSoqU8s+IZC+qm+fl+rfkIcEbQMm2BAUFl5+C+DE4AXgNe8Mp94/oPBcbA7vLdwKHRQ8GGhI4U1kI/ArX9fLWfteHJd9wKywqJlVgqtRJBIuNLu8B7VAArgERc996duO6a5bgviYAmnS998+U1L1Oyr8Rf9sSoJ+zz3IpYl4sxIZS/Op+b5t0UPtcbKLAG+BswCdcH/09gIvB9b5ktwH+Ac6nxckPfF50vVRPgZwt/5g/8YOmcR4sFdGOaQUN/meWvzufGeTeyt2Kvv8wXII/aL4IDuEytLOA7XIrtOcBZuP76Z4GtwHW4E7Y9cf3vR6oS199/EtARC+7NwAK6MS2sIcG/pi6g1MRU9h/cH5pfAy8DX+G6YaqAfsDFwN+B1d4yJwCf47JrrvOWiz1sTbX7AFgADPcenvbx7Xlm9DMW2EPAAroxESj4S+KC4y6o1v/tEx8TT3lVuWuBP4XrgungzUwCNgNn4/rcCwNe2BXXsr+NhqVP7AOmeX9PAC6vebHgVnv+6vxq3TfWb183C+jGRDl/0JxT4lrjpwBveTMvAgYB7+KGuOgLbMNd/axADi6HvivuYqddwIk1bGQZrm8+Ddf18tMjqOBmb73HHSqywF6zugK6XUpmTBTIGZDDtru3Ubm0kl2bd3Hflfe5GV1w/d3gWtXxwOnAtbiWeTzwJq6PfQHwKjDfW74saCOrcBfenYi7+O5Irpp+B5hbvahkXwkTX5uI/Fzo8usuNmR1A1gL3ZgotHv3bk4++WRGTRnFs7ufPXTC1rsy2T9y6Ow9h/rXA10P/Am4Etei/w7XnTMSN3bRS8BPcBc8NcSzuFz5e3A59nWo7URytLTorYVujKmmffv2fP755/z2p79l+pjpZKRkIAgZHTP46yV/Zfd9u9l9327e+M0bxMXFcd7/nOda676+9E/dnx4be5DUJslltgjwA9yQBeBSIQtxJ2MP1lMhX2t/e/11ry0ryFr01kI3xtRj165dJCcn88tXf8nv/vk7vpv+HbGdY6ncXklGRgajbhrFM/c9A2dC6uhUtErZ/tB2lynzHa5v/HrcdE0qAN9tesfhvhRCLHDM+8Kywmqt/HDLn7eTosaYkNi9ezfJycnVyhISEhg2bBhvvfUWcXGuCf/YY49x//33o6Iu9fF8XCv9e7gc90AlwO+95yNwGTctRBAmZ03mqR8/BdSfSdQS3TwW0I0xIdO9e3c2b97MqaeeynvvvUeXLl345JNP6NWreof5+++/z5yVc/jNfb9BY9VlzpwEXBK0wm+A593Tbqd3Y/N5m4/CXtQtITaBuJi4BuX/x8fGM3PszKMW1C2gG2NC5swzz+Tdd9/lF7/4BZWVlZxzzjmccUbw6GGHnD76dJbNXwZAXJc4nnvrOX/w27JlCwsXLuTaa6+lV69e9O7dmylPTeH6nOup+EHFodElAYqAbhy6KUwr5GuxA4ddJBaqLh07KWqMCZnjjnPJ4ieeeCIPPvhgncEc4MpRVwIQFxfHwW0HOb/b+Wzfvp0xY8bQrVs3HnnkEQBGjBjBl19+SdrmNCo+q+Dc7efy10v+SkZKhjvBOpND48K3Ur4TsxNfm0hhmbtKq1IrATe6pe+kbXOduLWAbow5It//vhvR68QTa7q66HDnnnsubdq04Z577gFcV8y0adOYP38+PXv25JtvviEtLY2BAweybds27rvP5cgvWbKEThs6Ma54HHe2uxOA9qXtXTZOisvG0YeUv17yV1ITGzPwTMsq2VfCdf93XUiDunW5GGOOyKZNm3jttde4+eabG3x/07179yIidOjQgf/6r/9i1qxZnHDCCYwZM4bbbruNIUOG8MYbb3DGGWewbt06srKyWLFiBfHx8ZSXlxMTE0NVVRXDhw/n7bffrnNbwUMJtHYZKRkU3F7Q4OWb3OUiIiNFZK2IrBeRe+pY7lIRURGpcWPGmPDXvXt3brnlliO6WXVSUhKJiYlkZWUxbdo0NmzYwA033MAVV1xBmzZt6N27N2lpabz11lvcfPPNvPLKKyQlJVFeXs6gQYOoqqoiNTWVtWvX1rst31WxvtZ7RkoGALESW+2vr5U/JWtKI96F0CkqKwrZuuptoYtILLAOOA93y9oPgQmq+lnQcsm4i4LjgVtVtc7mt7XQjYk+69at49Zbb6W4uJiVK1cSHx/PX/7yF773ve9x+umnV1v25ptvZs+ePfzud79j5syZ7Nu3jwcffJCysjI6dOhQbdlf/vKXqCr33ntvndsvLCyka9euJCYmVitvyVZ9KFvoDQnopwIPq+qPvOl7AVT1f4OWm4ob9eEu4E4L6MaYUJozZw6XXHIJH3zwASeffLK/fN++faSlpQHw3XffkZSUVOPrt2zZwrHHHsu1117LH/7wh1q3U9MwxsGZKnAoi6UpGpPy2NR7ivYENgRMF+PGagvcwBCgt6rOF5G76qjIjcCNAOnp6Q3YtDHGOP369QNg7dq11QL6G2+8wZ49Ll98/vz5XHbZZVRWVhIbW30g9yeeeIK9e/fy3HPPkZeXR0pKSo3byRmQ06AAG7hMTS38dm3a0TauLSX7Smq8xWFzXJTUkBb6OGCkqv7Em74KOEVVb/WmY3ADcU5S1QIReQdroRtjQqy8vJykpCQyMjIYNGgQI0eOZM6cOWzcuJFvv/2W2NhYevfuTZcuXVi0aBEzZsxg27ZtvPfee/z+97+nf//+ZGRksGrVKqZNm8Ztt93WpPqsWrWK3/72tzz77LMkJCSEaC/rV1cLHVWt8wGcCvwjYPpe4N6A6RTcNWAF3mM/7q6FWXWtd+jQoWqMMUdi2LBhmpqaqh07dlRAO3XqpIDedNNNevvttyugffr00czMTO3Zs6cmJCQooMnJyZqQkKArV67UH/7wh9qzZ0/dunWrfvDBB1pVVdWoutxyyy0K6EsvvRTivawbsEJri9e1zdBDATsO+Brogzvh+R/gxDqWf6e+YK4W0I0xjXDgwAEtLy/XLVu26JtvvqkVFRW6dOlSLS0t1b179+qaNWu0qqpK582bp4DGxcXpVVddpXFxcfr666+rqury5cs1JiZGO3TooID+8Y9/bFRd+vXrp4Ced955odzFejUpoLvXcwEu0+UrINcrewS4sIZlLaAbY1pUVVWVnn/++XrPPfdoVVWVlpaWVpt///33a1pamp500knaoUMHfeedd7S0tFS/+uorXbNmTb3rLy4uVkB79uypIqKPPvqoFhYWVtv+ihUrdM2aNTpu3DgdNGiQLl26VFVVd+zYoVu3bm30vjU5oDfHwwK6MaYlVVZW6vr16/3dNoGPRx99VMvLy/Wrr77SZcuW6TfffKOlpaX6xBNP6IwZM/SBBx5QQOfPn6/9+/dXQLt06aIvv/yyzp07V7OysvzriouL0+7du/u7g2JjYzU3N7fR9a4roNuVosaYqLZz504WLlzIxo0bSU5O5u233+bFF190Y88cPHRnDt9Vqz5paWls3ryZmJgY1q1bx5gxY1i3bh0Axx57LHfeeSexsbEMHTqUvn37MnPmTBYvXsxJJ53EpZdeyuDBgxtVXxtt0RhjGqiqqoq5c+eyfPlyevfuzfe//33Wr1/PmjVruP766+ncuTOfffYZPXr0YMiQIf7XHThwgKVLl7Jz505Gjx7tHxs+1CygG2NMhLDhc40xJgpYQDfGmAhhAd0YYyKEBXRjjIkQFtCNMSZCWEA3xpgIYQHdGGMihAV0Y4yJEC12YZGIbAUae7uPLrghe6NNNO637XN0sH1uuAxVTatpRosF9KYQkRW1XSkVyaJxv22fo4Ptc2hYl4sxxkQIC+jGGBMhwjWgT2/pCrSQaNxv2+foYPscAmHZh26MMeZw4dpCN8YYE8QCujHGRIiwC+giMlJE1orIehG5p6Xr01xEpEBEVovIShFZ4ZV1FpE3ReRL72+nlq5nU4jITBH5TkQ+DSircR/FmeYd91UiMqT2NbdetezzwyLyrXesV4rIBQHz7vX2ea2I/Khlat00ItJbRN4Wkc9EZI2I/Mwrj9hjXcc+N++xru1mo63xAcQCXwHHAvHAf4D+LV2vZtrXAqBLUNmvgXu85/cAv2rpejZxH88ChgCf1rePwAXAQkCAHwLLW7r+Idznh4E7a1i2v/cZTwD6eJ/92Jbeh0bsc3dgiPc8GVjn7VvEHus69rlZj3W4tdCHAetV9WtVLQdmA2NbuE5H01jgee/588BFLViXJlPVJcD2oOLa9nEs8Bd13gc6ikj3o1PT0Klln2szFpitqgdU9RtgPe5/IKyo6iZV/dh7vgv4HOhJBB/rOva5NiE51uEW0HsCGwKmi6n7TQpnCvxTRD4SkRu9smNUdZP3fDNwTMtUrVnVto+Rfuxv9boXZgZ0pUXcPotIJjAYWE6UHOugfYZmPNbhFtCjyRmqOgQYBdwiImcFzlT3Oy2ic06jYR89TwPfAwYBm4D/17LVaR4i0h54FbhdVXcGzovUY13DPjfrsQ63gP4t0DtgupdXFnFU9Vvv73fAHNzPry2+n57e3+9arobNprZ9jNhjr6pbVLVSVauAGRz6qR0x+ywibXCBLV9VX/OKI/pY17TPzX2swy2gfwgcJyJ9RCQeuAJ4vYXrFHIi0k5Ekn3PgfOBT3H7eo232DXA/7VMDZtVbfv4OnC1lwHxQ6As4Od6WAvqH74Yd6zB7fMVIpIgIn2A44APjnb9mkpEBPgT8Lmq/jZgVsQe69r2udmPdUufDW7E2eMLcGeMvwJyW7o+zbSPx+LOeP8HWOPbTyAVWAx8CSwCOrd0XZu4n7NwPzsrcH2G19e2j7iMhye9474ayGrp+odwn1/w9mmV94/dPWD5XG+f1wKjWrr+jdznM3DdKauAld7jgkg+1nXsc7Mea7v03xhjIkS4dbkYY4yphQV0Y4yJEBbQjTEmQlhAN8aYCGEB3RhjIoQFdGOMiRAW0I0xJkL8f9NUhw8pvAA9AAAAAElFTkSuQmCC\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "epochs_x"
      ],
      "metadata": {
        "id": "N_sP_ZmSY-Jv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6f5ad21e-e9a0-451e-fb40-c4df7d9cf73f"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "range(0, 250)"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Download the model\n"
      ],
      "metadata": {
        "id": "R19IJQSYoW7J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "os.makedirs('/content/drive/My Drive/cut_panoramic/Model', exist_ok=True)\n",
        "model.save('/content/drive/My Drive/cut_panoramic/Model/1G_1e-4_16_0.2_Gender_250.h5')"
      ],
      "metadata": {
        "id": "Zed4TdFcG2iJ"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "n5YxZ-5QjQ0-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# from google.colab import files\n",
        "# files.download('/content/drive/My Drive/cut_panoramic/Model/1.1_รอบแรก_Flimpano_Male125_250.h5')"
      ],
      "metadata": {
        "id": "P5eMxm1NV-oY"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "wY_pDlxkRwxS"
      },
      "execution_count": 22,
      "outputs": []
    }
  ]
}