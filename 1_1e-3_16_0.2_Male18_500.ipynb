{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Wanita-8943/Project_2023/blob/main/1_1e-3_16_0.2_Male18_500.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#เรียกใช้ CSV"
      ],
      "metadata": {
        "id": "ow7eWoNw6U-c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import shutil"
      ],
      "metadata": {
        "id": "DlQ2oT7cIR6o"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1_2Fe8u81d5r",
        "outputId": "e64b81f7-c073-401b-b595-c25cb42c8c8e"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Imports"
      ],
      "metadata": {
        "id": "5qxePnnn7TGW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import models\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import optimizers\n",
        "import os\n",
        "import glob\n",
        "import shutil\n",
        "import sys\n",
        "import numpy as np\n",
        "from skimage.io import imread\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import Image\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "D-hCRloc3t39"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras import backend as K"
      ],
      "metadata": {
        "id": "YZWXwjXeGxZP"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#กำหนดค่าพารามิเตอร์\n"
      ],
      "metadata": {
        "id": "RooqSdBc7QHC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 16\n",
        "width = 150\n",
        "height = 150\n",
        "epochs = 500\n",
        "NUM_TRAIN = 1425\n",
        "NUM_TEST = 475\n",
        "dropout_rate = 0.2\n",
        "input_shape = (height, width, 3)"
      ],
      "metadata": {
        "id": "thDb7U9B3xOo"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Clone efficientnet repo\n"
      ],
      "metadata": {
        "id": "pumGmy6f3eSW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#ดึงข้อมูลใน Github มาใช้\n",
        "import os\n",
        "%cd /content\n",
        "if not os.path.isdir(\"efficientnet_keras_transfer_learning\"):\n",
        " !git clone https://github.com/Wanita-8943/efficientnet_keras_transfer_learning\n",
        "%cd efficientnet_keras_transfer_learning/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P7iy2f8n16p0",
        "outputId": "3e6323f9-bf5a-4518-869f-85c17a1896d3"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "Cloning into 'efficientnet_keras_transfer_learning'...\n",
            "remote: Enumerating objects: 837, done.\u001b[K\n",
            "remote: Counting objects: 100% (359/359), done.\u001b[K\n",
            "remote: Compressing objects: 100% (124/124), done.\u001b[K\n",
            "remote: Total 837 (delta 255), reused 328 (delta 235), pack-reused 478\u001b[K\n",
            "Receiving objects: 100% (837/837), 13.82 MiB | 6.51 MiB/s, done.\n",
            "Resolving deltas: 100% (495/495), done.\n",
            "/content/efficientnet_keras_transfer_learning\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import keras"
      ],
      "metadata": {
        "id": "Vbdblwbv89fe"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ],
      "metadata": {
        "id": "vnLrobY_-GCx",
        "outputId": "b8b7c70d-6fe3-4c7f-c11d-d0527b24ce94",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.11.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Options: EfficientNetB0, EfficientNetB1, EfficientNetB2, EfficientNetB3\n",
        "# Higher the number, the more complex the model is.\n",
        "from efficientnet import EfficientNetB0 as Net\n",
        "from efficientnet import center_crop_and_resize, preprocess_input"
      ],
      "metadata": {
        "id": "tjZBRnfo3bN0"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# loading pretrained conv base model\n",
        "# โหลดโมเดล มาโดยตัด output ของโมเดลออก เเต่ยังใช้ input อันเดิม\n",
        "# เเละโหลด weight ของโมเดล มาด้วยที่ชื่อว่า imagenet\n",
        "conv_base = Net(weights='imagenet', include_top=False, input_shape=input_shape)"
      ],
      "metadata": {
        "id": "hNZAzbDp3lgA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "49d69f23-1ad5-4c14-c661-e5371c4376c1"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
            "Instructions for updating:\n",
            "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://github.com/qubvel/efficientnet/releases/download/v0.0.1/efficientnet-b0_imagenet_1000_notop.h5\n",
            "16717576/16717576 [==============================] - 1s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = models.Sequential()\n",
        "model.add(conv_base)\n",
        "model.add(layers.GlobalMaxPooling2D(name=\"gap\"))\n",
        "# model.add(layers.Flatten(name=\"flatten\"))\n",
        "if dropout_rate > 0:\n",
        "    model.add(layers.Dropout(dropout_rate, name=\"dropout_out\"))\n",
        "# model.add(layers.Dense(256, activation='relu', name=\"fc1\"))\n",
        "model.add(layers.Dense(19, activation='softmax', name=\"fc_out\"))\n",
        "model.add(layers.Dense(1))"
      ],
      "metadata": {
        "id": "yWNKfQUt5rga"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "NadBB12251jh",
        "outputId": "f17b1973-f917-407c-8a90-a4512520712a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " efficientnet-b0 (Functional  (None, 5, 5, 1280)       4049564   \n",
            " )                                                               \n",
            "                                                                 \n",
            " gap (GlobalMaxPooling2D)    (None, 1280)              0         \n",
            "                                                                 \n",
            " dropout_out (Dropout)       (None, 1280)              0         \n",
            "                                                                 \n",
            " fc_out (Dense)              (None, 19)                24339     \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1)                 20        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4,073,923\n",
            "Trainable params: 4,031,907\n",
            "Non-trainable params: 42,016\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('This is the number of trainable layers '\n",
        "      'before freezing the conv base:', len(model.trainable_weights))\n",
        "\n",
        "conv_base.trainable = False\n",
        "\n",
        "print('This is the number of trainable layers '\n",
        "      'after freezing the conv base:', len(model.trainable_weights))"
      ],
      "metadata": {
        "id": "GepWq3yy53t5",
        "outputId": "113f3d5a-849a-475b-f9f9-9cb273b49e57",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This is the number of trainable layers before freezing the conv base: 215\n",
            "This is the number of trainable layers after freezing the conv base: 4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "conv_base.summary() #ดู Summary"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iD76D6c_79py",
        "outputId": "fd48682f-fde3-427a-82c4-5d7a4f67b9fd"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"efficientnet-b0\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 150, 150, 3  0           []                               \n",
            "                                )]                                                                \n",
            "                                                                                                  \n",
            " conv2d (Conv2D)                (None, 75, 75, 32)   864         ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " batch_normalization (BatchNorm  (None, 75, 75, 32)  128         ['conv2d[0][0]']                 \n",
            " alization)                                                                                       \n",
            "                                                                                                  \n",
            " swish (Swish)                  (None, 75, 75, 32)   0           ['batch_normalization[0][0]']    \n",
            "                                                                                                  \n",
            " depthwise_conv2d (DepthwiseCon  (None, 75, 75, 32)  288         ['swish[0][0]']                  \n",
            " v2D)                                                                                             \n",
            "                                                                                                  \n",
            " batch_normalization_1 (BatchNo  (None, 75, 75, 32)  128         ['depthwise_conv2d[0][0]']       \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " swish_1 (Swish)                (None, 75, 75, 32)   0           ['batch_normalization_1[0][0]']  \n",
            "                                                                                                  \n",
            " lambda (Lambda)                (None, 1, 1, 32)     0           ['swish_1[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d_1 (Conv2D)              (None, 1, 1, 8)      264         ['lambda[0][0]']                 \n",
            "                                                                                                  \n",
            " swish_2 (Swish)                (None, 1, 1, 8)      0           ['conv2d_1[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_2 (Conv2D)              (None, 1, 1, 32)     288         ['swish_2[0][0]']                \n",
            "                                                                                                  \n",
            " activation (Activation)        (None, 1, 1, 32)     0           ['conv2d_2[0][0]']               \n",
            "                                                                                                  \n",
            " multiply (Multiply)            (None, 75, 75, 32)   0           ['activation[0][0]',             \n",
            "                                                                  'swish_1[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d_3 (Conv2D)              (None, 75, 75, 16)   512         ['multiply[0][0]']               \n",
            "                                                                                                  \n",
            " batch_normalization_2 (BatchNo  (None, 75, 75, 16)  64          ['conv2d_3[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv2d_4 (Conv2D)              (None, 75, 75, 96)   1536        ['batch_normalization_2[0][0]']  \n",
            "                                                                                                  \n",
            " batch_normalization_3 (BatchNo  (None, 75, 75, 96)  384         ['conv2d_4[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " swish_3 (Swish)                (None, 75, 75, 96)   0           ['batch_normalization_3[0][0]']  \n",
            "                                                                                                  \n",
            " depthwise_conv2d_1 (DepthwiseC  (None, 38, 38, 96)  864         ['swish_3[0][0]']                \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_4 (BatchNo  (None, 38, 38, 96)  384         ['depthwise_conv2d_1[0][0]']     \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " swish_4 (Swish)                (None, 38, 38, 96)   0           ['batch_normalization_4[0][0]']  \n",
            "                                                                                                  \n",
            " lambda_1 (Lambda)              (None, 1, 1, 96)     0           ['swish_4[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d_5 (Conv2D)              (None, 1, 1, 4)      388         ['lambda_1[0][0]']               \n",
            "                                                                                                  \n",
            " swish_5 (Swish)                (None, 1, 1, 4)      0           ['conv2d_5[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_6 (Conv2D)              (None, 1, 1, 96)     480         ['swish_5[0][0]']                \n",
            "                                                                                                  \n",
            " activation_1 (Activation)      (None, 1, 1, 96)     0           ['conv2d_6[0][0]']               \n",
            "                                                                                                  \n",
            " multiply_1 (Multiply)          (None, 38, 38, 96)   0           ['activation_1[0][0]',           \n",
            "                                                                  'swish_4[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d_7 (Conv2D)              (None, 38, 38, 24)   2304        ['multiply_1[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_5 (BatchNo  (None, 38, 38, 24)  96          ['conv2d_7[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv2d_8 (Conv2D)              (None, 38, 38, 144)  3456        ['batch_normalization_5[0][0]']  \n",
            "                                                                                                  \n",
            " batch_normalization_6 (BatchNo  (None, 38, 38, 144)  576        ['conv2d_8[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " swish_6 (Swish)                (None, 38, 38, 144)  0           ['batch_normalization_6[0][0]']  \n",
            "                                                                                                  \n",
            " depthwise_conv2d_2 (DepthwiseC  (None, 38, 38, 144)  1296       ['swish_6[0][0]']                \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_7 (BatchNo  (None, 38, 38, 144)  576        ['depthwise_conv2d_2[0][0]']     \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " swish_7 (Swish)                (None, 38, 38, 144)  0           ['batch_normalization_7[0][0]']  \n",
            "                                                                                                  \n",
            " lambda_2 (Lambda)              (None, 1, 1, 144)    0           ['swish_7[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d_9 (Conv2D)              (None, 1, 1, 6)      870         ['lambda_2[0][0]']               \n",
            "                                                                                                  \n",
            " swish_8 (Swish)                (None, 1, 1, 6)      0           ['conv2d_9[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_10 (Conv2D)             (None, 1, 1, 144)    1008        ['swish_8[0][0]']                \n",
            "                                                                                                  \n",
            " activation_2 (Activation)      (None, 1, 1, 144)    0           ['conv2d_10[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_2 (Multiply)          (None, 38, 38, 144)  0           ['activation_2[0][0]',           \n",
            "                                                                  'swish_7[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d_11 (Conv2D)             (None, 38, 38, 24)   3456        ['multiply_2[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_8 (BatchNo  (None, 38, 38, 24)  96          ['conv2d_11[0][0]']              \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " drop_connect (DropConnect)     (None, 38, 38, 24)   0           ['batch_normalization_8[0][0]']  \n",
            "                                                                                                  \n",
            " add (Add)                      (None, 38, 38, 24)   0           ['drop_connect[0][0]',           \n",
            "                                                                  'batch_normalization_5[0][0]']  \n",
            "                                                                                                  \n",
            " conv2d_12 (Conv2D)             (None, 38, 38, 144)  3456        ['add[0][0]']                    \n",
            "                                                                                                  \n",
            " batch_normalization_9 (BatchNo  (None, 38, 38, 144)  576        ['conv2d_12[0][0]']              \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " swish_9 (Swish)                (None, 38, 38, 144)  0           ['batch_normalization_9[0][0]']  \n",
            "                                                                                                  \n",
            " depthwise_conv2d_3 (DepthwiseC  (None, 19, 19, 144)  3600       ['swish_9[0][0]']                \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_10 (BatchN  (None, 19, 19, 144)  576        ['depthwise_conv2d_3[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_10 (Swish)               (None, 19, 19, 144)  0           ['batch_normalization_10[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_3 (Lambda)              (None, 1, 1, 144)    0           ['swish_10[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_13 (Conv2D)             (None, 1, 1, 6)      870         ['lambda_3[0][0]']               \n",
            "                                                                                                  \n",
            " swish_11 (Swish)               (None, 1, 1, 6)      0           ['conv2d_13[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_14 (Conv2D)             (None, 1, 1, 144)    1008        ['swish_11[0][0]']               \n",
            "                                                                                                  \n",
            " activation_3 (Activation)      (None, 1, 1, 144)    0           ['conv2d_14[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_3 (Multiply)          (None, 19, 19, 144)  0           ['activation_3[0][0]',           \n",
            "                                                                  'swish_10[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_15 (Conv2D)             (None, 19, 19, 40)   5760        ['multiply_3[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_11 (BatchN  (None, 19, 19, 40)  160         ['conv2d_15[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_16 (Conv2D)             (None, 19, 19, 240)  9600        ['batch_normalization_11[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_12 (BatchN  (None, 19, 19, 240)  960        ['conv2d_16[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_12 (Swish)               (None, 19, 19, 240)  0           ['batch_normalization_12[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_4 (DepthwiseC  (None, 19, 19, 240)  6000       ['swish_12[0][0]']               \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_13 (BatchN  (None, 19, 19, 240)  960        ['depthwise_conv2d_4[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_13 (Swish)               (None, 19, 19, 240)  0           ['batch_normalization_13[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_4 (Lambda)              (None, 1, 1, 240)    0           ['swish_13[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_17 (Conv2D)             (None, 1, 1, 10)     2410        ['lambda_4[0][0]']               \n",
            "                                                                                                  \n",
            " swish_14 (Swish)               (None, 1, 1, 10)     0           ['conv2d_17[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_18 (Conv2D)             (None, 1, 1, 240)    2640        ['swish_14[0][0]']               \n",
            "                                                                                                  \n",
            " activation_4 (Activation)      (None, 1, 1, 240)    0           ['conv2d_18[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_4 (Multiply)          (None, 19, 19, 240)  0           ['activation_4[0][0]',           \n",
            "                                                                  'swish_13[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_19 (Conv2D)             (None, 19, 19, 40)   9600        ['multiply_4[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_14 (BatchN  (None, 19, 19, 40)  160         ['conv2d_19[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_1 (DropConnect)   (None, 19, 19, 40)   0           ['batch_normalization_14[0][0]'] \n",
            "                                                                                                  \n",
            " add_1 (Add)                    (None, 19, 19, 40)   0           ['drop_connect_1[0][0]',         \n",
            "                                                                  'batch_normalization_11[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_20 (Conv2D)             (None, 19, 19, 240)  9600        ['add_1[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_15 (BatchN  (None, 19, 19, 240)  960        ['conv2d_20[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_15 (Swish)               (None, 19, 19, 240)  0           ['batch_normalization_15[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_5 (DepthwiseC  (None, 10, 10, 240)  2160       ['swish_15[0][0]']               \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_16 (BatchN  (None, 10, 10, 240)  960        ['depthwise_conv2d_5[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_16 (Swish)               (None, 10, 10, 240)  0           ['batch_normalization_16[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_5 (Lambda)              (None, 1, 1, 240)    0           ['swish_16[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_21 (Conv2D)             (None, 1, 1, 10)     2410        ['lambda_5[0][0]']               \n",
            "                                                                                                  \n",
            " swish_17 (Swish)               (None, 1, 1, 10)     0           ['conv2d_21[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_22 (Conv2D)             (None, 1, 1, 240)    2640        ['swish_17[0][0]']               \n",
            "                                                                                                  \n",
            " activation_5 (Activation)      (None, 1, 1, 240)    0           ['conv2d_22[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_5 (Multiply)          (None, 10, 10, 240)  0           ['activation_5[0][0]',           \n",
            "                                                                  'swish_16[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_23 (Conv2D)             (None, 10, 10, 80)   19200       ['multiply_5[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_17 (BatchN  (None, 10, 10, 80)  320         ['conv2d_23[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_24 (Conv2D)             (None, 10, 10, 480)  38400       ['batch_normalization_17[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_18 (BatchN  (None, 10, 10, 480)  1920       ['conv2d_24[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_18 (Swish)               (None, 10, 10, 480)  0           ['batch_normalization_18[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_6 (DepthwiseC  (None, 10, 10, 480)  4320       ['swish_18[0][0]']               \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_19 (BatchN  (None, 10, 10, 480)  1920       ['depthwise_conv2d_6[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_19 (Swish)               (None, 10, 10, 480)  0           ['batch_normalization_19[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_6 (Lambda)              (None, 1, 1, 480)    0           ['swish_19[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_25 (Conv2D)             (None, 1, 1, 20)     9620        ['lambda_6[0][0]']               \n",
            "                                                                                                  \n",
            " swish_20 (Swish)               (None, 1, 1, 20)     0           ['conv2d_25[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_26 (Conv2D)             (None, 1, 1, 480)    10080       ['swish_20[0][0]']               \n",
            "                                                                                                  \n",
            " activation_6 (Activation)      (None, 1, 1, 480)    0           ['conv2d_26[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_6 (Multiply)          (None, 10, 10, 480)  0           ['activation_6[0][0]',           \n",
            "                                                                  'swish_19[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_27 (Conv2D)             (None, 10, 10, 80)   38400       ['multiply_6[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_20 (BatchN  (None, 10, 10, 80)  320         ['conv2d_27[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_2 (DropConnect)   (None, 10, 10, 80)   0           ['batch_normalization_20[0][0]'] \n",
            "                                                                                                  \n",
            " add_2 (Add)                    (None, 10, 10, 80)   0           ['drop_connect_2[0][0]',         \n",
            "                                                                  'batch_normalization_17[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_28 (Conv2D)             (None, 10, 10, 480)  38400       ['add_2[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_21 (BatchN  (None, 10, 10, 480)  1920       ['conv2d_28[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_21 (Swish)               (None, 10, 10, 480)  0           ['batch_normalization_21[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_7 (DepthwiseC  (None, 10, 10, 480)  4320       ['swish_21[0][0]']               \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_22 (BatchN  (None, 10, 10, 480)  1920       ['depthwise_conv2d_7[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_22 (Swish)               (None, 10, 10, 480)  0           ['batch_normalization_22[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_7 (Lambda)              (None, 1, 1, 480)    0           ['swish_22[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_29 (Conv2D)             (None, 1, 1, 20)     9620        ['lambda_7[0][0]']               \n",
            "                                                                                                  \n",
            " swish_23 (Swish)               (None, 1, 1, 20)     0           ['conv2d_29[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_30 (Conv2D)             (None, 1, 1, 480)    10080       ['swish_23[0][0]']               \n",
            "                                                                                                  \n",
            " activation_7 (Activation)      (None, 1, 1, 480)    0           ['conv2d_30[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_7 (Multiply)          (None, 10, 10, 480)  0           ['activation_7[0][0]',           \n",
            "                                                                  'swish_22[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_31 (Conv2D)             (None, 10, 10, 80)   38400       ['multiply_7[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_23 (BatchN  (None, 10, 10, 80)  320         ['conv2d_31[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_3 (DropConnect)   (None, 10, 10, 80)   0           ['batch_normalization_23[0][0]'] \n",
            "                                                                                                  \n",
            " add_3 (Add)                    (None, 10, 10, 80)   0           ['drop_connect_3[0][0]',         \n",
            "                                                                  'add_2[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_32 (Conv2D)             (None, 10, 10, 480)  38400       ['add_3[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_24 (BatchN  (None, 10, 10, 480)  1920       ['conv2d_32[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_24 (Swish)               (None, 10, 10, 480)  0           ['batch_normalization_24[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_8 (DepthwiseC  (None, 10, 10, 480)  12000      ['swish_24[0][0]']               \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_25 (BatchN  (None, 10, 10, 480)  1920       ['depthwise_conv2d_8[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_25 (Swish)               (None, 10, 10, 480)  0           ['batch_normalization_25[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_8 (Lambda)              (None, 1, 1, 480)    0           ['swish_25[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_33 (Conv2D)             (None, 1, 1, 20)     9620        ['lambda_8[0][0]']               \n",
            "                                                                                                  \n",
            " swish_26 (Swish)               (None, 1, 1, 20)     0           ['conv2d_33[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_34 (Conv2D)             (None, 1, 1, 480)    10080       ['swish_26[0][0]']               \n",
            "                                                                                                  \n",
            " activation_8 (Activation)      (None, 1, 1, 480)    0           ['conv2d_34[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_8 (Multiply)          (None, 10, 10, 480)  0           ['activation_8[0][0]',           \n",
            "                                                                  'swish_25[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_35 (Conv2D)             (None, 10, 10, 112)  53760       ['multiply_8[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_26 (BatchN  (None, 10, 10, 112)  448        ['conv2d_35[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_36 (Conv2D)             (None, 10, 10, 672)  75264       ['batch_normalization_26[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_27 (BatchN  (None, 10, 10, 672)  2688       ['conv2d_36[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_27 (Swish)               (None, 10, 10, 672)  0           ['batch_normalization_27[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_9 (DepthwiseC  (None, 10, 10, 672)  16800      ['swish_27[0][0]']               \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_28 (BatchN  (None, 10, 10, 672)  2688       ['depthwise_conv2d_9[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_28 (Swish)               (None, 10, 10, 672)  0           ['batch_normalization_28[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_9 (Lambda)              (None, 1, 1, 672)    0           ['swish_28[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_37 (Conv2D)             (None, 1, 1, 28)     18844       ['lambda_9[0][0]']               \n",
            "                                                                                                  \n",
            " swish_29 (Swish)               (None, 1, 1, 28)     0           ['conv2d_37[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_38 (Conv2D)             (None, 1, 1, 672)    19488       ['swish_29[0][0]']               \n",
            "                                                                                                  \n",
            " activation_9 (Activation)      (None, 1, 1, 672)    0           ['conv2d_38[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_9 (Multiply)          (None, 10, 10, 672)  0           ['activation_9[0][0]',           \n",
            "                                                                  'swish_28[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_39 (Conv2D)             (None, 10, 10, 112)  75264       ['multiply_9[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_29 (BatchN  (None, 10, 10, 112)  448        ['conv2d_39[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_4 (DropConnect)   (None, 10, 10, 112)  0           ['batch_normalization_29[0][0]'] \n",
            "                                                                                                  \n",
            " add_4 (Add)                    (None, 10, 10, 112)  0           ['drop_connect_4[0][0]',         \n",
            "                                                                  'batch_normalization_26[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_40 (Conv2D)             (None, 10, 10, 672)  75264       ['add_4[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_30 (BatchN  (None, 10, 10, 672)  2688       ['conv2d_40[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_30 (Swish)               (None, 10, 10, 672)  0           ['batch_normalization_30[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_10 (Depthwise  (None, 10, 10, 672)  16800      ['swish_30[0][0]']               \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_31 (BatchN  (None, 10, 10, 672)  2688       ['depthwise_conv2d_10[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_31 (Swish)               (None, 10, 10, 672)  0           ['batch_normalization_31[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_10 (Lambda)             (None, 1, 1, 672)    0           ['swish_31[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_41 (Conv2D)             (None, 1, 1, 28)     18844       ['lambda_10[0][0]']              \n",
            "                                                                                                  \n",
            " swish_32 (Swish)               (None, 1, 1, 28)     0           ['conv2d_41[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_42 (Conv2D)             (None, 1, 1, 672)    19488       ['swish_32[0][0]']               \n",
            "                                                                                                  \n",
            " activation_10 (Activation)     (None, 1, 1, 672)    0           ['conv2d_42[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_10 (Multiply)         (None, 10, 10, 672)  0           ['activation_10[0][0]',          \n",
            "                                                                  'swish_31[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_43 (Conv2D)             (None, 10, 10, 112)  75264       ['multiply_10[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_32 (BatchN  (None, 10, 10, 112)  448        ['conv2d_43[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_5 (DropConnect)   (None, 10, 10, 112)  0           ['batch_normalization_32[0][0]'] \n",
            "                                                                                                  \n",
            " add_5 (Add)                    (None, 10, 10, 112)  0           ['drop_connect_5[0][0]',         \n",
            "                                                                  'add_4[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_44 (Conv2D)             (None, 10, 10, 672)  75264       ['add_5[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_33 (BatchN  (None, 10, 10, 672)  2688       ['conv2d_44[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_33 (Swish)               (None, 10, 10, 672)  0           ['batch_normalization_33[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_11 (Depthwise  (None, 5, 5, 672)   16800       ['swish_33[0][0]']               \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_34 (BatchN  (None, 5, 5, 672)   2688        ['depthwise_conv2d_11[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_34 (Swish)               (None, 5, 5, 672)    0           ['batch_normalization_34[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_11 (Lambda)             (None, 1, 1, 672)    0           ['swish_34[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_45 (Conv2D)             (None, 1, 1, 28)     18844       ['lambda_11[0][0]']              \n",
            "                                                                                                  \n",
            " swish_35 (Swish)               (None, 1, 1, 28)     0           ['conv2d_45[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_46 (Conv2D)             (None, 1, 1, 672)    19488       ['swish_35[0][0]']               \n",
            "                                                                                                  \n",
            " activation_11 (Activation)     (None, 1, 1, 672)    0           ['conv2d_46[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_11 (Multiply)         (None, 5, 5, 672)    0           ['activation_11[0][0]',          \n",
            "                                                                  'swish_34[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_47 (Conv2D)             (None, 5, 5, 192)    129024      ['multiply_11[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_35 (BatchN  (None, 5, 5, 192)   768         ['conv2d_47[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_48 (Conv2D)             (None, 5, 5, 1152)   221184      ['batch_normalization_35[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_36 (BatchN  (None, 5, 5, 1152)  4608        ['conv2d_48[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_36 (Swish)               (None, 5, 5, 1152)   0           ['batch_normalization_36[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_12 (Depthwise  (None, 5, 5, 1152)  28800       ['swish_36[0][0]']               \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_37 (BatchN  (None, 5, 5, 1152)  4608        ['depthwise_conv2d_12[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_37 (Swish)               (None, 5, 5, 1152)   0           ['batch_normalization_37[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_12 (Lambda)             (None, 1, 1, 1152)   0           ['swish_37[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_49 (Conv2D)             (None, 1, 1, 48)     55344       ['lambda_12[0][0]']              \n",
            "                                                                                                  \n",
            " swish_38 (Swish)               (None, 1, 1, 48)     0           ['conv2d_49[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_50 (Conv2D)             (None, 1, 1, 1152)   56448       ['swish_38[0][0]']               \n",
            "                                                                                                  \n",
            " activation_12 (Activation)     (None, 1, 1, 1152)   0           ['conv2d_50[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_12 (Multiply)         (None, 5, 5, 1152)   0           ['activation_12[0][0]',          \n",
            "                                                                  'swish_37[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_51 (Conv2D)             (None, 5, 5, 192)    221184      ['multiply_12[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_38 (BatchN  (None, 5, 5, 192)   768         ['conv2d_51[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_6 (DropConnect)   (None, 5, 5, 192)    0           ['batch_normalization_38[0][0]'] \n",
            "                                                                                                  \n",
            " add_6 (Add)                    (None, 5, 5, 192)    0           ['drop_connect_6[0][0]',         \n",
            "                                                                  'batch_normalization_35[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_52 (Conv2D)             (None, 5, 5, 1152)   221184      ['add_6[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_39 (BatchN  (None, 5, 5, 1152)  4608        ['conv2d_52[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_39 (Swish)               (None, 5, 5, 1152)   0           ['batch_normalization_39[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_13 (Depthwise  (None, 5, 5, 1152)  28800       ['swish_39[0][0]']               \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_40 (BatchN  (None, 5, 5, 1152)  4608        ['depthwise_conv2d_13[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_40 (Swish)               (None, 5, 5, 1152)   0           ['batch_normalization_40[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_13 (Lambda)             (None, 1, 1, 1152)   0           ['swish_40[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_53 (Conv2D)             (None, 1, 1, 48)     55344       ['lambda_13[0][0]']              \n",
            "                                                                                                  \n",
            " swish_41 (Swish)               (None, 1, 1, 48)     0           ['conv2d_53[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_54 (Conv2D)             (None, 1, 1, 1152)   56448       ['swish_41[0][0]']               \n",
            "                                                                                                  \n",
            " activation_13 (Activation)     (None, 1, 1, 1152)   0           ['conv2d_54[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_13 (Multiply)         (None, 5, 5, 1152)   0           ['activation_13[0][0]',          \n",
            "                                                                  'swish_40[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_55 (Conv2D)             (None, 5, 5, 192)    221184      ['multiply_13[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_41 (BatchN  (None, 5, 5, 192)   768         ['conv2d_55[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_7 (DropConnect)   (None, 5, 5, 192)    0           ['batch_normalization_41[0][0]'] \n",
            "                                                                                                  \n",
            " add_7 (Add)                    (None, 5, 5, 192)    0           ['drop_connect_7[0][0]',         \n",
            "                                                                  'add_6[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_56 (Conv2D)             (None, 5, 5, 1152)   221184      ['add_7[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_42 (BatchN  (None, 5, 5, 1152)  4608        ['conv2d_56[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_42 (Swish)               (None, 5, 5, 1152)   0           ['batch_normalization_42[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_14 (Depthwise  (None, 5, 5, 1152)  28800       ['swish_42[0][0]']               \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_43 (BatchN  (None, 5, 5, 1152)  4608        ['depthwise_conv2d_14[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_43 (Swish)               (None, 5, 5, 1152)   0           ['batch_normalization_43[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_14 (Lambda)             (None, 1, 1, 1152)   0           ['swish_43[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_57 (Conv2D)             (None, 1, 1, 48)     55344       ['lambda_14[0][0]']              \n",
            "                                                                                                  \n",
            " swish_44 (Swish)               (None, 1, 1, 48)     0           ['conv2d_57[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_58 (Conv2D)             (None, 1, 1, 1152)   56448       ['swish_44[0][0]']               \n",
            "                                                                                                  \n",
            " activation_14 (Activation)     (None, 1, 1, 1152)   0           ['conv2d_58[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_14 (Multiply)         (None, 5, 5, 1152)   0           ['activation_14[0][0]',          \n",
            "                                                                  'swish_43[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_59 (Conv2D)             (None, 5, 5, 192)    221184      ['multiply_14[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_44 (BatchN  (None, 5, 5, 192)   768         ['conv2d_59[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_8 (DropConnect)   (None, 5, 5, 192)    0           ['batch_normalization_44[0][0]'] \n",
            "                                                                                                  \n",
            " add_8 (Add)                    (None, 5, 5, 192)    0           ['drop_connect_8[0][0]',         \n",
            "                                                                  'add_7[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_60 (Conv2D)             (None, 5, 5, 1152)   221184      ['add_8[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_45 (BatchN  (None, 5, 5, 1152)  4608        ['conv2d_60[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_45 (Swish)               (None, 5, 5, 1152)   0           ['batch_normalization_45[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_15 (Depthwise  (None, 5, 5, 1152)  10368       ['swish_45[0][0]']               \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_46 (BatchN  (None, 5, 5, 1152)  4608        ['depthwise_conv2d_15[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_46 (Swish)               (None, 5, 5, 1152)   0           ['batch_normalization_46[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_15 (Lambda)             (None, 1, 1, 1152)   0           ['swish_46[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_61 (Conv2D)             (None, 1, 1, 48)     55344       ['lambda_15[0][0]']              \n",
            "                                                                                                  \n",
            " swish_47 (Swish)               (None, 1, 1, 48)     0           ['conv2d_61[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_62 (Conv2D)             (None, 1, 1, 1152)   56448       ['swish_47[0][0]']               \n",
            "                                                                                                  \n",
            " activation_15 (Activation)     (None, 1, 1, 1152)   0           ['conv2d_62[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_15 (Multiply)         (None, 5, 5, 1152)   0           ['activation_15[0][0]',          \n",
            "                                                                  'swish_46[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_63 (Conv2D)             (None, 5, 5, 320)    368640      ['multiply_15[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_47 (BatchN  (None, 5, 5, 320)   1280        ['conv2d_63[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_64 (Conv2D)             (None, 5, 5, 1280)   409600      ['batch_normalization_47[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_48 (BatchN  (None, 5, 5, 1280)  5120        ['conv2d_64[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_48 (Swish)               (None, 5, 5, 1280)   0           ['batch_normalization_48[0][0]'] \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 4,049,564\n",
            "Trainable params: 0\n",
            "Non-trainable params: 4,049,564\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#สร้างโฟลเดอร์ Train Valodation และ Test"
      ],
      "metadata": {
        "id": "J36J9EAE7qSB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv (r'/content/drive/MyDrive/cut_panoramic/Data/New_Data_Male125.csv')\n",
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "skoKhKJDngAZ",
        "outputId": "622055f3-5b49-4433-bdf9-4050f344dae4"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      Fig_Age  Fig_Person_Sex  Age(year) Class  Class_Re       Filename  \\\n",
              "0           1               1          7  Y07M         0       VV03.jpg   \n",
              "1           2               1          7  Y07M         0  Flip_VV03.jpg   \n",
              "2           3               2          7  Y07M         0       VV04.jpg   \n",
              "3           4               2          7  Y07M         0  Flip_VV04.jpg   \n",
              "4           5               3          7  Y07M         0       VV05.jpg   \n",
              "...       ...             ...        ...   ...       ...            ...   \n",
              "2370      121              77         25  Y25M        18  Flip_J463.jpg   \n",
              "2371      122              78         25  Y25M        18       J464.jpg   \n",
              "2372      123              78         25  Y25M        18  Flip_J464.jpg   \n",
              "2373      124              79         25  Y25M        18       J465.jpg   \n",
              "2374      125              79         25  Y25M        18  Flip_J465.jpg   \n",
              "\n",
              "                                          Path_filename     Sex Floder  \n",
              "0     /content/drive/My Drive/TVT_Male125/train/Y07M...  เพศชาย   Both  \n",
              "1     /content/drive/My Drive/TVT_Male125/train/Y07M...  เพศชาย   Both  \n",
              "2     /content/drive/My Drive/TVT_Male125/train/Y07M...  เพศชาย   Both  \n",
              "3     /content/drive/My Drive/TVT_Male125/train/Y07M...  เพศชาย   Both  \n",
              "4     /content/drive/My Drive/TVT_Male125/train/Y07M...  เพศชาย   Both  \n",
              "...                                                 ...     ...    ...  \n",
              "2370  /content/drive/My Drive/TVT_Male125/test/Y25M/...  เพศชาย   Both  \n",
              "2371  /content/drive/My Drive/TVT_Male125/test/Y25M/...  เพศชาย   Both  \n",
              "2372  /content/drive/My Drive/TVT_Male125/test/Y25M/...  เพศชาย   Both  \n",
              "2373  /content/drive/My Drive/TVT_Male125/test/Y25M/...  เพศชาย   Both  \n",
              "2374  /content/drive/My Drive/TVT_Male125/test/Y25M/...  เพศชาย   Both  \n",
              "\n",
              "[2375 rows x 9 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-79a59562-a6d0-4fd5-84a6-663a6d522604\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Fig_Age</th>\n",
              "      <th>Fig_Person_Sex</th>\n",
              "      <th>Age(year)</th>\n",
              "      <th>Class</th>\n",
              "      <th>Class_Re</th>\n",
              "      <th>Filename</th>\n",
              "      <th>Path_filename</th>\n",
              "      <th>Sex</th>\n",
              "      <th>Floder</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>Y07M</td>\n",
              "      <td>0</td>\n",
              "      <td>VV03.jpg</td>\n",
              "      <td>/content/drive/My Drive/TVT_Male125/train/Y07M...</td>\n",
              "      <td>เพศชาย</td>\n",
              "      <td>Both</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>Y07M</td>\n",
              "      <td>0</td>\n",
              "      <td>Flip_VV03.jpg</td>\n",
              "      <td>/content/drive/My Drive/TVT_Male125/train/Y07M...</td>\n",
              "      <td>เพศชาย</td>\n",
              "      <td>Both</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>7</td>\n",
              "      <td>Y07M</td>\n",
              "      <td>0</td>\n",
              "      <td>VV04.jpg</td>\n",
              "      <td>/content/drive/My Drive/TVT_Male125/train/Y07M...</td>\n",
              "      <td>เพศชาย</td>\n",
              "      <td>Both</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>7</td>\n",
              "      <td>Y07M</td>\n",
              "      <td>0</td>\n",
              "      <td>Flip_VV04.jpg</td>\n",
              "      <td>/content/drive/My Drive/TVT_Male125/train/Y07M...</td>\n",
              "      <td>เพศชาย</td>\n",
              "      <td>Both</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>7</td>\n",
              "      <td>Y07M</td>\n",
              "      <td>0</td>\n",
              "      <td>VV05.jpg</td>\n",
              "      <td>/content/drive/My Drive/TVT_Male125/train/Y07M...</td>\n",
              "      <td>เพศชาย</td>\n",
              "      <td>Both</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2370</th>\n",
              "      <td>121</td>\n",
              "      <td>77</td>\n",
              "      <td>25</td>\n",
              "      <td>Y25M</td>\n",
              "      <td>18</td>\n",
              "      <td>Flip_J463.jpg</td>\n",
              "      <td>/content/drive/My Drive/TVT_Male125/test/Y25M/...</td>\n",
              "      <td>เพศชาย</td>\n",
              "      <td>Both</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2371</th>\n",
              "      <td>122</td>\n",
              "      <td>78</td>\n",
              "      <td>25</td>\n",
              "      <td>Y25M</td>\n",
              "      <td>18</td>\n",
              "      <td>J464.jpg</td>\n",
              "      <td>/content/drive/My Drive/TVT_Male125/test/Y25M/...</td>\n",
              "      <td>เพศชาย</td>\n",
              "      <td>Both</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2372</th>\n",
              "      <td>123</td>\n",
              "      <td>78</td>\n",
              "      <td>25</td>\n",
              "      <td>Y25M</td>\n",
              "      <td>18</td>\n",
              "      <td>Flip_J464.jpg</td>\n",
              "      <td>/content/drive/My Drive/TVT_Male125/test/Y25M/...</td>\n",
              "      <td>เพศชาย</td>\n",
              "      <td>Both</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2373</th>\n",
              "      <td>124</td>\n",
              "      <td>79</td>\n",
              "      <td>25</td>\n",
              "      <td>Y25M</td>\n",
              "      <td>18</td>\n",
              "      <td>J465.jpg</td>\n",
              "      <td>/content/drive/My Drive/TVT_Male125/test/Y25M/...</td>\n",
              "      <td>เพศชาย</td>\n",
              "      <td>Both</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2374</th>\n",
              "      <td>125</td>\n",
              "      <td>79</td>\n",
              "      <td>25</td>\n",
              "      <td>Y25M</td>\n",
              "      <td>18</td>\n",
              "      <td>Flip_J465.jpg</td>\n",
              "      <td>/content/drive/My Drive/TVT_Male125/test/Y25M/...</td>\n",
              "      <td>เพศชาย</td>\n",
              "      <td>Both</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2375 rows × 9 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-79a59562-a6d0-4fd5-84a6-663a6d522604')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-79a59562-a6d0-4fd5-84a6-663a6d522604 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-79a59562-a6d0-4fd5-84a6-663a6d522604');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train = df[df['Fig_Age'].between(1,75)]\n",
        "val = df[df['Fig_Age'].between(76,100)]"
      ],
      "metadata": {
        "id": "Z1zBw01Gl8Ac"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DATA_PATH = \"/content/drive/My Drive/TVT_Male125\"\n",
        "os.chdir(DATA_PATH)\n",
        "train_dir = os.path.join(DATA_PATH, 'train')\n",
        "print(train_dir)\n",
        "validation_dir = os.path.join(DATA_PATH, 'validation')\n",
        "print(validation_dir)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QL0g-8iOnMC4",
        "outputId": "53a9fab3-a09b-42dd-a8cb-8546a5bf4848"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/My Drive/TVT_Male125/train\n",
            "/content/drive/My Drive/TVT_Male125/validation\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "#Train"
      ],
      "metadata": {
        "id": "bWEnlTSwazL5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train ด้วย ImageDataGenerator ของ Keras ซึ่งจะเพิ่มข้อมูลเสริมระหว่างการฝึกเพื่อลดโอกาสเกิด overfitting\n",
        "#overfitting เกิดจากข้อมูลที่ซับซ้อนกันเกินไป\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "train_datagen = ImageDataGenerator(\n",
        "      rescale=1./255, #โมเดลส่วนใหญ่ต้องใช้ RGB ในช่วง 0–1\n",
        "      rotation_range=40,\n",
        "      width_shift_range=0.2,\n",
        "      height_shift_range=0.2,\n",
        "      shear_range=0.2,\n",
        "      zoom_range=0.2,\n",
        "      horizontal_flip=True,\n",
        "      fill_mode='nearest')\n",
        "\n",
        "# Note that the validation data should not be augmented!\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)"
      ],
      "metadata": {
        "id": "xGPrsn9no_pa"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_generator = train_datagen.flow_from_dataframe(\n",
        "        dataframe = train,\n",
        "        directory = train_dir,\n",
        "        x_col = 'Path_filename',\n",
        "        y_col = 'Class_Re',\n",
        "        class_mode = 'other',\n",
        "        target_size=(height, width),\n",
        "        batch_size=batch_size)\n",
        "\n",
        "validation_generator = test_datagen.flow_from_dataframe(\n",
        "        dataframe = val,\n",
        "        directory = validation_dir,\n",
        "        x_col = 'Path_filename',\n",
        "        y_col = 'Class_Re',\n",
        "        class_mode = 'other',\n",
        "        target_size=(height, width),\n",
        "        batch_size=batch_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8nVlmAszntK_",
        "outputId": "ac099b9d-d295-4054-a458-4252b57517ec"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1425 validated image filenames.\n",
            "Found 475 validated image filenames.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='mse',\n",
        "          optimizer=Adam(learning_rate=1e-3),\n",
        "          metrics=['mae'])\n",
        "history = model.fit_generator(\n",
        "      train_generator,\n",
        "      steps_per_epoch= NUM_TRAIN //batch_size,\n",
        "      epochs=epochs,\n",
        "      validation_data=validation_generator,\n",
        "      validation_steps= NUM_TEST //batch_size,\n",
        "      verbose=1,\n",
        "      use_multiprocessing=True,\n",
        "      workers=4)"
      ],
      "metadata": {
        "id": "N6qUmmF856ZE",
        "outputId": "22324014-f431-47eb-ec0d-6516f52f0e4e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-20-2af770e0aff0>:4: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  history = model.fit_generator(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "89/89 [==============================] - 390s 4s/step - loss: 100.5361 - mae: 8.4567 - val_loss: 99.3378 - val_mae: 8.4051\n",
            "Epoch 2/500\n",
            "89/89 [==============================] - 23s 251ms/step - loss: 97.5507 - mae: 8.3025 - val_loss: 96.0064 - val_mae: 8.2289\n",
            "Epoch 3/500\n",
            "89/89 [==============================] - 28s 312ms/step - loss: 94.4673 - mae: 8.1312 - val_loss: 92.5250 - val_mae: 8.0309\n",
            "Epoch 4/500\n",
            "89/89 [==============================] - 27s 300ms/step - loss: 91.9650 - mae: 8.0068 - val_loss: 90.7703 - val_mae: 7.9337\n",
            "Epoch 5/500\n",
            "89/89 [==============================] - 28s 310ms/step - loss: 89.2163 - mae: 7.8588 - val_loss: 88.2754 - val_mae: 7.8029\n",
            "Epoch 6/500\n",
            "89/89 [==============================] - 27s 291ms/step - loss: 86.3195 - mae: 7.7122 - val_loss: 85.5190 - val_mae: 7.6550\n",
            "Epoch 7/500\n",
            "89/89 [==============================] - 21s 237ms/step - loss: 84.4757 - mae: 7.6207 - val_loss: 82.2128 - val_mae: 7.4947\n",
            "Epoch 8/500\n",
            "89/89 [==============================] - 28s 305ms/step - loss: 81.6489 - mae: 7.4590 - val_loss: 80.3397 - val_mae: 7.3801\n",
            "Epoch 9/500\n",
            "89/89 [==============================] - 27s 301ms/step - loss: 79.9894 - mae: 7.3770 - val_loss: 77.4782 - val_mae: 7.2315\n",
            "Epoch 10/500\n",
            "89/89 [==============================] - 26s 290ms/step - loss: 77.6311 - mae: 7.2426 - val_loss: 76.3088 - val_mae: 7.1940\n",
            "Epoch 11/500\n",
            "89/89 [==============================] - 22s 242ms/step - loss: 74.9347 - mae: 7.1111 - val_loss: 74.1403 - val_mae: 7.0801\n",
            "Epoch 12/500\n",
            "89/89 [==============================] - 28s 306ms/step - loss: 73.5897 - mae: 7.0471 - val_loss: 72.0725 - val_mae: 6.9565\n",
            "Epoch 13/500\n",
            "89/89 [==============================] - 27s 294ms/step - loss: 71.2316 - mae: 6.9205 - val_loss: 68.8163 - val_mae: 6.7711\n",
            "Epoch 14/500\n",
            "89/89 [==============================] - 26s 287ms/step - loss: 68.7365 - mae: 6.7876 - val_loss: 68.2052 - val_mae: 6.7515\n",
            "Epoch 15/500\n",
            "89/89 [==============================] - 27s 300ms/step - loss: 67.4328 - mae: 6.7152 - val_loss: 66.3199 - val_mae: 6.6528\n",
            "Epoch 16/500\n",
            "89/89 [==============================] - 26s 289ms/step - loss: 65.5344 - mae: 6.6122 - val_loss: 65.0029 - val_mae: 6.5889\n",
            "Epoch 17/500\n",
            "89/89 [==============================] - 27s 300ms/step - loss: 63.4054 - mae: 6.5065 - val_loss: 62.8369 - val_mae: 6.4686\n",
            "Epoch 18/500\n",
            "89/89 [==============================] - 27s 309ms/step - loss: 62.0303 - mae: 6.4349 - val_loss: 61.6976 - val_mae: 6.4253\n",
            "Epoch 19/500\n",
            "89/89 [==============================] - 26s 286ms/step - loss: 60.2698 - mae: 6.3394 - val_loss: 60.2037 - val_mae: 6.3601\n",
            "Epoch 20/500\n",
            "89/89 [==============================] - 26s 287ms/step - loss: 58.7931 - mae: 6.2645 - val_loss: 58.2832 - val_mae: 6.2525\n",
            "Epoch 21/500\n",
            "89/89 [==============================] - 26s 288ms/step - loss: 56.9244 - mae: 6.1519 - val_loss: 56.2147 - val_mae: 6.1234\n",
            "Epoch 22/500\n",
            "89/89 [==============================] - 27s 292ms/step - loss: 55.7511 - mae: 6.0928 - val_loss: 55.6807 - val_mae: 6.0921\n",
            "Epoch 23/500\n",
            "89/89 [==============================] - 27s 302ms/step - loss: 54.2248 - mae: 6.0128 - val_loss: 53.4723 - val_mae: 5.9726\n",
            "Epoch 24/500\n",
            "89/89 [==============================] - 26s 291ms/step - loss: 53.2401 - mae: 5.9722 - val_loss: 53.1008 - val_mae: 5.9746\n",
            "Epoch 25/500\n",
            "89/89 [==============================] - 26s 282ms/step - loss: 51.7316 - mae: 5.8916 - val_loss: 51.2019 - val_mae: 5.8619\n",
            "Epoch 26/500\n",
            "89/89 [==============================] - 26s 285ms/step - loss: 50.6056 - mae: 5.8364 - val_loss: 50.1902 - val_mae: 5.8115\n",
            "Epoch 27/500\n",
            "89/89 [==============================] - 26s 283ms/step - loss: 49.2477 - mae: 5.7610 - val_loss: 48.0450 - val_mae: 5.6976\n",
            "Epoch 28/500\n",
            "89/89 [==============================] - 27s 296ms/step - loss: 48.2680 - mae: 5.7122 - val_loss: 48.2119 - val_mae: 5.7160\n",
            "Epoch 29/500\n",
            "89/89 [==============================] - 27s 294ms/step - loss: 47.2652 - mae: 5.6532 - val_loss: 46.2918 - val_mae: 5.5967\n",
            "Epoch 30/500\n",
            "89/89 [==============================] - 26s 284ms/step - loss: 46.1162 - mae: 5.5841 - val_loss: 45.1368 - val_mae: 5.5297\n",
            "Epoch 31/500\n",
            "89/89 [==============================] - 27s 298ms/step - loss: 45.2545 - mae: 5.5477 - val_loss: 45.1383 - val_mae: 5.5530\n",
            "Epoch 32/500\n",
            "89/89 [==============================] - 26s 284ms/step - loss: 44.0654 - mae: 5.4831 - val_loss: 43.4765 - val_mae: 5.4462\n",
            "Epoch 33/500\n",
            "89/89 [==============================] - 26s 286ms/step - loss: 43.2892 - mae: 5.4503 - val_loss: 42.4289 - val_mae: 5.4010\n",
            "Epoch 34/500\n",
            "89/89 [==============================] - 26s 285ms/step - loss: 42.1247 - mae: 5.3908 - val_loss: 41.4047 - val_mae: 5.3448\n",
            "Epoch 35/500\n",
            "89/89 [==============================] - 27s 292ms/step - loss: 41.6048 - mae: 5.3720 - val_loss: 41.3995 - val_mae: 5.3575\n",
            "Epoch 36/500\n",
            "89/89 [==============================] - 26s 285ms/step - loss: 40.7408 - mae: 5.3161 - val_loss: 40.1939 - val_mae: 5.2829\n",
            "Epoch 37/500\n",
            "89/89 [==============================] - 26s 289ms/step - loss: 39.8311 - mae: 5.2592 - val_loss: 39.4806 - val_mae: 5.2415\n",
            "Epoch 38/500\n",
            "89/89 [==============================] - 26s 291ms/step - loss: 39.1137 - mae: 5.2213 - val_loss: 39.1870 - val_mae: 5.2354\n",
            "Epoch 39/500\n",
            "89/89 [==============================] - 27s 292ms/step - loss: 38.5323 - mae: 5.1903 - val_loss: 38.4289 - val_mae: 5.1934\n",
            "Epoch 40/500\n",
            "89/89 [==============================] - 26s 285ms/step - loss: 38.0149 - mae: 5.1679 - val_loss: 37.6542 - val_mae: 5.1484\n",
            "Epoch 41/500\n",
            "89/89 [==============================] - 21s 229ms/step - loss: 37.3491 - mae: 5.1396 - val_loss: 36.9392 - val_mae: 5.1142\n",
            "Epoch 42/500\n",
            "89/89 [==============================] - 28s 305ms/step - loss: 36.6472 - mae: 5.1016 - val_loss: 36.1927 - val_mae: 5.0763\n",
            "Epoch 43/500\n",
            "89/89 [==============================] - 28s 309ms/step - loss: 36.2073 - mae: 5.0817 - val_loss: 36.0199 - val_mae: 5.0788\n",
            "Epoch 44/500\n",
            "89/89 [==============================] - 28s 309ms/step - loss: 35.5507 - mae: 5.0374 - val_loss: 35.3741 - val_mae: 5.0333\n",
            "Epoch 45/500\n",
            "89/89 [==============================] - 28s 312ms/step - loss: 35.1582 - mae: 5.0250 - val_loss: 34.8207 - val_mae: 5.0006\n",
            "Epoch 46/500\n",
            "89/89 [==============================] - 28s 311ms/step - loss: 34.5979 - mae: 4.9879 - val_loss: 34.4067 - val_mae: 4.9761\n",
            "Epoch 47/500\n",
            "89/89 [==============================] - 27s 297ms/step - loss: 34.2572 - mae: 4.9610 - val_loss: 34.4476 - val_mae: 4.9804\n",
            "Epoch 48/500\n",
            "89/89 [==============================] - 27s 295ms/step - loss: 33.8811 - mae: 4.9470 - val_loss: 33.5271 - val_mae: 4.9256\n",
            "Epoch 49/500\n",
            "89/89 [==============================] - 29s 315ms/step - loss: 33.3593 - mae: 4.9153 - val_loss: 33.4002 - val_mae: 4.9320\n",
            "Epoch 50/500\n",
            "89/89 [==============================] - 22s 238ms/step - loss: 33.2754 - mae: 4.9243 - val_loss: 32.9015 - val_mae: 4.8875\n",
            "Epoch 51/500\n",
            "89/89 [==============================] - 27s 291ms/step - loss: 32.8796 - mae: 4.8990 - val_loss: 32.5715 - val_mae: 4.8779\n",
            "Epoch 52/500\n",
            "89/89 [==============================] - 28s 300ms/step - loss: 32.6623 - mae: 4.8904 - val_loss: 32.3800 - val_mae: 4.8656\n",
            "Epoch 53/500\n",
            "89/89 [==============================] - 27s 287ms/step - loss: 32.2833 - mae: 4.8683 - val_loss: 32.3380 - val_mae: 4.8742\n",
            "Epoch 54/500\n",
            "89/89 [==============================] - 21s 227ms/step - loss: 32.1124 - mae: 4.8624 - val_loss: 32.2907 - val_mae: 4.8827\n",
            "Epoch 55/500\n",
            "89/89 [==============================] - 26s 284ms/step - loss: 31.9318 - mae: 4.8524 - val_loss: 31.8641 - val_mae: 4.8511\n",
            "Epoch 56/500\n",
            "89/89 [==============================] - 25s 279ms/step - loss: 31.7902 - mae: 4.8452 - val_loss: 31.5230 - val_mae: 4.8280\n",
            "Epoch 57/500\n",
            "89/89 [==============================] - 27s 294ms/step - loss: 31.4756 - mae: 4.8204 - val_loss: 31.5797 - val_mae: 4.8358\n",
            "Epoch 58/500\n",
            "89/89 [==============================] - 27s 299ms/step - loss: 31.2779 - mae: 4.8080 - val_loss: 31.0618 - val_mae: 4.7844\n",
            "Epoch 59/500\n",
            "89/89 [==============================] - 27s 295ms/step - loss: 31.1902 - mae: 4.8067 - val_loss: 31.4510 - val_mae: 4.8337\n",
            "Epoch 60/500\n",
            "89/89 [==============================] - 26s 282ms/step - loss: 30.9695 - mae: 4.7855 - val_loss: 30.9401 - val_mae: 4.7829\n",
            "Epoch 61/500\n",
            "89/89 [==============================] - 26s 281ms/step - loss: 30.9986 - mae: 4.7988 - val_loss: 30.7622 - val_mae: 4.7770\n",
            "Epoch 62/500\n",
            "89/89 [==============================] - 26s 281ms/step - loss: 30.6894 - mae: 4.7734 - val_loss: 30.8191 - val_mae: 4.8024\n",
            "Epoch 63/500\n",
            "89/89 [==============================] - 21s 224ms/step - loss: 30.6283 - mae: 4.7765 - val_loss: 30.7436 - val_mae: 4.7921\n",
            "Epoch 64/500\n",
            "89/89 [==============================] - 27s 293ms/step - loss: 30.5088 - mae: 4.7696 - val_loss: 30.5382 - val_mae: 4.7688\n",
            "Epoch 65/500\n",
            "89/89 [==============================] - 27s 302ms/step - loss: 30.5486 - mae: 4.7768 - val_loss: 30.5183 - val_mae: 4.7734\n",
            "Epoch 66/500\n",
            "89/89 [==============================] - 27s 299ms/step - loss: 30.3465 - mae: 4.7632 - val_loss: 30.3882 - val_mae: 4.7732\n",
            "Epoch 67/500\n",
            "89/89 [==============================] - 27s 296ms/step - loss: 30.3109 - mae: 4.7618 - val_loss: 30.3491 - val_mae: 4.7667\n",
            "Epoch 68/500\n",
            "89/89 [==============================] - 26s 284ms/step - loss: 30.3150 - mae: 4.7666 - val_loss: 30.1843 - val_mae: 4.7502\n",
            "Epoch 69/500\n",
            "89/89 [==============================] - 22s 245ms/step - loss: 30.2846 - mae: 4.7648 - val_loss: 30.0701 - val_mae: 4.7407\n",
            "Epoch 70/500\n",
            "89/89 [==============================] - 27s 297ms/step - loss: 29.6211 - mae: 4.6664 - val_loss: 21.9296 - val_mae: 3.8959\n",
            "Epoch 71/500\n",
            "89/89 [==============================] - 26s 291ms/step - loss: 22.5032 - mae: 3.9106 - val_loss: 23.0007 - val_mae: 4.0754\n",
            "Epoch 72/500\n",
            "89/89 [==============================] - 27s 297ms/step - loss: 20.8864 - mae: 3.7384 - val_loss: 19.2332 - val_mae: 3.5795\n",
            "Epoch 73/500\n",
            "89/89 [==============================] - 21s 225ms/step - loss: 20.2763 - mae: 3.6682 - val_loss: 18.5792 - val_mae: 3.4769\n",
            "Epoch 74/500\n",
            "89/89 [==============================] - 27s 301ms/step - loss: 19.4338 - mae: 3.6128 - val_loss: 18.1805 - val_mae: 3.4038\n",
            "Epoch 75/500\n",
            "89/89 [==============================] - 26s 286ms/step - loss: 19.0773 - mae: 3.5775 - val_loss: 17.4637 - val_mae: 3.3609\n",
            "Epoch 76/500\n",
            "89/89 [==============================] - 26s 281ms/step - loss: 18.4901 - mae: 3.5142 - val_loss: 16.5516 - val_mae: 3.2486\n",
            "Epoch 77/500\n",
            "89/89 [==============================] - 26s 288ms/step - loss: 17.7034 - mae: 3.4285 - val_loss: 16.2872 - val_mae: 3.2288\n",
            "Epoch 78/500\n",
            "89/89 [==============================] - 27s 298ms/step - loss: 17.1404 - mae: 3.3640 - val_loss: 16.6972 - val_mae: 3.2516\n",
            "Epoch 79/500\n",
            "89/89 [==============================] - 27s 295ms/step - loss: 17.0501 - mae: 3.3676 - val_loss: 20.1369 - val_mae: 3.4880\n",
            "Epoch 80/500\n",
            "89/89 [==============================] - 27s 300ms/step - loss: 18.5825 - mae: 3.4984 - val_loss: 16.9462 - val_mae: 3.4436\n",
            "Epoch 81/500\n",
            "89/89 [==============================] - 27s 300ms/step - loss: 16.4332 - mae: 3.3328 - val_loss: 14.6217 - val_mae: 3.0656\n",
            "Epoch 82/500\n",
            "89/89 [==============================] - 27s 297ms/step - loss: 16.1615 - mae: 3.2956 - val_loss: 15.0834 - val_mae: 3.1985\n",
            "Epoch 83/500\n",
            "89/89 [==============================] - 27s 301ms/step - loss: 16.3998 - mae: 3.3327 - val_loss: 14.1619 - val_mae: 3.0212\n",
            "Epoch 84/500\n",
            "89/89 [==============================] - 22s 239ms/step - loss: 16.0419 - mae: 3.2798 - val_loss: 14.9417 - val_mae: 3.0876\n",
            "Epoch 85/500\n",
            "89/89 [==============================] - 26s 284ms/step - loss: 15.2996 - mae: 3.2024 - val_loss: 14.7381 - val_mae: 3.0738\n",
            "Epoch 86/500\n",
            "89/89 [==============================] - 27s 289ms/step - loss: 15.4129 - mae: 3.2051 - val_loss: 13.1861 - val_mae: 2.9372\n",
            "Epoch 87/500\n",
            "89/89 [==============================] - 21s 228ms/step - loss: 15.2353 - mae: 3.2432 - val_loss: 13.0042 - val_mae: 2.9097\n",
            "Epoch 88/500\n",
            "89/89 [==============================] - 22s 238ms/step - loss: 15.0313 - mae: 3.2030 - val_loss: 13.1967 - val_mae: 2.9861\n",
            "Epoch 89/500\n",
            "89/89 [==============================] - 27s 285ms/step - loss: 14.8045 - mae: 3.1779 - val_loss: 13.8841 - val_mae: 2.9908\n",
            "Epoch 90/500\n",
            "89/89 [==============================] - 26s 280ms/step - loss: 14.6657 - mae: 3.1765 - val_loss: 12.2766 - val_mae: 2.8501\n",
            "Epoch 91/500\n",
            "89/89 [==============================] - 26s 282ms/step - loss: 14.6125 - mae: 3.1698 - val_loss: 12.0277 - val_mae: 2.8213\n",
            "Epoch 92/500\n",
            "89/89 [==============================] - 26s 285ms/step - loss: 14.1805 - mae: 3.1037 - val_loss: 12.0451 - val_mae: 2.8383\n",
            "Epoch 93/500\n",
            "89/89 [==============================] - 26s 283ms/step - loss: 14.6792 - mae: 3.1415 - val_loss: 12.0650 - val_mae: 2.8309\n",
            "Epoch 94/500\n",
            "89/89 [==============================] - 27s 297ms/step - loss: 14.4635 - mae: 3.1358 - val_loss: 13.8930 - val_mae: 2.9633\n",
            "Epoch 95/500\n",
            "89/89 [==============================] - 21s 224ms/step - loss: 13.9055 - mae: 3.0966 - val_loss: 14.3057 - val_mae: 2.9720\n",
            "Epoch 96/500\n",
            "89/89 [==============================] - 27s 297ms/step - loss: 14.4175 - mae: 3.1324 - val_loss: 13.9913 - val_mae: 2.9523\n",
            "Epoch 97/500\n",
            "89/89 [==============================] - 26s 285ms/step - loss: 13.7685 - mae: 3.0562 - val_loss: 11.1265 - val_mae: 2.7129\n",
            "Epoch 98/500\n",
            "89/89 [==============================] - 27s 299ms/step - loss: 13.7562 - mae: 3.0409 - val_loss: 11.4829 - val_mae: 2.7440\n",
            "Epoch 99/500\n",
            "89/89 [==============================] - 27s 298ms/step - loss: 13.4078 - mae: 3.0119 - val_loss: 11.0126 - val_mae: 2.7129\n",
            "Epoch 100/500\n",
            "89/89 [==============================] - 27s 299ms/step - loss: 14.2184 - mae: 3.0888 - val_loss: 14.2766 - val_mae: 2.9806\n",
            "Epoch 101/500\n",
            "89/89 [==============================] - 26s 285ms/step - loss: 13.2738 - mae: 2.9998 - val_loss: 11.5520 - val_mae: 2.7586\n",
            "Epoch 102/500\n",
            "89/89 [==============================] - 21s 227ms/step - loss: 13.9226 - mae: 3.0712 - val_loss: 11.0634 - val_mae: 2.7194\n",
            "Epoch 103/500\n",
            "89/89 [==============================] - 27s 299ms/step - loss: 13.1732 - mae: 2.9814 - val_loss: 10.7702 - val_mae: 2.6862\n",
            "Epoch 104/500\n",
            "89/89 [==============================] - 28s 304ms/step - loss: 13.8556 - mae: 3.0488 - val_loss: 18.5717 - val_mae: 3.3040\n",
            "Epoch 105/500\n",
            "89/89 [==============================] - 27s 302ms/step - loss: 13.1774 - mae: 2.9759 - val_loss: 11.7644 - val_mae: 2.7744\n",
            "Epoch 106/500\n",
            "89/89 [==============================] - 27s 292ms/step - loss: 13.2736 - mae: 3.0153 - val_loss: 11.1443 - val_mae: 2.7286\n",
            "Epoch 107/500\n",
            "89/89 [==============================] - 25s 278ms/step - loss: 13.3349 - mae: 3.0032 - val_loss: 10.7120 - val_mae: 2.6902\n",
            "Epoch 108/500\n",
            "89/89 [==============================] - 27s 296ms/step - loss: 13.0733 - mae: 2.9720 - val_loss: 11.2448 - val_mae: 2.7331\n",
            "Epoch 109/500\n",
            "89/89 [==============================] - 27s 297ms/step - loss: 13.5875 - mae: 3.0014 - val_loss: 14.5568 - val_mae: 2.9898\n",
            "Epoch 110/500\n",
            "89/89 [==============================] - 27s 295ms/step - loss: 13.7860 - mae: 3.0413 - val_loss: 17.4942 - val_mae: 3.2365\n",
            "Epoch 111/500\n",
            "89/89 [==============================] - 26s 283ms/step - loss: 13.2050 - mae: 2.9756 - val_loss: 14.1975 - val_mae: 2.9547\n",
            "Epoch 112/500\n",
            "89/89 [==============================] - 25s 279ms/step - loss: 12.9832 - mae: 2.9669 - val_loss: 21.0795 - val_mae: 3.5208\n",
            "Epoch 113/500\n",
            "89/89 [==============================] - 26s 281ms/step - loss: 12.8339 - mae: 2.9387 - val_loss: 12.0249 - val_mae: 2.7720\n",
            "Epoch 114/500\n",
            "89/89 [==============================] - 25s 278ms/step - loss: 13.0628 - mae: 2.9496 - val_loss: 26.3226 - val_mae: 3.9018\n",
            "Epoch 115/500\n",
            "89/89 [==============================] - 26s 288ms/step - loss: 12.9695 - mae: 2.9217 - val_loss: 18.6691 - val_mae: 3.3424\n",
            "Epoch 116/500\n",
            "89/89 [==============================] - 26s 286ms/step - loss: 12.8954 - mae: 2.9265 - val_loss: 15.4291 - val_mae: 3.0750\n",
            "Epoch 117/500\n",
            "89/89 [==============================] - 26s 283ms/step - loss: 12.6223 - mae: 2.8958 - val_loss: 31.5829 - val_mae: 4.3264\n",
            "Epoch 118/500\n",
            "89/89 [==============================] - 26s 280ms/step - loss: 14.1919 - mae: 3.0678 - val_loss: 11.5684 - val_mae: 2.7274\n",
            "Epoch 119/500\n",
            "89/89 [==============================] - 25s 278ms/step - loss: 12.5062 - mae: 2.9081 - val_loss: 18.5323 - val_mae: 3.3170\n",
            "Epoch 120/500\n",
            "89/89 [==============================] - 26s 281ms/step - loss: 12.8258 - mae: 2.9420 - val_loss: 14.7065 - val_mae: 2.9926\n",
            "Epoch 121/500\n",
            "89/89 [==============================] - 21s 224ms/step - loss: 12.8318 - mae: 2.9159 - val_loss: 14.4303 - val_mae: 2.9648\n",
            "Epoch 122/500\n",
            "89/89 [==============================] - 26s 286ms/step - loss: 13.0768 - mae: 2.9329 - val_loss: 27.7360 - val_mae: 4.0129\n",
            "Epoch 123/500\n",
            "89/89 [==============================] - 26s 282ms/step - loss: 12.6993 - mae: 2.9027 - val_loss: 15.1368 - val_mae: 3.0252\n",
            "Epoch 124/500\n",
            "89/89 [==============================] - 27s 296ms/step - loss: 12.6780 - mae: 2.9091 - val_loss: 11.8350 - val_mae: 2.7528\n",
            "Epoch 125/500\n",
            "89/89 [==============================] - 27s 294ms/step - loss: 12.5565 - mae: 2.8923 - val_loss: 19.9295 - val_mae: 3.4201\n",
            "Epoch 126/500\n",
            "89/89 [==============================] - 26s 284ms/step - loss: 12.8155 - mae: 2.9037 - val_loss: 11.7024 - val_mae: 2.7230\n",
            "Epoch 127/500\n",
            "89/89 [==============================] - 27s 297ms/step - loss: 13.3913 - mae: 2.9844 - val_loss: 12.2238 - val_mae: 2.7874\n",
            "Epoch 128/500\n",
            "89/89 [==============================] - 25s 278ms/step - loss: 13.3529 - mae: 2.9573 - val_loss: 10.3383 - val_mae: 2.6406\n",
            "Epoch 129/500\n",
            "89/89 [==============================] - 21s 224ms/step - loss: 13.5756 - mae: 3.0041 - val_loss: 12.0008 - val_mae: 2.7628\n",
            "Epoch 130/500\n",
            "89/89 [==============================] - 26s 288ms/step - loss: 13.5490 - mae: 3.0025 - val_loss: 10.2788 - val_mae: 2.6423\n",
            "Epoch 131/500\n",
            "89/89 [==============================] - 26s 291ms/step - loss: 13.4047 - mae: 2.9798 - val_loss: 10.6325 - val_mae: 2.6552\n",
            "Epoch 132/500\n",
            "89/89 [==============================] - 27s 299ms/step - loss: 13.1738 - mae: 2.9350 - val_loss: 19.4067 - val_mae: 3.3960\n",
            "Epoch 133/500\n",
            "89/89 [==============================] - 27s 299ms/step - loss: 12.7599 - mae: 2.9014 - val_loss: 19.0163 - val_mae: 3.3318\n",
            "Epoch 134/500\n",
            "89/89 [==============================] - 26s 283ms/step - loss: 12.3783 - mae: 2.8798 - val_loss: 16.3216 - val_mae: 3.1156\n",
            "Epoch 135/500\n",
            "89/89 [==============================] - 26s 284ms/step - loss: 12.9497 - mae: 2.9227 - val_loss: 19.5656 - val_mae: 3.4033\n",
            "Epoch 136/500\n",
            "89/89 [==============================] - 26s 286ms/step - loss: 12.7474 - mae: 2.8791 - val_loss: 13.8519 - val_mae: 2.9291\n",
            "Epoch 137/500\n",
            "89/89 [==============================] - 26s 281ms/step - loss: 13.6182 - mae: 2.9690 - val_loss: 10.2327 - val_mae: 2.6210\n",
            "Epoch 138/500\n",
            "89/89 [==============================] - 22s 242ms/step - loss: 13.6757 - mae: 3.0200 - val_loss: 22.6266 - val_mae: 3.6948\n",
            "Epoch 139/500\n",
            "89/89 [==============================] - 26s 285ms/step - loss: 13.7671 - mae: 3.0016 - val_loss: 13.7362 - val_mae: 2.9245\n",
            "Epoch 140/500\n",
            "89/89 [==============================] - 21s 234ms/step - loss: 12.8862 - mae: 2.9221 - val_loss: 15.5122 - val_mae: 3.0765\n",
            "Epoch 141/500\n",
            "89/89 [==============================] - 28s 307ms/step - loss: 12.9600 - mae: 2.9217 - val_loss: 47.2836 - val_mae: 5.4427\n",
            "Epoch 142/500\n",
            "89/89 [==============================] - 28s 307ms/step - loss: 12.8310 - mae: 2.9083 - val_loss: 18.4844 - val_mae: 3.3241\n",
            "Epoch 143/500\n",
            "89/89 [==============================] - 23s 248ms/step - loss: 12.7583 - mae: 2.9079 - val_loss: 11.5229 - val_mae: 2.7406\n",
            "Epoch 144/500\n",
            "89/89 [==============================] - 28s 303ms/step - loss: 13.1750 - mae: 2.9685 - val_loss: 14.6954 - val_mae: 3.0019\n",
            "Epoch 145/500\n",
            "89/89 [==============================] - 27s 298ms/step - loss: 12.5426 - mae: 2.8921 - val_loss: 17.8476 - val_mae: 3.2319\n",
            "Epoch 146/500\n",
            "89/89 [==============================] - 27s 299ms/step - loss: 12.5688 - mae: 2.8912 - val_loss: 15.1088 - val_mae: 3.0462\n",
            "Epoch 147/500\n",
            "89/89 [==============================] - 27s 301ms/step - loss: 12.5404 - mae: 2.9002 - val_loss: 12.2160 - val_mae: 2.8143\n",
            "Epoch 148/500\n",
            "89/89 [==============================] - 27s 295ms/step - loss: 13.0492 - mae: 2.9509 - val_loss: 19.2291 - val_mae: 3.3683\n",
            "Epoch 149/500\n",
            "89/89 [==============================] - 26s 286ms/step - loss: 13.8394 - mae: 3.0204 - val_loss: 15.5304 - val_mae: 3.0624\n",
            "Epoch 150/500\n",
            "89/89 [==============================] - 26s 283ms/step - loss: 12.4907 - mae: 2.8788 - val_loss: 11.4802 - val_mae: 2.7297\n",
            "Epoch 151/500\n",
            "89/89 [==============================] - 26s 287ms/step - loss: 13.0758 - mae: 2.9248 - val_loss: 10.9884 - val_mae: 2.6977\n",
            "Epoch 152/500\n",
            "89/89 [==============================] - 26s 284ms/step - loss: 13.0709 - mae: 2.9577 - val_loss: 13.8537 - val_mae: 2.9269\n",
            "Epoch 153/500\n",
            "89/89 [==============================] - 25s 278ms/step - loss: 12.3705 - mae: 2.8739 - val_loss: 17.7282 - val_mae: 3.2231\n",
            "Epoch 154/500\n",
            "89/89 [==============================] - 21s 225ms/step - loss: 12.7440 - mae: 2.8956 - val_loss: 14.4667 - val_mae: 2.9765\n",
            "Epoch 155/500\n",
            "89/89 [==============================] - 27s 287ms/step - loss: 12.9606 - mae: 2.9349 - val_loss: 15.0099 - val_mae: 3.0263\n",
            "Epoch 156/500\n",
            "89/89 [==============================] - 26s 283ms/step - loss: 12.5027 - mae: 2.8868 - val_loss: 16.0453 - val_mae: 3.0774\n",
            "Epoch 157/500\n",
            "89/89 [==============================] - 27s 289ms/step - loss: 14.4757 - mae: 3.0298 - val_loss: 24.2519 - val_mae: 3.7350\n",
            "Epoch 158/500\n",
            "89/89 [==============================] - 27s 285ms/step - loss: 13.3285 - mae: 2.9422 - val_loss: 13.6395 - val_mae: 2.9009\n",
            "Epoch 159/500\n",
            "89/89 [==============================] - 26s 281ms/step - loss: 13.0026 - mae: 2.9202 - val_loss: 17.5011 - val_mae: 3.2363\n",
            "Epoch 160/500\n",
            "89/89 [==============================] - 22s 229ms/step - loss: 12.6183 - mae: 2.8818 - val_loss: 20.1537 - val_mae: 3.4286\n",
            "Epoch 161/500\n",
            "89/89 [==============================] - 21s 229ms/step - loss: 12.7258 - mae: 2.9042 - val_loss: 11.9810 - val_mae: 2.7773\n",
            "Epoch 162/500\n",
            "89/89 [==============================] - 28s 308ms/step - loss: 12.1238 - mae: 2.8324 - val_loss: 16.6214 - val_mae: 3.1520\n",
            "Epoch 163/500\n",
            "89/89 [==============================] - 27s 300ms/step - loss: 12.6736 - mae: 2.8996 - val_loss: 14.8287 - val_mae: 3.0212\n",
            "Epoch 164/500\n",
            "89/89 [==============================] - 26s 288ms/step - loss: 12.3896 - mae: 2.8753 - val_loss: 18.5814 - val_mae: 3.2910\n",
            "Epoch 165/500\n",
            "89/89 [==============================] - 26s 284ms/step - loss: 12.4329 - mae: 2.8589 - val_loss: 15.9667 - val_mae: 3.0960\n",
            "Epoch 166/500\n",
            "89/89 [==============================] - 27s 300ms/step - loss: 11.9437 - mae: 2.8263 - val_loss: 13.2367 - val_mae: 2.8786\n",
            "Epoch 167/500\n",
            "89/89 [==============================] - 26s 286ms/step - loss: 12.9456 - mae: 2.9254 - val_loss: 12.4998 - val_mae: 2.7990\n",
            "Epoch 168/500\n",
            "89/89 [==============================] - 26s 283ms/step - loss: 12.7916 - mae: 2.9170 - val_loss: 13.8707 - val_mae: 2.9407\n",
            "Epoch 169/500\n",
            "89/89 [==============================] - 26s 290ms/step - loss: 12.4884 - mae: 2.8637 - val_loss: 17.8573 - val_mae: 3.2416\n",
            "Epoch 170/500\n",
            "89/89 [==============================] - 26s 287ms/step - loss: 12.9765 - mae: 2.9294 - val_loss: 14.5175 - val_mae: 2.9914\n",
            "Epoch 171/500\n",
            "89/89 [==============================] - 27s 295ms/step - loss: 13.1216 - mae: 2.9155 - val_loss: 17.3610 - val_mae: 3.1951\n",
            "Epoch 172/500\n",
            "89/89 [==============================] - 26s 290ms/step - loss: 12.8759 - mae: 2.8982 - val_loss: 10.3287 - val_mae: 2.6480\n",
            "Epoch 173/500\n",
            "89/89 [==============================] - 26s 286ms/step - loss: 12.8083 - mae: 2.9094 - val_loss: 11.5275 - val_mae: 2.7450\n",
            "Epoch 174/500\n",
            "89/89 [==============================] - 27s 294ms/step - loss: 12.3371 - mae: 2.8625 - val_loss: 13.2604 - val_mae: 2.8576\n",
            "Epoch 175/500\n",
            "89/89 [==============================] - 26s 289ms/step - loss: 12.6837 - mae: 2.9219 - val_loss: 10.2967 - val_mae: 2.6453\n",
            "Epoch 176/500\n",
            "89/89 [==============================] - 26s 283ms/step - loss: 12.7198 - mae: 2.9002 - val_loss: 11.1987 - val_mae: 2.7132\n",
            "Epoch 177/500\n",
            "89/89 [==============================] - 27s 299ms/step - loss: 12.5499 - mae: 2.8727 - val_loss: 12.0158 - val_mae: 2.7646\n",
            "Epoch 178/500\n",
            "89/89 [==============================] - 27s 300ms/step - loss: 11.8824 - mae: 2.8299 - val_loss: 10.7751 - val_mae: 2.6876\n",
            "Epoch 179/500\n",
            "89/89 [==============================] - 27s 294ms/step - loss: 13.2917 - mae: 2.9374 - val_loss: 14.0989 - val_mae: 2.9304\n",
            "Epoch 180/500\n",
            "89/89 [==============================] - 26s 286ms/step - loss: 14.0313 - mae: 3.0408 - val_loss: 9.9619 - val_mae: 2.6134\n",
            "Epoch 181/500\n",
            "89/89 [==============================] - 26s 285ms/step - loss: 12.8582 - mae: 2.9274 - val_loss: 11.9236 - val_mae: 2.7628\n",
            "Epoch 182/500\n",
            "89/89 [==============================] - 26s 284ms/step - loss: 12.5002 - mae: 2.8972 - val_loss: 11.0449 - val_mae: 2.7074\n",
            "Epoch 183/500\n",
            "89/89 [==============================] - 26s 283ms/step - loss: 13.0560 - mae: 2.9132 - val_loss: 13.0396 - val_mae: 2.8553\n",
            "Epoch 184/500\n",
            "89/89 [==============================] - 27s 301ms/step - loss: 12.9148 - mae: 2.9265 - val_loss: 20.1884 - val_mae: 3.4267\n",
            "Epoch 185/500\n",
            "89/89 [==============================] - 26s 291ms/step - loss: 12.6925 - mae: 2.8894 - val_loss: 13.2830 - val_mae: 2.8777\n",
            "Epoch 186/500\n",
            "89/89 [==============================] - 28s 303ms/step - loss: 12.7929 - mae: 2.9285 - val_loss: 11.6998 - val_mae: 2.7520\n",
            "Epoch 187/500\n",
            "89/89 [==============================] - 26s 288ms/step - loss: 12.8637 - mae: 2.9210 - val_loss: 10.0543 - val_mae: 2.6229\n",
            "Epoch 188/500\n",
            "89/89 [==============================] - 27s 295ms/step - loss: 12.3396 - mae: 2.8715 - val_loss: 11.2591 - val_mae: 2.7098\n",
            "Epoch 189/500\n",
            "89/89 [==============================] - 28s 305ms/step - loss: 12.9131 - mae: 2.9302 - val_loss: 13.4988 - val_mae: 2.8927\n",
            "Epoch 190/500\n",
            "89/89 [==============================] - 26s 288ms/step - loss: 12.9891 - mae: 2.9297 - val_loss: 11.1233 - val_mae: 2.7179\n",
            "Epoch 191/500\n",
            "89/89 [==============================] - 26s 283ms/step - loss: 12.5420 - mae: 2.8939 - val_loss: 11.9584 - val_mae: 2.7647\n",
            "Epoch 192/500\n",
            "89/89 [==============================] - 22s 241ms/step - loss: 13.6367 - mae: 2.9953 - val_loss: 9.8237 - val_mae: 2.5899\n",
            "Epoch 193/500\n",
            "89/89 [==============================] - 27s 295ms/step - loss: 12.9152 - mae: 2.9309 - val_loss: 10.2701 - val_mae: 2.6309\n",
            "Epoch 194/500\n",
            "89/89 [==============================] - 28s 303ms/step - loss: 12.2651 - mae: 2.8623 - val_loss: 16.0086 - val_mae: 3.0874\n",
            "Epoch 195/500\n",
            "89/89 [==============================] - 25s 279ms/step - loss: 12.3538 - mae: 2.8866 - val_loss: 12.8615 - val_mae: 2.8308\n",
            "Epoch 196/500\n",
            "89/89 [==============================] - 27s 299ms/step - loss: 13.2151 - mae: 2.9319 - val_loss: 17.6732 - val_mae: 3.2085\n",
            "Epoch 197/500\n",
            "89/89 [==============================] - 26s 281ms/step - loss: 12.9264 - mae: 2.9344 - val_loss: 12.6778 - val_mae: 2.8419\n",
            "Epoch 198/500\n",
            "89/89 [==============================] - 26s 290ms/step - loss: 13.4090 - mae: 2.9248 - val_loss: 10.9506 - val_mae: 2.7009\n",
            "Epoch 199/500\n",
            "89/89 [==============================] - 26s 279ms/step - loss: 12.5960 - mae: 2.9054 - val_loss: 15.6133 - val_mae: 3.0462\n",
            "Epoch 200/500\n",
            "89/89 [==============================] - 26s 286ms/step - loss: 12.8115 - mae: 2.9036 - val_loss: 13.1036 - val_mae: 2.8785\n",
            "Epoch 201/500\n",
            "89/89 [==============================] - 27s 298ms/step - loss: 13.3648 - mae: 2.9501 - val_loss: 28.7803 - val_mae: 4.0934\n",
            "Epoch 202/500\n",
            "89/89 [==============================] - 26s 287ms/step - loss: 13.1161 - mae: 2.9226 - val_loss: 17.2373 - val_mae: 3.2040\n",
            "Epoch 203/500\n",
            "89/89 [==============================] - 25s 279ms/step - loss: 12.4489 - mae: 2.8487 - val_loss: 14.1207 - val_mae: 2.9397\n",
            "Epoch 204/500\n",
            "89/89 [==============================] - 21s 225ms/step - loss: 13.0478 - mae: 2.9183 - val_loss: 14.7825 - val_mae: 2.9913\n",
            "Epoch 205/500\n",
            "89/89 [==============================] - 26s 281ms/step - loss: 13.1926 - mae: 2.9164 - val_loss: 16.0905 - val_mae: 3.1254\n",
            "Epoch 206/500\n",
            "89/89 [==============================] - 26s 281ms/step - loss: 12.9060 - mae: 2.9071 - val_loss: 14.7512 - val_mae: 2.9834\n",
            "Epoch 207/500\n",
            "89/89 [==============================] - 27s 291ms/step - loss: 12.5160 - mae: 2.8572 - val_loss: 16.5598 - val_mae: 3.1276\n",
            "Epoch 208/500\n",
            "89/89 [==============================] - 26s 289ms/step - loss: 13.0670 - mae: 2.9331 - val_loss: 15.5482 - val_mae: 3.0424\n",
            "Epoch 209/500\n",
            "89/89 [==============================] - 23s 257ms/step - loss: 14.0629 - mae: 3.0293 - val_loss: 9.9129 - val_mae: 2.5947\n",
            "Epoch 210/500\n",
            "89/89 [==============================] - 27s 300ms/step - loss: 12.6598 - mae: 2.9206 - val_loss: 14.5631 - val_mae: 2.9605\n",
            "Epoch 211/500\n",
            "89/89 [==============================] - 28s 302ms/step - loss: 12.1899 - mae: 2.8595 - val_loss: 20.5990 - val_mae: 3.4171\n",
            "Epoch 212/500\n",
            "89/89 [==============================] - 27s 292ms/step - loss: 12.9129 - mae: 2.9178 - val_loss: 11.9239 - val_mae: 2.7759\n",
            "Epoch 213/500\n",
            "89/89 [==============================] - 27s 300ms/step - loss: 13.2489 - mae: 2.9454 - val_loss: 15.2829 - val_mae: 3.0200\n",
            "Epoch 214/500\n",
            "89/89 [==============================] - 27s 292ms/step - loss: 12.4891 - mae: 2.8717 - val_loss: 15.9388 - val_mae: 3.0839\n",
            "Epoch 215/500\n",
            "89/89 [==============================] - 28s 304ms/step - loss: 12.3615 - mae: 2.8841 - val_loss: 13.6893 - val_mae: 2.9153\n",
            "Epoch 216/500\n",
            "89/89 [==============================] - 27s 296ms/step - loss: 13.1365 - mae: 2.9419 - val_loss: 14.1031 - val_mae: 2.9627\n",
            "Epoch 217/500\n",
            "89/89 [==============================] - 27s 300ms/step - loss: 13.0359 - mae: 2.9362 - val_loss: 11.2680 - val_mae: 2.7235\n",
            "Epoch 218/500\n",
            "89/89 [==============================] - 27s 295ms/step - loss: 12.2958 - mae: 2.8690 - val_loss: 12.1494 - val_mae: 2.7794\n",
            "Epoch 219/500\n",
            "89/89 [==============================] - 26s 286ms/step - loss: 12.3982 - mae: 2.8745 - val_loss: 17.8644 - val_mae: 3.2391\n",
            "Epoch 220/500\n",
            "89/89 [==============================] - 28s 308ms/step - loss: 13.9133 - mae: 3.0073 - val_loss: 10.5392 - val_mae: 2.6693\n",
            "Epoch 221/500\n",
            "89/89 [==============================] - 27s 295ms/step - loss: 13.1014 - mae: 2.9314 - val_loss: 10.0861 - val_mae: 2.6220\n",
            "Epoch 222/500\n",
            "89/89 [==============================] - 26s 291ms/step - loss: 12.7879 - mae: 2.9141 - val_loss: 15.1543 - val_mae: 3.0079\n",
            "Epoch 223/500\n",
            "89/89 [==============================] - 22s 236ms/step - loss: 13.0642 - mae: 2.9257 - val_loss: 11.9668 - val_mae: 2.7698\n",
            "Epoch 224/500\n",
            "89/89 [==============================] - 27s 295ms/step - loss: 13.5954 - mae: 2.9996 - val_loss: 13.3561 - val_mae: 2.8832\n",
            "Epoch 225/500\n",
            "89/89 [==============================] - 28s 302ms/step - loss: 13.0453 - mae: 2.9476 - val_loss: 23.0814 - val_mae: 3.6662\n",
            "Epoch 226/500\n",
            "89/89 [==============================] - 27s 298ms/step - loss: 13.4881 - mae: 2.9835 - val_loss: 14.9965 - val_mae: 3.0237\n",
            "Epoch 227/500\n",
            "89/89 [==============================] - 28s 306ms/step - loss: 12.8038 - mae: 2.8932 - val_loss: 17.9947 - val_mae: 3.2286\n",
            "Epoch 228/500\n",
            "89/89 [==============================] - 28s 306ms/step - loss: 12.8849 - mae: 2.9132 - val_loss: 13.4608 - val_mae: 2.8712\n",
            "Epoch 229/500\n",
            "89/89 [==============================] - 28s 306ms/step - loss: 12.6026 - mae: 2.8971 - val_loss: 10.2999 - val_mae: 2.6365\n",
            "Epoch 230/500\n",
            "89/89 [==============================] - 28s 307ms/step - loss: 12.9961 - mae: 2.9277 - val_loss: 10.1426 - val_mae: 2.6282\n",
            "Epoch 231/500\n",
            "89/89 [==============================] - 24s 267ms/step - loss: 13.0649 - mae: 2.9591 - val_loss: 11.4279 - val_mae: 2.7411\n",
            "Epoch 232/500\n",
            "89/89 [==============================] - 26s 291ms/step - loss: 12.8615 - mae: 2.9348 - val_loss: 10.1839 - val_mae: 2.6220\n",
            "Epoch 233/500\n",
            "89/89 [==============================] - 27s 301ms/step - loss: 12.5748 - mae: 2.8892 - val_loss: 14.0860 - val_mae: 2.9309\n",
            "Epoch 234/500\n",
            "89/89 [==============================] - 28s 304ms/step - loss: 13.1079 - mae: 2.9428 - val_loss: 10.9276 - val_mae: 2.6945\n",
            "Epoch 235/500\n",
            "89/89 [==============================] - 28s 304ms/step - loss: 12.7944 - mae: 2.9132 - val_loss: 11.5826 - val_mae: 2.7615\n",
            "Epoch 236/500\n",
            "89/89 [==============================] - 27s 297ms/step - loss: 12.1755 - mae: 2.8597 - val_loss: 13.4139 - val_mae: 2.8891\n",
            "Epoch 237/500\n",
            "89/89 [==============================] - 27s 299ms/step - loss: 12.2042 - mae: 2.8443 - val_loss: 14.4047 - val_mae: 2.9518\n",
            "Epoch 238/500\n",
            "89/89 [==============================] - 26s 285ms/step - loss: 13.1919 - mae: 2.9404 - val_loss: 10.2751 - val_mae: 2.6416\n",
            "Epoch 239/500\n",
            "89/89 [==============================] - 26s 286ms/step - loss: 13.0201 - mae: 2.9361 - val_loss: 11.3967 - val_mae: 2.7430\n",
            "Epoch 240/500\n",
            "89/89 [==============================] - 27s 302ms/step - loss: 13.3926 - mae: 2.9662 - val_loss: 10.2419 - val_mae: 2.6610\n",
            "Epoch 241/500\n",
            "89/89 [==============================] - 22s 238ms/step - loss: 12.7241 - mae: 2.9154 - val_loss: 10.9846 - val_mae: 2.6960\n",
            "Epoch 242/500\n",
            "89/89 [==============================] - 27s 291ms/step - loss: 13.3251 - mae: 2.9495 - val_loss: 23.3210 - val_mae: 3.6606\n",
            "Epoch 243/500\n",
            "89/89 [==============================] - 21s 229ms/step - loss: 13.5328 - mae: 2.9627 - val_loss: 11.4952 - val_mae: 2.7402\n",
            "Epoch 244/500\n",
            "89/89 [==============================] - 27s 289ms/step - loss: 12.0871 - mae: 2.8362 - val_loss: 13.1107 - val_mae: 2.8648\n",
            "Epoch 245/500\n",
            "89/89 [==============================] - 27s 287ms/step - loss: 13.1888 - mae: 2.9449 - val_loss: 11.5322 - val_mae: 2.7553\n",
            "Epoch 246/500\n",
            "89/89 [==============================] - 25s 278ms/step - loss: 12.5042 - mae: 2.8761 - val_loss: 13.7384 - val_mae: 2.9009\n",
            "Epoch 247/500\n",
            "89/89 [==============================] - 21s 226ms/step - loss: 12.3772 - mae: 2.8624 - val_loss: 10.1074 - val_mae: 2.6232\n",
            "Epoch 248/500\n",
            "89/89 [==============================] - 27s 296ms/step - loss: 12.3468 - mae: 2.8730 - val_loss: 10.9997 - val_mae: 2.6886\n",
            "Epoch 249/500\n",
            "89/89 [==============================] - 26s 289ms/step - loss: 12.9962 - mae: 2.9257 - val_loss: 18.5636 - val_mae: 3.3067\n",
            "Epoch 250/500\n",
            "89/89 [==============================] - 26s 283ms/step - loss: 13.1949 - mae: 2.9363 - val_loss: 11.7824 - val_mae: 2.7385\n",
            "Epoch 251/500\n",
            "89/89 [==============================] - 27s 297ms/step - loss: 12.8234 - mae: 2.9079 - val_loss: 10.4394 - val_mae: 2.6473\n",
            "Epoch 252/500\n",
            "89/89 [==============================] - 26s 286ms/step - loss: 12.5520 - mae: 2.9022 - val_loss: 9.9149 - val_mae: 2.6033\n",
            "Epoch 253/500\n",
            "89/89 [==============================] - 28s 303ms/step - loss: 12.5706 - mae: 2.9093 - val_loss: 18.0532 - val_mae: 3.2681\n",
            "Epoch 254/500\n",
            "89/89 [==============================] - 21s 235ms/step - loss: 12.3122 - mae: 2.8592 - val_loss: 23.7082 - val_mae: 3.7043\n",
            "Epoch 255/500\n",
            "89/89 [==============================] - 26s 286ms/step - loss: 12.6760 - mae: 2.8926 - val_loss: 16.2474 - val_mae: 3.1279\n",
            "Epoch 256/500\n",
            "89/89 [==============================] - 28s 303ms/step - loss: 12.6814 - mae: 2.9147 - val_loss: 13.5057 - val_mae: 2.8921\n",
            "Epoch 257/500\n",
            "89/89 [==============================] - 28s 304ms/step - loss: 12.9078 - mae: 2.9089 - val_loss: 11.1230 - val_mae: 2.7156\n",
            "Epoch 258/500\n",
            "89/89 [==============================] - 27s 291ms/step - loss: 12.5214 - mae: 2.8926 - val_loss: 15.3367 - val_mae: 3.0379\n",
            "Epoch 259/500\n",
            "89/89 [==============================] - 27s 297ms/step - loss: 12.3343 - mae: 2.8696 - val_loss: 13.3944 - val_mae: 2.8686\n",
            "Epoch 260/500\n",
            "89/89 [==============================] - 27s 302ms/step - loss: 12.6151 - mae: 2.8906 - val_loss: 12.5876 - val_mae: 2.8057\n",
            "Epoch 261/500\n",
            "89/89 [==============================] - 28s 302ms/step - loss: 13.1624 - mae: 2.9647 - val_loss: 12.5792 - val_mae: 2.8197\n",
            "Epoch 262/500\n",
            "89/89 [==============================] - 28s 307ms/step - loss: 12.3117 - mae: 2.8595 - val_loss: 12.3428 - val_mae: 2.7884\n",
            "Epoch 263/500\n",
            "89/89 [==============================] - 26s 289ms/step - loss: 12.2585 - mae: 2.8419 - val_loss: 14.3942 - val_mae: 2.9384\n",
            "Epoch 264/500\n",
            "89/89 [==============================] - 22s 235ms/step - loss: 12.8075 - mae: 2.8702 - val_loss: 10.9796 - val_mae: 2.7090\n",
            "Epoch 265/500\n",
            "89/89 [==============================] - 26s 283ms/step - loss: 12.9575 - mae: 2.9242 - val_loss: 15.6283 - val_mae: 3.0465\n",
            "Epoch 266/500\n",
            "89/89 [==============================] - 27s 299ms/step - loss: 12.1699 - mae: 2.8368 - val_loss: 15.5173 - val_mae: 3.0518\n",
            "Epoch 267/500\n",
            "89/89 [==============================] - 26s 287ms/step - loss: 13.1451 - mae: 2.9321 - val_loss: 14.3268 - val_mae: 2.9597\n",
            "Epoch 268/500\n",
            "89/89 [==============================] - 21s 227ms/step - loss: 12.3829 - mae: 2.8600 - val_loss: 12.2650 - val_mae: 2.8020\n",
            "Epoch 269/500\n",
            "89/89 [==============================] - 27s 298ms/step - loss: 12.5100 - mae: 2.8870 - val_loss: 11.0707 - val_mae: 2.7202\n",
            "Epoch 270/500\n",
            "89/89 [==============================] - 27s 300ms/step - loss: 12.5881 - mae: 2.8694 - val_loss: 12.2043 - val_mae: 2.8064\n",
            "Epoch 271/500\n",
            "89/89 [==============================] - 27s 301ms/step - loss: 12.9698 - mae: 2.9340 - val_loss: 14.1822 - val_mae: 2.9481\n",
            "Epoch 272/500\n",
            "89/89 [==============================] - 26s 286ms/step - loss: 12.5342 - mae: 2.8893 - val_loss: 10.7704 - val_mae: 2.6823\n",
            "Epoch 273/500\n",
            "89/89 [==============================] - 27s 303ms/step - loss: 12.6253 - mae: 2.8880 - val_loss: 15.6624 - val_mae: 3.0314\n",
            "Epoch 274/500\n",
            "89/89 [==============================] - 27s 296ms/step - loss: 12.3227 - mae: 2.8637 - val_loss: 11.9819 - val_mae: 2.7702\n",
            "Epoch 275/500\n",
            "89/89 [==============================] - 26s 282ms/step - loss: 13.0843 - mae: 2.9258 - val_loss: 9.9051 - val_mae: 2.5996\n",
            "Epoch 276/500\n",
            "89/89 [==============================] - 27s 301ms/step - loss: 13.1748 - mae: 2.9447 - val_loss: 10.3268 - val_mae: 2.6269\n",
            "Epoch 277/500\n",
            "89/89 [==============================] - 28s 315ms/step - loss: 12.2975 - mae: 2.8479 - val_loss: 11.2404 - val_mae: 2.7094\n",
            "Epoch 278/500\n",
            "89/89 [==============================] - 28s 308ms/step - loss: 12.7855 - mae: 2.8843 - val_loss: 14.1809 - val_mae: 2.9548\n",
            "Epoch 279/500\n",
            "89/89 [==============================] - 28s 303ms/step - loss: 13.1158 - mae: 2.9267 - val_loss: 14.9852 - val_mae: 3.0075\n",
            "Epoch 280/500\n",
            "89/89 [==============================] - 27s 301ms/step - loss: 12.3124 - mae: 2.8530 - val_loss: 9.9693 - val_mae: 2.6136\n",
            "Epoch 281/500\n",
            "89/89 [==============================] - 27s 302ms/step - loss: 12.5515 - mae: 2.8751 - val_loss: 11.8942 - val_mae: 2.7633\n",
            "Epoch 282/500\n",
            "89/89 [==============================] - 28s 308ms/step - loss: 12.4225 - mae: 2.8808 - val_loss: 11.8143 - val_mae: 2.7532\n",
            "Epoch 283/500\n",
            "89/89 [==============================] - 27s 299ms/step - loss: 12.8120 - mae: 2.9034 - val_loss: 15.2580 - val_mae: 3.0170\n",
            "Epoch 284/500\n",
            "89/89 [==============================] - 27s 300ms/step - loss: 12.3466 - mae: 2.8139 - val_loss: 22.8076 - val_mae: 3.7330\n",
            "Epoch 285/500\n",
            "89/89 [==============================] - 27s 301ms/step - loss: 12.3313 - mae: 2.8231 - val_loss: 17.1581 - val_mae: 3.1776\n",
            "Epoch 286/500\n",
            "89/89 [==============================] - 28s 305ms/step - loss: 12.2876 - mae: 2.8513 - val_loss: 16.1598 - val_mae: 3.1646\n",
            "Epoch 287/500\n",
            "89/89 [==============================] - 28s 309ms/step - loss: 12.2356 - mae: 2.8253 - val_loss: 12.9375 - val_mae: 2.8643\n",
            "Epoch 288/500\n",
            "89/89 [==============================] - 27s 296ms/step - loss: 12.9041 - mae: 2.9128 - val_loss: 13.9208 - val_mae: 2.9273\n",
            "Epoch 289/500\n",
            "89/89 [==============================] - 28s 306ms/step - loss: 12.4933 - mae: 2.8818 - val_loss: 16.4025 - val_mae: 3.1087\n",
            "Epoch 290/500\n",
            "89/89 [==============================] - 28s 310ms/step - loss: 12.9011 - mae: 2.9001 - val_loss: 11.0289 - val_mae: 2.7077\n",
            "Epoch 291/500\n",
            "89/89 [==============================] - 28s 302ms/step - loss: 12.8684 - mae: 2.9104 - val_loss: 12.5473 - val_mae: 2.8338\n",
            "Epoch 292/500\n",
            "89/89 [==============================] - 28s 306ms/step - loss: 13.0072 - mae: 2.9249 - val_loss: 12.4321 - val_mae: 2.8074\n",
            "Epoch 293/500\n",
            "89/89 [==============================] - 27s 296ms/step - loss: 12.3403 - mae: 2.8673 - val_loss: 19.7189 - val_mae: 3.4170\n",
            "Epoch 294/500\n",
            "89/89 [==============================] - 26s 288ms/step - loss: 12.6411 - mae: 2.8719 - val_loss: 15.7201 - val_mae: 3.0816\n",
            "Epoch 295/500\n",
            "89/89 [==============================] - 26s 289ms/step - loss: 12.5048 - mae: 2.8715 - val_loss: 18.0662 - val_mae: 3.2526\n",
            "Epoch 296/500\n",
            "89/89 [==============================] - 27s 300ms/step - loss: 12.1477 - mae: 2.8509 - val_loss: 17.8509 - val_mae: 3.2416\n",
            "Epoch 297/500\n",
            "89/89 [==============================] - 29s 314ms/step - loss: 12.9677 - mae: 2.8998 - val_loss: 11.6507 - val_mae: 2.7478\n",
            "Epoch 298/500\n",
            "89/89 [==============================] - 22s 242ms/step - loss: 12.3240 - mae: 2.8614 - val_loss: 12.5615 - val_mae: 2.8153\n",
            "Epoch 299/500\n",
            "89/89 [==============================] - 28s 295ms/step - loss: 12.8308 - mae: 2.9344 - val_loss: 16.3486 - val_mae: 3.1028\n",
            "Epoch 300/500\n",
            "89/89 [==============================] - 27s 295ms/step - loss: 12.5709 - mae: 2.8932 - val_loss: 10.7541 - val_mae: 2.6871\n",
            "Epoch 301/500\n",
            "89/89 [==============================] - 27s 292ms/step - loss: 11.9894 - mae: 2.8305 - val_loss: 13.5705 - val_mae: 2.8987\n",
            "Epoch 302/500\n",
            "89/89 [==============================] - 28s 296ms/step - loss: 12.7544 - mae: 2.9014 - val_loss: 14.3030 - val_mae: 2.9475\n",
            "Epoch 303/500\n",
            "89/89 [==============================] - 23s 244ms/step - loss: 12.4553 - mae: 2.8725 - val_loss: 13.7036 - val_mae: 2.9110\n",
            "Epoch 304/500\n",
            "89/89 [==============================] - 29s 314ms/step - loss: 12.8825 - mae: 2.9380 - val_loss: 17.8759 - val_mae: 3.2513\n",
            "Epoch 305/500\n",
            "89/89 [==============================] - 23s 252ms/step - loss: 13.1204 - mae: 2.9319 - val_loss: 14.3561 - val_mae: 2.9712\n",
            "Epoch 306/500\n",
            "89/89 [==============================] - 27s 293ms/step - loss: 13.3622 - mae: 2.9432 - val_loss: 9.9668 - val_mae: 2.6031\n",
            "Epoch 307/500\n",
            "89/89 [==============================] - 27s 296ms/step - loss: 13.6491 - mae: 3.0053 - val_loss: 19.4430 - val_mae: 3.3769\n",
            "Epoch 308/500\n",
            "89/89 [==============================] - 27s 298ms/step - loss: 12.6685 - mae: 2.8860 - val_loss: 14.8886 - val_mae: 3.0084\n",
            "Epoch 309/500\n",
            "89/89 [==============================] - 27s 294ms/step - loss: 12.3430 - mae: 2.8620 - val_loss: 12.7128 - val_mae: 2.8519\n",
            "Epoch 310/500\n",
            "89/89 [==============================] - 28s 311ms/step - loss: 12.3590 - mae: 2.8793 - val_loss: 14.8511 - val_mae: 3.0010\n",
            "Epoch 311/500\n",
            "89/89 [==============================] - 28s 304ms/step - loss: 12.4584 - mae: 2.8785 - val_loss: 10.5136 - val_mae: 2.6535\n",
            "Epoch 312/500\n",
            "89/89 [==============================] - 27s 297ms/step - loss: 13.2386 - mae: 2.9454 - val_loss: 13.4802 - val_mae: 2.9065\n",
            "Epoch 313/500\n",
            "89/89 [==============================] - 27s 293ms/step - loss: 12.0609 - mae: 2.8420 - val_loss: 10.3941 - val_mae: 2.6457\n",
            "Epoch 314/500\n",
            "89/89 [==============================] - 28s 313ms/step - loss: 11.9985 - mae: 2.8389 - val_loss: 11.4273 - val_mae: 2.7378\n",
            "Epoch 315/500\n",
            "89/89 [==============================] - 27s 294ms/step - loss: 12.5968 - mae: 2.8829 - val_loss: 10.0159 - val_mae: 2.6054\n",
            "Epoch 316/500\n",
            "89/89 [==============================] - 27s 292ms/step - loss: 13.1121 - mae: 2.9573 - val_loss: 11.0217 - val_mae: 2.6984\n",
            "Epoch 317/500\n",
            "89/89 [==============================] - 28s 308ms/step - loss: 13.0337 - mae: 2.9435 - val_loss: 16.8409 - val_mae: 3.1997\n",
            "Epoch 318/500\n",
            "89/89 [==============================] - 28s 302ms/step - loss: 12.4040 - mae: 2.8639 - val_loss: 15.0053 - val_mae: 3.0439\n",
            "Epoch 319/500\n",
            "89/89 [==============================] - 27s 294ms/step - loss: 12.9874 - mae: 2.9156 - val_loss: 10.4634 - val_mae: 2.6573\n",
            "Epoch 320/500\n",
            "89/89 [==============================] - 28s 310ms/step - loss: 12.5084 - mae: 2.8728 - val_loss: 15.3178 - val_mae: 3.0430\n",
            "Epoch 321/500\n",
            "89/89 [==============================] - 28s 308ms/step - loss: 13.0166 - mae: 2.9557 - val_loss: 15.3344 - val_mae: 3.0476\n",
            "Epoch 322/500\n",
            "89/89 [==============================] - 27s 293ms/step - loss: 13.2333 - mae: 2.9531 - val_loss: 10.7120 - val_mae: 2.6801\n",
            "Epoch 323/500\n",
            "89/89 [==============================] - 28s 306ms/step - loss: 13.2531 - mae: 2.9547 - val_loss: 15.6735 - val_mae: 3.0896\n",
            "Epoch 324/500\n",
            "89/89 [==============================] - 29s 316ms/step - loss: 12.8951 - mae: 2.9166 - val_loss: 19.7852 - val_mae: 3.4428\n",
            "Epoch 325/500\n",
            "89/89 [==============================] - 27s 296ms/step - loss: 13.4802 - mae: 2.9459 - val_loss: 17.6639 - val_mae: 3.2508\n",
            "Epoch 326/500\n",
            "89/89 [==============================] - 28s 311ms/step - loss: 12.7305 - mae: 2.9064 - val_loss: 10.8008 - val_mae: 2.6773\n",
            "Epoch 327/500\n",
            "89/89 [==============================] - 23s 247ms/step - loss: 12.6865 - mae: 2.9085 - val_loss: 13.1086 - val_mae: 2.8748\n",
            "Epoch 328/500\n",
            "89/89 [==============================] - 27s 304ms/step - loss: 12.9558 - mae: 2.9300 - val_loss: 13.5013 - val_mae: 2.9064\n",
            "Epoch 329/500\n",
            "89/89 [==============================] - 27s 291ms/step - loss: 12.7166 - mae: 2.9151 - val_loss: 20.2982 - val_mae: 3.4659\n",
            "Epoch 330/500\n",
            "89/89 [==============================] - 27s 294ms/step - loss: 12.8561 - mae: 2.9249 - val_loss: 21.0404 - val_mae: 3.5239\n",
            "Epoch 331/500\n",
            "89/89 [==============================] - 27s 295ms/step - loss: 13.0255 - mae: 2.9200 - val_loss: 17.5310 - val_mae: 3.2300\n",
            "Epoch 332/500\n",
            "89/89 [==============================] - 27s 291ms/step - loss: 12.6267 - mae: 2.8973 - val_loss: 17.6101 - val_mae: 3.2415\n",
            "Epoch 333/500\n",
            "89/89 [==============================] - 22s 244ms/step - loss: 13.5327 - mae: 3.0009 - val_loss: 9.9457 - val_mae: 2.6103\n",
            "Epoch 334/500\n",
            "89/89 [==============================] - 23s 243ms/step - loss: 12.6398 - mae: 2.8930 - val_loss: 15.0325 - val_mae: 3.0168\n",
            "Epoch 335/500\n",
            "89/89 [==============================] - 24s 262ms/step - loss: 12.3754 - mae: 2.8665 - val_loss: 12.0742 - val_mae: 2.7829\n",
            "Epoch 336/500\n",
            "89/89 [==============================] - 28s 309ms/step - loss: 12.1074 - mae: 2.8326 - val_loss: 15.7613 - val_mae: 3.0817\n",
            "Epoch 337/500\n",
            "89/89 [==============================] - 27s 301ms/step - loss: 12.3712 - mae: 2.8813 - val_loss: 13.1800 - val_mae: 2.8707\n",
            "Epoch 338/500\n",
            "89/89 [==============================] - 22s 241ms/step - loss: 12.8770 - mae: 2.9096 - val_loss: 22.5917 - val_mae: 3.6469\n",
            "Epoch 339/500\n",
            "89/89 [==============================] - 29s 313ms/step - loss: 13.0211 - mae: 2.8819 - val_loss: 25.2118 - val_mae: 3.8698\n",
            "Epoch 340/500\n",
            "89/89 [==============================] - 28s 307ms/step - loss: 12.3821 - mae: 2.8692 - val_loss: 16.9749 - val_mae: 3.1647\n",
            "Epoch 341/500\n",
            "89/89 [==============================] - 27s 297ms/step - loss: 12.8450 - mae: 2.9006 - val_loss: 18.0114 - val_mae: 3.2427\n",
            "Epoch 342/500\n",
            "89/89 [==============================] - 23s 251ms/step - loss: 12.8630 - mae: 2.9214 - val_loss: 11.1962 - val_mae: 2.7010\n",
            "Epoch 343/500\n",
            "89/89 [==============================] - 28s 293ms/step - loss: 13.0298 - mae: 2.9279 - val_loss: 12.2408 - val_mae: 2.7907\n",
            "Epoch 344/500\n",
            "89/89 [==============================] - 22s 239ms/step - loss: 13.1836 - mae: 2.9652 - val_loss: 12.8314 - val_mae: 2.8349\n",
            "Epoch 345/500\n",
            "89/89 [==============================] - 29s 315ms/step - loss: 13.3273 - mae: 2.9931 - val_loss: 16.9678 - val_mae: 3.1607\n",
            "Epoch 346/500\n",
            "89/89 [==============================] - 29s 326ms/step - loss: 12.5442 - mae: 2.8671 - val_loss: 16.2445 - val_mae: 3.0956\n",
            "Epoch 347/500\n",
            "89/89 [==============================] - 29s 316ms/step - loss: 16.4541 - mae: 3.2806 - val_loss: 13.0652 - val_mae: 2.8591\n",
            "Epoch 348/500\n",
            "89/89 [==============================] - 29s 319ms/step - loss: 12.6660 - mae: 2.8960 - val_loss: 15.4189 - val_mae: 3.0434\n",
            "Epoch 349/500\n",
            "89/89 [==============================] - 24s 261ms/step - loss: 12.7631 - mae: 2.9265 - val_loss: 13.8630 - val_mae: 2.9342\n",
            "Epoch 350/500\n",
            "89/89 [==============================] - 27s 292ms/step - loss: 13.3501 - mae: 2.9646 - val_loss: 18.1526 - val_mae: 3.2415\n",
            "Epoch 351/500\n",
            "89/89 [==============================] - 22s 241ms/step - loss: 13.1341 - mae: 2.9693 - val_loss: 18.6444 - val_mae: 3.3155\n",
            "Epoch 352/500\n",
            "89/89 [==============================] - 27s 295ms/step - loss: 12.4773 - mae: 2.8690 - val_loss: 18.7647 - val_mae: 3.3355\n",
            "Epoch 353/500\n",
            "89/89 [==============================] - 27s 292ms/step - loss: 12.7167 - mae: 2.8791 - val_loss: 12.7473 - val_mae: 2.8172\n",
            "Epoch 354/500\n",
            "89/89 [==============================] - 27s 300ms/step - loss: 12.8898 - mae: 2.9332 - val_loss: 13.2885 - val_mae: 2.8732\n",
            "Epoch 355/500\n",
            "89/89 [==============================] - 28s 312ms/step - loss: 13.0594 - mae: 2.9377 - val_loss: 11.0449 - val_mae: 2.6828\n",
            "Epoch 356/500\n",
            "89/89 [==============================] - 28s 306ms/step - loss: 12.6988 - mae: 2.9301 - val_loss: 13.7954 - val_mae: 2.9295\n",
            "Epoch 357/500\n",
            "89/89 [==============================] - 27s 293ms/step - loss: 12.4826 - mae: 2.8833 - val_loss: 13.5214 - val_mae: 2.9198\n",
            "Epoch 358/500\n",
            "89/89 [==============================] - 28s 306ms/step - loss: 12.9541 - mae: 2.8803 - val_loss: 14.4820 - val_mae: 2.9755\n",
            "Epoch 359/500\n",
            "89/89 [==============================] - 28s 304ms/step - loss: 12.5429 - mae: 2.8997 - val_loss: 13.7133 - val_mae: 2.9264\n",
            "Epoch 360/500\n",
            "89/89 [==============================] - 28s 305ms/step - loss: 12.8471 - mae: 2.9113 - val_loss: 15.5833 - val_mae: 3.0712\n",
            "Epoch 361/500\n",
            "89/89 [==============================] - 28s 310ms/step - loss: 12.4714 - mae: 2.8395 - val_loss: 18.9022 - val_mae: 3.3366\n",
            "Epoch 362/500\n",
            "89/89 [==============================] - 28s 313ms/step - loss: 13.7059 - mae: 2.9685 - val_loss: 12.6555 - val_mae: 2.8169\n",
            "Epoch 363/500\n",
            "89/89 [==============================] - 28s 304ms/step - loss: 12.1756 - mae: 2.8475 - val_loss: 14.3270 - val_mae: 2.9714\n",
            "Epoch 364/500\n",
            "89/89 [==============================] - 28s 307ms/step - loss: 12.3881 - mae: 2.8707 - val_loss: 12.2182 - val_mae: 2.7873\n",
            "Epoch 365/500\n",
            "89/89 [==============================] - 28s 304ms/step - loss: 12.7792 - mae: 2.9138 - val_loss: 19.6488 - val_mae: 3.3906\n",
            "Epoch 366/500\n",
            "89/89 [==============================] - 27s 300ms/step - loss: 12.8820 - mae: 2.9381 - val_loss: 20.0521 - val_mae: 3.4298\n",
            "Epoch 367/500\n",
            "89/89 [==============================] - 27s 297ms/step - loss: 13.1493 - mae: 2.9539 - val_loss: 15.1638 - val_mae: 3.0332\n",
            "Epoch 368/500\n",
            "89/89 [==============================] - 27s 292ms/step - loss: 13.0028 - mae: 2.9483 - val_loss: 21.7644 - val_mae: 3.5839\n",
            "Epoch 369/500\n",
            "89/89 [==============================] - 27s 290ms/step - loss: 13.1955 - mae: 2.9555 - val_loss: 17.2635 - val_mae: 3.2221\n",
            "Epoch 370/500\n",
            "89/89 [==============================] - 26s 290ms/step - loss: 12.9585 - mae: 2.9388 - val_loss: 12.3185 - val_mae: 2.8111\n",
            "Epoch 371/500\n",
            "89/89 [==============================] - 27s 294ms/step - loss: 13.0963 - mae: 2.9721 - val_loss: 13.6655 - val_mae: 2.9069\n",
            "Epoch 372/500\n",
            "89/89 [==============================] - 22s 240ms/step - loss: 12.1147 - mae: 2.8455 - val_loss: 15.1577 - val_mae: 3.0233\n",
            "Epoch 373/500\n",
            "89/89 [==============================] - 28s 298ms/step - loss: 12.3612 - mae: 2.8615 - val_loss: 12.7110 - val_mae: 2.8443\n",
            "Epoch 374/500\n",
            "89/89 [==============================] - 28s 296ms/step - loss: 13.1319 - mae: 2.9492 - val_loss: 20.4923 - val_mae: 3.4701\n",
            "Epoch 375/500\n",
            "89/89 [==============================] - 27s 290ms/step - loss: 12.3997 - mae: 2.8654 - val_loss: 12.9260 - val_mae: 2.8518\n",
            "Epoch 376/500\n",
            "89/89 [==============================] - 27s 295ms/step - loss: 12.8870 - mae: 2.9167 - val_loss: 19.9114 - val_mae: 3.4264\n",
            "Epoch 377/500\n",
            "89/89 [==============================] - 27s 293ms/step - loss: 12.8141 - mae: 2.9095 - val_loss: 14.5246 - val_mae: 2.9733\n",
            "Epoch 378/500\n",
            "89/89 [==============================] - 26s 291ms/step - loss: 13.2453 - mae: 2.9582 - val_loss: 13.7750 - val_mae: 2.9168\n",
            "Epoch 379/500\n",
            "89/89 [==============================] - 26s 288ms/step - loss: 13.4429 - mae: 3.0004 - val_loss: 18.4626 - val_mae: 3.2894\n",
            "Epoch 380/500\n",
            "89/89 [==============================] - 27s 289ms/step - loss: 12.3933 - mae: 2.8684 - val_loss: 16.8519 - val_mae: 3.1890\n",
            "Epoch 381/500\n",
            "89/89 [==============================] - 27s 290ms/step - loss: 13.0460 - mae: 2.9234 - val_loss: 17.1971 - val_mae: 3.2096\n",
            "Epoch 382/500\n",
            "89/89 [==============================] - 26s 288ms/step - loss: 12.6388 - mae: 2.9154 - val_loss: 15.2483 - val_mae: 3.0326\n",
            "Epoch 383/500\n",
            "89/89 [==============================] - 27s 292ms/step - loss: 12.7285 - mae: 2.9103 - val_loss: 18.8654 - val_mae: 3.3182\n",
            "Epoch 384/500\n",
            "89/89 [==============================] - 27s 298ms/step - loss: 12.8197 - mae: 2.8910 - val_loss: 19.3282 - val_mae: 3.3483\n",
            "Epoch 385/500\n",
            "89/89 [==============================] - 21s 229ms/step - loss: 13.1838 - mae: 2.9257 - val_loss: 13.7356 - val_mae: 2.8955\n",
            "Epoch 386/500\n",
            "89/89 [==============================] - 27s 291ms/step - loss: 13.1267 - mae: 2.9562 - val_loss: 24.9654 - val_mae: 3.8045\n",
            "Epoch 387/500\n",
            "89/89 [==============================] - 28s 305ms/step - loss: 13.2050 - mae: 2.9072 - val_loss: 23.0397 - val_mae: 3.6844\n",
            "Epoch 388/500\n",
            "89/89 [==============================] - 26s 288ms/step - loss: 14.3714 - mae: 3.0844 - val_loss: 10.9764 - val_mae: 2.7087\n",
            "Epoch 389/500\n",
            "89/89 [==============================] - 26s 287ms/step - loss: 13.3629 - mae: 2.9917 - val_loss: 23.1192 - val_mae: 3.6760\n",
            "Epoch 390/500\n",
            "89/89 [==============================] - 26s 285ms/step - loss: 12.7860 - mae: 2.9136 - val_loss: 18.7044 - val_mae: 3.3183\n",
            "Epoch 391/500\n",
            "89/89 [==============================] - 26s 285ms/step - loss: 12.4052 - mae: 2.8841 - val_loss: 16.7936 - val_mae: 3.1871\n",
            "Epoch 392/500\n",
            "89/89 [==============================] - 27s 291ms/step - loss: 12.5712 - mae: 2.8826 - val_loss: 16.3541 - val_mae: 3.1470\n",
            "Epoch 393/500\n",
            "89/89 [==============================] - 26s 289ms/step - loss: 14.0615 - mae: 3.0680 - val_loss: 15.2032 - val_mae: 3.0362\n",
            "Epoch 394/500\n",
            "89/89 [==============================] - 26s 291ms/step - loss: 12.7818 - mae: 2.9239 - val_loss: 13.2668 - val_mae: 2.8806\n",
            "Epoch 395/500\n",
            "89/89 [==============================] - 22s 234ms/step - loss: 12.6085 - mae: 2.9010 - val_loss: 19.1812 - val_mae: 3.3540\n",
            "Epoch 396/500\n",
            "89/89 [==============================] - 28s 302ms/step - loss: 12.8869 - mae: 2.8965 - val_loss: 12.9534 - val_mae: 2.8596\n",
            "Epoch 397/500\n",
            "89/89 [==============================] - 26s 284ms/step - loss: 12.8533 - mae: 2.9198 - val_loss: 16.3691 - val_mae: 3.1458\n",
            "Epoch 398/500\n",
            "89/89 [==============================] - 27s 298ms/step - loss: 13.1062 - mae: 2.9427 - val_loss: 13.2366 - val_mae: 2.8724\n",
            "Epoch 399/500\n",
            "89/89 [==============================] - 28s 304ms/step - loss: 13.0660 - mae: 2.9414 - val_loss: 12.9604 - val_mae: 2.8517\n",
            "Epoch 400/500\n",
            "89/89 [==============================] - 27s 294ms/step - loss: 12.8298 - mae: 2.9366 - val_loss: 20.1780 - val_mae: 3.4271\n",
            "Epoch 401/500\n",
            "89/89 [==============================] - 26s 290ms/step - loss: 12.7181 - mae: 2.9169 - val_loss: 16.0448 - val_mae: 3.1269\n",
            "Epoch 402/500\n",
            "89/89 [==============================] - 26s 286ms/step - loss: 13.0991 - mae: 2.9113 - val_loss: 17.0051 - val_mae: 3.1802\n",
            "Epoch 403/500\n",
            "89/89 [==============================] - 26s 285ms/step - loss: 12.8276 - mae: 2.9156 - val_loss: 21.7133 - val_mae: 3.5330\n",
            "Epoch 404/500\n",
            "89/89 [==============================] - 26s 284ms/step - loss: 12.8718 - mae: 2.9294 - val_loss: 25.8782 - val_mae: 3.9097\n",
            "Epoch 405/500\n",
            "89/89 [==============================] - 28s 311ms/step - loss: 12.9672 - mae: 2.8957 - val_loss: 14.5608 - val_mae: 3.0008\n",
            "Epoch 406/500\n",
            "89/89 [==============================] - 27s 301ms/step - loss: 12.6175 - mae: 2.8954 - val_loss: 14.4643 - val_mae: 2.9798\n",
            "Epoch 407/500\n",
            "89/89 [==============================] - 28s 305ms/step - loss: 12.4005 - mae: 2.8787 - val_loss: 13.7404 - val_mae: 2.9077\n",
            "Epoch 408/500\n",
            "89/89 [==============================] - 28s 302ms/step - loss: 12.6862 - mae: 2.8955 - val_loss: 24.4747 - val_mae: 3.7734\n",
            "Epoch 409/500\n",
            "89/89 [==============================] - 27s 295ms/step - loss: 12.2670 - mae: 2.8576 - val_loss: 25.9722 - val_mae: 3.8961\n",
            "Epoch 410/500\n",
            "89/89 [==============================] - 23s 247ms/step - loss: 12.9028 - mae: 2.9104 - val_loss: 11.5648 - val_mae: 2.7458\n",
            "Epoch 411/500\n",
            "89/89 [==============================] - 28s 305ms/step - loss: 12.8560 - mae: 2.9233 - val_loss: 27.4980 - val_mae: 3.9904\n",
            "Epoch 412/500\n",
            "89/89 [==============================] - 27s 301ms/step - loss: 12.9325 - mae: 2.9180 - val_loss: 11.0190 - val_mae: 2.7068\n",
            "Epoch 413/500\n",
            "89/89 [==============================] - 28s 311ms/step - loss: 13.1022 - mae: 2.9394 - val_loss: 14.3372 - val_mae: 2.9791\n",
            "Epoch 414/500\n",
            "89/89 [==============================] - 27s 291ms/step - loss: 13.1735 - mae: 2.9335 - val_loss: 15.0269 - val_mae: 3.0152\n",
            "Epoch 415/500\n",
            "89/89 [==============================] - 21s 230ms/step - loss: 12.8862 - mae: 2.9100 - val_loss: 18.3933 - val_mae: 3.2575\n",
            "Epoch 416/500\n",
            "89/89 [==============================] - 27s 297ms/step - loss: 13.7890 - mae: 2.9738 - val_loss: 18.6102 - val_mae: 3.2909\n",
            "Epoch 417/500\n",
            "89/89 [==============================] - 28s 303ms/step - loss: 13.1138 - mae: 2.9662 - val_loss: 16.7319 - val_mae: 3.1444\n",
            "Epoch 418/500\n",
            "89/89 [==============================] - 27s 300ms/step - loss: 12.8370 - mae: 2.8886 - val_loss: 14.6417 - val_mae: 2.9807\n",
            "Epoch 419/500\n",
            "89/89 [==============================] - 27s 299ms/step - loss: 12.0191 - mae: 2.8207 - val_loss: 25.7562 - val_mae: 3.9120\n",
            "Epoch 420/500\n",
            "89/89 [==============================] - 28s 308ms/step - loss: 12.5115 - mae: 2.8651 - val_loss: 15.4393 - val_mae: 3.0411\n",
            "Epoch 421/500\n",
            "89/89 [==============================] - 23s 247ms/step - loss: 13.0640 - mae: 2.9385 - val_loss: 13.8718 - val_mae: 2.9294\n",
            "Epoch 422/500\n",
            "89/89 [==============================] - 27s 291ms/step - loss: 12.3565 - mae: 2.8212 - val_loss: 13.8728 - val_mae: 2.9295\n",
            "Epoch 423/500\n",
            "89/89 [==============================] - 26s 287ms/step - loss: 11.9166 - mae: 2.7877 - val_loss: 13.7039 - val_mae: 2.9160\n",
            "Epoch 424/500\n",
            "89/89 [==============================] - 26s 288ms/step - loss: 12.7333 - mae: 2.9004 - val_loss: 11.1008 - val_mae: 2.6864\n",
            "Epoch 425/500\n",
            "89/89 [==============================] - 26s 285ms/step - loss: 12.4006 - mae: 2.8481 - val_loss: 20.0040 - val_mae: 3.4388\n",
            "Epoch 426/500\n",
            "89/89 [==============================] - 26s 288ms/step - loss: 12.2382 - mae: 2.8046 - val_loss: 21.6504 - val_mae: 3.5605\n",
            "Epoch 427/500\n",
            "89/89 [==============================] - 26s 288ms/step - loss: 11.9287 - mae: 2.7743 - val_loss: 13.9473 - val_mae: 2.9117\n",
            "Epoch 428/500\n",
            "89/89 [==============================] - 27s 298ms/step - loss: 12.4046 - mae: 2.7822 - val_loss: 24.2319 - val_mae: 3.7583\n",
            "Epoch 429/500\n",
            "89/89 [==============================] - 26s 289ms/step - loss: 12.0983 - mae: 2.7937 - val_loss: 12.5091 - val_mae: 2.7333\n",
            "Epoch 430/500\n",
            "89/89 [==============================] - 28s 302ms/step - loss: 12.3487 - mae: 2.8083 - val_loss: 12.7266 - val_mae: 2.7467\n",
            "Epoch 431/500\n",
            "89/89 [==============================] - 21s 231ms/step - loss: 12.4500 - mae: 2.8046 - val_loss: 11.5042 - val_mae: 2.6372\n",
            "Epoch 432/500\n",
            "89/89 [==============================] - 27s 299ms/step - loss: 11.9544 - mae: 2.7909 - val_loss: 20.7501 - val_mae: 3.4354\n",
            "Epoch 433/500\n",
            "89/89 [==============================] - 27s 300ms/step - loss: 11.4845 - mae: 2.7083 - val_loss: 20.9155 - val_mae: 3.4772\n",
            "Epoch 434/500\n",
            "89/89 [==============================] - 28s 303ms/step - loss: 11.7534 - mae: 2.7296 - val_loss: 16.0407 - val_mae: 3.0546\n",
            "Epoch 435/500\n",
            "89/89 [==============================] - 27s 291ms/step - loss: 11.8488 - mae: 2.7447 - val_loss: 13.0967 - val_mae: 2.7903\n",
            "Epoch 436/500\n",
            "89/89 [==============================] - 26s 290ms/step - loss: 11.8144 - mae: 2.7514 - val_loss: 17.6557 - val_mae: 3.2012\n",
            "Epoch 437/500\n",
            "89/89 [==============================] - 21s 233ms/step - loss: 11.3060 - mae: 2.6610 - val_loss: 23.3468 - val_mae: 3.6702\n",
            "Epoch 438/500\n",
            "89/89 [==============================] - 28s 305ms/step - loss: 11.5781 - mae: 2.7212 - val_loss: 10.7863 - val_mae: 2.5652\n",
            "Epoch 439/500\n",
            "89/89 [==============================] - 28s 305ms/step - loss: 11.0730 - mae: 2.6725 - val_loss: 13.9962 - val_mae: 2.8677\n",
            "Epoch 440/500\n",
            "89/89 [==============================] - 28s 302ms/step - loss: 11.0636 - mae: 2.6403 - val_loss: 16.1251 - val_mae: 3.0443\n",
            "Epoch 441/500\n",
            "89/89 [==============================] - 23s 254ms/step - loss: 11.6919 - mae: 2.7412 - val_loss: 17.5553 - val_mae: 3.1548\n",
            "Epoch 442/500\n",
            "89/89 [==============================] - 26s 282ms/step - loss: 11.3349 - mae: 2.7197 - val_loss: 15.8282 - val_mae: 3.0250\n",
            "Epoch 443/500\n",
            "89/89 [==============================] - 21s 230ms/step - loss: 11.3945 - mae: 2.6616 - val_loss: 20.5124 - val_mae: 3.4067\n",
            "Epoch 444/500\n",
            "89/89 [==============================] - 26s 285ms/step - loss: 10.9541 - mae: 2.6448 - val_loss: 23.7015 - val_mae: 3.6832\n",
            "Epoch 445/500\n",
            "89/89 [==============================] - 21s 232ms/step - loss: 11.8648 - mae: 2.7319 - val_loss: 12.4126 - val_mae: 2.7309\n",
            "Epoch 446/500\n",
            "89/89 [==============================] - 23s 246ms/step - loss: 10.6859 - mae: 2.6138 - val_loss: 18.2486 - val_mae: 3.2037\n",
            "Epoch 447/500\n",
            "89/89 [==============================] - 26s 281ms/step - loss: 11.1785 - mae: 2.6570 - val_loss: 18.1594 - val_mae: 3.2170\n",
            "Epoch 448/500\n",
            "89/89 [==============================] - 26s 287ms/step - loss: 11.3101 - mae: 2.6470 - val_loss: 17.0310 - val_mae: 3.1070\n",
            "Epoch 449/500\n",
            "89/89 [==============================] - 28s 305ms/step - loss: 11.8186 - mae: 2.7409 - val_loss: 17.5100 - val_mae: 3.1629\n",
            "Epoch 450/500\n",
            "89/89 [==============================] - 28s 307ms/step - loss: 13.1488 - mae: 2.9065 - val_loss: 20.2312 - val_mae: 3.3904\n",
            "Epoch 451/500\n",
            "89/89 [==============================] - 27s 292ms/step - loss: 13.0961 - mae: 2.9197 - val_loss: 18.1556 - val_mae: 3.2693\n",
            "Epoch 452/500\n",
            "89/89 [==============================] - 28s 311ms/step - loss: 13.7224 - mae: 2.9800 - val_loss: 12.5188 - val_mae: 2.8298\n",
            "Epoch 453/500\n",
            "89/89 [==============================] - 27s 300ms/step - loss: 13.5471 - mae: 2.9621 - val_loss: 12.2867 - val_mae: 2.8113\n",
            "Epoch 454/500\n",
            "89/89 [==============================] - 27s 295ms/step - loss: 12.2585 - mae: 2.8634 - val_loss: 16.1709 - val_mae: 3.0853\n",
            "Epoch 455/500\n",
            "89/89 [==============================] - 28s 305ms/step - loss: 13.1526 - mae: 2.9220 - val_loss: 17.8860 - val_mae: 3.2520\n",
            "Epoch 456/500\n",
            "89/89 [==============================] - 27s 296ms/step - loss: 12.9635 - mae: 2.9104 - val_loss: 23.1976 - val_mae: 3.6647\n",
            "Epoch 457/500\n",
            "89/89 [==============================] - 24s 267ms/step - loss: 12.6468 - mae: 2.8972 - val_loss: 16.3832 - val_mae: 3.1014\n",
            "Epoch 458/500\n",
            "89/89 [==============================] - 28s 305ms/step - loss: 12.3448 - mae: 2.8421 - val_loss: 18.1783 - val_mae: 3.2905\n",
            "Epoch 459/500\n",
            "89/89 [==============================] - 27s 302ms/step - loss: 12.8510 - mae: 2.9171 - val_loss: 20.6763 - val_mae: 3.4786\n",
            "Epoch 460/500\n",
            "89/89 [==============================] - 27s 293ms/step - loss: 13.2181 - mae: 2.9568 - val_loss: 13.7170 - val_mae: 2.9177\n",
            "Epoch 461/500\n",
            "89/89 [==============================] - 28s 309ms/step - loss: 12.5092 - mae: 2.8728 - val_loss: 11.9507 - val_mae: 2.7786\n",
            "Epoch 462/500\n",
            "89/89 [==============================] - 28s 305ms/step - loss: 12.6320 - mae: 2.8888 - val_loss: 12.3700 - val_mae: 2.8010\n",
            "Epoch 463/500\n",
            "89/89 [==============================] - 29s 315ms/step - loss: 12.7088 - mae: 2.8980 - val_loss: 11.7586 - val_mae: 2.7532\n",
            "Epoch 464/500\n",
            "89/89 [==============================] - 29s 317ms/step - loss: 12.9444 - mae: 2.9145 - val_loss: 14.1867 - val_mae: 2.9601\n",
            "Epoch 465/500\n",
            "89/89 [==============================] - 27s 295ms/step - loss: 13.3292 - mae: 2.9611 - val_loss: 10.9706 - val_mae: 2.6884\n",
            "Epoch 466/500\n",
            "89/89 [==============================] - 26s 285ms/step - loss: 12.4491 - mae: 2.8883 - val_loss: 10.5263 - val_mae: 2.6890\n",
            "Epoch 467/500\n",
            "89/89 [==============================] - 27s 297ms/step - loss: 14.9478 - mae: 3.1212 - val_loss: 10.7499 - val_mae: 2.7047\n",
            "Epoch 468/500\n",
            "89/89 [==============================] - 26s 287ms/step - loss: 12.7768 - mae: 2.9162 - val_loss: 12.3544 - val_mae: 2.8213\n",
            "Epoch 469/500\n",
            "89/89 [==============================] - 26s 284ms/step - loss: 12.8149 - mae: 2.9038 - val_loss: 15.6915 - val_mae: 3.0748\n",
            "Epoch 470/500\n",
            "89/89 [==============================] - 26s 288ms/step - loss: 12.2186 - mae: 2.8515 - val_loss: 19.7460 - val_mae: 3.4350\n",
            "Epoch 471/500\n",
            "89/89 [==============================] - 26s 290ms/step - loss: 12.9355 - mae: 2.8987 - val_loss: 15.1592 - val_mae: 3.0339\n",
            "Epoch 472/500\n",
            "89/89 [==============================] - 26s 288ms/step - loss: 13.1068 - mae: 2.9069 - val_loss: 14.5460 - val_mae: 3.0056\n",
            "Epoch 473/500\n",
            "89/89 [==============================] - 26s 289ms/step - loss: 12.4025 - mae: 2.8820 - val_loss: 16.8883 - val_mae: 3.1658\n",
            "Epoch 474/500\n",
            "89/89 [==============================] - 27s 302ms/step - loss: 12.6114 - mae: 2.8873 - val_loss: 18.4431 - val_mae: 3.3087\n",
            "Epoch 475/500\n",
            "89/89 [==============================] - 27s 301ms/step - loss: 12.9226 - mae: 2.9224 - val_loss: 11.9509 - val_mae: 2.7790\n",
            "Epoch 476/500\n",
            "89/89 [==============================] - 28s 303ms/step - loss: 12.6364 - mae: 2.9020 - val_loss: 15.6995 - val_mae: 3.0748\n",
            "Epoch 477/500\n",
            "89/89 [==============================] - 27s 295ms/step - loss: 13.0544 - mae: 2.9064 - val_loss: 18.3832 - val_mae: 3.3027\n",
            "Epoch 478/500\n",
            "89/89 [==============================] - 26s 285ms/step - loss: 12.4210 - mae: 2.8774 - val_loss: 12.5361 - val_mae: 2.8356\n",
            "Epoch 479/500\n",
            "89/89 [==============================] - 26s 284ms/step - loss: 12.5149 - mae: 2.8837 - val_loss: 13.8816 - val_mae: 2.9375\n",
            "Epoch 480/500\n",
            "89/89 [==============================] - 26s 283ms/step - loss: 12.8872 - mae: 2.9223 - val_loss: 10.5012 - val_mae: 2.6784\n",
            "Epoch 481/500\n",
            "89/89 [==============================] - 26s 288ms/step - loss: 13.7741 - mae: 2.9489 - val_loss: 12.7342 - val_mae: 2.8438\n",
            "Epoch 482/500\n",
            "89/89 [==============================] - 22s 237ms/step - loss: 12.5106 - mae: 2.8914 - val_loss: 14.4121 - val_mae: 2.9837\n",
            "Epoch 483/500\n",
            "89/89 [==============================] - 27s 296ms/step - loss: 12.2807 - mae: 2.8650 - val_loss: 14.8884 - val_mae: 3.0071\n",
            "Epoch 484/500\n",
            "89/89 [==============================] - 28s 301ms/step - loss: 13.6913 - mae: 3.0169 - val_loss: 11.9043 - val_mae: 2.7726\n",
            "Epoch 485/500\n",
            "89/89 [==============================] - 28s 307ms/step - loss: 12.6246 - mae: 2.8888 - val_loss: 16.9219 - val_mae: 3.2013\n",
            "Epoch 486/500\n",
            "89/89 [==============================] - 23s 252ms/step - loss: 13.3624 - mae: 2.9818 - val_loss: 16.2158 - val_mae: 3.1203\n",
            "Epoch 487/500\n",
            "89/89 [==============================] - 26s 287ms/step - loss: 12.3003 - mae: 2.8565 - val_loss: 22.6791 - val_mae: 3.6757\n",
            "Epoch 488/500\n",
            "89/89 [==============================] - 26s 286ms/step - loss: 14.3905 - mae: 2.9989 - val_loss: 19.5239 - val_mae: 3.4174\n",
            "Epoch 489/500\n",
            "89/89 [==============================] - 26s 286ms/step - loss: 12.5431 - mae: 2.8907 - val_loss: 18.2412 - val_mae: 3.2992\n",
            "Epoch 490/500\n",
            "89/89 [==============================] - 27s 296ms/step - loss: 12.6980 - mae: 2.8885 - val_loss: 21.0613 - val_mae: 3.5369\n",
            "Epoch 491/500\n",
            "89/89 [==============================] - 27s 297ms/step - loss: 13.2501 - mae: 2.9444 - val_loss: 16.3552 - val_mae: 3.1388\n",
            "Epoch 492/500\n",
            "89/89 [==============================] - 28s 309ms/step - loss: 12.7286 - mae: 2.9086 - val_loss: 19.6293 - val_mae: 3.4318\n",
            "Epoch 493/500\n",
            "89/89 [==============================] - 22s 242ms/step - loss: 12.3646 - mae: 2.8718 - val_loss: 20.3797 - val_mae: 3.4805\n",
            "Epoch 494/500\n",
            "89/89 [==============================] - 28s 303ms/step - loss: 12.3688 - mae: 2.8729 - val_loss: 15.0854 - val_mae: 3.0272\n",
            "Epoch 495/500\n",
            "89/89 [==============================] - 27s 299ms/step - loss: 13.0076 - mae: 2.9371 - val_loss: 12.7235 - val_mae: 2.8375\n",
            "Epoch 496/500\n",
            "89/89 [==============================] - 26s 287ms/step - loss: 12.6227 - mae: 2.8620 - val_loss: 18.7817 - val_mae: 3.3689\n",
            "Epoch 497/500\n",
            "89/89 [==============================] - 27s 302ms/step - loss: 13.0349 - mae: 2.9280 - val_loss: 16.5665 - val_mae: 3.1542\n",
            "Epoch 498/500\n",
            "89/89 [==============================] - 28s 303ms/step - loss: 12.6777 - mae: 2.8747 - val_loss: 15.8187 - val_mae: 3.0925\n",
            "Epoch 499/500\n",
            "89/89 [==============================] - 27s 293ms/step - loss: 12.6651 - mae: 2.8878 - val_loss: 12.9780 - val_mae: 2.8407\n",
            "Epoch 500/500\n",
            "89/89 [==============================] - 26s 290ms/step - loss: 13.1768 - mae: 2.9266 - val_loss: 20.3211 - val_mae: 3.4785\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "mae = history.history['mae']\n",
        "val_mae = history.history['val_mae']\n",
        "\n",
        "\n",
        "epochs_x = range(len(loss))\n",
        "\n",
        "\n",
        "plt.plot(epochs_x, mae, 'co', label='Training MAE')\n",
        "plt.plot(epochs_x, val_mae, 'k', label='Validation MAE')\n",
        "plt.title('Training and validation MeanAbsoluteError')\n",
        "plt.legend()\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(epochs_x, loss, 'co', label='Training loss')\n",
        "plt.plot(epochs_x, val_loss, 'k', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Y3K89-CM-dfg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545
        },
        "outputId": "c46837fb-7a1a-48e4-bde2-8513ed188319"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "epochs_x"
      ],
      "metadata": {
        "id": "N_sP_ZmSY-Jv",
        "outputId": "157bf506-91fc-4c58-8dea-e0fa15573795",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "range(0, 500)"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Download the model\n"
      ],
      "metadata": {
        "id": "R19IJQSYoW7J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "os.makedirs('/content/drive/My Drive/cut_panoramic/Model', exist_ok=True)\n",
        "model.save('/content/drive/My Drive/cut_panoramic/Model/1e-3_16_0.2_Male18_500.h5')"
      ],
      "metadata": {
        "id": "Zed4TdFcG2iJ"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "n5YxZ-5QjQ0-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# from google.colab import files\n",
        "# files.download('/content/drive/My Drive/cut_panoramic/Model/1.1_รอบแรก_Flimpano_Male125_250.h5')"
      ],
      "metadata": {
        "id": "P5eMxm1NV-oY"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "wY_pDlxkRwxS"
      },
      "execution_count": 24,
      "outputs": []
    }
  ]
}