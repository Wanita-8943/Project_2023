{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Wanita-8943/Project_2023/blob/main/1_2e-5_32_0.2_Male18_500.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#เรียกใช้ CSV"
      ],
      "metadata": {
        "id": "ow7eWoNw6U-c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import shutil"
      ],
      "metadata": {
        "id": "DlQ2oT7cIR6o"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1_2Fe8u81d5r",
        "outputId": "28dd77d7-3dce-486f-a6e4-d6ccb40f9ed1"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Imports"
      ],
      "metadata": {
        "id": "5qxePnnn7TGW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import models\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import optimizers\n",
        "import os\n",
        "import glob\n",
        "import shutil\n",
        "import sys\n",
        "import numpy as np\n",
        "from skimage.io import imread\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import Image\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "D-hCRloc3t39"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras import backend as K"
      ],
      "metadata": {
        "id": "YZWXwjXeGxZP"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#กำหนดค่าพารามิเตอร์\n"
      ],
      "metadata": {
        "id": "RooqSdBc7QHC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 32\n",
        "width = 150\n",
        "height = 150\n",
        "epochs = 500\n",
        "NUM_TRAIN = 1425\n",
        "NUM_TEST = 475\n",
        "dropout_rate = 0.2\n",
        "input_shape = (height, width, 3)"
      ],
      "metadata": {
        "id": "thDb7U9B3xOo"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Clone efficientnet repo\n"
      ],
      "metadata": {
        "id": "pumGmy6f3eSW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#ดึงข้อมูลใน Github มาใช้\n",
        "import os\n",
        "%cd /content\n",
        "if not os.path.isdir(\"efficientnet_keras_transfer_learning\"):\n",
        " !git clone https://github.com/Wanita-8943/efficientnet_keras_transfer_learning\n",
        "%cd efficientnet_keras_transfer_learning/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P7iy2f8n16p0",
        "outputId": "fe2bd810-419a-49cf-b637-af066e069cfd"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "Cloning into 'efficientnet_keras_transfer_learning'...\n",
            "remote: Enumerating objects: 831, done.\u001b[K\n",
            "remote: Counting objects: 100% (353/353), done.\u001b[K\n",
            "remote: Compressing objects: 100% (166/166), done.\u001b[K\n",
            "remote: Total 831 (delta 249), reused 248 (delta 187), pack-reused 478\u001b[K\n",
            "Receiving objects: 100% (831/831), 13.73 MiB | 28.63 MiB/s, done.\n",
            "Resolving deltas: 100% (489/489), done.\n",
            "/content/efficientnet_keras_transfer_learning\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import keras"
      ],
      "metadata": {
        "id": "Vbdblwbv89fe"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ],
      "metadata": {
        "id": "vnLrobY_-GCx",
        "outputId": "9111f8c8-9571-4f30-d871-b6d5608aab83",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.11.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Options: EfficientNetB0, EfficientNetB1, EfficientNetB2, EfficientNetB3\n",
        "# Higher the number, the more complex the model is.\n",
        "from efficientnet import EfficientNetB0 as Net\n",
        "from efficientnet import center_crop_and_resize, preprocess_input"
      ],
      "metadata": {
        "id": "tjZBRnfo3bN0"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# loading pretrained conv base model\n",
        "# โหลดโมเดล มาโดยตัด output ของโมเดลออก เเต่ยังใช้ input อันเดิม\n",
        "# เเละโหลด weight ของโมเดล มาด้วยที่ชื่อว่า imagenet\n",
        "conv_base = Net(weights='imagenet', include_top=False, input_shape=input_shape)"
      ],
      "metadata": {
        "id": "hNZAzbDp3lgA",
        "outputId": "f84be63f-24b4-464c-d5d9-527d203d5336",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
            "Instructions for updating:\n",
            "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://github.com/qubvel/efficientnet/releases/download/v0.0.1/efficientnet-b0_imagenet_1000_notop.h5\n",
            "16717576/16717576 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = models.Sequential()\n",
        "model.add(conv_base)\n",
        "model.add(layers.GlobalMaxPooling2D(name=\"gap\"))\n",
        "# model.add(layers.Flatten(name=\"flatten\"))\n",
        "if dropout_rate > 0:\n",
        "    model.add(layers.Dropout(dropout_rate, name=\"dropout_out\"))\n",
        "# model.add(layers.Dense(256, activation='relu', name=\"fc1\"))\n",
        "model.add(layers.Dense(19, activation='softmax', name=\"fc_out\"))\n",
        "model.add(layers.Dense(1))"
      ],
      "metadata": {
        "id": "yWNKfQUt5rga"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "NadBB12251jh",
        "outputId": "4f086e24-a503-498c-ee37-f94fb99fb9b8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " efficientnet-b0 (Functional  (None, 5, 5, 1280)       4049564   \n",
            " )                                                               \n",
            "                                                                 \n",
            " gap (GlobalMaxPooling2D)    (None, 1280)              0         \n",
            "                                                                 \n",
            " dropout_out (Dropout)       (None, 1280)              0         \n",
            "                                                                 \n",
            " fc_out (Dense)              (None, 19)                24339     \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1)                 20        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4,073,923\n",
            "Trainable params: 4,031,907\n",
            "Non-trainable params: 42,016\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('This is the number of trainable layers '\n",
        "      'before freezing the conv base:', len(model.trainable_weights))\n",
        "\n",
        "conv_base.trainable = False\n",
        "\n",
        "print('This is the number of trainable layers '\n",
        "      'after freezing the conv base:', len(model.trainable_weights))"
      ],
      "metadata": {
        "id": "GepWq3yy53t5",
        "outputId": "5e3476d4-e4de-40a4-9672-fde7c9546e1f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This is the number of trainable layers before freezing the conv base: 215\n",
            "This is the number of trainable layers after freezing the conv base: 4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "conv_base.summary() #ดู Summary"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iD76D6c_79py",
        "outputId": "ae6a752a-8df9-4988-8239-b7e8044218ce"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"efficientnet-b0\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 150, 150, 3  0           []                               \n",
            "                                )]                                                                \n",
            "                                                                                                  \n",
            " conv2d (Conv2D)                (None, 75, 75, 32)   864         ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " batch_normalization (BatchNorm  (None, 75, 75, 32)  128         ['conv2d[0][0]']                 \n",
            " alization)                                                                                       \n",
            "                                                                                                  \n",
            " swish (Swish)                  (None, 75, 75, 32)   0           ['batch_normalization[0][0]']    \n",
            "                                                                                                  \n",
            " depthwise_conv2d (DepthwiseCon  (None, 75, 75, 32)  288         ['swish[0][0]']                  \n",
            " v2D)                                                                                             \n",
            "                                                                                                  \n",
            " batch_normalization_1 (BatchNo  (None, 75, 75, 32)  128         ['depthwise_conv2d[0][0]']       \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " swish_1 (Swish)                (None, 75, 75, 32)   0           ['batch_normalization_1[0][0]']  \n",
            "                                                                                                  \n",
            " lambda (Lambda)                (None, 1, 1, 32)     0           ['swish_1[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d_1 (Conv2D)              (None, 1, 1, 8)      264         ['lambda[0][0]']                 \n",
            "                                                                                                  \n",
            " swish_2 (Swish)                (None, 1, 1, 8)      0           ['conv2d_1[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_2 (Conv2D)              (None, 1, 1, 32)     288         ['swish_2[0][0]']                \n",
            "                                                                                                  \n",
            " activation (Activation)        (None, 1, 1, 32)     0           ['conv2d_2[0][0]']               \n",
            "                                                                                                  \n",
            " multiply (Multiply)            (None, 75, 75, 32)   0           ['activation[0][0]',             \n",
            "                                                                  'swish_1[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d_3 (Conv2D)              (None, 75, 75, 16)   512         ['multiply[0][0]']               \n",
            "                                                                                                  \n",
            " batch_normalization_2 (BatchNo  (None, 75, 75, 16)  64          ['conv2d_3[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv2d_4 (Conv2D)              (None, 75, 75, 96)   1536        ['batch_normalization_2[0][0]']  \n",
            "                                                                                                  \n",
            " batch_normalization_3 (BatchNo  (None, 75, 75, 96)  384         ['conv2d_4[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " swish_3 (Swish)                (None, 75, 75, 96)   0           ['batch_normalization_3[0][0]']  \n",
            "                                                                                                  \n",
            " depthwise_conv2d_1 (DepthwiseC  (None, 38, 38, 96)  864         ['swish_3[0][0]']                \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_4 (BatchNo  (None, 38, 38, 96)  384         ['depthwise_conv2d_1[0][0]']     \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " swish_4 (Swish)                (None, 38, 38, 96)   0           ['batch_normalization_4[0][0]']  \n",
            "                                                                                                  \n",
            " lambda_1 (Lambda)              (None, 1, 1, 96)     0           ['swish_4[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d_5 (Conv2D)              (None, 1, 1, 4)      388         ['lambda_1[0][0]']               \n",
            "                                                                                                  \n",
            " swish_5 (Swish)                (None, 1, 1, 4)      0           ['conv2d_5[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_6 (Conv2D)              (None, 1, 1, 96)     480         ['swish_5[0][0]']                \n",
            "                                                                                                  \n",
            " activation_1 (Activation)      (None, 1, 1, 96)     0           ['conv2d_6[0][0]']               \n",
            "                                                                                                  \n",
            " multiply_1 (Multiply)          (None, 38, 38, 96)   0           ['activation_1[0][0]',           \n",
            "                                                                  'swish_4[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d_7 (Conv2D)              (None, 38, 38, 24)   2304        ['multiply_1[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_5 (BatchNo  (None, 38, 38, 24)  96          ['conv2d_7[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv2d_8 (Conv2D)              (None, 38, 38, 144)  3456        ['batch_normalization_5[0][0]']  \n",
            "                                                                                                  \n",
            " batch_normalization_6 (BatchNo  (None, 38, 38, 144)  576        ['conv2d_8[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " swish_6 (Swish)                (None, 38, 38, 144)  0           ['batch_normalization_6[0][0]']  \n",
            "                                                                                                  \n",
            " depthwise_conv2d_2 (DepthwiseC  (None, 38, 38, 144)  1296       ['swish_6[0][0]']                \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_7 (BatchNo  (None, 38, 38, 144)  576        ['depthwise_conv2d_2[0][0]']     \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " swish_7 (Swish)                (None, 38, 38, 144)  0           ['batch_normalization_7[0][0]']  \n",
            "                                                                                                  \n",
            " lambda_2 (Lambda)              (None, 1, 1, 144)    0           ['swish_7[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d_9 (Conv2D)              (None, 1, 1, 6)      870         ['lambda_2[0][0]']               \n",
            "                                                                                                  \n",
            " swish_8 (Swish)                (None, 1, 1, 6)      0           ['conv2d_9[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_10 (Conv2D)             (None, 1, 1, 144)    1008        ['swish_8[0][0]']                \n",
            "                                                                                                  \n",
            " activation_2 (Activation)      (None, 1, 1, 144)    0           ['conv2d_10[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_2 (Multiply)          (None, 38, 38, 144)  0           ['activation_2[0][0]',           \n",
            "                                                                  'swish_7[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d_11 (Conv2D)             (None, 38, 38, 24)   3456        ['multiply_2[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_8 (BatchNo  (None, 38, 38, 24)  96          ['conv2d_11[0][0]']              \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " drop_connect (DropConnect)     (None, 38, 38, 24)   0           ['batch_normalization_8[0][0]']  \n",
            "                                                                                                  \n",
            " add (Add)                      (None, 38, 38, 24)   0           ['drop_connect[0][0]',           \n",
            "                                                                  'batch_normalization_5[0][0]']  \n",
            "                                                                                                  \n",
            " conv2d_12 (Conv2D)             (None, 38, 38, 144)  3456        ['add[0][0]']                    \n",
            "                                                                                                  \n",
            " batch_normalization_9 (BatchNo  (None, 38, 38, 144)  576        ['conv2d_12[0][0]']              \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " swish_9 (Swish)                (None, 38, 38, 144)  0           ['batch_normalization_9[0][0]']  \n",
            "                                                                                                  \n",
            " depthwise_conv2d_3 (DepthwiseC  (None, 19, 19, 144)  3600       ['swish_9[0][0]']                \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_10 (BatchN  (None, 19, 19, 144)  576        ['depthwise_conv2d_3[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_10 (Swish)               (None, 19, 19, 144)  0           ['batch_normalization_10[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_3 (Lambda)              (None, 1, 1, 144)    0           ['swish_10[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_13 (Conv2D)             (None, 1, 1, 6)      870         ['lambda_3[0][0]']               \n",
            "                                                                                                  \n",
            " swish_11 (Swish)               (None, 1, 1, 6)      0           ['conv2d_13[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_14 (Conv2D)             (None, 1, 1, 144)    1008        ['swish_11[0][0]']               \n",
            "                                                                                                  \n",
            " activation_3 (Activation)      (None, 1, 1, 144)    0           ['conv2d_14[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_3 (Multiply)          (None, 19, 19, 144)  0           ['activation_3[0][0]',           \n",
            "                                                                  'swish_10[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_15 (Conv2D)             (None, 19, 19, 40)   5760        ['multiply_3[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_11 (BatchN  (None, 19, 19, 40)  160         ['conv2d_15[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_16 (Conv2D)             (None, 19, 19, 240)  9600        ['batch_normalization_11[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_12 (BatchN  (None, 19, 19, 240)  960        ['conv2d_16[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_12 (Swish)               (None, 19, 19, 240)  0           ['batch_normalization_12[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_4 (DepthwiseC  (None, 19, 19, 240)  6000       ['swish_12[0][0]']               \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_13 (BatchN  (None, 19, 19, 240)  960        ['depthwise_conv2d_4[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_13 (Swish)               (None, 19, 19, 240)  0           ['batch_normalization_13[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_4 (Lambda)              (None, 1, 1, 240)    0           ['swish_13[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_17 (Conv2D)             (None, 1, 1, 10)     2410        ['lambda_4[0][0]']               \n",
            "                                                                                                  \n",
            " swish_14 (Swish)               (None, 1, 1, 10)     0           ['conv2d_17[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_18 (Conv2D)             (None, 1, 1, 240)    2640        ['swish_14[0][0]']               \n",
            "                                                                                                  \n",
            " activation_4 (Activation)      (None, 1, 1, 240)    0           ['conv2d_18[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_4 (Multiply)          (None, 19, 19, 240)  0           ['activation_4[0][0]',           \n",
            "                                                                  'swish_13[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_19 (Conv2D)             (None, 19, 19, 40)   9600        ['multiply_4[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_14 (BatchN  (None, 19, 19, 40)  160         ['conv2d_19[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_1 (DropConnect)   (None, 19, 19, 40)   0           ['batch_normalization_14[0][0]'] \n",
            "                                                                                                  \n",
            " add_1 (Add)                    (None, 19, 19, 40)   0           ['drop_connect_1[0][0]',         \n",
            "                                                                  'batch_normalization_11[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_20 (Conv2D)             (None, 19, 19, 240)  9600        ['add_1[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_15 (BatchN  (None, 19, 19, 240)  960        ['conv2d_20[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_15 (Swish)               (None, 19, 19, 240)  0           ['batch_normalization_15[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_5 (DepthwiseC  (None, 10, 10, 240)  2160       ['swish_15[0][0]']               \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_16 (BatchN  (None, 10, 10, 240)  960        ['depthwise_conv2d_5[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_16 (Swish)               (None, 10, 10, 240)  0           ['batch_normalization_16[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_5 (Lambda)              (None, 1, 1, 240)    0           ['swish_16[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_21 (Conv2D)             (None, 1, 1, 10)     2410        ['lambda_5[0][0]']               \n",
            "                                                                                                  \n",
            " swish_17 (Swish)               (None, 1, 1, 10)     0           ['conv2d_21[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_22 (Conv2D)             (None, 1, 1, 240)    2640        ['swish_17[0][0]']               \n",
            "                                                                                                  \n",
            " activation_5 (Activation)      (None, 1, 1, 240)    0           ['conv2d_22[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_5 (Multiply)          (None, 10, 10, 240)  0           ['activation_5[0][0]',           \n",
            "                                                                  'swish_16[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_23 (Conv2D)             (None, 10, 10, 80)   19200       ['multiply_5[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_17 (BatchN  (None, 10, 10, 80)  320         ['conv2d_23[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_24 (Conv2D)             (None, 10, 10, 480)  38400       ['batch_normalization_17[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_18 (BatchN  (None, 10, 10, 480)  1920       ['conv2d_24[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_18 (Swish)               (None, 10, 10, 480)  0           ['batch_normalization_18[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_6 (DepthwiseC  (None, 10, 10, 480)  4320       ['swish_18[0][0]']               \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_19 (BatchN  (None, 10, 10, 480)  1920       ['depthwise_conv2d_6[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_19 (Swish)               (None, 10, 10, 480)  0           ['batch_normalization_19[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_6 (Lambda)              (None, 1, 1, 480)    0           ['swish_19[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_25 (Conv2D)             (None, 1, 1, 20)     9620        ['lambda_6[0][0]']               \n",
            "                                                                                                  \n",
            " swish_20 (Swish)               (None, 1, 1, 20)     0           ['conv2d_25[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_26 (Conv2D)             (None, 1, 1, 480)    10080       ['swish_20[0][0]']               \n",
            "                                                                                                  \n",
            " activation_6 (Activation)      (None, 1, 1, 480)    0           ['conv2d_26[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_6 (Multiply)          (None, 10, 10, 480)  0           ['activation_6[0][0]',           \n",
            "                                                                  'swish_19[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_27 (Conv2D)             (None, 10, 10, 80)   38400       ['multiply_6[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_20 (BatchN  (None, 10, 10, 80)  320         ['conv2d_27[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_2 (DropConnect)   (None, 10, 10, 80)   0           ['batch_normalization_20[0][0]'] \n",
            "                                                                                                  \n",
            " add_2 (Add)                    (None, 10, 10, 80)   0           ['drop_connect_2[0][0]',         \n",
            "                                                                  'batch_normalization_17[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_28 (Conv2D)             (None, 10, 10, 480)  38400       ['add_2[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_21 (BatchN  (None, 10, 10, 480)  1920       ['conv2d_28[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_21 (Swish)               (None, 10, 10, 480)  0           ['batch_normalization_21[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_7 (DepthwiseC  (None, 10, 10, 480)  4320       ['swish_21[0][0]']               \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_22 (BatchN  (None, 10, 10, 480)  1920       ['depthwise_conv2d_7[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_22 (Swish)               (None, 10, 10, 480)  0           ['batch_normalization_22[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_7 (Lambda)              (None, 1, 1, 480)    0           ['swish_22[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_29 (Conv2D)             (None, 1, 1, 20)     9620        ['lambda_7[0][0]']               \n",
            "                                                                                                  \n",
            " swish_23 (Swish)               (None, 1, 1, 20)     0           ['conv2d_29[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_30 (Conv2D)             (None, 1, 1, 480)    10080       ['swish_23[0][0]']               \n",
            "                                                                                                  \n",
            " activation_7 (Activation)      (None, 1, 1, 480)    0           ['conv2d_30[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_7 (Multiply)          (None, 10, 10, 480)  0           ['activation_7[0][0]',           \n",
            "                                                                  'swish_22[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_31 (Conv2D)             (None, 10, 10, 80)   38400       ['multiply_7[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_23 (BatchN  (None, 10, 10, 80)  320         ['conv2d_31[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_3 (DropConnect)   (None, 10, 10, 80)   0           ['batch_normalization_23[0][0]'] \n",
            "                                                                                                  \n",
            " add_3 (Add)                    (None, 10, 10, 80)   0           ['drop_connect_3[0][0]',         \n",
            "                                                                  'add_2[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_32 (Conv2D)             (None, 10, 10, 480)  38400       ['add_3[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_24 (BatchN  (None, 10, 10, 480)  1920       ['conv2d_32[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_24 (Swish)               (None, 10, 10, 480)  0           ['batch_normalization_24[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_8 (DepthwiseC  (None, 10, 10, 480)  12000      ['swish_24[0][0]']               \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_25 (BatchN  (None, 10, 10, 480)  1920       ['depthwise_conv2d_8[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_25 (Swish)               (None, 10, 10, 480)  0           ['batch_normalization_25[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_8 (Lambda)              (None, 1, 1, 480)    0           ['swish_25[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_33 (Conv2D)             (None, 1, 1, 20)     9620        ['lambda_8[0][0]']               \n",
            "                                                                                                  \n",
            " swish_26 (Swish)               (None, 1, 1, 20)     0           ['conv2d_33[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_34 (Conv2D)             (None, 1, 1, 480)    10080       ['swish_26[0][0]']               \n",
            "                                                                                                  \n",
            " activation_8 (Activation)      (None, 1, 1, 480)    0           ['conv2d_34[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_8 (Multiply)          (None, 10, 10, 480)  0           ['activation_8[0][0]',           \n",
            "                                                                  'swish_25[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_35 (Conv2D)             (None, 10, 10, 112)  53760       ['multiply_8[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_26 (BatchN  (None, 10, 10, 112)  448        ['conv2d_35[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_36 (Conv2D)             (None, 10, 10, 672)  75264       ['batch_normalization_26[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_27 (BatchN  (None, 10, 10, 672)  2688       ['conv2d_36[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_27 (Swish)               (None, 10, 10, 672)  0           ['batch_normalization_27[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_9 (DepthwiseC  (None, 10, 10, 672)  16800      ['swish_27[0][0]']               \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_28 (BatchN  (None, 10, 10, 672)  2688       ['depthwise_conv2d_9[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_28 (Swish)               (None, 10, 10, 672)  0           ['batch_normalization_28[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_9 (Lambda)              (None, 1, 1, 672)    0           ['swish_28[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_37 (Conv2D)             (None, 1, 1, 28)     18844       ['lambda_9[0][0]']               \n",
            "                                                                                                  \n",
            " swish_29 (Swish)               (None, 1, 1, 28)     0           ['conv2d_37[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_38 (Conv2D)             (None, 1, 1, 672)    19488       ['swish_29[0][0]']               \n",
            "                                                                                                  \n",
            " activation_9 (Activation)      (None, 1, 1, 672)    0           ['conv2d_38[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_9 (Multiply)          (None, 10, 10, 672)  0           ['activation_9[0][0]',           \n",
            "                                                                  'swish_28[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_39 (Conv2D)             (None, 10, 10, 112)  75264       ['multiply_9[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_29 (BatchN  (None, 10, 10, 112)  448        ['conv2d_39[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_4 (DropConnect)   (None, 10, 10, 112)  0           ['batch_normalization_29[0][0]'] \n",
            "                                                                                                  \n",
            " add_4 (Add)                    (None, 10, 10, 112)  0           ['drop_connect_4[0][0]',         \n",
            "                                                                  'batch_normalization_26[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_40 (Conv2D)             (None, 10, 10, 672)  75264       ['add_4[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_30 (BatchN  (None, 10, 10, 672)  2688       ['conv2d_40[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_30 (Swish)               (None, 10, 10, 672)  0           ['batch_normalization_30[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_10 (Depthwise  (None, 10, 10, 672)  16800      ['swish_30[0][0]']               \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_31 (BatchN  (None, 10, 10, 672)  2688       ['depthwise_conv2d_10[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_31 (Swish)               (None, 10, 10, 672)  0           ['batch_normalization_31[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_10 (Lambda)             (None, 1, 1, 672)    0           ['swish_31[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_41 (Conv2D)             (None, 1, 1, 28)     18844       ['lambda_10[0][0]']              \n",
            "                                                                                                  \n",
            " swish_32 (Swish)               (None, 1, 1, 28)     0           ['conv2d_41[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_42 (Conv2D)             (None, 1, 1, 672)    19488       ['swish_32[0][0]']               \n",
            "                                                                                                  \n",
            " activation_10 (Activation)     (None, 1, 1, 672)    0           ['conv2d_42[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_10 (Multiply)         (None, 10, 10, 672)  0           ['activation_10[0][0]',          \n",
            "                                                                  'swish_31[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_43 (Conv2D)             (None, 10, 10, 112)  75264       ['multiply_10[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_32 (BatchN  (None, 10, 10, 112)  448        ['conv2d_43[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_5 (DropConnect)   (None, 10, 10, 112)  0           ['batch_normalization_32[0][0]'] \n",
            "                                                                                                  \n",
            " add_5 (Add)                    (None, 10, 10, 112)  0           ['drop_connect_5[0][0]',         \n",
            "                                                                  'add_4[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_44 (Conv2D)             (None, 10, 10, 672)  75264       ['add_5[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_33 (BatchN  (None, 10, 10, 672)  2688       ['conv2d_44[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_33 (Swish)               (None, 10, 10, 672)  0           ['batch_normalization_33[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_11 (Depthwise  (None, 5, 5, 672)   16800       ['swish_33[0][0]']               \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_34 (BatchN  (None, 5, 5, 672)   2688        ['depthwise_conv2d_11[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_34 (Swish)               (None, 5, 5, 672)    0           ['batch_normalization_34[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_11 (Lambda)             (None, 1, 1, 672)    0           ['swish_34[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_45 (Conv2D)             (None, 1, 1, 28)     18844       ['lambda_11[0][0]']              \n",
            "                                                                                                  \n",
            " swish_35 (Swish)               (None, 1, 1, 28)     0           ['conv2d_45[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_46 (Conv2D)             (None, 1, 1, 672)    19488       ['swish_35[0][0]']               \n",
            "                                                                                                  \n",
            " activation_11 (Activation)     (None, 1, 1, 672)    0           ['conv2d_46[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_11 (Multiply)         (None, 5, 5, 672)    0           ['activation_11[0][0]',          \n",
            "                                                                  'swish_34[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_47 (Conv2D)             (None, 5, 5, 192)    129024      ['multiply_11[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_35 (BatchN  (None, 5, 5, 192)   768         ['conv2d_47[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_48 (Conv2D)             (None, 5, 5, 1152)   221184      ['batch_normalization_35[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_36 (BatchN  (None, 5, 5, 1152)  4608        ['conv2d_48[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_36 (Swish)               (None, 5, 5, 1152)   0           ['batch_normalization_36[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_12 (Depthwise  (None, 5, 5, 1152)  28800       ['swish_36[0][0]']               \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_37 (BatchN  (None, 5, 5, 1152)  4608        ['depthwise_conv2d_12[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_37 (Swish)               (None, 5, 5, 1152)   0           ['batch_normalization_37[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_12 (Lambda)             (None, 1, 1, 1152)   0           ['swish_37[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_49 (Conv2D)             (None, 1, 1, 48)     55344       ['lambda_12[0][0]']              \n",
            "                                                                                                  \n",
            " swish_38 (Swish)               (None, 1, 1, 48)     0           ['conv2d_49[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_50 (Conv2D)             (None, 1, 1, 1152)   56448       ['swish_38[0][0]']               \n",
            "                                                                                                  \n",
            " activation_12 (Activation)     (None, 1, 1, 1152)   0           ['conv2d_50[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_12 (Multiply)         (None, 5, 5, 1152)   0           ['activation_12[0][0]',          \n",
            "                                                                  'swish_37[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_51 (Conv2D)             (None, 5, 5, 192)    221184      ['multiply_12[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_38 (BatchN  (None, 5, 5, 192)   768         ['conv2d_51[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_6 (DropConnect)   (None, 5, 5, 192)    0           ['batch_normalization_38[0][0]'] \n",
            "                                                                                                  \n",
            " add_6 (Add)                    (None, 5, 5, 192)    0           ['drop_connect_6[0][0]',         \n",
            "                                                                  'batch_normalization_35[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_52 (Conv2D)             (None, 5, 5, 1152)   221184      ['add_6[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_39 (BatchN  (None, 5, 5, 1152)  4608        ['conv2d_52[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_39 (Swish)               (None, 5, 5, 1152)   0           ['batch_normalization_39[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_13 (Depthwise  (None, 5, 5, 1152)  28800       ['swish_39[0][0]']               \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_40 (BatchN  (None, 5, 5, 1152)  4608        ['depthwise_conv2d_13[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_40 (Swish)               (None, 5, 5, 1152)   0           ['batch_normalization_40[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_13 (Lambda)             (None, 1, 1, 1152)   0           ['swish_40[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_53 (Conv2D)             (None, 1, 1, 48)     55344       ['lambda_13[0][0]']              \n",
            "                                                                                                  \n",
            " swish_41 (Swish)               (None, 1, 1, 48)     0           ['conv2d_53[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_54 (Conv2D)             (None, 1, 1, 1152)   56448       ['swish_41[0][0]']               \n",
            "                                                                                                  \n",
            " activation_13 (Activation)     (None, 1, 1, 1152)   0           ['conv2d_54[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_13 (Multiply)         (None, 5, 5, 1152)   0           ['activation_13[0][0]',          \n",
            "                                                                  'swish_40[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_55 (Conv2D)             (None, 5, 5, 192)    221184      ['multiply_13[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_41 (BatchN  (None, 5, 5, 192)   768         ['conv2d_55[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_7 (DropConnect)   (None, 5, 5, 192)    0           ['batch_normalization_41[0][0]'] \n",
            "                                                                                                  \n",
            " add_7 (Add)                    (None, 5, 5, 192)    0           ['drop_connect_7[0][0]',         \n",
            "                                                                  'add_6[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_56 (Conv2D)             (None, 5, 5, 1152)   221184      ['add_7[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_42 (BatchN  (None, 5, 5, 1152)  4608        ['conv2d_56[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_42 (Swish)               (None, 5, 5, 1152)   0           ['batch_normalization_42[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_14 (Depthwise  (None, 5, 5, 1152)  28800       ['swish_42[0][0]']               \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_43 (BatchN  (None, 5, 5, 1152)  4608        ['depthwise_conv2d_14[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_43 (Swish)               (None, 5, 5, 1152)   0           ['batch_normalization_43[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_14 (Lambda)             (None, 1, 1, 1152)   0           ['swish_43[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_57 (Conv2D)             (None, 1, 1, 48)     55344       ['lambda_14[0][0]']              \n",
            "                                                                                                  \n",
            " swish_44 (Swish)               (None, 1, 1, 48)     0           ['conv2d_57[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_58 (Conv2D)             (None, 1, 1, 1152)   56448       ['swish_44[0][0]']               \n",
            "                                                                                                  \n",
            " activation_14 (Activation)     (None, 1, 1, 1152)   0           ['conv2d_58[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_14 (Multiply)         (None, 5, 5, 1152)   0           ['activation_14[0][0]',          \n",
            "                                                                  'swish_43[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_59 (Conv2D)             (None, 5, 5, 192)    221184      ['multiply_14[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_44 (BatchN  (None, 5, 5, 192)   768         ['conv2d_59[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_8 (DropConnect)   (None, 5, 5, 192)    0           ['batch_normalization_44[0][0]'] \n",
            "                                                                                                  \n",
            " add_8 (Add)                    (None, 5, 5, 192)    0           ['drop_connect_8[0][0]',         \n",
            "                                                                  'add_7[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_60 (Conv2D)             (None, 5, 5, 1152)   221184      ['add_8[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_45 (BatchN  (None, 5, 5, 1152)  4608        ['conv2d_60[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_45 (Swish)               (None, 5, 5, 1152)   0           ['batch_normalization_45[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_15 (Depthwise  (None, 5, 5, 1152)  10368       ['swish_45[0][0]']               \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_46 (BatchN  (None, 5, 5, 1152)  4608        ['depthwise_conv2d_15[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_46 (Swish)               (None, 5, 5, 1152)   0           ['batch_normalization_46[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_15 (Lambda)             (None, 1, 1, 1152)   0           ['swish_46[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_61 (Conv2D)             (None, 1, 1, 48)     55344       ['lambda_15[0][0]']              \n",
            "                                                                                                  \n",
            " swish_47 (Swish)               (None, 1, 1, 48)     0           ['conv2d_61[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_62 (Conv2D)             (None, 1, 1, 1152)   56448       ['swish_47[0][0]']               \n",
            "                                                                                                  \n",
            " activation_15 (Activation)     (None, 1, 1, 1152)   0           ['conv2d_62[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_15 (Multiply)         (None, 5, 5, 1152)   0           ['activation_15[0][0]',          \n",
            "                                                                  'swish_46[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_63 (Conv2D)             (None, 5, 5, 320)    368640      ['multiply_15[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_47 (BatchN  (None, 5, 5, 320)   1280        ['conv2d_63[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_64 (Conv2D)             (None, 5, 5, 1280)   409600      ['batch_normalization_47[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_48 (BatchN  (None, 5, 5, 1280)  5120        ['conv2d_64[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_48 (Swish)               (None, 5, 5, 1280)   0           ['batch_normalization_48[0][0]'] \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 4,049,564\n",
            "Trainable params: 0\n",
            "Non-trainable params: 4,049,564\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#สร้างโฟลเดอร์ Train Valodation และ Test"
      ],
      "metadata": {
        "id": "J36J9EAE7qSB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv (r'/content/drive/MyDrive/cut_panoramic/Data/New_Data_Male125.csv')\n",
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "skoKhKJDngAZ",
        "outputId": "4a6ce669-898f-40c9-9dce-9b56ca641608"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      Fig_Age  Fig_Person_Sex  Age(year) Class  Class_Re       Filename  \\\n",
              "0           1               1          7  Y07M         0       VV03.jpg   \n",
              "1           2               1          7  Y07M         0  Flip_VV03.jpg   \n",
              "2           3               2          7  Y07M         0       VV04.jpg   \n",
              "3           4               2          7  Y07M         0  Flip_VV04.jpg   \n",
              "4           5               3          7  Y07M         0       VV05.jpg   \n",
              "...       ...             ...        ...   ...       ...            ...   \n",
              "2370      121              77         25  Y25M        18  Flip_J463.jpg   \n",
              "2371      122              78         25  Y25M        18       J464.jpg   \n",
              "2372      123              78         25  Y25M        18  Flip_J464.jpg   \n",
              "2373      124              79         25  Y25M        18       J465.jpg   \n",
              "2374      125              79         25  Y25M        18  Flip_J465.jpg   \n",
              "\n",
              "                                          Path_filename     Sex Floder  \n",
              "0     /content/drive/My Drive/TVT_Male125/train/Y07M...  เพศชาย   Both  \n",
              "1     /content/drive/My Drive/TVT_Male125/train/Y07M...  เพศชาย   Both  \n",
              "2     /content/drive/My Drive/TVT_Male125/train/Y07M...  เพศชาย   Both  \n",
              "3     /content/drive/My Drive/TVT_Male125/train/Y07M...  เพศชาย   Both  \n",
              "4     /content/drive/My Drive/TVT_Male125/train/Y07M...  เพศชาย   Both  \n",
              "...                                                 ...     ...    ...  \n",
              "2370  /content/drive/My Drive/TVT_Male125/test/Y25M/...  เพศชาย   Both  \n",
              "2371  /content/drive/My Drive/TVT_Male125/test/Y25M/...  เพศชาย   Both  \n",
              "2372  /content/drive/My Drive/TVT_Male125/test/Y25M/...  เพศชาย   Both  \n",
              "2373  /content/drive/My Drive/TVT_Male125/test/Y25M/...  เพศชาย   Both  \n",
              "2374  /content/drive/My Drive/TVT_Male125/test/Y25M/...  เพศชาย   Both  \n",
              "\n",
              "[2375 rows x 9 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d8a435c7-0b35-4074-8085-a90460f785b5\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Fig_Age</th>\n",
              "      <th>Fig_Person_Sex</th>\n",
              "      <th>Age(year)</th>\n",
              "      <th>Class</th>\n",
              "      <th>Class_Re</th>\n",
              "      <th>Filename</th>\n",
              "      <th>Path_filename</th>\n",
              "      <th>Sex</th>\n",
              "      <th>Floder</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>Y07M</td>\n",
              "      <td>0</td>\n",
              "      <td>VV03.jpg</td>\n",
              "      <td>/content/drive/My Drive/TVT_Male125/train/Y07M...</td>\n",
              "      <td>เพศชาย</td>\n",
              "      <td>Both</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>Y07M</td>\n",
              "      <td>0</td>\n",
              "      <td>Flip_VV03.jpg</td>\n",
              "      <td>/content/drive/My Drive/TVT_Male125/train/Y07M...</td>\n",
              "      <td>เพศชาย</td>\n",
              "      <td>Both</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>7</td>\n",
              "      <td>Y07M</td>\n",
              "      <td>0</td>\n",
              "      <td>VV04.jpg</td>\n",
              "      <td>/content/drive/My Drive/TVT_Male125/train/Y07M...</td>\n",
              "      <td>เพศชาย</td>\n",
              "      <td>Both</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>7</td>\n",
              "      <td>Y07M</td>\n",
              "      <td>0</td>\n",
              "      <td>Flip_VV04.jpg</td>\n",
              "      <td>/content/drive/My Drive/TVT_Male125/train/Y07M...</td>\n",
              "      <td>เพศชาย</td>\n",
              "      <td>Both</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>7</td>\n",
              "      <td>Y07M</td>\n",
              "      <td>0</td>\n",
              "      <td>VV05.jpg</td>\n",
              "      <td>/content/drive/My Drive/TVT_Male125/train/Y07M...</td>\n",
              "      <td>เพศชาย</td>\n",
              "      <td>Both</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2370</th>\n",
              "      <td>121</td>\n",
              "      <td>77</td>\n",
              "      <td>25</td>\n",
              "      <td>Y25M</td>\n",
              "      <td>18</td>\n",
              "      <td>Flip_J463.jpg</td>\n",
              "      <td>/content/drive/My Drive/TVT_Male125/test/Y25M/...</td>\n",
              "      <td>เพศชาย</td>\n",
              "      <td>Both</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2371</th>\n",
              "      <td>122</td>\n",
              "      <td>78</td>\n",
              "      <td>25</td>\n",
              "      <td>Y25M</td>\n",
              "      <td>18</td>\n",
              "      <td>J464.jpg</td>\n",
              "      <td>/content/drive/My Drive/TVT_Male125/test/Y25M/...</td>\n",
              "      <td>เพศชาย</td>\n",
              "      <td>Both</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2372</th>\n",
              "      <td>123</td>\n",
              "      <td>78</td>\n",
              "      <td>25</td>\n",
              "      <td>Y25M</td>\n",
              "      <td>18</td>\n",
              "      <td>Flip_J464.jpg</td>\n",
              "      <td>/content/drive/My Drive/TVT_Male125/test/Y25M/...</td>\n",
              "      <td>เพศชาย</td>\n",
              "      <td>Both</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2373</th>\n",
              "      <td>124</td>\n",
              "      <td>79</td>\n",
              "      <td>25</td>\n",
              "      <td>Y25M</td>\n",
              "      <td>18</td>\n",
              "      <td>J465.jpg</td>\n",
              "      <td>/content/drive/My Drive/TVT_Male125/test/Y25M/...</td>\n",
              "      <td>เพศชาย</td>\n",
              "      <td>Both</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2374</th>\n",
              "      <td>125</td>\n",
              "      <td>79</td>\n",
              "      <td>25</td>\n",
              "      <td>Y25M</td>\n",
              "      <td>18</td>\n",
              "      <td>Flip_J465.jpg</td>\n",
              "      <td>/content/drive/My Drive/TVT_Male125/test/Y25M/...</td>\n",
              "      <td>เพศชาย</td>\n",
              "      <td>Both</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2375 rows × 9 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d8a435c7-0b35-4074-8085-a90460f785b5')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d8a435c7-0b35-4074-8085-a90460f785b5 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d8a435c7-0b35-4074-8085-a90460f785b5');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train = df[df['Fig_Age'].between(1,75)]\n",
        "val = df[df['Fig_Age'].between(76,100)]"
      ],
      "metadata": {
        "id": "Z1zBw01Gl8Ac"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DATA_PATH = \"/content/drive/My Drive/TVT_Male125\"\n",
        "os.chdir(DATA_PATH)\n",
        "train_dir = os.path.join(DATA_PATH, 'train')\n",
        "print(train_dir)\n",
        "validation_dir = os.path.join(DATA_PATH, 'validation')\n",
        "print(validation_dir)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QL0g-8iOnMC4",
        "outputId": "3d6126db-1943-40fb-e8e8-2c76802598ea"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/My Drive/TVT_Male125/train\n",
            "/content/drive/My Drive/TVT_Male125/validation\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "#Train"
      ],
      "metadata": {
        "id": "bWEnlTSwazL5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train ด้วย ImageDataGenerator ของ Keras ซึ่งจะเพิ่มข้อมูลเสริมระหว่างการฝึกเพื่อลดโอกาสเกิด overfitting\n",
        "#overfitting เกิดจากข้อมูลที่ซับซ้อนกันเกินไป\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "train_datagen = ImageDataGenerator(\n",
        "      rescale=1./255, #โมเดลส่วนใหญ่ต้องใช้ RGB ในช่วง 0–1\n",
        "      rotation_range=40,\n",
        "      width_shift_range=0.2,\n",
        "      height_shift_range=0.2,\n",
        "      shear_range=0.2,\n",
        "      zoom_range=0.2,\n",
        "      horizontal_flip=True,\n",
        "      fill_mode='nearest')\n",
        "\n",
        "# Note that the validation data should not be augmented!\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)"
      ],
      "metadata": {
        "id": "xGPrsn9no_pa"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_generator = train_datagen.flow_from_dataframe(\n",
        "        dataframe = train,\n",
        "        directory = train_dir,\n",
        "        x_col = 'Path_filename',\n",
        "        y_col = 'Class_Re',\n",
        "        class_mode = 'other',\n",
        "        target_size=(height, width),\n",
        "        batch_size=batch_size)\n",
        "\n",
        "validation_generator = test_datagen.flow_from_dataframe(\n",
        "        dataframe = val,\n",
        "        directory = validation_dir,\n",
        "        x_col = 'Path_filename',\n",
        "        y_col = 'Class_Re',\n",
        "        class_mode = 'other',\n",
        "        target_size=(height, width),\n",
        "        batch_size=batch_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8nVlmAszntK_",
        "outputId": "f2835df0-05fb-429b-cfe9-fb31e058c0ad"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1425 validated image filenames.\n",
            "Found 475 validated image filenames.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='mse',\n",
        "          optimizer=Adam(learning_rate=2e-5),\n",
        "          metrics=['mae'])\n",
        "history = model.fit_generator(\n",
        "      train_generator,\n",
        "      steps_per_epoch= NUM_TRAIN //batch_size,\n",
        "      epochs=epochs,\n",
        "      validation_data=validation_generator,\n",
        "      validation_steps= NUM_TEST //batch_size,\n",
        "      verbose=1,\n",
        "      use_multiprocessing=True,\n",
        "      workers=4)"
      ],
      "metadata": {
        "id": "N6qUmmF856ZE",
        "outputId": "b3d6d5da-11eb-46fe-8148-39abd4daaa37",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-20-133268624aea>:4: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  history = model.fit_generator(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "44/44 [==============================] - 102s 2s/step - loss: 109.5402 - mae: 8.9138 - val_loss: 107.5442 - val_mae: 8.8163\n",
            "Epoch 2/500\n",
            "44/44 [==============================] - 25s 548ms/step - loss: 105.6099 - mae: 8.7069 - val_loss: 102.3106 - val_mae: 8.5219\n",
            "Epoch 3/500\n",
            "44/44 [==============================] - 25s 534ms/step - loss: 103.9755 - mae: 8.6469 - val_loss: 103.0888 - val_mae: 8.5818\n",
            "Epoch 4/500\n",
            "44/44 [==============================] - 24s 533ms/step - loss: 103.1385 - mae: 8.5918 - val_loss: 100.9933 - val_mae: 8.5046\n",
            "Epoch 5/500\n",
            "44/44 [==============================] - 25s 525ms/step - loss: 102.7155 - mae: 8.5727 - val_loss: 101.5843 - val_mae: 8.5101\n",
            "Epoch 6/500\n",
            "44/44 [==============================] - 25s 547ms/step - loss: 102.3218 - mae: 8.5471 - val_loss: 102.5367 - val_mae: 8.5576\n",
            "Epoch 7/500\n",
            "44/44 [==============================] - 25s 531ms/step - loss: 102.2469 - mae: 8.5585 - val_loss: 102.2407 - val_mae: 8.5567\n",
            "Epoch 8/500\n",
            "44/44 [==============================] - 25s 540ms/step - loss: 103.0512 - mae: 8.5927 - val_loss: 103.8955 - val_mae: 8.6612\n",
            "Epoch 9/500\n",
            "44/44 [==============================] - 26s 557ms/step - loss: 103.0510 - mae: 8.6046 - val_loss: 101.5286 - val_mae: 8.4959\n",
            "Epoch 10/500\n",
            "44/44 [==============================] - 27s 587ms/step - loss: 101.6075 - mae: 8.5165 - val_loss: 104.1210 - val_mae: 8.6700\n",
            "Epoch 11/500\n",
            "44/44 [==============================] - 26s 589ms/step - loss: 102.4593 - mae: 8.5684 - val_loss: 102.2793 - val_mae: 8.5363\n",
            "Epoch 12/500\n",
            "44/44 [==============================] - 25s 546ms/step - loss: 101.5433 - mae: 8.5177 - val_loss: 99.6297 - val_mae: 8.4179\n",
            "Epoch 13/500\n",
            "44/44 [==============================] - 26s 567ms/step - loss: 101.6475 - mae: 8.5235 - val_loss: 99.6785 - val_mae: 8.4157\n",
            "Epoch 14/500\n",
            "44/44 [==============================] - 26s 573ms/step - loss: 102.0344 - mae: 8.5448 - val_loss: 102.3287 - val_mae: 8.5492\n",
            "Epoch 15/500\n",
            "44/44 [==============================] - 25s 556ms/step - loss: 101.9702 - mae: 8.5374 - val_loss: 103.4942 - val_mae: 8.6246\n",
            "Epoch 16/500\n",
            "44/44 [==============================] - 25s 550ms/step - loss: 102.0854 - mae: 8.5392 - val_loss: 101.6028 - val_mae: 8.5278\n",
            "Epoch 17/500\n",
            "44/44 [==============================] - 25s 541ms/step - loss: 101.4622 - mae: 8.5225 - val_loss: 101.7370 - val_mae: 8.5387\n",
            "Epoch 18/500\n",
            "44/44 [==============================] - 25s 538ms/step - loss: 102.0399 - mae: 8.5378 - val_loss: 101.6169 - val_mae: 8.4935\n",
            "Epoch 19/500\n",
            "44/44 [==============================] - 25s 541ms/step - loss: 101.9646 - mae: 8.5424 - val_loss: 101.5342 - val_mae: 8.4886\n",
            "Epoch 20/500\n",
            "44/44 [==============================] - 25s 551ms/step - loss: 101.5373 - mae: 8.5190 - val_loss: 100.1664 - val_mae: 8.4365\n",
            "Epoch 21/500\n",
            "44/44 [==============================] - 25s 547ms/step - loss: 101.0790 - mae: 8.4922 - val_loss: 100.8123 - val_mae: 8.4789\n",
            "Epoch 22/500\n",
            "44/44 [==============================] - 24s 534ms/step - loss: 101.1502 - mae: 8.4941 - val_loss: 101.1490 - val_mae: 8.4633\n",
            "Epoch 23/500\n",
            "44/44 [==============================] - 25s 539ms/step - loss: 100.9687 - mae: 8.4931 - val_loss: 101.0561 - val_mae: 8.4809\n",
            "Epoch 24/500\n",
            "44/44 [==============================] - 25s 555ms/step - loss: 100.7836 - mae: 8.4668 - val_loss: 99.2232 - val_mae: 8.3851\n",
            "Epoch 25/500\n",
            "44/44 [==============================] - 25s 551ms/step - loss: 101.4609 - mae: 8.5125 - val_loss: 100.4372 - val_mae: 8.4700\n",
            "Epoch 26/500\n",
            "44/44 [==============================] - 25s 551ms/step - loss: 100.8753 - mae: 8.4790 - val_loss: 102.1327 - val_mae: 8.5280\n",
            "Epoch 27/500\n",
            "44/44 [==============================] - 25s 538ms/step - loss: 100.4883 - mae: 8.4590 - val_loss: 102.8162 - val_mae: 8.5818\n",
            "Epoch 28/500\n",
            "44/44 [==============================] - 27s 567ms/step - loss: 101.6659 - mae: 8.5165 - val_loss: 100.5818 - val_mae: 8.4644\n",
            "Epoch 29/500\n",
            "44/44 [==============================] - 25s 552ms/step - loss: 101.4041 - mae: 8.5034 - val_loss: 101.3547 - val_mae: 8.4916\n",
            "Epoch 30/500\n",
            "44/44 [==============================] - 25s 539ms/step - loss: 101.3304 - mae: 8.4956 - val_loss: 101.0090 - val_mae: 8.5098\n",
            "Epoch 31/500\n",
            "44/44 [==============================] - 25s 539ms/step - loss: 100.7613 - mae: 8.4773 - val_loss: 100.1840 - val_mae: 8.4184\n",
            "Epoch 32/500\n",
            "44/44 [==============================] - 25s 547ms/step - loss: 100.6759 - mae: 8.4661 - val_loss: 102.1966 - val_mae: 8.5260\n",
            "Epoch 33/500\n",
            "44/44 [==============================] - 25s 542ms/step - loss: 100.7813 - mae: 8.4740 - val_loss: 100.1663 - val_mae: 8.4197\n",
            "Epoch 34/500\n",
            "44/44 [==============================] - 24s 526ms/step - loss: 100.5729 - mae: 8.4579 - val_loss: 101.4109 - val_mae: 8.5463\n",
            "Epoch 35/500\n",
            "44/44 [==============================] - 25s 550ms/step - loss: 101.0477 - mae: 8.4929 - val_loss: 99.0822 - val_mae: 8.3887\n",
            "Epoch 36/500\n",
            "44/44 [==============================] - 27s 570ms/step - loss: 100.4673 - mae: 8.4565 - val_loss: 100.3433 - val_mae: 8.4547\n",
            "Epoch 37/500\n",
            "44/44 [==============================] - 26s 575ms/step - loss: 100.0316 - mae: 8.4377 - val_loss: 100.0041 - val_mae: 8.4217\n",
            "Epoch 38/500\n",
            "44/44 [==============================] - 27s 590ms/step - loss: 100.9936 - mae: 8.4833 - val_loss: 101.1472 - val_mae: 8.5055\n",
            "Epoch 39/500\n",
            "44/44 [==============================] - 25s 553ms/step - loss: 101.2570 - mae: 8.5098 - val_loss: 100.4880 - val_mae: 8.4492\n",
            "Epoch 40/500\n",
            "44/44 [==============================] - 25s 536ms/step - loss: 100.6175 - mae: 8.4653 - val_loss: 100.5146 - val_mae: 8.4891\n",
            "Epoch 41/500\n",
            "44/44 [==============================] - 25s 544ms/step - loss: 101.2553 - mae: 8.4975 - val_loss: 98.1431 - val_mae: 8.3521\n",
            "Epoch 42/500\n",
            "44/44 [==============================] - 24s 532ms/step - loss: 100.8547 - mae: 8.4786 - val_loss: 100.4801 - val_mae: 8.4602\n",
            "Epoch 43/500\n",
            "44/44 [==============================] - 25s 549ms/step - loss: 100.6311 - mae: 8.4590 - val_loss: 100.2493 - val_mae: 8.4519\n",
            "Epoch 44/500\n",
            "44/44 [==============================] - 24s 528ms/step - loss: 100.2198 - mae: 8.4431 - val_loss: 100.4074 - val_mae: 8.4609\n",
            "Epoch 45/500\n",
            "44/44 [==============================] - 25s 532ms/step - loss: 100.5776 - mae: 8.4504 - val_loss: 100.0755 - val_mae: 8.4481\n",
            "Epoch 46/500\n",
            "44/44 [==============================] - 24s 528ms/step - loss: 100.5615 - mae: 8.4647 - val_loss: 102.4334 - val_mae: 8.5563\n",
            "Epoch 47/500\n",
            "44/44 [==============================] - 25s 523ms/step - loss: 101.0076 - mae: 8.4818 - val_loss: 99.3842 - val_mae: 8.3774\n",
            "Epoch 48/500\n",
            "44/44 [==============================] - 25s 556ms/step - loss: 101.0103 - mae: 8.4870 - val_loss: 98.4040 - val_mae: 8.3512\n",
            "Epoch 49/500\n",
            "44/44 [==============================] - 26s 543ms/step - loss: 100.2820 - mae: 8.4421 - val_loss: 98.6992 - val_mae: 8.3692\n",
            "Epoch 50/500\n",
            "44/44 [==============================] - 27s 577ms/step - loss: 100.1648 - mae: 8.4396 - val_loss: 100.5327 - val_mae: 8.4471\n",
            "Epoch 51/500\n",
            "44/44 [==============================] - 26s 577ms/step - loss: 100.0947 - mae: 8.4302 - val_loss: 99.2132 - val_mae: 8.3982\n",
            "Epoch 52/500\n",
            "44/44 [==============================] - 25s 559ms/step - loss: 100.2298 - mae: 8.4434 - val_loss: 100.7850 - val_mae: 8.4791\n",
            "Epoch 53/500\n",
            "44/44 [==============================] - 27s 596ms/step - loss: 100.0719 - mae: 8.4354 - val_loss: 99.5591 - val_mae: 8.4123\n",
            "Epoch 54/500\n",
            "44/44 [==============================] - 26s 576ms/step - loss: 100.3218 - mae: 8.4414 - val_loss: 100.9667 - val_mae: 8.4692\n",
            "Epoch 55/500\n",
            "44/44 [==============================] - 25s 555ms/step - loss: 100.5530 - mae: 8.4607 - val_loss: 99.9528 - val_mae: 8.4336\n",
            "Epoch 56/500\n",
            "44/44 [==============================] - 24s 532ms/step - loss: 100.4383 - mae: 8.4547 - val_loss: 100.1956 - val_mae: 8.4833\n",
            "Epoch 57/500\n",
            "44/44 [==============================] - 24s 531ms/step - loss: 100.0027 - mae: 8.4325 - val_loss: 98.3944 - val_mae: 8.3651\n",
            "Epoch 58/500\n",
            "44/44 [==============================] - 22s 447ms/step - loss: 100.0792 - mae: 8.4441 - val_loss: 100.6726 - val_mae: 8.4583\n",
            "Epoch 59/500\n",
            "44/44 [==============================] - 25s 545ms/step - loss: 99.7619 - mae: 8.4108 - val_loss: 100.9824 - val_mae: 8.5053\n",
            "Epoch 60/500\n",
            "44/44 [==============================] - 24s 531ms/step - loss: 99.6869 - mae: 8.4232 - val_loss: 98.6213 - val_mae: 8.3525\n",
            "Epoch 61/500\n",
            "44/44 [==============================] - 24s 531ms/step - loss: 99.4533 - mae: 8.4116 - val_loss: 100.8329 - val_mae: 8.4535\n",
            "Epoch 62/500\n",
            "44/44 [==============================] - 26s 581ms/step - loss: 99.9583 - mae: 8.4288 - val_loss: 99.5854 - val_mae: 8.4112\n",
            "Epoch 63/500\n",
            "44/44 [==============================] - 26s 567ms/step - loss: 99.3369 - mae: 8.4024 - val_loss: 99.3605 - val_mae: 8.3873\n",
            "Epoch 64/500\n",
            "44/44 [==============================] - 26s 571ms/step - loss: 99.7753 - mae: 8.4255 - val_loss: 99.0102 - val_mae: 8.3863\n",
            "Epoch 65/500\n",
            "44/44 [==============================] - 25s 543ms/step - loss: 100.4555 - mae: 8.4604 - val_loss: 100.3154 - val_mae: 8.4801\n",
            "Epoch 66/500\n",
            "44/44 [==============================] - 24s 535ms/step - loss: 99.6509 - mae: 8.4118 - val_loss: 101.4874 - val_mae: 8.5075\n",
            "Epoch 67/500\n",
            "44/44 [==============================] - 25s 546ms/step - loss: 100.4505 - mae: 8.4554 - val_loss: 101.7532 - val_mae: 8.5199\n",
            "Epoch 68/500\n",
            "44/44 [==============================] - 25s 549ms/step - loss: 99.6985 - mae: 8.4149 - val_loss: 99.2799 - val_mae: 8.3822\n",
            "Epoch 69/500\n",
            "44/44 [==============================] - 25s 568ms/step - loss: 99.9074 - mae: 8.4234 - val_loss: 100.1252 - val_mae: 8.4431\n",
            "Epoch 70/500\n",
            "44/44 [==============================] - 25s 538ms/step - loss: 100.0110 - mae: 8.4218 - val_loss: 100.9989 - val_mae: 8.4788\n",
            "Epoch 71/500\n",
            "44/44 [==============================] - 26s 546ms/step - loss: 99.3800 - mae: 8.3999 - val_loss: 98.0861 - val_mae: 8.3290\n",
            "Epoch 72/500\n",
            "44/44 [==============================] - 25s 549ms/step - loss: 100.1384 - mae: 8.4387 - val_loss: 102.1425 - val_mae: 8.5611\n",
            "Epoch 73/500\n",
            "44/44 [==============================] - 25s 542ms/step - loss: 100.2733 - mae: 8.4527 - val_loss: 99.1327 - val_mae: 8.3772\n",
            "Epoch 74/500\n",
            "44/44 [==============================] - 24s 534ms/step - loss: 99.5434 - mae: 8.4124 - val_loss: 101.5229 - val_mae: 8.5044\n",
            "Epoch 75/500\n",
            "44/44 [==============================] - 25s 559ms/step - loss: 99.7598 - mae: 8.4204 - val_loss: 99.7656 - val_mae: 8.4128\n",
            "Epoch 76/500\n",
            "44/44 [==============================] - 25s 539ms/step - loss: 99.3550 - mae: 8.3922 - val_loss: 99.9259 - val_mae: 8.4440\n",
            "Epoch 77/500\n",
            "44/44 [==============================] - 25s 553ms/step - loss: 99.5134 - mae: 8.4021 - val_loss: 101.2678 - val_mae: 8.4826\n",
            "Epoch 78/500\n",
            "44/44 [==============================] - 25s 560ms/step - loss: 99.1530 - mae: 8.3833 - val_loss: 97.7117 - val_mae: 8.2934\n",
            "Epoch 79/500\n",
            "44/44 [==============================] - 25s 552ms/step - loss: 99.5306 - mae: 8.4014 - val_loss: 99.4385 - val_mae: 8.4140\n",
            "Epoch 80/500\n",
            "44/44 [==============================] - 25s 540ms/step - loss: 98.6266 - mae: 8.3701 - val_loss: 99.4114 - val_mae: 8.4191\n",
            "Epoch 81/500\n",
            "44/44 [==============================] - 27s 582ms/step - loss: 99.0953 - mae: 8.3827 - val_loss: 98.6976 - val_mae: 8.3505\n",
            "Epoch 82/500\n",
            "44/44 [==============================] - 26s 583ms/step - loss: 99.5072 - mae: 8.4079 - val_loss: 97.9585 - val_mae: 8.3222\n",
            "Epoch 83/500\n",
            "44/44 [==============================] - 26s 573ms/step - loss: 100.0702 - mae: 8.4429 - val_loss: 100.7526 - val_mae: 8.4686\n",
            "Epoch 84/500\n",
            "44/44 [==============================] - 26s 578ms/step - loss: 99.1666 - mae: 8.3916 - val_loss: 100.7460 - val_mae: 8.4782\n",
            "Epoch 85/500\n",
            "44/44 [==============================] - 24s 530ms/step - loss: 99.1139 - mae: 8.3761 - val_loss: 98.8892 - val_mae: 8.3866\n",
            "Epoch 86/500\n",
            "44/44 [==============================] - 25s 558ms/step - loss: 99.4951 - mae: 8.3951 - val_loss: 98.9904 - val_mae: 8.3814\n",
            "Epoch 87/500\n",
            "44/44 [==============================] - 26s 564ms/step - loss: 100.0031 - mae: 8.4371 - val_loss: 99.3254 - val_mae: 8.4081\n",
            "Epoch 88/500\n",
            "44/44 [==============================] - 24s 532ms/step - loss: 99.8763 - mae: 8.4271 - val_loss: 98.2671 - val_mae: 8.3239\n",
            "Epoch 89/500\n",
            "44/44 [==============================] - 25s 536ms/step - loss: 99.6743 - mae: 8.4198 - val_loss: 98.3357 - val_mae: 8.3461\n",
            "Epoch 90/500\n",
            "44/44 [==============================] - 21s 446ms/step - loss: 98.9038 - mae: 8.3761 - val_loss: 100.0470 - val_mae: 8.4174\n",
            "Epoch 91/500\n",
            "44/44 [==============================] - 25s 547ms/step - loss: 99.1000 - mae: 8.3844 - val_loss: 97.8522 - val_mae: 8.3155\n",
            "Epoch 92/500\n",
            "44/44 [==============================] - 25s 540ms/step - loss: 99.5027 - mae: 8.3984 - val_loss: 99.3179 - val_mae: 8.4083\n",
            "Epoch 93/500\n",
            "44/44 [==============================] - 26s 557ms/step - loss: 99.2018 - mae: 8.3894 - val_loss: 99.5041 - val_mae: 8.4157\n",
            "Epoch 94/500\n",
            "44/44 [==============================] - 25s 546ms/step - loss: 99.6673 - mae: 8.4181 - val_loss: 101.7148 - val_mae: 8.5154\n",
            "Epoch 95/500\n",
            "44/44 [==============================] - 25s 539ms/step - loss: 98.6216 - mae: 8.3602 - val_loss: 99.7253 - val_mae: 8.4220\n",
            "Epoch 96/500\n",
            "44/44 [==============================] - 20s 429ms/step - loss: 98.3698 - mae: 8.3507 - val_loss: 99.8275 - val_mae: 8.3926\n",
            "Epoch 97/500\n",
            "44/44 [==============================] - 23s 431ms/step - loss: 99.6157 - mae: 8.3990 - val_loss: 98.2687 - val_mae: 8.3469\n",
            "Epoch 98/500\n",
            "44/44 [==============================] - 26s 538ms/step - loss: 99.3673 - mae: 8.3973 - val_loss: 100.2280 - val_mae: 8.4498\n",
            "Epoch 99/500\n",
            "44/44 [==============================] - 24s 532ms/step - loss: 98.9364 - mae: 8.3640 - val_loss: 97.8301 - val_mae: 8.3348\n",
            "Epoch 100/500\n",
            "44/44 [==============================] - 26s 540ms/step - loss: 99.4008 - mae: 8.4049 - val_loss: 100.0909 - val_mae: 8.4248\n",
            "Epoch 101/500\n",
            "44/44 [==============================] - 26s 547ms/step - loss: 98.3580 - mae: 8.3418 - val_loss: 100.9037 - val_mae: 8.4996\n",
            "Epoch 102/500\n",
            "44/44 [==============================] - 27s 576ms/step - loss: 99.1174 - mae: 8.3865 - val_loss: 102.1231 - val_mae: 8.5511\n",
            "Epoch 103/500\n",
            "44/44 [==============================] - 26s 569ms/step - loss: 99.1697 - mae: 8.3771 - val_loss: 99.3980 - val_mae: 8.4237\n",
            "Epoch 104/500\n",
            "44/44 [==============================] - 27s 589ms/step - loss: 98.6504 - mae: 8.3533 - val_loss: 98.8065 - val_mae: 8.3757\n",
            "Epoch 105/500\n",
            "44/44 [==============================] - 26s 572ms/step - loss: 98.6181 - mae: 8.3612 - val_loss: 98.3127 - val_mae: 8.3509\n",
            "Epoch 106/500\n",
            "44/44 [==============================] - 22s 476ms/step - loss: 99.4588 - mae: 8.4030 - val_loss: 97.9357 - val_mae: 8.3101\n",
            "Epoch 107/500\n",
            "44/44 [==============================] - 27s 587ms/step - loss: 98.3623 - mae: 8.3357 - val_loss: 100.2045 - val_mae: 8.4540\n",
            "Epoch 108/500\n",
            "44/44 [==============================] - 25s 545ms/step - loss: 98.5409 - mae: 8.3518 - val_loss: 99.3707 - val_mae: 8.4282\n",
            "Epoch 109/500\n",
            "44/44 [==============================] - 21s 460ms/step - loss: 99.1530 - mae: 8.3853 - val_loss: 100.3028 - val_mae: 8.4630\n",
            "Epoch 110/500\n",
            "44/44 [==============================] - 26s 533ms/step - loss: 98.2250 - mae: 8.3314 - val_loss: 97.3312 - val_mae: 8.2873\n",
            "Epoch 111/500\n",
            "44/44 [==============================] - 26s 558ms/step - loss: 99.0139 - mae: 8.3805 - val_loss: 98.4110 - val_mae: 8.3269\n",
            "Epoch 112/500\n",
            "44/44 [==============================] - 25s 535ms/step - loss: 98.8210 - mae: 8.3745 - val_loss: 99.7395 - val_mae: 8.4241\n",
            "Epoch 113/500\n",
            "44/44 [==============================] - 24s 533ms/step - loss: 98.4189 - mae: 8.3317 - val_loss: 99.3773 - val_mae: 8.4044\n",
            "Epoch 114/500\n",
            "44/44 [==============================] - 26s 553ms/step - loss: 98.6309 - mae: 8.3600 - val_loss: 96.6060 - val_mae: 8.2419\n",
            "Epoch 115/500\n",
            "44/44 [==============================] - 27s 597ms/step - loss: 98.4173 - mae: 8.3459 - val_loss: 96.8165 - val_mae: 8.2617\n",
            "Epoch 116/500\n",
            "44/44 [==============================] - 26s 567ms/step - loss: 98.2566 - mae: 8.3439 - val_loss: 98.6842 - val_mae: 8.3943\n",
            "Epoch 117/500\n",
            "44/44 [==============================] - 24s 536ms/step - loss: 98.3619 - mae: 8.3427 - val_loss: 97.8064 - val_mae: 8.3121\n",
            "Epoch 118/500\n",
            "44/44 [==============================] - 24s 535ms/step - loss: 99.2218 - mae: 8.3878 - val_loss: 100.4496 - val_mae: 8.4447\n",
            "Epoch 119/500\n",
            "44/44 [==============================] - 24s 536ms/step - loss: 97.6840 - mae: 8.3069 - val_loss: 97.7369 - val_mae: 8.3101\n",
            "Epoch 120/500\n",
            "44/44 [==============================] - 25s 540ms/step - loss: 98.6056 - mae: 8.3618 - val_loss: 98.2726 - val_mae: 8.3387\n",
            "Epoch 121/500\n",
            "44/44 [==============================] - 26s 563ms/step - loss: 98.5846 - mae: 8.3612 - val_loss: 96.1441 - val_mae: 8.2133\n",
            "Epoch 122/500\n",
            "44/44 [==============================] - 25s 547ms/step - loss: 98.2859 - mae: 8.3360 - val_loss: 98.8968 - val_mae: 8.3725\n",
            "Epoch 123/500\n",
            "44/44 [==============================] - 25s 543ms/step - loss: 98.1836 - mae: 8.3430 - val_loss: 99.5952 - val_mae: 8.4056\n",
            "Epoch 124/500\n",
            "44/44 [==============================] - 26s 561ms/step - loss: 97.9156 - mae: 8.3210 - val_loss: 96.6637 - val_mae: 8.2689\n",
            "Epoch 125/500\n",
            "44/44 [==============================] - 25s 544ms/step - loss: 98.5971 - mae: 8.3597 - val_loss: 98.4109 - val_mae: 8.3376\n",
            "Epoch 126/500\n",
            "44/44 [==============================] - 25s 556ms/step - loss: 98.1329 - mae: 8.3409 - val_loss: 97.3515 - val_mae: 8.2892\n",
            "Epoch 127/500\n",
            "44/44 [==============================] - 25s 551ms/step - loss: 98.2148 - mae: 8.3451 - val_loss: 98.4202 - val_mae: 8.3289\n",
            "Epoch 128/500\n",
            "44/44 [==============================] - 25s 550ms/step - loss: 98.3992 - mae: 8.3424 - val_loss: 99.5530 - val_mae: 8.4156\n",
            "Epoch 129/500\n",
            "44/44 [==============================] - 26s 569ms/step - loss: 98.1659 - mae: 8.3344 - val_loss: 99.2661 - val_mae: 8.3794\n",
            "Epoch 130/500\n",
            "44/44 [==============================] - 25s 543ms/step - loss: 97.4532 - mae: 8.3020 - val_loss: 98.9001 - val_mae: 8.3678\n",
            "Epoch 131/500\n",
            "44/44 [==============================] - 25s 558ms/step - loss: 98.2099 - mae: 8.3327 - val_loss: 98.9590 - val_mae: 8.4030\n",
            "Epoch 132/500\n",
            "44/44 [==============================] - 25s 547ms/step - loss: 98.0184 - mae: 8.3330 - val_loss: 98.0961 - val_mae: 8.3133\n",
            "Epoch 133/500\n",
            "44/44 [==============================] - 25s 556ms/step - loss: 97.9869 - mae: 8.3210 - val_loss: 96.8269 - val_mae: 8.2705\n",
            "Epoch 134/500\n",
            "44/44 [==============================] - 25s 540ms/step - loss: 98.1617 - mae: 8.3270 - val_loss: 95.2540 - val_mae: 8.1964\n",
            "Epoch 135/500\n",
            "44/44 [==============================] - 25s 547ms/step - loss: 98.0072 - mae: 8.3219 - val_loss: 97.1475 - val_mae: 8.3041\n",
            "Epoch 136/500\n",
            "44/44 [==============================] - 25s 547ms/step - loss: 98.2321 - mae: 8.3210 - val_loss: 96.4280 - val_mae: 8.2490\n",
            "Epoch 137/500\n",
            "44/44 [==============================] - 25s 544ms/step - loss: 97.2752 - mae: 8.2875 - val_loss: 97.8717 - val_mae: 8.3345\n",
            "Epoch 138/500\n",
            "44/44 [==============================] - 25s 549ms/step - loss: 98.0302 - mae: 8.3201 - val_loss: 96.7284 - val_mae: 8.2403\n",
            "Epoch 139/500\n",
            "44/44 [==============================] - 25s 555ms/step - loss: 97.3635 - mae: 8.2880 - val_loss: 97.4954 - val_mae: 8.2947\n",
            "Epoch 140/500\n",
            "44/44 [==============================] - 26s 557ms/step - loss: 97.8007 - mae: 8.3198 - val_loss: 99.4774 - val_mae: 8.4247\n",
            "Epoch 141/500\n",
            "44/44 [==============================] - 26s 542ms/step - loss: 97.9813 - mae: 8.3093 - val_loss: 96.3379 - val_mae: 8.2291\n",
            "Epoch 142/500\n",
            "44/44 [==============================] - 28s 608ms/step - loss: 97.9955 - mae: 8.3224 - val_loss: 99.6297 - val_mae: 8.3881\n",
            "Epoch 143/500\n",
            "44/44 [==============================] - 27s 586ms/step - loss: 97.6414 - mae: 8.3055 - val_loss: 97.2131 - val_mae: 8.2950\n",
            "Epoch 144/500\n",
            "44/44 [==============================] - 27s 598ms/step - loss: 98.0855 - mae: 8.3257 - val_loss: 99.0593 - val_mae: 8.3827\n",
            "Epoch 145/500\n",
            "44/44 [==============================] - 24s 532ms/step - loss: 97.8066 - mae: 8.3248 - val_loss: 98.0036 - val_mae: 8.3164\n",
            "Epoch 146/500\n",
            "44/44 [==============================] - 25s 551ms/step - loss: 97.8785 - mae: 8.3226 - val_loss: 97.8706 - val_mae: 8.3084\n",
            "Epoch 147/500\n",
            "44/44 [==============================] - 25s 546ms/step - loss: 97.9999 - mae: 8.3268 - val_loss: 98.1455 - val_mae: 8.3471\n",
            "Epoch 148/500\n",
            "44/44 [==============================] - 25s 538ms/step - loss: 97.4870 - mae: 8.2980 - val_loss: 99.6506 - val_mae: 8.4333\n",
            "Epoch 149/500\n",
            "44/44 [==============================] - 26s 568ms/step - loss: 97.1021 - mae: 8.2691 - val_loss: 97.6300 - val_mae: 8.3016\n",
            "Epoch 150/500\n",
            "44/44 [==============================] - 25s 547ms/step - loss: 97.2136 - mae: 8.2741 - val_loss: 98.0760 - val_mae: 8.3220\n",
            "Epoch 151/500\n",
            "44/44 [==============================] - 25s 543ms/step - loss: 97.7141 - mae: 8.3181 - val_loss: 96.3646 - val_mae: 8.2337\n",
            "Epoch 152/500\n",
            "44/44 [==============================] - 25s 540ms/step - loss: 97.4723 - mae: 8.2889 - val_loss: 96.1322 - val_mae: 8.2265\n",
            "Epoch 153/500\n",
            "44/44 [==============================] - 27s 578ms/step - loss: 97.5506 - mae: 8.2932 - val_loss: 99.3552 - val_mae: 8.4161\n",
            "Epoch 154/500\n",
            "44/44 [==============================] - 26s 541ms/step - loss: 97.2113 - mae: 8.2768 - val_loss: 98.5708 - val_mae: 8.3699\n",
            "Epoch 155/500\n",
            "44/44 [==============================] - 27s 593ms/step - loss: 97.9293 - mae: 8.3158 - val_loss: 96.1546 - val_mae: 8.2097\n",
            "Epoch 156/500\n",
            "44/44 [==============================] - 28s 616ms/step - loss: 97.6128 - mae: 8.3057 - val_loss: 95.7149 - val_mae: 8.2100\n",
            "Epoch 157/500\n",
            "44/44 [==============================] - 20s 437ms/step - loss: 97.5193 - mae: 8.2916 - val_loss: 98.6902 - val_mae: 8.3669\n",
            "Epoch 158/500\n",
            "44/44 [==============================] - 27s 532ms/step - loss: 97.7149 - mae: 8.3075 - val_loss: 97.6183 - val_mae: 8.2993\n",
            "Epoch 159/500\n",
            "44/44 [==============================] - 26s 549ms/step - loss: 97.9214 - mae: 8.3181 - val_loss: 98.3680 - val_mae: 8.3691\n",
            "Epoch 160/500\n",
            "44/44 [==============================] - 27s 592ms/step - loss: 96.9697 - mae: 8.2685 - val_loss: 97.4978 - val_mae: 8.3086\n",
            "Epoch 161/500\n",
            "44/44 [==============================] - 26s 581ms/step - loss: 98.1512 - mae: 8.3327 - val_loss: 96.4708 - val_mae: 8.2160\n",
            "Epoch 162/500\n",
            "44/44 [==============================] - 26s 574ms/step - loss: 97.0526 - mae: 8.2812 - val_loss: 96.0541 - val_mae: 8.2145\n",
            "Epoch 163/500\n",
            "44/44 [==============================] - 24s 536ms/step - loss: 97.1839 - mae: 8.2750 - val_loss: 95.8800 - val_mae: 8.2102\n",
            "Epoch 164/500\n",
            "44/44 [==============================] - 26s 576ms/step - loss: 97.5581 - mae: 8.3082 - val_loss: 98.1738 - val_mae: 8.3158\n",
            "Epoch 165/500\n",
            "44/44 [==============================] - 25s 553ms/step - loss: 97.2620 - mae: 8.2817 - val_loss: 95.9813 - val_mae: 8.2151\n",
            "Epoch 166/500\n",
            "44/44 [==============================] - 24s 534ms/step - loss: 96.6500 - mae: 8.2421 - val_loss: 97.5054 - val_mae: 8.2619\n",
            "Epoch 167/500\n",
            "44/44 [==============================] - 25s 555ms/step - loss: 97.4067 - mae: 8.2923 - val_loss: 95.5228 - val_mae: 8.2017\n",
            "Epoch 168/500\n",
            "44/44 [==============================] - 26s 535ms/step - loss: 96.8447 - mae: 8.2569 - val_loss: 96.4586 - val_mae: 8.2359\n",
            "Epoch 169/500\n",
            "44/44 [==============================] - 26s 572ms/step - loss: 96.7089 - mae: 8.2575 - val_loss: 97.4628 - val_mae: 8.2848\n",
            "Epoch 170/500\n",
            "44/44 [==============================] - 26s 561ms/step - loss: 97.1398 - mae: 8.2727 - val_loss: 97.4237 - val_mae: 8.3243\n",
            "Epoch 171/500\n",
            "44/44 [==============================] - 21s 466ms/step - loss: 96.9020 - mae: 8.2609 - val_loss: 96.2164 - val_mae: 8.2498\n",
            "Epoch 172/500\n",
            "44/44 [==============================] - 22s 427ms/step - loss: 96.9906 - mae: 8.2723 - val_loss: 97.1334 - val_mae: 8.2877\n",
            "Epoch 173/500\n",
            "44/44 [==============================] - 25s 548ms/step - loss: 96.8335 - mae: 8.2523 - val_loss: 98.1679 - val_mae: 8.3166\n",
            "Epoch 174/500\n",
            "44/44 [==============================] - 25s 548ms/step - loss: 96.7333 - mae: 8.2519 - val_loss: 99.0800 - val_mae: 8.4564\n",
            "Epoch 175/500\n",
            "44/44 [==============================] - 25s 550ms/step - loss: 96.7700 - mae: 8.2635 - val_loss: 96.5462 - val_mae: 8.2554\n",
            "Epoch 176/500\n",
            "44/44 [==============================] - 24s 531ms/step - loss: 96.9987 - mae: 8.2684 - val_loss: 96.9166 - val_mae: 8.2516\n",
            "Epoch 177/500\n",
            "44/44 [==============================] - 25s 549ms/step - loss: 96.8426 - mae: 8.2647 - val_loss: 95.8480 - val_mae: 8.2226\n",
            "Epoch 178/500\n",
            "44/44 [==============================] - 26s 563ms/step - loss: 96.7454 - mae: 8.2677 - val_loss: 95.3523 - val_mae: 8.1659\n",
            "Epoch 179/500\n",
            "44/44 [==============================] - 26s 558ms/step - loss: 95.7605 - mae: 8.2035 - val_loss: 97.5602 - val_mae: 8.3050\n",
            "Epoch 180/500\n",
            "44/44 [==============================] - 25s 560ms/step - loss: 96.0639 - mae: 8.2213 - val_loss: 97.3028 - val_mae: 8.2618\n",
            "Epoch 181/500\n",
            "44/44 [==============================] - 25s 549ms/step - loss: 97.3501 - mae: 8.2918 - val_loss: 95.7943 - val_mae: 8.1948\n",
            "Epoch 182/500\n",
            "44/44 [==============================] - 26s 550ms/step - loss: 96.5234 - mae: 8.2328 - val_loss: 96.6271 - val_mae: 8.2430\n",
            "Epoch 183/500\n",
            "44/44 [==============================] - 26s 550ms/step - loss: 96.6012 - mae: 8.2389 - val_loss: 95.0285 - val_mae: 8.1774\n",
            "Epoch 184/500\n",
            "44/44 [==============================] - 27s 605ms/step - loss: 96.5456 - mae: 8.2560 - val_loss: 96.2313 - val_mae: 8.2206\n",
            "Epoch 185/500\n",
            "44/44 [==============================] - 27s 584ms/step - loss: 96.5950 - mae: 8.2482 - val_loss: 96.8521 - val_mae: 8.2569\n",
            "Epoch 186/500\n",
            "44/44 [==============================] - 26s 582ms/step - loss: 96.0862 - mae: 8.2206 - val_loss: 96.0817 - val_mae: 8.2004\n",
            "Epoch 187/500\n",
            "44/44 [==============================] - 26s 573ms/step - loss: 96.4521 - mae: 8.2449 - val_loss: 97.2233 - val_mae: 8.2738\n",
            "Epoch 188/500\n",
            "44/44 [==============================] - 27s 592ms/step - loss: 96.4174 - mae: 8.2407 - val_loss: 98.0874 - val_mae: 8.3615\n",
            "Epoch 189/500\n",
            "44/44 [==============================] - 25s 555ms/step - loss: 96.6878 - mae: 8.2604 - val_loss: 94.8053 - val_mae: 8.1549\n",
            "Epoch 190/500\n",
            "44/44 [==============================] - 26s 564ms/step - loss: 96.1528 - mae: 8.2339 - val_loss: 97.8640 - val_mae: 8.3338\n",
            "Epoch 191/500\n",
            "44/44 [==============================] - 25s 556ms/step - loss: 96.2883 - mae: 8.2298 - val_loss: 97.4949 - val_mae: 8.3042\n",
            "Epoch 192/500\n",
            "44/44 [==============================] - 25s 555ms/step - loss: 96.7057 - mae: 8.2564 - val_loss: 95.9194 - val_mae: 8.2197\n",
            "Epoch 193/500\n",
            "44/44 [==============================] - 25s 541ms/step - loss: 96.4864 - mae: 8.2406 - val_loss: 96.1612 - val_mae: 8.2179\n",
            "Epoch 194/500\n",
            "44/44 [==============================] - 25s 546ms/step - loss: 96.3132 - mae: 8.2369 - val_loss: 97.7198 - val_mae: 8.3085\n",
            "Epoch 195/500\n",
            "44/44 [==============================] - 25s 551ms/step - loss: 95.6324 - mae: 8.1944 - val_loss: 95.2483 - val_mae: 8.1730\n",
            "Epoch 196/500\n",
            "44/44 [==============================] - 24s 534ms/step - loss: 96.0586 - mae: 8.2169 - val_loss: 97.4986 - val_mae: 8.2713\n",
            "Epoch 197/500\n",
            "44/44 [==============================] - 25s 528ms/step - loss: 96.5523 - mae: 8.2495 - val_loss: 98.0719 - val_mae: 8.3357\n",
            "Epoch 198/500\n",
            "44/44 [==============================] - 25s 545ms/step - loss: 96.4945 - mae: 8.2457 - val_loss: 97.0788 - val_mae: 8.2700\n",
            "Epoch 199/500\n",
            "44/44 [==============================] - 20s 446ms/step - loss: 96.9462 - mae: 8.2639 - val_loss: 95.7644 - val_mae: 8.2120\n",
            "Epoch 200/500\n",
            "44/44 [==============================] - 28s 582ms/step - loss: 95.6494 - mae: 8.2029 - val_loss: 96.8872 - val_mae: 8.2557\n",
            "Epoch 201/500\n",
            "44/44 [==============================] - 26s 562ms/step - loss: 95.9212 - mae: 8.2057 - val_loss: 95.1278 - val_mae: 8.1631\n",
            "Epoch 202/500\n",
            "44/44 [==============================] - 25s 546ms/step - loss: 96.0071 - mae: 8.2172 - val_loss: 96.6956 - val_mae: 8.2380\n",
            "Epoch 203/500\n",
            "44/44 [==============================] - 25s 538ms/step - loss: 95.5259 - mae: 8.1884 - val_loss: 95.5330 - val_mae: 8.1857\n",
            "Epoch 204/500\n",
            "44/44 [==============================] - 21s 459ms/step - loss: 96.0589 - mae: 8.2213 - val_loss: 95.3466 - val_mae: 8.1713\n",
            "Epoch 205/500\n",
            "44/44 [==============================] - 27s 538ms/step - loss: 96.2705 - mae: 8.2334 - val_loss: 95.3985 - val_mae: 8.1664\n",
            "Epoch 206/500\n",
            "44/44 [==============================] - 26s 541ms/step - loss: 95.5325 - mae: 8.1911 - val_loss: 96.2154 - val_mae: 8.2485\n",
            "Epoch 207/500\n",
            "44/44 [==============================] - 25s 540ms/step - loss: 96.0364 - mae: 8.2263 - val_loss: 97.1896 - val_mae: 8.2570\n",
            "Epoch 208/500\n",
            "44/44 [==============================] - 27s 569ms/step - loss: 96.1408 - mae: 8.2346 - val_loss: 95.1826 - val_mae: 8.1890\n",
            "Epoch 209/500\n",
            "44/44 [==============================] - 26s 533ms/step - loss: 96.2075 - mae: 8.2265 - val_loss: 96.2166 - val_mae: 8.2415\n",
            "Epoch 210/500\n",
            "44/44 [==============================] - 25s 538ms/step - loss: 95.7565 - mae: 8.2114 - val_loss: 97.1561 - val_mae: 8.2868\n",
            "Epoch 211/500\n",
            "44/44 [==============================] - 25s 552ms/step - loss: 95.3163 - mae: 8.1781 - val_loss: 95.9409 - val_mae: 8.2312\n",
            "Epoch 212/500\n",
            "44/44 [==============================] - 26s 566ms/step - loss: 95.1706 - mae: 8.1683 - val_loss: 95.8268 - val_mae: 8.2140\n",
            "Epoch 213/500\n",
            "44/44 [==============================] - 25s 537ms/step - loss: 95.7491 - mae: 8.1958 - val_loss: 96.4408 - val_mae: 8.2343\n",
            "Epoch 214/500\n",
            "44/44 [==============================] - 27s 592ms/step - loss: 96.2066 - mae: 8.2339 - val_loss: 95.4218 - val_mae: 8.1703\n",
            "Epoch 215/500\n",
            "44/44 [==============================] - 25s 556ms/step - loss: 95.6360 - mae: 8.2003 - val_loss: 92.0574 - val_mae: 8.0009\n",
            "Epoch 216/500\n",
            "44/44 [==============================] - 25s 548ms/step - loss: 95.2738 - mae: 8.1732 - val_loss: 96.9646 - val_mae: 8.2721\n",
            "Epoch 217/500\n",
            "44/44 [==============================] - 25s 553ms/step - loss: 95.9929 - mae: 8.2127 - val_loss: 97.1076 - val_mae: 8.2795\n",
            "Epoch 218/500\n",
            "44/44 [==============================] - 26s 563ms/step - loss: 95.1372 - mae: 8.1751 - val_loss: 94.2453 - val_mae: 8.1257\n",
            "Epoch 219/500\n",
            "44/44 [==============================] - 25s 552ms/step - loss: 94.9410 - mae: 8.1578 - val_loss: 96.3876 - val_mae: 8.2223\n",
            "Epoch 220/500\n",
            "44/44 [==============================] - 22s 476ms/step - loss: 95.3708 - mae: 8.1898 - val_loss: 94.8964 - val_mae: 8.1427\n",
            "Epoch 221/500\n",
            "44/44 [==============================] - 25s 553ms/step - loss: 95.6880 - mae: 8.1985 - val_loss: 95.1728 - val_mae: 8.1795\n",
            "Epoch 222/500\n",
            "44/44 [==============================] - 25s 540ms/step - loss: 94.8231 - mae: 8.1474 - val_loss: 94.8228 - val_mae: 8.1582\n",
            "Epoch 223/500\n",
            "44/44 [==============================] - 25s 557ms/step - loss: 94.9104 - mae: 8.1523 - val_loss: 95.5468 - val_mae: 8.1626\n",
            "Epoch 224/500\n",
            "44/44 [==============================] - 26s 541ms/step - loss: 95.8345 - mae: 8.2143 - val_loss: 96.1367 - val_mae: 8.2236\n",
            "Epoch 225/500\n",
            "44/44 [==============================] - 26s 561ms/step - loss: 95.0639 - mae: 8.1638 - val_loss: 95.1132 - val_mae: 8.1420\n",
            "Epoch 226/500\n",
            "44/44 [==============================] - 25s 545ms/step - loss: 96.1261 - mae: 8.2268 - val_loss: 94.0119 - val_mae: 8.1003\n",
            "Epoch 227/500\n",
            "44/44 [==============================] - 25s 544ms/step - loss: 96.1195 - mae: 8.2226 - val_loss: 96.3521 - val_mae: 8.2278\n",
            "Epoch 228/500\n",
            "44/44 [==============================] - 20s 432ms/step - loss: 95.6040 - mae: 8.2000 - val_loss: 94.1985 - val_mae: 8.1217\n",
            "Epoch 229/500\n",
            "44/44 [==============================] - 28s 559ms/step - loss: 95.9794 - mae: 8.2135 - val_loss: 96.8439 - val_mae: 8.2742\n",
            "Epoch 230/500\n",
            "44/44 [==============================] - 27s 585ms/step - loss: 95.7306 - mae: 8.2038 - val_loss: 94.9176 - val_mae: 8.1521\n",
            "Epoch 231/500\n",
            "44/44 [==============================] - 27s 582ms/step - loss: 95.6256 - mae: 8.1981 - val_loss: 93.7153 - val_mae: 8.0954\n",
            "Epoch 232/500\n",
            "44/44 [==============================] - 28s 608ms/step - loss: 95.2573 - mae: 8.1678 - val_loss: 95.3525 - val_mae: 8.1646\n",
            "Epoch 233/500\n",
            "44/44 [==============================] - 20s 429ms/step - loss: 95.8967 - mae: 8.2101 - val_loss: 93.7201 - val_mae: 8.0757\n",
            "Epoch 234/500\n",
            "44/44 [==============================] - 27s 544ms/step - loss: 95.1002 - mae: 8.1592 - val_loss: 96.0651 - val_mae: 8.2444\n",
            "Epoch 235/500\n",
            "44/44 [==============================] - 26s 548ms/step - loss: 94.8450 - mae: 8.1472 - val_loss: 94.9580 - val_mae: 8.1463\n",
            "Epoch 236/500\n",
            "44/44 [==============================] - 26s 557ms/step - loss: 95.1798 - mae: 8.1658 - val_loss: 96.9137 - val_mae: 8.2795\n",
            "Epoch 237/500\n",
            "44/44 [==============================] - 28s 621ms/step - loss: 95.8210 - mae: 8.2139 - val_loss: 95.5914 - val_mae: 8.1839\n",
            "Epoch 238/500\n",
            "44/44 [==============================] - 27s 604ms/step - loss: 95.0447 - mae: 8.1581 - val_loss: 94.2063 - val_mae: 8.1109\n",
            "Epoch 239/500\n",
            "44/44 [==============================] - 26s 579ms/step - loss: 95.5275 - mae: 8.1887 - val_loss: 93.5421 - val_mae: 8.0915\n",
            "Epoch 240/500\n",
            "44/44 [==============================] - 26s 563ms/step - loss: 94.8653 - mae: 8.1481 - val_loss: 94.4391 - val_mae: 8.1388\n",
            "Epoch 241/500\n",
            "44/44 [==============================] - 26s 576ms/step - loss: 95.0512 - mae: 8.1761 - val_loss: 94.9312 - val_mae: 8.1868\n",
            "Epoch 242/500\n",
            "44/44 [==============================] - 28s 621ms/step - loss: 94.8475 - mae: 8.1499 - val_loss: 95.3817 - val_mae: 8.1984\n",
            "Epoch 243/500\n",
            "44/44 [==============================] - 25s 549ms/step - loss: 94.7995 - mae: 8.1520 - val_loss: 93.9626 - val_mae: 8.0982\n",
            "Epoch 244/500\n",
            "44/44 [==============================] - 26s 561ms/step - loss: 95.4705 - mae: 8.1870 - val_loss: 93.6702 - val_mae: 8.0631\n",
            "Epoch 245/500\n",
            "44/44 [==============================] - 25s 558ms/step - loss: 95.1172 - mae: 8.1612 - val_loss: 92.6040 - val_mae: 8.0306\n",
            "Epoch 246/500\n",
            "44/44 [==============================] - 26s 568ms/step - loss: 94.9076 - mae: 8.1590 - val_loss: 94.2117 - val_mae: 8.1074\n",
            "Epoch 247/500\n",
            "44/44 [==============================] - 25s 550ms/step - loss: 95.0867 - mae: 8.1565 - val_loss: 93.9204 - val_mae: 8.1058\n",
            "Epoch 248/500\n",
            "44/44 [==============================] - 25s 544ms/step - loss: 94.5042 - mae: 8.1335 - val_loss: 95.4366 - val_mae: 8.1692\n",
            "Epoch 249/500\n",
            "44/44 [==============================] - 25s 550ms/step - loss: 94.6017 - mae: 8.1377 - val_loss: 94.0498 - val_mae: 8.1090\n",
            "Epoch 250/500\n",
            "44/44 [==============================] - 25s 541ms/step - loss: 94.8652 - mae: 8.1614 - val_loss: 94.7170 - val_mae: 8.1433\n",
            "Epoch 251/500\n",
            "44/44 [==============================] - 27s 566ms/step - loss: 94.9247 - mae: 8.1625 - val_loss: 95.0000 - val_mae: 8.1775\n",
            "Epoch 252/500\n",
            "44/44 [==============================] - 25s 550ms/step - loss: 94.9843 - mae: 8.1545 - val_loss: 94.2659 - val_mae: 8.1047\n",
            "Epoch 253/500\n",
            "44/44 [==============================] - 26s 546ms/step - loss: 94.2588 - mae: 8.1170 - val_loss: 95.1853 - val_mae: 8.1993\n",
            "Epoch 254/500\n",
            "44/44 [==============================] - 25s 549ms/step - loss: 94.2701 - mae: 8.1212 - val_loss: 94.5320 - val_mae: 8.1307\n",
            "Epoch 255/500\n",
            "44/44 [==============================] - 26s 559ms/step - loss: 94.9170 - mae: 8.1636 - val_loss: 93.8906 - val_mae: 8.1024\n",
            "Epoch 256/500\n",
            "44/44 [==============================] - 25s 548ms/step - loss: 93.8405 - mae: 8.0930 - val_loss: 94.9868 - val_mae: 8.1544\n",
            "Epoch 257/500\n",
            "44/44 [==============================] - 24s 527ms/step - loss: 93.9717 - mae: 8.0950 - val_loss: 92.6649 - val_mae: 8.0436\n",
            "Epoch 258/500\n",
            "44/44 [==============================] - 25s 550ms/step - loss: 94.2557 - mae: 8.1180 - val_loss: 94.5606 - val_mae: 8.1220\n",
            "Epoch 259/500\n",
            "44/44 [==============================] - 26s 549ms/step - loss: 94.4061 - mae: 8.1236 - val_loss: 94.4609 - val_mae: 8.1115\n",
            "Epoch 260/500\n",
            "44/44 [==============================] - 26s 551ms/step - loss: 93.7364 - mae: 8.0890 - val_loss: 93.4987 - val_mae: 8.0787\n",
            "Epoch 261/500\n",
            "44/44 [==============================] - 27s 576ms/step - loss: 94.3311 - mae: 8.1349 - val_loss: 95.9671 - val_mae: 8.1978\n",
            "Epoch 262/500\n",
            "44/44 [==============================] - 25s 554ms/step - loss: 94.2973 - mae: 8.1153 - val_loss: 93.0946 - val_mae: 8.0622\n",
            "Epoch 263/500\n",
            "44/44 [==============================] - 20s 439ms/step - loss: 94.3608 - mae: 8.1202 - val_loss: 94.0994 - val_mae: 8.0964\n",
            "Epoch 264/500\n",
            "44/44 [==============================] - 28s 585ms/step - loss: 94.0161 - mae: 8.1108 - val_loss: 91.8175 - val_mae: 7.9787\n",
            "Epoch 265/500\n",
            "44/44 [==============================] - 26s 578ms/step - loss: 93.9515 - mae: 8.1042 - val_loss: 94.3396 - val_mae: 8.1291\n",
            "Epoch 266/500\n",
            "44/44 [==============================] - 26s 571ms/step - loss: 94.7904 - mae: 8.1580 - val_loss: 94.6622 - val_mae: 8.1386\n",
            "Epoch 267/500\n",
            "44/44 [==============================] - 25s 549ms/step - loss: 94.3653 - mae: 8.1348 - val_loss: 94.3413 - val_mae: 8.1080\n",
            "Epoch 268/500\n",
            "44/44 [==============================] - 20s 444ms/step - loss: 93.9658 - mae: 8.1081 - val_loss: 94.7541 - val_mae: 8.1623\n",
            "Epoch 269/500\n",
            "44/44 [==============================] - 27s 577ms/step - loss: 94.2428 - mae: 8.1368 - val_loss: 95.1613 - val_mae: 8.1585\n",
            "Epoch 270/500\n",
            "44/44 [==============================] - 26s 573ms/step - loss: 93.7610 - mae: 8.0813 - val_loss: 94.3449 - val_mae: 8.1145\n",
            "Epoch 271/500\n",
            "44/44 [==============================] - 25s 537ms/step - loss: 94.4806 - mae: 8.1301 - val_loss: 94.9645 - val_mae: 8.1487\n",
            "Epoch 272/500\n",
            "44/44 [==============================] - 26s 546ms/step - loss: 94.4589 - mae: 8.1349 - val_loss: 95.1174 - val_mae: 8.1851\n",
            "Epoch 273/500\n",
            "44/44 [==============================] - 20s 435ms/step - loss: 94.3899 - mae: 8.1298 - val_loss: 95.3038 - val_mae: 8.1746\n",
            "Epoch 274/500\n",
            "44/44 [==============================] - 24s 504ms/step - loss: 93.8136 - mae: 8.0953 - val_loss: 93.5659 - val_mae: 8.0616\n",
            "Epoch 275/500\n",
            "44/44 [==============================] - 25s 534ms/step - loss: 94.2618 - mae: 8.1219 - val_loss: 94.6827 - val_mae: 8.1517\n",
            "Epoch 276/500\n",
            "44/44 [==============================] - 25s 553ms/step - loss: 93.8148 - mae: 8.0904 - val_loss: 94.1103 - val_mae: 8.1146\n",
            "Epoch 277/500\n",
            "44/44 [==============================] - 25s 541ms/step - loss: 94.0373 - mae: 8.1055 - val_loss: 92.6775 - val_mae: 8.0284\n",
            "Epoch 278/500\n",
            "44/44 [==============================] - 20s 440ms/step - loss: 94.2323 - mae: 8.1221 - val_loss: 94.4988 - val_mae: 8.1320\n",
            "Epoch 279/500\n",
            "44/44 [==============================] - 27s 569ms/step - loss: 94.1492 - mae: 8.1142 - val_loss: 94.4997 - val_mae: 8.1373\n",
            "Epoch 280/500\n",
            "44/44 [==============================] - 25s 557ms/step - loss: 93.3215 - mae: 8.0640 - val_loss: 94.5257 - val_mae: 8.1047\n",
            "Epoch 281/500\n",
            "44/44 [==============================] - 20s 429ms/step - loss: 93.0938 - mae: 8.0605 - val_loss: 93.7001 - val_mae: 8.0721\n",
            "Epoch 282/500\n",
            "44/44 [==============================] - 26s 552ms/step - loss: 93.1104 - mae: 8.0634 - val_loss: 94.3179 - val_mae: 8.1286\n",
            "Epoch 283/500\n",
            "44/44 [==============================] - 25s 552ms/step - loss: 93.6944 - mae: 8.0930 - val_loss: 94.6824 - val_mae: 8.1407\n",
            "Epoch 284/500\n",
            "44/44 [==============================] - 24s 530ms/step - loss: 93.3579 - mae: 8.0707 - val_loss: 93.8550 - val_mae: 8.0925\n",
            "Epoch 285/500\n",
            "44/44 [==============================] - 25s 534ms/step - loss: 93.3220 - mae: 8.0815 - val_loss: 93.3347 - val_mae: 8.0665\n",
            "Epoch 286/500\n",
            "44/44 [==============================] - 27s 594ms/step - loss: 93.2528 - mae: 8.0744 - val_loss: 91.1800 - val_mae: 7.9694\n",
            "Epoch 287/500\n",
            "44/44 [==============================] - 26s 575ms/step - loss: 93.3420 - mae: 8.0781 - val_loss: 95.0796 - val_mae: 8.1820\n",
            "Epoch 288/500\n",
            "44/44 [==============================] - 27s 593ms/step - loss: 93.4021 - mae: 8.0710 - val_loss: 94.6243 - val_mae: 8.1628\n",
            "Epoch 289/500\n",
            "44/44 [==============================] - 27s 602ms/step - loss: 93.8071 - mae: 8.0976 - val_loss: 92.7606 - val_mae: 8.0475\n",
            "Epoch 290/500\n",
            "44/44 [==============================] - 20s 432ms/step - loss: 93.7160 - mae: 8.0897 - val_loss: 92.5699 - val_mae: 8.0481\n",
            "Epoch 291/500\n",
            "44/44 [==============================] - 24s 456ms/step - loss: 92.9348 - mae: 8.0461 - val_loss: 93.6894 - val_mae: 8.0942\n",
            "Epoch 292/500\n",
            "44/44 [==============================] - 25s 530ms/step - loss: 93.4944 - mae: 8.0784 - val_loss: 94.2294 - val_mae: 8.1172\n",
            "Epoch 293/500\n",
            "44/44 [==============================] - 24s 531ms/step - loss: 93.9910 - mae: 8.1050 - val_loss: 92.4096 - val_mae: 8.0090\n",
            "Epoch 294/500\n",
            "44/44 [==============================] - 25s 554ms/step - loss: 93.7334 - mae: 8.0880 - val_loss: 92.8338 - val_mae: 8.0564\n",
            "Epoch 295/500\n",
            "44/44 [==============================] - 20s 430ms/step - loss: 93.5136 - mae: 8.0900 - val_loss: 93.7922 - val_mae: 8.1266\n",
            "Epoch 296/500\n",
            "44/44 [==============================] - 28s 550ms/step - loss: 93.7678 - mae: 8.1031 - val_loss: 94.1034 - val_mae: 8.1251\n",
            "Epoch 297/500\n",
            "44/44 [==============================] - 27s 562ms/step - loss: 93.2818 - mae: 8.0630 - val_loss: 94.6831 - val_mae: 8.1196\n",
            "Epoch 298/500\n",
            "44/44 [==============================] - 27s 559ms/step - loss: 93.1338 - mae: 8.0602 - val_loss: 93.2409 - val_mae: 8.0556\n",
            "Epoch 299/500\n",
            "44/44 [==============================] - 27s 584ms/step - loss: 92.7980 - mae: 8.0388 - val_loss: 92.4389 - val_mae: 8.0321\n",
            "Epoch 300/500\n",
            "44/44 [==============================] - 26s 575ms/step - loss: 93.3534 - mae: 8.0788 - val_loss: 93.3607 - val_mae: 8.0928\n",
            "Epoch 301/500\n",
            "44/44 [==============================] - 24s 531ms/step - loss: 93.4487 - mae: 8.0720 - val_loss: 92.9994 - val_mae: 8.0443\n",
            "Epoch 302/500\n",
            "44/44 [==============================] - 25s 548ms/step - loss: 92.7003 - mae: 8.0339 - val_loss: 93.9848 - val_mae: 8.1211\n",
            "Epoch 303/500\n",
            "44/44 [==============================] - 25s 542ms/step - loss: 93.2401 - mae: 8.0614 - val_loss: 92.6087 - val_mae: 8.0398\n",
            "Epoch 304/500\n",
            "44/44 [==============================] - 21s 464ms/step - loss: 93.6995 - mae: 8.0907 - val_loss: 92.8857 - val_mae: 8.0447\n",
            "Epoch 305/500\n",
            "44/44 [==============================] - 24s 537ms/step - loss: 93.1908 - mae: 8.0621 - val_loss: 92.8648 - val_mae: 8.0463\n",
            "Epoch 306/500\n",
            "44/44 [==============================] - 25s 554ms/step - loss: 93.8699 - mae: 8.1051 - val_loss: 95.2418 - val_mae: 8.2135\n",
            "Epoch 307/500\n",
            "44/44 [==============================] - 25s 551ms/step - loss: 93.1297 - mae: 8.0578 - val_loss: 92.2102 - val_mae: 7.9967\n",
            "Epoch 308/500\n",
            "44/44 [==============================] - 19s 415ms/step - loss: 92.5824 - mae: 8.0238 - val_loss: 92.2729 - val_mae: 8.0372\n",
            "Epoch 309/500\n",
            "44/44 [==============================] - 28s 551ms/step - loss: 93.3425 - mae: 8.0738 - val_loss: 94.1653 - val_mae: 8.1424\n",
            "Epoch 310/500\n",
            "44/44 [==============================] - 27s 597ms/step - loss: 92.8474 - mae: 8.0474 - val_loss: 91.8100 - val_mae: 7.9920\n",
            "Epoch 311/500\n",
            "44/44 [==============================] - 27s 593ms/step - loss: 92.4927 - mae: 8.0231 - val_loss: 93.7294 - val_mae: 8.1329\n",
            "Epoch 312/500\n",
            "44/44 [==============================] - 25s 541ms/step - loss: 92.6336 - mae: 8.0289 - val_loss: 93.6364 - val_mae: 8.0933\n",
            "Epoch 313/500\n",
            "44/44 [==============================] - 28s 604ms/step - loss: 92.2548 - mae: 8.0160 - val_loss: 91.7630 - val_mae: 7.9754\n",
            "Epoch 314/500\n",
            "44/44 [==============================] - 20s 427ms/step - loss: 92.8253 - mae: 8.0452 - val_loss: 94.1047 - val_mae: 8.1233\n",
            "Epoch 315/500\n",
            "44/44 [==============================] - 28s 586ms/step - loss: 92.8233 - mae: 8.0554 - val_loss: 93.4931 - val_mae: 8.0700\n",
            "Epoch 316/500\n",
            "44/44 [==============================] - 27s 580ms/step - loss: 92.9174 - mae: 8.0531 - val_loss: 92.6529 - val_mae: 8.0269\n",
            "Epoch 317/500\n",
            "44/44 [==============================] - 20s 422ms/step - loss: 92.7571 - mae: 8.0378 - val_loss: 93.2384 - val_mae: 8.0806\n",
            "Epoch 318/500\n",
            "44/44 [==============================] - 28s 540ms/step - loss: 92.6018 - mae: 8.0313 - val_loss: 93.4851 - val_mae: 8.1076\n",
            "Epoch 319/500\n",
            "44/44 [==============================] - 26s 559ms/step - loss: 92.7658 - mae: 8.0428 - val_loss: 93.3593 - val_mae: 8.0894\n",
            "Epoch 320/500\n",
            "44/44 [==============================] - 26s 536ms/step - loss: 92.6203 - mae: 8.0358 - val_loss: 93.2583 - val_mae: 8.0590\n",
            "Epoch 321/500\n",
            "44/44 [==============================] - 27s 583ms/step - loss: 92.2549 - mae: 8.0143 - val_loss: 91.3658 - val_mae: 7.9643\n",
            "Epoch 322/500\n",
            "44/44 [==============================] - 26s 588ms/step - loss: 93.0366 - mae: 8.0560 - val_loss: 92.8143 - val_mae: 8.0619\n",
            "Epoch 323/500\n",
            "44/44 [==============================] - 26s 571ms/step - loss: 93.0850 - mae: 8.0686 - val_loss: 92.8998 - val_mae: 8.0631\n",
            "Epoch 324/500\n",
            "44/44 [==============================] - 26s 562ms/step - loss: 92.7431 - mae: 8.0389 - val_loss: 92.8019 - val_mae: 8.0688\n",
            "Epoch 325/500\n",
            "44/44 [==============================] - 25s 555ms/step - loss: 92.3441 - mae: 8.0104 - val_loss: 91.1650 - val_mae: 7.9607\n",
            "Epoch 326/500\n",
            "44/44 [==============================] - 25s 541ms/step - loss: 92.9274 - mae: 8.0478 - val_loss: 93.3985 - val_mae: 8.0500\n",
            "Epoch 327/500\n",
            "44/44 [==============================] - 25s 542ms/step - loss: 93.2665 - mae: 8.0838 - val_loss: 93.5686 - val_mae: 8.0884\n",
            "Epoch 328/500\n",
            "44/44 [==============================] - 25s 544ms/step - loss: 93.3308 - mae: 8.0864 - val_loss: 92.5145 - val_mae: 8.0651\n",
            "Epoch 329/500\n",
            "44/44 [==============================] - 27s 575ms/step - loss: 92.0293 - mae: 8.0001 - val_loss: 92.1051 - val_mae: 7.9887\n",
            "Epoch 330/500\n",
            "44/44 [==============================] - 26s 538ms/step - loss: 93.2948 - mae: 8.0833 - val_loss: 92.6821 - val_mae: 8.0337\n",
            "Epoch 331/500\n",
            "44/44 [==============================] - 26s 543ms/step - loss: 92.6010 - mae: 8.0359 - val_loss: 91.9289 - val_mae: 8.0002\n",
            "Epoch 332/500\n",
            "44/44 [==============================] - 20s 438ms/step - loss: 92.0496 - mae: 8.0092 - val_loss: 94.0688 - val_mae: 8.1390\n",
            "Epoch 333/500\n",
            "44/44 [==============================] - 28s 594ms/step - loss: 92.1960 - mae: 8.0116 - val_loss: 92.1195 - val_mae: 8.0055\n",
            "Epoch 334/500\n",
            "44/44 [==============================] - 25s 542ms/step - loss: 92.6107 - mae: 8.0388 - val_loss: 92.4696 - val_mae: 8.0131\n",
            "Epoch 335/500\n",
            "44/44 [==============================] - 25s 540ms/step - loss: 92.7584 - mae: 8.0457 - val_loss: 92.5992 - val_mae: 8.0242\n",
            "Epoch 336/500\n",
            "44/44 [==============================] - 26s 570ms/step - loss: 92.2308 - mae: 8.0155 - val_loss: 92.5093 - val_mae: 8.0215\n",
            "Epoch 337/500\n",
            "44/44 [==============================] - 25s 540ms/step - loss: 92.9312 - mae: 8.0640 - val_loss: 92.3649 - val_mae: 8.0251\n",
            "Epoch 338/500\n",
            "44/44 [==============================] - 26s 583ms/step - loss: 93.1590 - mae: 8.0759 - val_loss: 90.8021 - val_mae: 7.9602\n",
            "Epoch 339/500\n",
            "44/44 [==============================] - 26s 581ms/step - loss: 92.4842 - mae: 8.0282 - val_loss: 92.2069 - val_mae: 8.0214\n",
            "Epoch 340/500\n",
            "44/44 [==============================] - 25s 540ms/step - loss: 92.4565 - mae: 8.0291 - val_loss: 92.8515 - val_mae: 8.0535\n",
            "Epoch 341/500\n",
            "44/44 [==============================] - 24s 526ms/step - loss: 92.5004 - mae: 8.0306 - val_loss: 92.8545 - val_mae: 8.0789\n",
            "Epoch 342/500\n",
            "44/44 [==============================] - 26s 548ms/step - loss: 92.0399 - mae: 8.0048 - val_loss: 92.0717 - val_mae: 8.0111\n",
            "Epoch 343/500\n",
            "44/44 [==============================] - 27s 586ms/step - loss: 91.3606 - mae: 7.9697 - val_loss: 92.3503 - val_mae: 8.0192\n",
            "Epoch 344/500\n",
            "44/44 [==============================] - 28s 607ms/step - loss: 92.9004 - mae: 8.0637 - val_loss: 94.1445 - val_mae: 8.1412\n",
            "Epoch 345/500\n",
            "44/44 [==============================] - 20s 434ms/step - loss: 92.4639 - mae: 8.0287 - val_loss: 90.9869 - val_mae: 7.9567\n",
            "Epoch 346/500\n",
            "44/44 [==============================] - 23s 443ms/step - loss: 92.4090 - mae: 8.0368 - val_loss: 91.0508 - val_mae: 7.9453\n",
            "Epoch 347/500\n",
            "44/44 [==============================] - 27s 555ms/step - loss: 91.7045 - mae: 7.9926 - val_loss: 91.4519 - val_mae: 7.9931\n",
            "Epoch 348/500\n",
            "44/44 [==============================] - 21s 458ms/step - loss: 91.3257 - mae: 7.9720 - val_loss: 91.7764 - val_mae: 8.0101\n",
            "Epoch 349/500\n",
            "44/44 [==============================] - 26s 528ms/step - loss: 91.9390 - mae: 7.9936 - val_loss: 90.0700 - val_mae: 7.8899\n",
            "Epoch 350/500\n",
            "44/44 [==============================] - 27s 581ms/step - loss: 91.9585 - mae: 8.0063 - val_loss: 90.1933 - val_mae: 7.9243\n",
            "Epoch 351/500\n",
            "44/44 [==============================] - 27s 602ms/step - loss: 91.0441 - mae: 7.9631 - val_loss: 91.5970 - val_mae: 7.9614\n",
            "Epoch 352/500\n",
            "44/44 [==============================] - 26s 560ms/step - loss: 91.3745 - mae: 7.9772 - val_loss: 93.8348 - val_mae: 8.1145\n",
            "Epoch 353/500\n",
            "44/44 [==============================] - 29s 632ms/step - loss: 92.0821 - mae: 8.0152 - val_loss: 93.0581 - val_mae: 8.0618\n",
            "Epoch 354/500\n",
            "44/44 [==============================] - 26s 561ms/step - loss: 91.3045 - mae: 7.9652 - val_loss: 90.6686 - val_mae: 7.9427\n",
            "Epoch 355/500\n",
            "44/44 [==============================] - 26s 572ms/step - loss: 92.7186 - mae: 8.0553 - val_loss: 90.4023 - val_mae: 7.9002\n",
            "Epoch 356/500\n",
            "44/44 [==============================] - 25s 556ms/step - loss: 91.8518 - mae: 7.9944 - val_loss: 91.1680 - val_mae: 7.9473\n",
            "Epoch 357/500\n",
            "44/44 [==============================] - 25s 535ms/step - loss: 91.8522 - mae: 7.9902 - val_loss: 91.8306 - val_mae: 7.9734\n",
            "Epoch 358/500\n",
            "44/44 [==============================] - 25s 544ms/step - loss: 92.3470 - mae: 8.0269 - val_loss: 92.3168 - val_mae: 8.0504\n",
            "Epoch 359/500\n",
            "44/44 [==============================] - 26s 550ms/step - loss: 91.3034 - mae: 7.9688 - val_loss: 92.4675 - val_mae: 8.0274\n",
            "Epoch 360/500\n",
            "44/44 [==============================] - 26s 549ms/step - loss: 91.6694 - mae: 7.9845 - val_loss: 90.6730 - val_mae: 7.9173\n",
            "Epoch 361/500\n",
            "44/44 [==============================] - 26s 542ms/step - loss: 91.4420 - mae: 7.9756 - val_loss: 92.2053 - val_mae: 8.0090\n",
            "Epoch 362/500\n",
            "44/44 [==============================] - 26s 560ms/step - loss: 91.4226 - mae: 7.9774 - val_loss: 91.3207 - val_mae: 7.9481\n",
            "Epoch 363/500\n",
            "44/44 [==============================] - 27s 567ms/step - loss: 91.7025 - mae: 7.9853 - val_loss: 92.9273 - val_mae: 8.0688\n",
            "Epoch 364/500\n",
            "44/44 [==============================] - 27s 580ms/step - loss: 91.7165 - mae: 7.9902 - val_loss: 91.4023 - val_mae: 7.9848\n",
            "Epoch 365/500\n",
            "44/44 [==============================] - 20s 443ms/step - loss: 91.6540 - mae: 7.9862 - val_loss: 92.2496 - val_mae: 8.0445\n",
            "Epoch 366/500\n",
            "44/44 [==============================] - 28s 551ms/step - loss: 90.8532 - mae: 7.9379 - val_loss: 92.6076 - val_mae: 8.0453\n",
            "Epoch 367/500\n",
            "44/44 [==============================] - 27s 570ms/step - loss: 91.7921 - mae: 8.0026 - val_loss: 89.7142 - val_mae: 7.8794\n",
            "Epoch 368/500\n",
            "44/44 [==============================] - 26s 561ms/step - loss: 91.4779 - mae: 7.9835 - val_loss: 90.9391 - val_mae: 7.9547\n",
            "Epoch 369/500\n",
            "44/44 [==============================] - 28s 595ms/step - loss: 91.8290 - mae: 8.0011 - val_loss: 91.3689 - val_mae: 7.9668\n",
            "Epoch 370/500\n",
            "44/44 [==============================] - 25s 551ms/step - loss: 91.4708 - mae: 7.9803 - val_loss: 90.9232 - val_mae: 7.9624\n",
            "Epoch 371/500\n",
            "44/44 [==============================] - 26s 562ms/step - loss: 91.4825 - mae: 7.9861 - val_loss: 91.1981 - val_mae: 7.9655\n",
            "Epoch 372/500\n",
            "44/44 [==============================] - 25s 561ms/step - loss: 90.7601 - mae: 7.9476 - val_loss: 91.9518 - val_mae: 8.0050\n",
            "Epoch 373/500\n",
            "44/44 [==============================] - 25s 549ms/step - loss: 90.9809 - mae: 7.9563 - val_loss: 91.9835 - val_mae: 8.0296\n",
            "Epoch 374/500\n",
            "44/44 [==============================] - 25s 532ms/step - loss: 90.7620 - mae: 7.9509 - val_loss: 92.6599 - val_mae: 8.0573\n",
            "Epoch 375/500\n",
            "44/44 [==============================] - 27s 564ms/step - loss: 91.4351 - mae: 7.9830 - val_loss: 89.7066 - val_mae: 7.8944\n",
            "Epoch 376/500\n",
            "44/44 [==============================] - 26s 546ms/step - loss: 91.2606 - mae: 7.9709 - val_loss: 91.7223 - val_mae: 7.9870\n",
            "Epoch 377/500\n",
            "44/44 [==============================] - 30s 620ms/step - loss: 91.4963 - mae: 7.9805 - val_loss: 90.6655 - val_mae: 7.9365\n",
            "Epoch 378/500\n",
            "44/44 [==============================] - 27s 582ms/step - loss: 91.2449 - mae: 7.9643 - val_loss: 89.9605 - val_mae: 7.8653\n",
            "Epoch 379/500\n",
            "44/44 [==============================] - 24s 529ms/step - loss: 91.4776 - mae: 7.9814 - val_loss: 88.3962 - val_mae: 7.8169\n",
            "Epoch 380/500\n",
            "44/44 [==============================] - 25s 551ms/step - loss: 90.9818 - mae: 7.9506 - val_loss: 91.3018 - val_mae: 7.9983\n",
            "Epoch 381/500\n",
            "44/44 [==============================] - 24s 532ms/step - loss: 91.0078 - mae: 7.9530 - val_loss: 90.6816 - val_mae: 7.9332\n",
            "Epoch 382/500\n",
            "44/44 [==============================] - 24s 535ms/step - loss: 91.0628 - mae: 7.9580 - val_loss: 92.8744 - val_mae: 8.0761\n",
            "Epoch 383/500\n",
            "44/44 [==============================] - 25s 557ms/step - loss: 90.6929 - mae: 7.9501 - val_loss: 89.3799 - val_mae: 7.8873\n",
            "Epoch 384/500\n",
            "44/44 [==============================] - 25s 549ms/step - loss: 91.0107 - mae: 7.9530 - val_loss: 91.6028 - val_mae: 7.9685\n",
            "Epoch 385/500\n",
            "44/44 [==============================] - 25s 535ms/step - loss: 91.0859 - mae: 7.9566 - val_loss: 90.8672 - val_mae: 7.9501\n",
            "Epoch 386/500\n",
            "44/44 [==============================] - 25s 553ms/step - loss: 91.2482 - mae: 7.9804 - val_loss: 90.7178 - val_mae: 7.9510\n",
            "Epoch 387/500\n",
            "44/44 [==============================] - 20s 422ms/step - loss: 91.1606 - mae: 7.9627 - val_loss: 91.4050 - val_mae: 7.9702\n",
            "Epoch 388/500\n",
            "44/44 [==============================] - 29s 568ms/step - loss: 90.7590 - mae: 7.9399 - val_loss: 91.7671 - val_mae: 8.0161\n",
            "Epoch 389/500\n",
            "44/44 [==============================] - 25s 536ms/step - loss: 90.7062 - mae: 7.9437 - val_loss: 90.4332 - val_mae: 7.9357\n",
            "Epoch 390/500\n",
            "44/44 [==============================] - 25s 556ms/step - loss: 90.1417 - mae: 7.9127 - val_loss: 89.9301 - val_mae: 7.8808\n",
            "Epoch 391/500\n",
            "44/44 [==============================] - 27s 590ms/step - loss: 91.0745 - mae: 7.9599 - val_loss: 90.0719 - val_mae: 7.9392\n",
            "Epoch 392/500\n",
            "44/44 [==============================] - 25s 536ms/step - loss: 91.2285 - mae: 7.9717 - val_loss: 89.8874 - val_mae: 7.8816\n",
            "Epoch 393/500\n",
            "44/44 [==============================] - 25s 535ms/step - loss: 90.7856 - mae: 7.9395 - val_loss: 92.3235 - val_mae: 8.0177\n",
            "Epoch 394/500\n",
            "44/44 [==============================] - 24s 532ms/step - loss: 90.2677 - mae: 7.9167 - val_loss: 88.7234 - val_mae: 7.8498\n",
            "Epoch 395/500\n",
            "44/44 [==============================] - 25s 550ms/step - loss: 90.6713 - mae: 7.9406 - val_loss: 92.1320 - val_mae: 8.0070\n",
            "Epoch 396/500\n",
            "44/44 [==============================] - 26s 543ms/step - loss: 90.5005 - mae: 7.9192 - val_loss: 90.6829 - val_mae: 7.9485\n",
            "Epoch 397/500\n",
            "44/44 [==============================] - 25s 536ms/step - loss: 90.4082 - mae: 7.9343 - val_loss: 90.6248 - val_mae: 7.9067\n",
            "Epoch 398/500\n",
            "44/44 [==============================] - 26s 553ms/step - loss: 90.4437 - mae: 7.9262 - val_loss: 90.6430 - val_mae: 7.9537\n",
            "Epoch 399/500\n",
            "44/44 [==============================] - 25s 533ms/step - loss: 90.4374 - mae: 7.9267 - val_loss: 91.1175 - val_mae: 7.9737\n",
            "Epoch 400/500\n",
            "44/44 [==============================] - 26s 570ms/step - loss: 91.0077 - mae: 7.9621 - val_loss: 90.0866 - val_mae: 7.9051\n",
            "Epoch 401/500\n",
            "44/44 [==============================] - 26s 568ms/step - loss: 91.0091 - mae: 7.9621 - val_loss: 91.2614 - val_mae: 7.9618\n",
            "Epoch 402/500\n",
            "44/44 [==============================] - 25s 557ms/step - loss: 90.3923 - mae: 7.9247 - val_loss: 90.1947 - val_mae: 7.9011\n",
            "Epoch 403/500\n",
            "44/44 [==============================] - 25s 545ms/step - loss: 90.5918 - mae: 7.9308 - val_loss: 89.6523 - val_mae: 7.9114\n",
            "Epoch 404/500\n",
            "44/44 [==============================] - 26s 563ms/step - loss: 90.3782 - mae: 7.9206 - val_loss: 91.1082 - val_mae: 7.9443\n",
            "Epoch 405/500\n",
            "44/44 [==============================] - 28s 609ms/step - loss: 90.4021 - mae: 7.9126 - val_loss: 89.5217 - val_mae: 7.8636\n",
            "Epoch 406/500\n",
            "44/44 [==============================] - 26s 559ms/step - loss: 90.4207 - mae: 7.9257 - val_loss: 90.1158 - val_mae: 7.9182\n",
            "Epoch 407/500\n",
            "44/44 [==============================] - 25s 543ms/step - loss: 90.1142 - mae: 7.9020 - val_loss: 89.1857 - val_mae: 7.8497\n",
            "Epoch 408/500\n",
            "44/44 [==============================] - 26s 548ms/step - loss: 90.3447 - mae: 7.9252 - val_loss: 91.6225 - val_mae: 7.9903\n",
            "Epoch 409/500\n",
            "44/44 [==============================] - 23s 480ms/step - loss: 90.0471 - mae: 7.9093 - val_loss: 91.2598 - val_mae: 8.0126\n",
            "Epoch 410/500\n",
            "44/44 [==============================] - 27s 577ms/step - loss: 90.1854 - mae: 7.9130 - val_loss: 89.0127 - val_mae: 7.8758\n",
            "Epoch 411/500\n",
            "44/44 [==============================] - 26s 548ms/step - loss: 89.6744 - mae: 7.8923 - val_loss: 89.8024 - val_mae: 7.8632\n",
            "Epoch 412/500\n",
            "44/44 [==============================] - 26s 580ms/step - loss: 89.2528 - mae: 7.8597 - val_loss: 90.1648 - val_mae: 7.8865\n",
            "Epoch 413/500\n",
            "44/44 [==============================] - 25s 549ms/step - loss: 90.2614 - mae: 7.9226 - val_loss: 89.6270 - val_mae: 7.9042\n",
            "Epoch 414/500\n",
            "44/44 [==============================] - 25s 543ms/step - loss: 90.5387 - mae: 7.9392 - val_loss: 90.5712 - val_mae: 7.9262\n",
            "Epoch 415/500\n",
            "44/44 [==============================] - 20s 431ms/step - loss: 89.1625 - mae: 7.8653 - val_loss: 90.4574 - val_mae: 7.9482\n",
            "Epoch 416/500\n",
            "44/44 [==============================] - 27s 558ms/step - loss: 89.6269 - mae: 7.8818 - val_loss: 89.0218 - val_mae: 7.8610\n",
            "Epoch 417/500\n",
            "44/44 [==============================] - 26s 573ms/step - loss: 89.4973 - mae: 7.8690 - val_loss: 89.0264 - val_mae: 7.8395\n",
            "Epoch 418/500\n",
            "44/44 [==============================] - 28s 623ms/step - loss: 90.3418 - mae: 7.9172 - val_loss: 91.3484 - val_mae: 7.9575\n",
            "Epoch 419/500\n",
            "44/44 [==============================] - 27s 603ms/step - loss: 90.1700 - mae: 7.9100 - val_loss: 89.6020 - val_mae: 7.8959\n",
            "Epoch 420/500\n",
            "44/44 [==============================] - 26s 559ms/step - loss: 89.9458 - mae: 7.8947 - val_loss: 91.1294 - val_mae: 7.9582\n",
            "Epoch 421/500\n",
            "44/44 [==============================] - 20s 437ms/step - loss: 89.7693 - mae: 7.8969 - val_loss: 89.1047 - val_mae: 7.8564\n",
            "Epoch 422/500\n",
            "44/44 [==============================] - 29s 551ms/step - loss: 89.8386 - mae: 7.8948 - val_loss: 88.4871 - val_mae: 7.8294\n",
            "Epoch 423/500\n",
            "44/44 [==============================] - 21s 438ms/step - loss: 89.5811 - mae: 7.8909 - val_loss: 89.8473 - val_mae: 7.8893\n",
            "Epoch 424/500\n",
            "44/44 [==============================] - 26s 555ms/step - loss: 89.7698 - mae: 7.8935 - val_loss: 89.5583 - val_mae: 7.8789\n",
            "Epoch 425/500\n",
            "44/44 [==============================] - 25s 542ms/step - loss: 89.7935 - mae: 7.8922 - val_loss: 90.1141 - val_mae: 7.8888\n",
            "Epoch 426/500\n",
            "44/44 [==============================] - 26s 554ms/step - loss: 89.7159 - mae: 7.8872 - val_loss: 91.3879 - val_mae: 7.9824\n",
            "Epoch 427/500\n",
            "44/44 [==============================] - 23s 469ms/step - loss: 89.3919 - mae: 7.8690 - val_loss: 90.0188 - val_mae: 7.8973\n",
            "Epoch 428/500\n",
            "44/44 [==============================] - 21s 441ms/step - loss: 90.1615 - mae: 7.9160 - val_loss: 90.8506 - val_mae: 7.9560\n",
            "Epoch 429/500\n",
            "44/44 [==============================] - 29s 570ms/step - loss: 89.8439 - mae: 7.9105 - val_loss: 87.8677 - val_mae: 7.7852\n",
            "Epoch 430/500\n",
            "44/44 [==============================] - 22s 454ms/step - loss: 89.8555 - mae: 7.9007 - val_loss: 91.0899 - val_mae: 7.9423\n",
            "Epoch 431/500\n",
            "44/44 [==============================] - 29s 621ms/step - loss: 90.0641 - mae: 7.9097 - val_loss: 90.3367 - val_mae: 7.9594\n",
            "Epoch 432/500\n",
            "44/44 [==============================] - 25s 551ms/step - loss: 89.8668 - mae: 7.9040 - val_loss: 89.6622 - val_mae: 7.8927\n",
            "Epoch 433/500\n",
            "44/44 [==============================] - 25s 549ms/step - loss: 89.8039 - mae: 7.8923 - val_loss: 88.2918 - val_mae: 7.8233\n",
            "Epoch 434/500\n",
            "44/44 [==============================] - 22s 479ms/step - loss: 88.7891 - mae: 7.8389 - val_loss: 89.2574 - val_mae: 7.8788\n",
            "Epoch 435/500\n",
            "44/44 [==============================] - 29s 606ms/step - loss: 88.9646 - mae: 7.8497 - val_loss: 88.7880 - val_mae: 7.8437\n",
            "Epoch 436/500\n",
            "44/44 [==============================] - 25s 552ms/step - loss: 89.5485 - mae: 7.8823 - val_loss: 90.6039 - val_mae: 7.9287\n",
            "Epoch 437/500\n",
            "44/44 [==============================] - 25s 555ms/step - loss: 89.4723 - mae: 7.8781 - val_loss: 87.8135 - val_mae: 7.7822\n",
            "Epoch 438/500\n",
            "44/44 [==============================] - 25s 555ms/step - loss: 89.3031 - mae: 7.8699 - val_loss: 89.5592 - val_mae: 7.8759\n",
            "Epoch 439/500\n",
            "44/44 [==============================] - 25s 548ms/step - loss: 89.1954 - mae: 7.8604 - val_loss: 89.5890 - val_mae: 7.8866\n",
            "Epoch 440/500\n",
            "44/44 [==============================] - 27s 579ms/step - loss: 89.0036 - mae: 7.8458 - val_loss: 91.1474 - val_mae: 7.9742\n",
            "Epoch 441/500\n",
            "44/44 [==============================] - 26s 558ms/step - loss: 89.8016 - mae: 7.8983 - val_loss: 87.7130 - val_mae: 7.7688\n",
            "Epoch 442/500\n",
            "44/44 [==============================] - 25s 553ms/step - loss: 89.2886 - mae: 7.8643 - val_loss: 89.4092 - val_mae: 7.8638\n",
            "Epoch 443/500\n",
            "44/44 [==============================] - 26s 577ms/step - loss: 89.1306 - mae: 7.8543 - val_loss: 89.6580 - val_mae: 7.8955\n",
            "Epoch 444/500\n",
            "44/44 [==============================] - 20s 433ms/step - loss: 89.2744 - mae: 7.8689 - val_loss: 91.0694 - val_mae: 7.9652\n",
            "Epoch 445/500\n",
            "44/44 [==============================] - 28s 573ms/step - loss: 89.3329 - mae: 7.8637 - val_loss: 91.1725 - val_mae: 7.9544\n",
            "Epoch 446/500\n",
            "44/44 [==============================] - 27s 593ms/step - loss: 89.3785 - mae: 7.8758 - val_loss: 88.7399 - val_mae: 7.8026\n",
            "Epoch 447/500\n",
            "44/44 [==============================] - 27s 603ms/step - loss: 89.7331 - mae: 7.8965 - val_loss: 87.8571 - val_mae: 7.8061\n",
            "Epoch 448/500\n",
            "44/44 [==============================] - 27s 582ms/step - loss: 88.8901 - mae: 7.8400 - val_loss: 88.9047 - val_mae: 7.8534\n",
            "Epoch 449/500\n",
            "44/44 [==============================] - 22s 481ms/step - loss: 89.2915 - mae: 7.8649 - val_loss: 90.2298 - val_mae: 7.9172\n",
            "Epoch 450/500\n",
            "44/44 [==============================] - 29s 601ms/step - loss: 88.9849 - mae: 7.8468 - val_loss: 90.5653 - val_mae: 7.9715\n",
            "Epoch 451/500\n",
            "44/44 [==============================] - 22s 477ms/step - loss: 89.4101 - mae: 7.8787 - val_loss: 88.1458 - val_mae: 7.8006\n",
            "Epoch 452/500\n",
            "44/44 [==============================] - 27s 586ms/step - loss: 89.0019 - mae: 7.8550 - val_loss: 89.9775 - val_mae: 7.9287\n",
            "Epoch 453/500\n",
            "44/44 [==============================] - 27s 586ms/step - loss: 88.9666 - mae: 7.8503 - val_loss: 86.5187 - val_mae: 7.6972\n",
            "Epoch 454/500\n",
            "44/44 [==============================] - 27s 598ms/step - loss: 89.4037 - mae: 7.8773 - val_loss: 88.7033 - val_mae: 7.8180\n",
            "Epoch 455/500\n",
            "44/44 [==============================] - 25s 544ms/step - loss: 89.7999 - mae: 7.9067 - val_loss: 89.6179 - val_mae: 7.8867\n",
            "Epoch 456/500\n",
            "44/44 [==============================] - 27s 599ms/step - loss: 88.9842 - mae: 7.8500 - val_loss: 88.8994 - val_mae: 7.8713\n",
            "Epoch 457/500\n",
            "44/44 [==============================] - 20s 449ms/step - loss: 88.9372 - mae: 7.8541 - val_loss: 90.0109 - val_mae: 7.9263\n",
            "Epoch 458/500\n",
            "44/44 [==============================] - 28s 563ms/step - loss: 89.7462 - mae: 7.9052 - val_loss: 89.6570 - val_mae: 7.8789\n",
            "Epoch 459/500\n",
            "44/44 [==============================] - 27s 581ms/step - loss: 89.2877 - mae: 7.8643 - val_loss: 87.9687 - val_mae: 7.7836\n",
            "Epoch 460/500\n",
            "44/44 [==============================] - 27s 600ms/step - loss: 88.8274 - mae: 7.8389 - val_loss: 89.1765 - val_mae: 7.8313\n",
            "Epoch 461/500\n",
            "44/44 [==============================] - 22s 477ms/step - loss: 88.8883 - mae: 7.8520 - val_loss: 88.0366 - val_mae: 7.8106\n",
            "Epoch 462/500\n",
            "44/44 [==============================] - 28s 578ms/step - loss: 88.2676 - mae: 7.8118 - val_loss: 88.6653 - val_mae: 7.8272\n",
            "Epoch 463/500\n",
            "44/44 [==============================] - 26s 560ms/step - loss: 88.3600 - mae: 7.8177 - val_loss: 88.3705 - val_mae: 7.8005\n",
            "Epoch 464/500\n",
            "44/44 [==============================] - 22s 476ms/step - loss: 89.5279 - mae: 7.8828 - val_loss: 89.0050 - val_mae: 7.8855\n",
            "Epoch 465/500\n",
            "44/44 [==============================] - 29s 581ms/step - loss: 88.2591 - mae: 7.8161 - val_loss: 88.6159 - val_mae: 7.8268\n",
            "Epoch 466/500\n",
            "44/44 [==============================] - 27s 590ms/step - loss: 88.9398 - mae: 7.8499 - val_loss: 87.0771 - val_mae: 7.7220\n",
            "Epoch 467/500\n",
            "44/44 [==============================] - 26s 565ms/step - loss: 88.3091 - mae: 7.8074 - val_loss: 88.8159 - val_mae: 7.8523\n",
            "Epoch 468/500\n",
            "44/44 [==============================] - 25s 549ms/step - loss: 89.1849 - mae: 7.8553 - val_loss: 87.8547 - val_mae: 7.7714\n",
            "Epoch 469/500\n",
            "44/44 [==============================] - 27s 587ms/step - loss: 89.0600 - mae: 7.8630 - val_loss: 89.4327 - val_mae: 7.8697\n",
            "Epoch 470/500\n",
            "44/44 [==============================] - 25s 555ms/step - loss: 89.2591 - mae: 7.8705 - val_loss: 89.2882 - val_mae: 7.8653\n",
            "Epoch 471/500\n",
            "44/44 [==============================] - 25s 558ms/step - loss: 88.5925 - mae: 7.8409 - val_loss: 87.1788 - val_mae: 7.7449\n",
            "Epoch 472/500\n",
            "44/44 [==============================] - 26s 555ms/step - loss: 88.2234 - mae: 7.8137 - val_loss: 87.6951 - val_mae: 7.7948\n",
            "Epoch 473/500\n",
            "44/44 [==============================] - 25s 556ms/step - loss: 88.6921 - mae: 7.8410 - val_loss: 90.1999 - val_mae: 7.9512\n",
            "Epoch 474/500\n",
            "44/44 [==============================] - 25s 550ms/step - loss: 88.2182 - mae: 7.8143 - val_loss: 88.8826 - val_mae: 7.8360\n",
            "Epoch 475/500\n",
            "44/44 [==============================] - 25s 554ms/step - loss: 88.5064 - mae: 7.8173 - val_loss: 88.6222 - val_mae: 7.8391\n",
            "Epoch 476/500\n",
            "44/44 [==============================] - 20s 430ms/step - loss: 88.1542 - mae: 7.8103 - val_loss: 89.4953 - val_mae: 7.9037\n",
            "Epoch 477/500\n",
            "44/44 [==============================] - 29s 587ms/step - loss: 88.0252 - mae: 7.8004 - val_loss: 89.2580 - val_mae: 7.8730\n",
            "Epoch 478/500\n",
            "44/44 [==============================] - 26s 578ms/step - loss: 88.7234 - mae: 7.8373 - val_loss: 90.4636 - val_mae: 7.9389\n",
            "Epoch 479/500\n",
            "44/44 [==============================] - 26s 592ms/step - loss: 88.4906 - mae: 7.8321 - val_loss: 87.9795 - val_mae: 7.8170\n",
            "Epoch 480/500\n",
            "44/44 [==============================] - 27s 607ms/step - loss: 88.1297 - mae: 7.8052 - val_loss: 87.4346 - val_mae: 7.7713\n",
            "Epoch 481/500\n",
            "44/44 [==============================] - 21s 451ms/step - loss: 88.8105 - mae: 7.8455 - val_loss: 87.2585 - val_mae: 7.7454\n",
            "Epoch 482/500\n",
            "44/44 [==============================] - 28s 570ms/step - loss: 88.8806 - mae: 7.8396 - val_loss: 88.4258 - val_mae: 7.8122\n",
            "Epoch 483/500\n",
            "44/44 [==============================] - 26s 537ms/step - loss: 88.7040 - mae: 7.8369 - val_loss: 88.0657 - val_mae: 7.8137\n",
            "Epoch 484/500\n",
            "44/44 [==============================] - 28s 615ms/step - loss: 88.8668 - mae: 7.8651 - val_loss: 88.1640 - val_mae: 7.8139\n",
            "Epoch 485/500\n",
            "44/44 [==============================] - 27s 606ms/step - loss: 88.6865 - mae: 7.8384 - val_loss: 89.2410 - val_mae: 7.8600\n",
            "Epoch 486/500\n",
            "44/44 [==============================] - 25s 563ms/step - loss: 87.7357 - mae: 7.7828 - val_loss: 88.2442 - val_mae: 7.8268\n",
            "Epoch 487/500\n",
            "44/44 [==============================] - 29s 604ms/step - loss: 87.7992 - mae: 7.7890 - val_loss: 88.0192 - val_mae: 7.8165\n",
            "Epoch 488/500\n",
            "44/44 [==============================] - 25s 555ms/step - loss: 87.8819 - mae: 7.7993 - val_loss: 86.8752 - val_mae: 7.7308\n",
            "Epoch 489/500\n",
            "44/44 [==============================] - 26s 563ms/step - loss: 87.8027 - mae: 7.7887 - val_loss: 87.7789 - val_mae: 7.7724\n",
            "Epoch 490/500\n",
            "44/44 [==============================] - 25s 554ms/step - loss: 88.7264 - mae: 7.8462 - val_loss: 90.4998 - val_mae: 7.9468\n",
            "Epoch 491/500\n",
            "44/44 [==============================] - 26s 560ms/step - loss: 88.0522 - mae: 7.8057 - val_loss: 89.2470 - val_mae: 7.8757\n",
            "Epoch 492/500\n",
            "44/44 [==============================] - 26s 569ms/step - loss: 87.9176 - mae: 7.7902 - val_loss: 87.8476 - val_mae: 7.8096\n",
            "Epoch 493/500\n",
            "44/44 [==============================] - 25s 543ms/step - loss: 88.1777 - mae: 7.8088 - val_loss: 88.6283 - val_mae: 7.8362\n",
            "Epoch 494/500\n",
            "44/44 [==============================] - 27s 587ms/step - loss: 88.2621 - mae: 7.8173 - val_loss: 88.8824 - val_mae: 7.8281\n",
            "Epoch 495/500\n",
            "44/44 [==============================] - 27s 567ms/step - loss: 89.0195 - mae: 7.8620 - val_loss: 89.1815 - val_mae: 7.8674\n",
            "Epoch 496/500\n",
            "44/44 [==============================] - 25s 533ms/step - loss: 87.9585 - mae: 7.7983 - val_loss: 88.5837 - val_mae: 7.8569\n",
            "Epoch 497/500\n",
            "44/44 [==============================] - 25s 560ms/step - loss: 87.4163 - mae: 7.7654 - val_loss: 87.4786 - val_mae: 7.7811\n",
            "Epoch 498/500\n",
            "44/44 [==============================] - 26s 542ms/step - loss: 87.8642 - mae: 7.7940 - val_loss: 87.0677 - val_mae: 7.7388\n",
            "Epoch 499/500\n",
            "44/44 [==============================] - 26s 556ms/step - loss: 88.1060 - mae: 7.8043 - val_loss: 87.6157 - val_mae: 7.7816\n",
            "Epoch 500/500\n",
            "44/44 [==============================] - 26s 544ms/step - loss: 88.0264 - mae: 7.7974 - val_loss: 88.8482 - val_mae: 7.8570\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "mae = history.history['mae']\n",
        "val_mae = history.history['val_mae']\n",
        "\n",
        "\n",
        "epochs_x = range(len(loss))\n",
        "\n",
        "\n",
        "plt.plot(epochs_x, mae, 'co', label='Training MAE')\n",
        "plt.plot(epochs_x, val_mae, 'k', label='Validation MAE')\n",
        "plt.title('Training and validation MeanAbsoluteError')\n",
        "plt.legend()\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(epochs_x, loss, 'co', label='Training loss')\n",
        "plt.plot(epochs_x, val_loss, 'k', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Y3K89-CM-dfg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545
        },
        "outputId": "7c883c6d-a2ad-4b92-ce0b-f98554bb72e6"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAEICAYAAABPgw/pAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOydd3gVVfrHPyc9IdQAoTeRoiLVghXEii6gYkEQkBWwgbqruCurYOG3urKuqFhQF12NoKIiqFhQgy2gICg1iBA6ASKElp7z+2Pm3HtmMrckJIQbz+d5eO6UMzPnziXfeec973lfIaXEYDAYDJFPVHV3wGAwGAyVgxF0g8FgqCEYQTcYDIYaghF0g8FgqCEYQTcYDIYaghF0g8FgqCEYQa9ihBALhBAjKrttdSKEyBJCXFgF55VCiPb28gtCiAfCaVuB6wwVQnxW0X5GMkKIPkKIbVVw3gr/HobKwwi6B0KIQ9q/UiFEnrY+tDznklJeJqV8rbLb1nSklLdIKR852vMIIdrYYhOjnTtNSnnx0Z7b41p97Gu979re1d6eXtnXDNKXkfY1rztW1wyX8oq/bUDkuf4un63KPkYqMaGb/PGQUiarZSFEFnCzlHKhu50QIkZKWXws+2Y47tkD9BZCpEgpc+xtI4D1x7gfI4DfgeHAW8f42lXBn7z+Bt14/U0KIaKllCXhXqi87Y8njIVeDtTrqhDiPiHELmCmEKK+EOJDIcQeIcQ+e7mFdky6EOJme3mkEOJbIcRUu+0mIcRlFWzbVgjxtRDioBBioRBiuhDijQD9DqePjwghvrPP95kQoqG2/0YhxGYhRI4QYmKQ+3OGEGKXECJa23alEOIXe/l0IUSGEGK/EGKnEOJZIURcgHO9KoR4VFu/1z5mhxBilKvt5UKI5UKIA0KIrUKIydrur+3P/bZl11vdW+34s4QQPwohcu3Ps8K9Nx4UAnOB6+3jo4HrgDRXnzsJIT4XQvwuhMgUQlwbzvfR3jhGCCG2CCH2un8TIURr4HxgDHCJEKKJx/293z42S2hvnUKI/kKINfZ33S6EuEfbN1oIscHu8zwhRDOvG6D/P7bXffdbCKF+j5/t3+M6e/sVQogV9v+N74UQpwa5x/q1Rtq/zX+EEDnAZPv/zvNCiI+FEIeBvkKIzna/9gshVgshBmjnKNM+nGsfjxhBLz9NgAZAa6w/mChgpr3eCsgDgr0OngFkAg2BfwGvCCFEBdq+CfwApACTgRuDXDOcPt4A3AQ0BuKAewCEECcBz9vnb2ZfrwUeSCmXAIeBC1znfdNeLgHutr9Pb6AfcFuQfmP34VK7PxcBJwJu//1hLEu0HnA5cKsQYpC97zz7s56UMllKmeE6dwPgI+Bp+7s9CXwkhEhxfYcy9yYI/7P7A3AJsArYoV2zFvA51n1pjCX+z9n3OtT3UZwDdMS6hw8KITpr+4YDS6WU7wJrAbebsAnWb9Acy5KfIYToaO97BRgrpawNnAJ8aff5AuCfwLVAU2AzMDvEfSiDlFL9Hl3t3+MtIUR34L/AWKzf4EVgnhAiPszTngFsBFKBKfa2G+zl2sASYD7wGdb9Hgekad/Z3f5bIhQj6OWnFJgkpSyQUuZJKXOklO9KKY9IKQ9i/ac4P8jxm6WUL9mvdK9h/XGklqetEKIVcBrwoJSyUEr5LTAv0AXD7ONMKeV6KWUe8DbQzd4+GPhQSvm1lLIAeMC+B4GYBQwBEELUBvrb25BSLpNSLpZSFksps7D+cIPdK8W1dv9WSSkPYz3A9O+XLqVcKaUslVL+Yl8vnPOCJZi/Silft/s1C1gH/ElrE+jeeCKl/B5oYAvGcCyB17kCyJJSzrSvuRx4F7imHN/nIfv/38/Az0BXbd9w/A/RN/E/XHQesP8PL8J6oKk3hCLgJCFEHSnlPinlT/b2ocB/pZQ/2f8P/o7lWmoT7F6EyRjgRSnlEilliT2OVACcqbWZa1vX6t9obd8OKeUz9r3Ms7d9IKX8TkpZivV7JQOP2X8vXwIfYv8/dbeXUuZXwneqFoygl589+g8uhEgSQrwoLJfEAaxX/HpCczu42KUWpJRH7MXkcrZtBvyubQPYGqjDYfZxl7Z8ROtTM/3ctqDmEJg3gats6+oq4Ccp5Wa7Hx2E5e7ZZffj/7AsxVA4+oBlHerf7wwhxFfCcinlAreEeV517s2ubZuxrFdFoHsTjNeBO7Be39937WsNnKELFJZgNinH9/HskxDibKAtfuv5TaCLEEJ/CO2zf0f9+yr3ydVYD+HNQohFQoje9nbHfZJSHsL6f6Dfp4rSGvir63601PoEMEhKWU/795K2z+v/vr6tGbDVFneF+zcO+PcTSRhBLz/u9JR/xXr1PUNKWQf/K34gN0plsBPLAkzStrUM0v5o+rhTP7d9zZRAjaWUa7D+WC7D6W4By3WzDjjR7sf9FekDlttI502sN5SWUsq6wAvaeUOlE92BJSg6rYDtYfQrGK9juZM+dj14wRKPRS6BSpZS3mrvD/Z9QjHCbrtCWOM8S7Ttivq220fRCtslJKX8UUo5EMs1MRfrjQRc98k+PgXv+3QY0P9vlvHhu9gKTHHdjyT7bSkcvH5jfdsOoKUQQtc7929cI9LOGkE/empj+aT32/7YSVV9QdviXYo1ABRnW1F/CnLI0fRxDnCFEOIcYQ1gPkzo/zdvAndiPTjecfXjAHBICNEJuNXjWC/eBkYKIU6yHyju/tfGemPJF0KcjvUgUezBchG1C3Duj4EOQogbhBAx9iDdSViv5BVGSrkJy03iNYj8oX3NG4UQsfa/0zQ/eLDvExAhRAKW62QMlptB/RsH3CC00E3gIfv/zrlYLqB37PWhQoi6UsoirN9KWbWzgJuEEN3st6//A5bYrjM3K7De0pKEFZ74Z9f+bJy/x0vALfabiRBC1BLWwHDtcL53GCzBeouZYN/rPlh/L+UeAzjeMYJ+9DwFJAJ7gcXAJ8foukOxBhZzgEexQtMKArStcB+llKuB27FEeiewDwg1MUX5fL+UUu7Vtt+DJU4Hsf6Iwwqnk1IusL/Dl8AG+1PnNuBhIcRB4EH8VqVyVU0BvrNf53W/LHZo4RVYbzE5wATgCle/K4SU8lsp5Q6P7QeBi7EGQ3dguU8eB9QgYMDvE4JBWA/u/0kpd6l/WAOOMcCldrtdWL/jDqzom1uklOvsfTcCWbZL7BbsAVVphQw+gOXr3wmcYPffi/9gRftkY439pLn2TwZes3+Pa6WUS4HRWAP1+7B+45GuY+YLZxy6240VECllIZaAX4b1N/AcMFz7zjUGIU2BixqBEOItYJ2UssrfEAwGw/GJsdAjFPsV/QQhRJQd1jcQy+dpMBj+oJiZopFLE+A9rIGpbcCtdvibwWD4g2JcLgaDwVBDMC4Xg8FgqCFUm8ulYcOGsk2bNtV1eYPBYIhIli1btldK2chrX7UJeps2bVi6dGl1Xd5gMBgiEiGEe2azD+NyMRgMhhqCEXSDwWCoIRhBNxgMhhqCiUM3GGo4RUVFbNu2jfz8iM0K+4ckISGBFi1aEBsbG/YxRtANhhrOtm3bqF27Nm3atEEErKViOJ6QUpKTk8O2bdto27Zt2MdFlMslLTubNhkZRKWn0yYjg7Ts7OruksFw3JOfn09KSooR8whCCEFKSkq536oixkJPy85mTGYmR0qtbJ6bCwoYk5kJwNDUQAV/DAYDYMQ8AqnIbxYxFvrEjRt9Yq44UlrKxI0bq6lHBoPBcHwRMYK+pcA71Xeg7QaD4fggJyeHbt260a1bN5o0aULz5s1964WFhUGPXbp0KePHjw95jbPOOqtS+pqeno4Qgpdfftm3bcWKFQghmDp1qm9bcXExjRo14m9/+5vj+D59+tCxY0ff9xs8eHCl9CtcIsbl0io+ns0e4t0qPtzC4AaDIRzSsrOZuHEjWwoKaBUfz5R27Y7KrZmSksKKFSsAmDx5MsnJydxzzz2+/cXFxcTEeEtRr1696NWrV8hrfP/99xXun5tTTjmFt99+m5tvvhmAWbNm0bVrV0ebzz//nA4dOvDOO+/wz3/+0+EeSUtLC6vPVUHEWOhT2rUjKcrZ3aSoKKa0C1RZzGAwlBc1VrW5oACJf6yqsgMQRo4cyS233MIZZ5zBhAkT+OGHH+jduzfdu3fnrLPOItMeH0tPT+eKK64ArIfBqFGj6NOnD+3atePpp5/2nS85OdnXvk+fPgwePJhOnToxdOhQVEbZjz/+mE6dOtGzZ0/Gjx/vO6+b1q1bk5+fT3Z2NlJKPvnkEy677DJHm1mzZnHnnXfSqlUrMjIyKvXeHA0RY6ErC6EyLQeDweAk2FhVZf+tbdu2je+//57o6GgOHDjAN998Q0xMDAsXLuT+++/n3XffLXPMunXr+Oqrrzh48CAdO3bk1ltvLROnvXz5clavXk2zZs04++yz+e677+jVqxdjx47l66+/pm3btgwZMiRo3wYPHsw777xD9+7d6dGjB/GaJyA/P5+FCxfy4osvsn//fmbNmuVw+QwdOpTExEQALrroIp544omjuU3lImIEHSxRNwJuMFQdx3Ks6pprriE6OhqA3NxcRowYwa+//ooQgqKiIs9jLr/8cuLj44mPj6dx48ZkZ2fTokULR5vTTz/dt61bt25kZWWRnJxMu3btfDHdQ4YMYcaMGQH7du2113Ldddexbt06hgwZ4nDpfPjhh/Tt25fExESuvvpqHnnkEZ566infdzEuF4PBcFwQaEyqKsaqatWq5Vt+4IEH6Nu3L6tWrWL+/PkB4691Szk6Opri4uIKtQlFkyZNiI2N5fPPP6dfv36OfbNmzWLhwoW0adOGnj17kpOTw5dfuuuWVw8RZaEbDIaqZUq7do75HnBsxqpyc3Np3rw5AK+++mqln79jx45s3LiRrKws2rRpw1tvvRXymIcffpjdu3f7LG/A5xraunWr78Exc+ZMZs2axUUXXVTp/S4vxkI3GAw+hqamMqNjR1rHxyOA1vHxzOjYscpdnRMmTODvf/873bt3r5BFHYrExESee+45Lr30Unr27Ent2rWpW7du0GPOOussBg0a5Nj2/vvvc8EFFzjeAgYOHMj8+fMpsN1SQ4cO9YUtXnjhhZX+XYJRbTVFe/XqJU2BC4Oh6lm7di2dO3eu7m5UO4cOHSI5ORkpJbfffjsnnngid999d3V3Kyhev50QYpmU0tNJbyx0g8Hwh+Cll16iW7dunHzyyeTm5jJ27Njq7lKlY3zoBoPhD8Hdd9993FvkR4ux0A0Gg6GGYATdYDAYaghG0A0Gg6GGYATdYDAYaggRJ+jz5s1j8ODBvphPg8FwfNO3b18+/fRTx7annnqKW2+9NeAxffr0QYU19+/fn/3795dpM3nyZEdKWy/mzp3LmjVrfOsPPvggCxcuLE/3PTle0+yGJehCiLuFEKuFEKuEELOEEAmu/a2EEF8JIZYLIX4RQvSvlN55sH79et59992QeZQNBsPxwZAhQ5g9e7Zj2+zZs0MmyFJ8/PHH1KtXr0LXdgv6ww8/XGmTfVSaXUWoNLvuOT9paWmsWLGCFStWMGfOnErpU0hBF0I0B8YDvaSUpwDRwPWuZv8A3pZSdrf3PVcpvfNATcMtKSmpqksYDIZKZPDgwXz00Uc+IywrK4sdO3Zw7rnncuutt9KrVy9OPvlkJk2a5Hl8mzZt2Lt3LwBTpkyhQ4cOnHPOOb4Uu2DFmJ922ml07dqVq6++miNHjvD9998zb9487r33Xrp168Zvv/3GyJEjfeL5xRdf0L17d7p06cKoUaN8b/1t2rRh0qRJ9OjRgy5durBu3TrPfh2PaXbDjUOPARKFEEVAErDDtV8Cdezluh77Kw0j6AZDxbnrrrt8xSYqi27duvHUU08F3N+gQQNOP/10FixYwMCBA5k9ezbXXnstQgimTJlCgwYNKCkpoV+/fvzyyy+ceuqpnudZtmwZs2fPZsWKFRQXF9OjRw969uwJwFVXXcXo0aMB+Mc//sErr7zCuHHjGDBgAFdccUUZl0Z+fj4jR47kiy++oEOHDgwfPpznn3+eu+66C4CGDRvy008/8dxzzzF16lSHa0XneEuzG9JCl1JuB6YCW4CdQK6U8jNXs8nAMCHENuBjYJzXuYQQY4QQS4UQS/fs2VOhDqvKJkbQDYbIQXe76O6Wt99+mx49etC9e3dWr17tcI+4+eabb7jyyitJSkqiTp06DBgwwLdv1apVnHvuuXTp0oW0tDRWr14dtD+ZmZm0bduWDh06ADBixAi+/vpr3/6rrroKgJ49e5KVlRXwPNdeey3vvPMOs2bNKuNCcqfZnTt3rkO3dJdLZeVMD2mhCyHqAwOBtsB+4B0hxDAp5RtasyHAq1LKfwshegOvCyFOkVI6MuVLKWcAM8DK5VKRDisLvSoS+BgMNZ1glnRVMnDgQO6++25++uknjhw5Qs+ePdm0aRNTp07lxx9/pH79+owcOTJg2txQjBw5krlz59K1a1deffVV0tPTj6q/ytIOlX5XT7M7bdo0R970WbNm8e2339KmTRsAX5rdqszKGM6g6IXAJinlHillEfAe4K7I+mfgbQApZQaQADSszI4qjMvFYIg8kpOT6du3L6NGjfJZsgcOHKBWrVrUrVuX7OxsFixYEPQc5513HnPnziUvL4+DBw8yf/58376DBw/StGlTioqKSEtL822vXbs2Bw8eLHOujh07kpWVxYYNGwB4/fXXOf/88yv03R5++GEef/xxzzS7W7ZsISsri6ysLKZPn86sWbMqdI1wCceHvgU4UwiRBOQB/QB3msQt9vZXhRCdsQS9Yj6VEBhBNxgikyFDhnDllVf6XC9du3ale/fudOrUiZYtW3L22WcHPb5Hjx5cd911dO3alcaNG3Paaaf59j3yyCOcccYZNGrUiDPOOMMn4tdffz2jR4/m6aefdkSSJCQkMHPmTK655hqKi4s57bTTuOWWWyr0vXS/uCJQmt0JEyY40uwqH3rDhg0rJZwyrPS5QoiHgOuAYmA5cDMwEVgqpZwnhDgJeAlIxhogneDhZ3dQ0fS5r7/+OsOHD2fDhg2ccMIJ5T7eYPijYdLnRi7lTZ8bVpSLlHIS4I4pelDbvwYI/nitJIwP3WAwGLyJuJmixuViMBgM3hhBNxj+AFRXZTJDxanIbxZxgm7i0A2G8pGQkEBOTo4R9QhCSklOTg4JCQmhG2tEXMUi40M3GMpHixYt2LZtGxWdzGeoHhISEmjRokW5jolYQTcWusEQHrGxsbRt27a6u2E4BkScy8UIusFgMHgTcYKebk8YOHvpUtpkZJCWnV3NPTIYDIbjg4gS9LTsbP6zfbu1UlLC5oICxmRmGlE3GAwGIkzQJ27cSIEQ1kqplffrSGkpEzdurMZeGQwGw/FBRAn6loICiLK7rPnQt5hydAaDwRBZgt4qPh5URrPSUud2g8Fg+IMTUYI+pV07EuyJRcpCT4qKYkq7dtXYK4PBYDg+iChBH5qaygNKvEtLaR0fz4yOHRmamlq9HTMYDIbjgIgSdIA/NW4MwDudO5PVu7cRc4PBYLCJOEEPlMvlzDPPZObMmdXRJYPBYDguiDhBd+dykVLy9ttvs2TJEkaNGlWdXTMYDIZqJWJzudyZmcmN6ek0/OEH9tx3XzX3ymAwGKqfiBP0+b//DkCOHXu+x8wSNRgMBiACXS5Td+ywFpQP3STpMhgMBiACBX27yoOuJhZpE4wMBoPhj0zECXoLVcFDWeZG0A0GgwGIQEGfqE0scnxqfPTRR6xfv/4Y9spgMBiqn4gT9CHNmgFQXwgEkOSqk5iWnc0VV1xBx44dq6F3BoPBUH2EJehCiLuFEKuFEKuEELOEEGUqlwohrhVCrLHbvVn5XbVQYYt/b9mS1zt3pshVW3T0unVVdWmDwWA4rgkp6EKI5sB4oJeU8hQgGrje1eZE4O/A2VLKk4G7qqCvgLME3cSNG8sIel5+flVd2mAwGI5rwnW5xACJQogYIAnY4do/GpgupdwHIKXcXXlddKIE/fFNm9hcUACFhc4GR45U1aUNBoPhuCakoEsptwNTgS3ATiBXSvmZq1kHoIMQ4jshxGIhxKVe5xJCjBFCLBVCLN2zZ0+FOvxWTg4A+5WQG0E3GAwGIDyXS31gINAWaAbUEkIMczWLAU4E+gBDgJeEEPXc55JSzpBS9pJS9mrUqFGFOvxAVpa1oMIW3dWK8vIqdF6DwWCIdMJxuVwIbJJS7pFSFgHvAWe52mwD5kkpi6SUm4D1WAJf6fjKzc2ebVnn5RT0lStX8u6771ZF1wwGg6FaCUfQtwBnCiGShBAC6AesdbWZi2WdI4RoiOWCqZLKzb5yc0VF8N57ZQU9hMvlySef5Pbbb6+KrhkMBkO1Eo4PfQkwB/gJWGkfM0MI8bAQYoDd7FMgRwixBvgKuFdKmVMVHXaUmztypKygHz4c9PicnByOGD+7wWCogYSVbVFKOQmY5Nr8oLZfAn+x/1UpQ1NT8Tnwo6PLCvrBg0GP37dvH/nHMLRx9+7dNGrUCOvlxmAwGKqOiJsp6mDvXli+3LktN9e3mOaRWnffvn0UFRWVqXgUiEWLFvG7nbK3vKxdu5bU1FSmT59eoeMNBoOhPES2oH/9ddlt+/f7FoetXIlITycmPZ3b7Nwu+/btA6DAbdl7UFRURJ8+fbjssssq1L1ff/0VgE8//bRCx+t88MEH/Pjjj0d9HoPBUHOJbEE/cACiXF9Bs9CxXSslwPM7dnDb+vU+QVdul02bNtG/f38OHTpU5vR5dsTMzz//XPl9LyeDBg3i9NNPr+5uGAyG45jIFnSAunWd6/qg6LffOna9mJXlE2n1ed9997FgwQI++uijMqdWbVRh6vISZT9spCuBmMFgMFQFkS/o9Vzzl3RBf/xxx65SbcBUWeildvrdKLelr7WpqKCrgdDSo8zZfiwHcQ0GQ+QScTVFyxDMQnejCXr7r7+m+c8/s+fjjwFvQVcWusofU16UoB+thV7RQVmDwfDHIvItdLegHzkCtWr51/VoFj2ksbCQ7cOHU2iL9je5ubTJyCAqPZ02GRmkZWdXyOVSXFzMyy+/TH5+vhF0g8FwTIlIQX/ttdd8y8kNGjh3HjoEDRvCHXdY67qI6wOfhYUOa/75nTvZXFCABDYXFDAmM5O527cD5RP0p556itGjR/Paa6/5rP7yulxefvllR6hjTk6VzNEyGAw1jIgU9OHDh3PeeecBcCg52bnz8GGIi4P69a11LYzRIe5PPeU4rFBKKw9MUREAR0pLeTQzEwjucsnPz3dY4HPmzAGgdu3aPiEvr4U+evRo7lAPJIygGwyG8IhIQQd/HHnTCy4ouzM21u+KCSToG12pZkpKoH9/+It/smupnZo3P8Asz71795KYmMiTTz7p2/bDDz/Ypyuh2C6+sXDhQv7xj3+E9b28UC6X2NjYCp/DYDDUfCJW0F977TU+//xznvCa9BMX549+0ePSg6UFsC1zVq3yb7MfGntKShDp6TT89lvH7NPffvsNgLfeeguw/OfKGi8oKPAJOsCUKVPC/WplUIKelJRU4XMYDIaaT8QKeseOHbnwwgsZmprKyMceI7pVK9++2Lg46qemWiv67Mpggq6XsvvlF+tTzSa1XS45xcWMWrfOJ+oHDhwAoE6dOgBs3brVdwq3oB8NatJTRaNtDAbDH4OIFXSdmffdxw5NuC9r0oT9ycnwpz/Bxx9bwnzwoDWzNJAo6nnU77zT+lTVkLRjCqVk4saNvPfee2RkZAB+QVcWO3gL+vz58zkYInmYF0rQw0lXYDAY/rjUCEEHiFd50u3lVvHxcOKJICXccAMMGAALF0JKivcJvIRWCaiKUV+/HoYNY3NODldffTWTJlkJKOva/vpNmzb5Dv3xxx+54YYbHKcbMGAAd93lr5/9xBNPBC22odw3RtANBkM4RP7EIpuEhATfcnx8PFPatWNU3boUAuhx3A0awG6PGtZegq4sdCXor74K27cj5s1Dj1upXbs2adnZTFCuGmD27Nme/cy23TU7duxgwoQJQOAomIKCAhISEjhsh1cWFxdTUlJiXC8Gg8GTGmOhx8XF+ZYTEhIYmprKPSefXLahO25dEY6FrnKzvPSSo9ncnBzGZGayX8W5e8w6VTRs2BCAefPmAdCyZUvH/iI1OAu+Qhx64jBlpR8+fJgdO3YEvI7BYPjjUWMEXQjhc7uoz2vbty/bMDkZkpLKzjB1C/qYMfC//1nLarZpAKHeeugQR0pLreyOsbFWlE0A9iQmArDfDqdUAq/I03z5XoKu8rqceeaZNG/ePOB1qpvc3FwK1RuOwWA4JtQYQQe/20UJeoruL1fpABIS4KOPYMQI58Hff+9ct3OZA/6QxkCW97x5kJFhWfSJiUEF/buSEtKys3lswwYAVh044AiF1MvjHT58mOLiYp/LBSxBnzp1Kqv08MrjkHr16jFgwIDQDQ0GQ6VRowW9ge5eUcu2hez7DIeSEis+fdGiwG3uv9+y0OPjLSs9ALmFhYzJzCTXtrSLCgq4ce1ahJ1DZtaWLb62c+bMITY2liVLlvi2FRQUcO+99wY8f2ZmpsNtU51URmEPg8EQPjVK0NVMSiXo+kScaCWySsgDia6ywoXwpwcoKoJx40J3ID/fegMINqOzqMhyzyjRzc/3DbBuLihgwurVvqazZs3yLasxgmCpdLdu3UqnTp2CCv6xwOR/Nxiqhxol6Ao94kVxku1yqZecjAAaBnKLXHml9SkEdO1qpQMIs/4oBQWWhR5M0NS5NEHXKdZCE3VXi3IfuUMXdfHcs2cPAOnp6eH1NwgrV670ldArL5U1ocpgMJSPGiXoKl2tHpP+ySefsHLlSp/w/d9JJ1Hapw/PderkfZLata1PZanHxDhnkQZDWejBBgPVuQIIur6+RUtboAZP3Ra6l3tFBMg9Ux5OPfVUOnToUKFjTby8wVA91ChBV+iCfskll3DKKaf4BD3Zzs4YUPTsWZ+o/TExfvHVufTSstv27w9P0PPy/MJeXOx8YGjHlmoRL8pCdwv6TTfdxJAhQwJfLwz69+9PixYtjuocOkbQDYbqoUYJuppwowu6Qgl6LaEebxMAACAASURBVNv1kuI1Y7RuXV80TEx0NK3j4y1B93K5eLlssrMtl0swQfvgA8uNo6UJID/fytV+yy3O6BpNvNPt7zYgI8MaB7DfIN58803fJKZgro60tDSysrI89y1YsIDtdu53L+bPn88HH3wQ+Du5MIJuMFQPYQm6EOJuIcRqIcQqIcQsIURZJ7XV7mohhBRC9KrcbobHs88+S9euXenVq+zlVW5yJeh9+vRh9uzZbLDDBwF4910a2gOp8dHRZPXuzd/atSO6pMRvsSu8BP3wYUvQw3HRaIm8WLsWvvgCMjPh5Ze9B1WbNAHg4O+/W28Mriid3bt3BxwwLSkpYdiwYZx22mmh++XBgAEDGDRoUNjtjaAbDNVDSEEXQjQHxgO9pJSnANHA9R7tagN3Akvc+44Vl19+OStWrODUU08ts8/L5XLddddxwgkn+Nv068fLXboA/hqjcXFxlBQVEatZ/U1ffbWswCsChUP+/e/QrJl/XRffCROcBTf69YPWrZ3Hq+yR+/dbDwzXdZYvX+4Q0sLCQpo1a8b777/vG1zdu3cvL7/8siPWvSowE4oMhuohXJdLDJAohIgBkgCvOeePAI8Dx2WJerfLJRDKXaMEXYVC6tlTdowYQe1Ak4w83D0AnHFG4EyPbho3hqZNndvq17feClT1IpegZ2dn88muXQCsOHyYtu+9x86dO7n33nsd0TKjR4/2JRULxNEKsrHQDYbqIaSgSym3A1OBLcBOIFdK+ZneRgjRA2gppfwo2LmEEGOEEEuFEEtViN2xQgl6YogJRUrQ1aCpO/5bhQSepQZP3XiETNonsvzx4ZCQUFbQExMtH//evf51jb/OnMmTw4dbK1Kywxb3qPr1HYIOBEzhq+6Ru71CT0sQDCPoBkP1EI7LpT4wEGgLNANqCSGGafujgCeBv4Y6l5RyhpSyl5SyV6NGjSre6wqgxCoqSOIsCGyhg1V16PzzzwfgRLclrtYDWehxcWVTBwRqm5BgFbrWCSHoe92x5/YDc1tiYhmBrq/qrbqIiori119/DSjoe9W1Q2AE3WCoHsJxuVwIbJJS7pFSFgHvAWdp+2sDpwDpQogs4ExgXnUNjAZi+vTpdO7cmVZaZSNFdna2L3NhMEFP1gpSq0FWRf3bboNLL6XpBRdQyx7AdBAdDa5jCBQLHx9fNnlYCEEvgy3oeXXqlBHoYG6nDh068MYbbwQ4ZXhvVUbQDYbqIRxB3wKcKYRIEpYfoh+wVu2UUuZKKRtKKdtIKdsAi4EBUsqlVdLjCnLxxRezZs0az5DGxo0b09R2cbgFXRe/2mrSEWUFfdFNNyEXLGDHsGFs+uUXHvOarekW9Dp14L//LdsuIcFfE1WhBF2JajBBF8Kf8z06mrNdiceCpQ+AwDlYjKAbDMc34fjQlwBzgJ+AlfYxM4QQDwshalw6Pbegt23b1rdPt9BLXLHpum++UaNG3Ge7ZgD+vGyZteAW9NhYaNsWevRwbvcSdLdfPVTBaDXLtKiozGzUQC4VhaqVCs7UAhs3buSOO+5ACEFaWlrA402Ui8FQPYQV5SKlnCSl7CSlPEVKeaOUskBK+aCUcp5H2z7Hm3VeHtyCfuKJJ/r2ddJcJP3793cclxREYF9Wgu2eoOROGObvhLeFrhfDCOVyUbNbi4r89VLtknihwhZ1QdfF+W9/+xvTp08HrPGEQIRjoa9du5Ybb7zR5H0xGCqRGjVTtDJQ0S1K0JtqVvFJJ53kWx40aBCHDx+mni28Xq4cndZeSbuUoLsjY5R7RScurnyCrueMUYJ+5ZXQrBmrVOgj3pkRc7UcMro461EubpeTTjiCPmTIEN544w1WrlwZsq3BYAgPI+gulJ/8iiuuAJxRMe5anklJSQwdOhQIHd8+pV07hBJB+5xRsbGkxMR4W+ju8wkB+oBuMEEvLnZa6MrlkpAACQl8n53tK6rhZSEHEnT9XoQj6MFqnyrLP9SD0GAwhI8RdBf16tVj8+bNPP30075ta9eu5Tc994rGtGnT+P333z1T9uoMTU2lnhJEu3TcJY0bs/ecc7hbc+sAlvB6zUTVfPhBBb2w0G+hFxb6BT0x0Tp3fj7D1q7ltvXrPQdIdTdLIEHfdOQIUXZRDr3ikn5MsBBRdQ1T8NpgqDyMoHvQqlUrR7hip06daNeunWfb6OjogHHdbuJt98agnj0BaBlospN6OHz5ZeCTBRP07dvhl1+s5aVLYeZMy70THW1Z/7aIP79+PSnPPx+0z/et9QU0OTJUFpeUILGKcozJzHSIejiCrtqsWrXK4faZM2eOccMYDBXECPoxREXGdO7cGcCX4dAdDugTeCHgtNPKTjKyGpXv4uohkZjot9gnTKDovvuCHvamVhLviO5m0UT4SGkpEzdu9K0r6zscC33w4MH8+9//9m2/5pprPHPxGAyG0BhBr0LOPvts+vXr51tXgt6+fXsAtm3bBlil43SeP/VUaxAVEP/6F7zzTtmTl1fQVRSO7XIBrCyPodBK4jnyvLt86FsKCti8eTO33367LywyWKEN3a0zb54VLGVK1xkMR0eYyUUMFeHbb791rCtBVxaoGlD917/+RWxsLPPnzwdgRIsWjLALTqRlZzNx40a2FBTQIDqaHCXIuqA3auSfcBQIVSRbF/RgxMZaA6r/+Y9/my7iKgRzwwZo0YKohAQuvf561i1e7EuPECwkUffNqzeVUPHxBoMhOEbQjyFK0Bs3bkxhYSExdrKuLl26MG/ePPr378+CBQscxwxNTWWoSp0LNKhfn307dzpzptepE76gx8f7wxiDkZjoXalJceSIdZ7Ro+Gccyh55BEybT+6Emav8ngK3ULftm0bBQUF7FazWw0GQ4UwLpdjiBL0hIQEYmNjy7gk5s6dy/79+4Oe45GJEwGYdvrp/o26uGvi70C5XOrWtQpx6IU9vPDy2+vk51vnAfj5ZwCkPWHpF9tNI6WkpKSEcTNm0PTVVx1RMfpM28LCQlJTUx256Q0GQ/kxgn4M0QXdi7i4OOq6JxS5uP3225FSMsYeWAU4R4nvySfD7Nlw5pllD1ThgWoG6ujRgS8yYwbcfHPQfgCg0vAq37ftyinU3gBe376dZ8eOZddNNzmiYtzose8Gg6FiGEE/hihBr4zJNHpYpcrZjvtTRwl6OCGWJ55oPRS6d/ferx46bhHWXTn228eDeo1UmyNBJiUpzACpwVB+jKAfQ7755htuu+02vwAfBfqEHHW+qGCCrlIYhBL0V16xPoWASy8tuz8lBW6/3VpWgq7EV4+CsQd1t1aw3F2gYhrPPPMMq1atqtA5DYaajhH0Y0jv3r2ZPn160HC+8nDPPfeQnp7us9a7N2hghTu6ikxfOnYsiUOGWCvBBL1ePdAnUHm5hmJi/Nt1C91tdasHSAWTb3m5YIqKihg/fjyna+MHq1atYpnKZhkG8+bNq/KaqgZDdWEEPYJ54oknOP/8830Wevs6dcjq3ZsxehIv4Ik77uClk0+2xN6dxVFHCFrHx5OsrH8vQY+N9Vda0rIy4i5rpwZn9UgXW/STQlSNAmj22Wdl0gr8/vvvgN96LygooEuXLvTq5V1LZe/evUybNs3nvvnll18YOHAgt6s3DIOhhmEEvQagBF0NtrpnaMbHxzM0NZWs3r0pvfxyYoK4fKa0a8chFYHiNXkpNtbbQndb1ErQ9Zh3W/SPhFMA4/DhMmkF3CXwvvjii6CnuOmmm7jrrrtYvny5fXnr+uvXrw99fYMhAjGCXgNQgu7O5T5q1CjGjh3rCAcUQtAggJVeLy7OEfMetsvl8GHIyHC2S0mxPnVfuG1hE47L49Ahq6mWViBHS/trXTb4RCRl0buzP7qLkxgMNQUzsagG0cCePKR89N26dWPcuHFl2tWuXdtzEk+SLXgp0dHklJQ4BT0uzhr01C103eXywgvOk6m3AF28c3Mtob7//tBf5s03oX17aNCALQUFTJ48mR9//NHRJFRxDHUfVKpftW4E3VBTMRZ6DWCDPUmoW7dugN9CDxT6F6i6khK8aR06EAtOQVfLuoWuC7qbli2tSJn//c+/LS8PPvgA1qwJfJxyF/38M/zznwA03bOHhx56iI8//tjRz1DC7BZ0ZakbQTfUVIyFXgNYbc/MdAt6oCIUsa4oGIUSQOV2+VtBAdvsfSm1a5Nz4ACn1KvH/jp1rO1ek4GuusrK237iidC3rzMF8AcfQOPGwb9M3bqwb5+1bLtd9ruKXMuoKBp++y05IcIX9fuwfft2brzxRsAIuqHmYiz0GsAQOyRRZXF0W6ZuVA6ZZ555xrFdD6ccmprKb337+tYb16kDQKvkZNarAthuCz02Fu64A266yVq3C3n4WLIE7ARkAdEHYtetgx9+4Ig7gqakhJyDBx01WvVomLTsbNpkZPC1/cBZsGsXd911F1vsVMDBqi0ZDJGMEfQawDPPPMOhQ4d8g36hXC5K0BMTE1m2bJkvK6Q7Pl6fAKVK7MXFxZGQkGC1tS1oH3XrOistafVYw8Zdwei++7yzQ/bv77D+1cBpWnY2N61dy+aCAp/7ZuqGDWzVJj0ZC91QUzGCXgOIjo521DQN5XLRBb1Hjx6+4tcDBw4s01aFQiq/e1xcHEIIbz98/frEArWUqFdE0L0mXQXKDvnTT77Fzfv3c9v69QxbvpyidetgyhSwwxVLCgtZqg3Orj10yLN0nsEQ6Rgfeg0kXJeLqoxUv359duzYQaNGjcq0XbduHc8++yyHDh3i66+/9oVGJiUllQkbjK9Vi1c6d/b54Fv8/jvby9t5r0lHuqC3bQubNlnLder43T79+/P8woXw2GOwaJHz+KIiSvTzlpQ4koQNDZSh0mCIMMKy0IUQdwshVgshVgkhZgkhElz7/yKEWCOE+EUI8YUQonXVdNcQDuFa6HrWx6ZNm/q267Ru3ZonnnjCYaGDVUzbTb9mzRziuD3cqkoXXKB3vux+3eWii6/bFZOfD171SAsLna4c+764S+cdT6xfv5677rrL+PsN5SKkoAshmgPjgV5SylOAaOB6V7Pl9v5TgTnAvyq7o4bw+ctf/sLll1/O2LFjPfcr4S6PWCQnJwNWDDvA66+/7tunXDWqjaKBaz0gDzxguUjAEt4+fZz7dQs9Nhb+8Q9rWU8Gptp5+cfdgq6NLWwJZ9ZqNTBw4ECmTZvGrx7ZKg2GQITrQ48BEoUQMUASsEPfKaX8SkqpnJSLgRaV10VDeWncuDEffvihb6KRGyXooSbm6IwbN460tDQm2gU2zjjjDPbs2cOGDRu46qqrAMq4bMJNQdavXj3/RCQhYNIkpyWuF/2IjoZ+/aBJk7InyssrmyQMygq6Ev3iYhK2baNNRoaj+AZAZmYmma687YcPH3ZUWqpK1G8TrNC2weAmpA9dSrldCDEV2ALkAZ9JKT8LcsifgQVeO4QQY4AxAK1atSp/bw2VQrNmzYDAhTa8aNiwITfccEOZbQ0bNqR58+YsW7aMyZMnO/b/HiiapG1baNYMvvsOgA15ef4MkUrA9AgdfVaraqcNAvvIy/PO7hjA5cIDD5C3eDGbP/0U4uIcfvVhnTrZ3fD3Izk5mV69epWZsVoVuGe3GgzhEI7LpT4wEGgLNANqCSGGBWg7DOgFPOG1X0o5Q0rZS0rZy2sAznBsmDp1KtOnT+fiiy+ulPMlJCQwbdo06rtS87bSC3mMHOlbbDxuHFIroL2loMAvuOpTt7RVDhjwW/KBBD0cl4uyshcv9h9nE8qvvnTpUs/tBZXsujEFPgwVIZz3uQuBTVLKPVLKIuA94Cx3IyHEhcBEYICU8vh0TBoAK6b8tttuq3Lrb4qeW/1PfwJ7AtSdp57qaNcqPt5vkSsL3e066dsXLrkE/vxna93LP799e2BB1wUyP985y9UlxuX1q2/dupWEhARmzpwZtN306dN9aRpCoQS9PG4xgyEcQd8CnCmESBKWAvQD1uoNhBDdgRexxNyUbjcArnDA2Fjq2aXrRp18sqPdlHbtiA8l6PXqwd/+5i/Q4WWhP/GEt6AXFTm3FxfDnj3+dVe0jHzkEd+ycPnWvVi3bh0Ad955Z8A2RUVF3HHHHZxyyikB2zj6YATdUAHC8aEvEULMAX4CirEiWmYIIR4Glkop52G5WJKBd2yrb4uUckDVddsQaRzu14/sU07h3RNOINUV9z00NZXt3bpxH0DHjrSOjycbyAdrcDQ7u2xZPS9BD0RhYdlwyJ07/cvKIv/lF+tTzz8jJZsLChhtizZYs1EnbtzIloICWsXHc6m976A7RYFGkV3oI1zXjPKhG0E3lIewJhZJKScBk1ybH9T2X1iZnTLUHE444QR+++034uPjadu2Lffcc49nuwnnncf5ixfTo0cPYmNjaSAE+UDS9ddzZNq0soIcbow7WLnaVcIvhZege1nYRUUQF0eeJsRjMjOtQte7d7N51y7+qyUJk1J6urJ0YS4pKXHUhPVCWehFesUngyEEJibKUKV88803fPDBByEFDKxQSJUJctq0adSrV4/cqVP55JNPeP6BB5xhkB6ToALiFnPwFnQvcnMt948WrnhEuYOmT4c776Too498+wJZ1Low79q1K2SXjcvFUBGMoBuqlKZNmzJgQPm9bzfeeCP79u0jJiaGSy65hFs6d+aWZs38oh5I0G+4wXvA1E24gn7ttfDII2UnMYE/OmaHf1rGrbfe6hmrrgtzvleyMRfK5WIsdEN5MIJuqDZ27tzJHn1wMgTPdejA6507W8WuA+R0Z/To8NwxuqDn53tPSFKkpxPjJegeD4JXXnmFu195pcx2XZjDEXRloefl5YUstWcwKIygG6qNJk2a0LBhw3Ido4pd/7tjx7I71WBrkCLYDLOnUOzc6c/sWFAQss6pcAt6RoZ/ENXFC2vX8lh6Ort372bevHn06dPHIeJ5gbJHaihBv/TSS8ukVAiHn3/+mVdffdVz35o1axBCsCpEgRBD5GEE3RCRxLlFOzkZlGUcoMQeDRrA5Zdby0VF/upJBQVWoesgFOmCfuRI2bqoWjGP0tWr+XvfvrS58koGDhzIokWL2LZtm29/eSx0xcMPP1yu3DvdunXjJlVoxMVbb70FwJw5c8I+nyEyMIJuiEjcgi5SU/2hjIEs2uJiZ7hjOQTd4UO3UxY40Ksz2WGPeXaFJIBsLY5dCXppaSmPPvoon31WNpOGW7wnTZrEl3o45VGgCnyEM1BtiCyMoBsiEndd1NHjx9M6Ph4BJNoZId2IkhKn9W4LemJRUWhBf+op/7KeikDhVcxj717f4oda1sS8vDyklKxfv54HHniASy65hO/tuqnTp0/n008/9bTGhwwZUu7ZvV4pBIyg11yMoBsiEmWhx8TEIKXkxfHjyerdm9I+fbjOTjnQvn17Rwrh+JISZL9+vqRkf+naldjYWC5MSiI+lKDraWy9Ik/smqsONNfKPC1z42c7dxIVFUVnOxUCwCVPPEFadjZ33HEHl156Kfs9rrHXfkCUJ/LFK+LGS9B3797N5MmTTf71CMcIuiEiUYLuJUB17RQDt956K2eccYZvuwodVFWXGjZsSFJSEm2FoFtGRvgX16Nbunf3/wvCAS2a51mVrXHFCt+2Q/v3+zI9ApQGSc61b98+Xn31VfZ5xde78PLXq3ump+YdP348Dz30EF988UXIcxqOX4ygGyIS5XIJJui5ubkOK1QJusoTrwR93759LJk3D4DEc86Bc84JfnEVEdO0Kdx9Nzz5JARw8/jIyfEvr1/v/jJw+DBH9HwzQQT922+/5aabbmLEiBHBr4l3qgFloeuCru7Nfj33vCHiMIJuiEjKRLloXHTRRQCceeaZnn7ili1bAlYt1aSkJHbaMenjxo3jpTlzSHzwQWsy0WOPeV/gvfesWPc33wT7XEFDJcHpd3dXIWrUyPLh626fIIL+k10cW8/LnpadTcNvvkGkpyPS033bZ2vRNQovl4sKjTx06FDw72E4rjFFog0RSTBBP+ecc8jNzaVOnTo+sdbp2rUrX3/9NWBVd/rtt98A6Nmzp5Uh8tRTGaYGXQcMANt6d+Ce2KTnfgdo0QKUmNat67TQ3X1q1Ai2brVSDCuCCLoScmVNp2Vnc9PatRTt3WtVd2rf3tf2nrVrWZeczMc5Ob5kYifaScS8BN1MYopsjIVuiEjcUS5u6tiDlE2bNuWIa9LQ//3f//Hoo48ycOBAWrRoQVZWFuAXNUfa30APDnfqAXe7Ro2sbUJAu3bO/OtuGjcuGzkTRNB/+OEHwPKPHzx4kIkbN1IEcPPN1kxZjaLCQl7YsYPNBQVIYHNBAen2tXR3laoVayz0yMYIuiEiCWahu3GX2ktOTmbixInExsbSsmVLX2hfbc0PnuKuoOQmlIUeG2sJdXKy3y3jRUyMlevdTRBB1/3c05ctY7Pyk6uHhu4HLyxEasvccw/Fq1cDcNe6db5c7+p+HjhwIHBfw2TRokXmwVBNGEE3RCTlEXQVu33NNdeU2deihb+euT7FflqHDsSCvzBG//7QurVvf5Rb0N39kdKy0mvXdk46cpOU5J3bPUT4oBr4nbx4sdVWz4mzebN/WQ9x/PVXWLYMbBcTxcW+OqrL7YeAV+TMkSNHyA32hqGxc+dO+vTpw/Dhw8Nqb6hcjA/dEJGEcrm4OXz4sOdDQBd03UJXbpdbheAgINq2RbZuDc8/D0CzWrX4PSrKn0rX7YKREgYOtHznroIeDmrV8hb0ELHmuW3bwooVFGzbBm+8AbbVDQQWdG2iE+ArqH2ktJRF9gPhf7/+yovp6bSKj2dKu3YMTU3l1FNP5bfffgurzqmyzFeuXBmyraHyMRa6ISIpj4UOkJSURIxHyt2WmjvEnQRraGoqN9rFzJ/p3Jk3zz3Xt69+XBwz7OpKAqwMkDpSwvnnw1VXWTlkApGYGF66XzetWllvBdOnO8UcnNa6PrFo+3ZnOy1M8oAdr35k/36fr31MZiZp2dm+QWMvVq1a5bDqlV++quvVGrwxgm6ISMor6IEIZKErVHx2dHQ0119/PVdffTVgCZfK/Fjapw9ZvXuzaNEiGvz1r9gN/Cdx+fAd1KpVMUGvU8dfX9WNns1Rt9C3bnW20/YJtawmIh05wpHcXCZu3BiwC6WlpXTp0oXLLrvMsQ2cMe6GY4e564aIpLwul0A0bdrUF77nlaZWxWzHxMQghOCCCy4AvCc0nXfeeYw+/XRrRXdPeD18lJulbl1o0qT8Ha9dO/CDQo/q0S10d7ik/bASgFQFOFT74cNhwAC2aBOTPvjgA19EEMB22+JftmyZb5tKS2AEvXowd90QkVSWhR4dHU3Tpk2JiYnxpQTQ6WjnXW/VqhXgj5gJlPOkvxLnQBb6iBFw4YXQu7e1Xrdu8CiYQNSpE56g6xb67t3OdvbDSurtlKDbcfNC+x6DBg3i3nvv9a3/ak+Qaq0NFquZqcblUj0YQTdEJJUl6GD50ZOTkz1F6C9/+QtfffUVF198MRBa0NU5OiQm+vzrLfXEXVdeCRMn+lP31q3rDHn8z38sV8qjjwbvdGKi/zj9XkRFwZIl/nUl0O5IGPBZ6IBf0F2DsaWuh4Ae068EXT3srMsV2t0w0lIdmCgXQ0RSWS4XsATJa0YpWBZ8nz59fOtK0ANFfCghaxgdzXe2FV5UVISS3MTYWPLAL6bKzZOQYPmvu3WzUguEoqTEb6HXqeOPYGnQwBnNUlRkuX927XIKuNqncLtcFJqLxbqsfyBVCXpj9XDCWOjVjXmMGiKSyrTQH3roIWbOnBlW20S7XmkgC71nz5707duXZ5991rdNf/g8q2qi2gOX5zZpQlJUFLzzDsydG04HrM8OHfwWuv4G4B4ofeYZuOACGDrUWk9J8e/Tk4G5XS4KrTCHtdu/f8OGDYCzALYSdGOhVw/mrhsiksq00Dt27OiwwoMRykJPSEjgyy+/pHuAdLrDmjcnq3dvhtkTg0a1bcuMjh1JqVvXcr+EondvqyJSixZ+C10/zmvWqY4+yUm32ANZ6K5sjd/n5BCVnk6bjAyWrl1rH1KoNXda6Fu3bmXy5MlIKfn+++9p1KhRyIyOpaWlYcW8G8oSlqALIe4WQqwWQqwSQswSQiS49scLId4SQmwQQiwRQrSpis4aDIrqeqVXgq67HsqDioVXSbCSk5MZmprK3nPP5Q3behdA0FpC6rsrQdfDLT0GdrGzTwJOwS4uhk8/hcWL/dsLC50DunbeGEWBnUpgc14e2zdtsg/xn9PtQx88eDAPPfQQ69at46GHHmLv3r189tlnQQX76quvNhZ+BQl514QQzYHxQC8p5SlY/9eudzX7M7BPStke+A/weGV31GA4Hgg1KBoKJVS33HILAGeffbZvnx7X/lrnzt4n0K+r3lJ0l4tXv1QoJcAdd1iRNiecYAn6Y4/B3//ut9BLS51pfLWQRMDfbs8en5tmq9be7XJRtVSllD4Rv+6663juuee8vx8wNxzXk8GTcB+DMUCiECIGSAJ2uPYPBF6zl+cA/YQZFTEcAzoHEr4qIpTLJVwuvvhipJQ09apFiivjo45+XfUnpgu6boG3bg2vvupMLdCpE4wcaT0MAqUICOYSUe206Jc1ubm0ycjghTVrfDlc1J+/qph0+PBhxz2bPXt2gK9nXC1HQ0hBl1JuB6YCW4CdQK6U0l2mvDmw1W5fDOQCKa42CCHGCCGWCiGW7nGHUBkM5eTXX38lozyl4yqBo7XQy8OZZ57pm5nqQ0pax8dza7Nm1FaZINVAKfh93tddBy+/bIm6PmFKHRMTAzt2+I/XBT1YIi5loat0vykpUFTE5oICbp082ddsc2EhbTIyyLZzu8zdssVxz9wpjRW73bHyhnIRjsulPpYF3hZoBtQSQgyryMWklDOklL2klL0a2TkyDIaK0r59e1/WwWNFZVno4ZCRkcGcOXO47777+KudUuDKlBSyevfmuQ4d+HOzW/ICQAAAFi5JREFUZgDcoKUv4OSTrc8BA3wJw+p6lcfT89o0buwcIA1mobsFPTUV1q2zXDda5NFuO5OjesA8npnJ19p5dwZI07tZe2sI56H5uzuP/B+ccFwuFwKbpJR7pJRFwHvAWa4224GWALZbpi6Qg8FQw1C+4WNhoSsee+wxzjrrrDLXVW6NHrpg//nPMHMmNGtGUlQUb3TuzM99+/p2p+gWuk5RkX9ANZCFXru235L//XdrEpMKg/z0U+eArHIH2Q+Akrw8irW+7zpwgDRXSCQ4i1p71UPVWbRoESkpKXz44YdB2/2RCEfQtwBnCiGSbL94P2Ctq808QFWsHQx8KY0zzFADSUlJoVWrVkyfPv2YXle90bZt2zZou9a1aiHatKF1fDwzOnZkaGqq4y0mT/1Z6oU7ioos4VW+di9BnzDBSlmgW+j16ztnqXoJuiI/3zFgK/PzGTVtGlHjxiHS04lJT+e29esdIh5K0BcvXgxYwh6If/3rX763G52dO3f6arPWJELOFJVSLhFCzAF+AoqB5cAMIcTDwFIp5TzgFeB1IcQG4HfKRsEYDDWCmJgYh1vgWHHuuefy/vvvOzIbKnTbKUvliNHQs0h65m8vLLREvUEDS6h3uGMesB4AMTGWoL/7LnzzjZVUTD+PLu4rV8ILL/jX8/KcA7oFBRT+85/W8tVXUwI8v2MHWVp2x1CCrt5QgtmO9913HwBTp05l4cKFXHjhhQghePTRR5k3bx5b3RkoI5ywolyklJOklJ2klKdIKW+UUhZIKR+0xRwpZb6U8hopZXsp5elSysA5Nw2GPyCbN2/2FXeuKIMGDXIkEDvttNMA6NKlS9Djor3K6HkJelKStb5pkxUFow+mFhVZxxw5As8+CwcPWrVS3efReest/7KHoPt4+GHfvk937dKaOAU9Ly+P3bt3+2L4dUGXUvLBBx84YuJ1Pv74Yy6++GIef9yKqN69e3eNLJNnovcNhmNAq1at6NWrV6Wec8iQIaxfv55LLrmE8ePH89RTTwVs26dPH+rdcYd/gz7T9tAhS4xVIY6NG6FZM6fbpLDQKd5XXgl33uk8T7ABSreg63z1lS/2vVSLttEFfdeuXSQlJZGamuobT1CC/uSTT3LDDTcwaNAgR8oF5+WtVAsv2G8N+/btCyj+wZBSHtPxk/JiBN1giGBOPPFEAKZNm8add94ZsN1XX33Fs//4h5U3BkCP31cCZUfNkJ9vpQjQhauoyJ8/p2FDGD/eCnfURT4nQBxE7drOohteKKtbi7Z5d/t22mRkIP76V05++mnf9l9++cVqqz1wVFx7IJFWVr1yl+3fv79Cgn7jjTd6v/F4sHDhwgrPKK4oRtANhj8IQ1NTfWXz0Mrp+VCCDsQ0bYrQLOrYvn0pVEKm+8p1cXMLemwsPPmk5co5dCi4qD/yCNx2Gx20B8RDv/7K5oMH4amn+P2jj8ocUuRRd9Urpz3AwYMH7S5ZbxT79++nuLi43OGnaWlpvmUppSMxmc6aNWu46KKL+PTTT8t1/qPFCLrB8AdCpReQ11zD8uXLmaxNBkIrVPFQjx7Usq35pmlpFDVq5Hev6G4W3Yp3u1zGjIHu3a2cMwsXWq6cQKxeDWvXkqlF2OQXFMCWLdY1bEHWOaynKLA5ECC+XW1X8whUgjCvh0I4SCm54447AiaJU9fb6y7MXcUYQTcY/qB069aNhg0b+tb3jBjhW27YsKHPV7xTuWm8LHTdpeAOd1QzWNVgazjoAltUZA3QAriEOi0723O26RI7r/38+fN9fnPrcOt4IQRSSp+gv/POO+H3TaOgoMCXj8bLSlfunEAPmKrCCLrB8AdGWazJyckOcW/UqJFP0FuoOHaXhS7AKehKvFSKXiXoeq6ZULgFXRXYcAnjTWvX8olHeOWCbduo99JLDBgwgHHjxmlds44vLCzk0KFDPt/2sGHDWL58OQsWLEAI4cvxHopQE6CU5W8E3WAwHDOUoDfX86TjtNAf6tTJGkxV/u3YWJKioni9c2dGa9WKKC2lVq1a9LZL0v31xBOpJYQz/DEU//2vf7mw0G+hu1wjRcAar6iaw4fJtbenL1/u26yEtaCggH379jkOuWzxYvr/+98AnPjf/9ImI8NzFquOLuj6sr/rxkI3GAzHmGCCnpaWRteuXRnZujUzOnakoW1xJ2izUN3uhtjYWJ/FenmLFjSMiyufha6jW+heeAgphw/7ZrNmaX73NPvBIKUkxzV4m11SYqUxACgtZXNBAWMyM4OKuu7O8RJ0Y6EbDIZjTiBBb9SoEYMHD2bFihVERUUxNDWV5+3EXxc2buxL7+seVNQFPTk5mS0FBeWz0HUOHoQAtV6BMtWUAGvik8ofo/dNG0Dt8fnnzmOiovzjA7ZlfaS0lIlBBnFXrVrlWzYWusFgOC4IJOj13bVJ8U+xV8dAWUGPi4tzCHqr+HhvC33CBKveqR1H78m6ddZnIAs/kIWu/Pr624MeJeN21URH+ydRaQK8JUjqgQEDBmjdMBa6wWA4DlDi3MyOQV+6dClTp071nDyjhEuP9U52Wd+6hZ6YmMiUdu2IS3BUrLS47DJSunXjjW++4fKXXoKbby7bZuVK67NrV+d2IaxZp4EsdPWQCZTj3Z0euLTU/3DQ9kWBr35qMPfL8WShh0zOZTAYai7KEj/hhBMA6NmzJz179vRsq0RKF/SpU6fSrl07vvzyS7744gtiY2N9/uX4+HiGpqbyVbNmvOI6l9SKcg+9+Wbq5uVRRvq2bYNGjRwTnujZ0yqLd8EF1vo558CuXaCiUw4f9gu9Lug5OZbr59ChsoL+669W+gFwCH/JsmXQqRObgTGZmZ73BIyFbjAYjhNOOukkvvvuOy699NKQbZXlHafFoderV4/777+fevXq+fYtWLCAsWPHkmr72XuHUYTk3o4dvXd06OCsyOR+2HTt6kzbe/gwqLS4bteKKgTi3v6f//iXc3MtUczNhXvugYceAiyf+rC17qzhFsEs9Nxg1Z+qACPoBsMfnLPOOstXuCMYfWyr+oYbbiizT6XojY2NpXv37rzwwgu+cw4ePJiLLrqIsWPHBjz3NdosVQetW1szTRW6uIOVo11hP1QIlB9djRO4whYdHDhAKfgzR65fH7itTX5+PmnZ2bTJyPC5aDLsh8YBu5CHvi9USOTRYFwuBoMhLE466aSAuU/q2AOXXlPh69aty2efWWWIX3zxRc/j3b54H61bO3PA6OL+yCN+EbcuVNadkpDg948rQXe3UXnewd9WXbO42PLXP/AAnOUu1GbxeXY2L2Vm+nLNby4oYMf27dalDhxg9Lp15C1YAOed53DfBCwEfhQYC91gMBw1StBj3KXtwiTJlR4gqlMna6FFC6eI62kHVF1i9ZDxcu3oD4pAFnpxsXWN00/3+9+VsBcXW774776DJ55wHDZ+/HgA0rZu9RcOsUMdlQ+9uLCQvLVr4fHHrQcQoUMijwYj6AaD4ahpYOdSzwuVJjcA9evX58knn/Stl06aBIMHWz50PWxRF3cl1sEEXZXVszppfe7bV9Z106WLVfDaS9ADhC82adIEgL0qxv2776yarl9+6QyZ3LbN+ly82AqfHDWKzVWUhdEIusFgOGpUHpijGQS8++67/StNmsDtt1vuEN2/rol7ojs+3UvQdctfWfelpVY9VHe7+PiyLpeSEtBiznUmK0tf+du3bLE+163zFnSwomw2bSKlglkeQ2F86AaD4ahRgh4qTG/ixIlBc5CPGjWK92JicHi5bUsY8LtNgBd69ODBLVvYHK7LRXcHpaQ4a6fWqmVZ7QUFlsXvNWnJRaF6KChBV+MHhYX+VAIAet1S+yEwNESx74piBN1gMBw14Vrojz76aND9r7zyChdkZzNGG2TUxfH13r250V4e3rw5w5s354w6dfgBnAOkCt3lovvflftFoSz00lLLZx6O68gt6Mr1UlDgfHh8+aVvsdGBA+wB+rdsGfr8FcC4XAwGw1GjBD1QBZ/yoFdWEkDr+Hgmf/QRixYtYphurbvRLXTljtEFXRdZLVWwr52KZ09LCy3oLVv60xYoQVfRMzk5ZbJDKvrbnwGjeo4SY6EbDIajJiUlpVLPNzQ1NWBYX/v27R15y30uHN2nrvK56IKuh1S6BT0pyT/g+r//Be/cyJEwfLiVgiAurqyg79oFelphjTR7cpKK269sjIVuMBiOmqoSKC9WrlzpqxGqE68iVy64wFcaL1Hr1zA9AZnrAfTn9u2JDlCPtAy1avmTecXF+a1x5W7autUKX9RdPHfdBUDxnj1ANQq6EKKjEGKF9u+AEOIuV5u6Qoj5QoifhRCrhRA3VUlvDQbDcYmwBe6sAJNvKpOEhASHy0JZ6H874QRafvEF3H8/wrbQHzv1VF+7qZ07+0/iEvQLmzUjUbfmg6G7blRkzBtvwPLloOLn1651vjEo94ydi/28tWurZMZoSEGXUmZKKbtJKbsBPYEjwPuuZrcDa6SUXYE+wL+FEHEYDIY/DDk5OXzxxRfVdv3+jRqx5YILkP36Ef3/7d1/aFX3Gcfx95Pc6I016ow2c9MZgz/qD1YnsmntH7bSzkrNJggaZJYpZLINHYxuEWEwRpFSWFepWJ0dgzGaEZaR4h92zvZPqbOtrXZOq0y3ajetqx3KGOt89sf5npuT602amHNzuSefF1xyzvecJN8nHp/7vc8553vCCH1iqKvncrk+c9CcWbOmz/fW19dzc7A3RSVLNxMmwKVL8OKL0RU1mzf3nsSN3yBmzOi9fDIk9PdzOb5x5gzfHsTUAkMx1Br6KuCCu18qanegwaK36fHAP4Hhnx0RkaoxufjKkRESj9DjTwlA4ZmhcUIfM2ZMn1kiZxbNHZPP52lqaGBQY+ZkQp80qfcxedu3w/Ll0eWPt25F++3dG11qGd+cdP16NP96XR0OvHDlCismTkxtGoCh1tA3Ai+VaH8emA9cAU4BO9z9dvFOZtZuZifM7MS1UEsSERmOUgk9bosTel1dHePGjePgwYOcPXuW+vp6Vq1aVdg/n8/z3TCFMFOmQHt732l7k5Ij+eT8MfGIPK7l53KwYEG0T9x240a0HPrqkOo0AINO6KGE0gp0ldj8VeAk8DlgMfC8md3xmBF3P+DuS9196dR4HgYRkRQkE3osOUIH2Lp1K3PnzgXg8OHDhf3y+TxfDwk8V18PbW3w5JOlf1Fy2oDkte9xQo+vlkkm/uQdq0Xz1gz0ZKShGsoI/THgTXcv9ankm0C3R84DfwHuS6ODIiIDiR/IManEjUUDzQKZfCpT8rF6D8yaha9cyfEVK0r+vnUtLRTeOgZK6MnfWVvbe9VL0TwyXxjs1TWDMJSE3kbpcgvAX4nq65hZEzAPKM90YiIiCXv27OHYsWOFpy4B9PT00NraWkjapRJ6ckSfz+dZuHAhu3fvprOzE4hOlJby9JIl/Gr+fGaOHTtwQi9+jF+8PXE1zbiaGp5qaRlUnIMxqIRuZvcAjwDdibZtZrYtrP4EeMDMTgFHgR+6+4ep9VJEpB/5fJ5ly5b1aWttbaWnp6cwjW3yCpf+foaZ0dHRwbRp04D+E3pjYyObmpq4uHw5XclRfFxKib+v+E0kniogfG3M5Tgwb16q86IP6ioXd78FNBa1vZBYvgI8mlqvRERSECfnjo6OAffLl3iQdTKhd3Z2snHjRqBvaWdGYk6W+oYG/h39sKhhwgSM6MQncEdCH19bm/pDLnSnqIhkVkNDA+7Oli1bBtxvbIk6djKhb9iwobCcfFzfnPiGIeDnCxdGZZiQ0B+fPZvbK1f21tvjG41CQk/zZGihb6n/RBGRKlNqhF78FKVSktfex2WYtjBPzEOhNl446RnX1ENCT/NkaEwJXURGvVIj9E+ru/fn5s2bADSFcspTLS2Mq6npnf8ln0/9ZGhMsy2KyKhX6hr24rb29vaS097u27eP5I2St8K86PeGGRfjOvm3amu5BTTW1fFcyidDY0roIiKDsH///pLt27Zt67MezwSZnFFxU1MT9z/zDF87d45j27cXkn3aVHIREUnR2rVrAWhubu7TvmjRIi5cuFC2ZA5K6CIiqdq1axfXrl3jswM9XalMVHIREelHV1fXkEfUNTU1hUfyjTQldBGRfqxfv77SXRgSlVxERDJCCV1EJCNUchGRUau7u5vcYB89VwWyE4mIyBCtW7eu0l1IlUouIiIZoYQuIpIRSugiIhmhhC4ikhFK6CIiGaGELiKSEUroIiIZoYQuIpIR5u6fvlc5frHZNeDSXX77FODDFLtTDRTz6KCYR4fhxDzT3aeW2lCxhD4cZnbC3ZdWuh8jSTGPDop5dChXzCq5iIhkhBK6iEhGVGtCP1DpDlSAYh4dFPPoUJaYq7KGLiIid6rWEbqIiBRRQhcRyYiqS+hmttrMzprZeTPrqHR/0mJmvzCzq2Z2OtE22cyOmNl74etnQruZ2Z7wN3jHzJZUrud3z8xmmNlrZvYnM3vXzHaE9szGbWZ5MztuZm+HmH8c2meZ2eshtt+Y2ZjQPjasnw/bmyvZ/7tlZrVm9paZHQrrmY4XwMwumtkpMztpZidCW1mP7apK6GZWC+wFHgMWAG1mtqCyvUrNL4HVRW0dwFF3nwMcDesQxT8nvNqBfSPUx7R9Anzf3RcAy4DvhH/PLMf9H+Bhd78fWAysNrNlwNPAs+4+G/gI2Br23wp8FNqfDftVox3AmcR61uONPeTuixPXnJf32Hb3qnkBy4FXEus7gZ2V7leK8TUDpxPrZ4FpYXkacDYs7wfaSu1XzS+gB3hktMQNjAPeBL5CdNdgLrQXjnPgFWB5WM6F/azSfR9inNND8noYOARYluNNxH0RmFLUVtZju6pG6MDngb8l1t8PbVnV5O4fhOW/A01hOXN/h/DR+kvA62Q87lB+OAlcBY4AF4Ab7v5J2CUZVyHmsP1joHFkezxsPwN+ANwO641kO96YA783szfMrD20lfXY1kOiq4S7u5ll8hpTMxsP/Bb4nrv/y8wK27IYt7v/D1hsZpOA3wH3VbhLZWNmjwNX3f0NM1tZ6f6MsAfd/bKZ3QscMbM/JzeW49iuthH6ZWBGYn16aMuqf5jZNIDw9Wpoz8zfwczqiJL5r929OzRnPm4Ad78BvEZUcphkZvEAKxlXIeawfSJwfYS7OhwrgFYzuwh0EpVdniO78Ra4++Xw9SrRG/eXKfOxXW0J/Y/AnHCGfAywEXi5wn0qp5eBJ8LyE0Q15rh9czgzvgz4OPExrmpYNBR/ETjj7j9NbMps3GY2NYzMMbN6onMGZ4gS+/qwW3HM8d9iPfCqhyJrNXD3ne4+3d2bif6/vurum8hovDEzu8fMGuJl4FHgNOU+tit94uAuTjSsAc4R1R13Vbo/Kcb1EvAB8F+i+tlWotrhUeA94A/A5LCvEV3tcwE4BSytdP/vMuYHieqM7wAnw2tNluMGvgi8FWI+DfwotLcAx4HzQBcwNrTnw/r5sL2l0jEMI/aVwKHREG+I7+3wejfOVeU+tnXrv4hIRlRbyUVERPqhhC4ikhFK6CIiGaGELiKSEUroIiIZoYQuIpIRSugiIhnxf0g3t+A2qr33AAAAAElFTkSuQmCC\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "epochs_x"
      ],
      "metadata": {
        "id": "N_sP_ZmSY-Jv",
        "outputId": "681ad3fe-dce5-4d8c-e309-d98e06827b18",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "range(0, 500)"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Download the model\n"
      ],
      "metadata": {
        "id": "R19IJQSYoW7J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "os.makedirs('/content/drive/My Drive/cut_panoramic/Model', exist_ok=True)\n",
        "model.save('/content/drive/My Drive/cut_panoramic/Model/2e-5_32_0.2_Male18_500.h5')"
      ],
      "metadata": {
        "id": "Zed4TdFcG2iJ"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "n5YxZ-5QjQ0-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# from google.colab import files\n",
        "# files.download('/content/drive/My Drive/cut_panoramic/Model/1.1_รอบแรก_Flimpano_Male125_250.h5')"
      ],
      "metadata": {
        "id": "P5eMxm1NV-oY"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "wY_pDlxkRwxS"
      },
      "execution_count": 24,
      "outputs": []
    }
  ]
}