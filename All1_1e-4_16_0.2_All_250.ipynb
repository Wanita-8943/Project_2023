{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Wanita-8943/Project_2023/blob/main/All1_1e-4_16_0.2_All_250.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#เรียกใช้ CSV"
      ],
      "metadata": {
        "id": "ow7eWoNw6U-c"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "z8o_VVNXzcL8"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import shutil"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1_2Fe8u81d5r",
        "outputId": "13d9bdf6-c7fa-445a-bb7c-883d1fe385d5"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Imports"
      ],
      "metadata": {
        "id": "5qxePnnn7TGW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import models\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import optimizers\n",
        "import os\n",
        "import glob\n",
        "import shutil\n",
        "import sys\n",
        "import numpy as np\n",
        "from skimage.io import imread\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import Image\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "D-hCRloc3t39"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras import backend as K"
      ],
      "metadata": {
        "id": "YZWXwjXeGxZP"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#กำหนดค่าพารามิเตอร์\n"
      ],
      "metadata": {
        "id": "RooqSdBc7QHC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 16\n",
        "width = 150\n",
        "height = 150\n",
        "epochs = 250\n",
        "NUM_TRAIN = 2850\n",
        "NUM_TEST = 950\n",
        "dropout_rate = 0.2\n",
        "input_shape = (height, width, 3)"
      ],
      "metadata": {
        "id": "thDb7U9B3xOo"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Clone efficientnet repo\n"
      ],
      "metadata": {
        "id": "pumGmy6f3eSW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#ดึงข้อมูลใน Github มาใช้\n",
        "import os\n",
        "%cd /content\n",
        "if not os.path.isdir(\"efficientnet_keras_transfer_learning\"):\n",
        " !git clone https://github.com/Wanita-8943/efficientnet_keras_transfer_learning\n",
        "%cd efficientnet_keras_transfer_learning/\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P7iy2f8n16p0",
        "outputId": "5df9573e-5aae-497c-f168-ab9916ed2c41"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "Cloning into 'efficientnet_keras_transfer_learning'...\n",
            "remote: Enumerating objects: 837, done.\u001b[K\n",
            "remote: Counting objects: 100% (359/359), done.\u001b[K\n",
            "remote: Compressing objects: 100% (124/124), done.\u001b[K\n",
            "remote: Total 837 (delta 255), reused 328 (delta 235), pack-reused 478\u001b[K\n",
            "Receiving objects: 100% (837/837), 13.82 MiB | 26.15 MiB/s, done.\n",
            "Resolving deltas: 100% (495/495), done.\n",
            "/content/efficientnet_keras_transfer_learning\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Options: EfficientNetB0, EfficientNetB1, EfficientNetB2, EfficientNetB3\n",
        "# Higher the number, the more complex the model is.\n",
        "from efficientnet import EfficientNetB0 as Net\n",
        "from efficientnet import center_crop_and_resize, preprocess_input"
      ],
      "metadata": {
        "id": "tjZBRnfo3bN0"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# loading pretrained conv base model\n",
        "# โหลดโมเดล มาโดยตัด output ของโมเดลออก เเต่ยังใช้ input อันเดิม\n",
        "# เเละโหลด weight ของโมเดล มาด้วยที่ชื่อว่า imagenet\n",
        "conv_base = Net(weights='imagenet', include_top=False, input_shape=input_shape)"
      ],
      "metadata": {
        "id": "hNZAzbDp3lgA",
        "outputId": "f3be1999-6753-472e-f80c-0f682ead14a3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
            "Instructions for updating:\n",
            "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://github.com/qubvel/efficientnet/releases/download/v0.0.1/efficientnet-b0_imagenet_1000_notop.h5\n",
            "16717576/16717576 [==============================] - 1s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = models.Sequential()\n",
        "model.add(conv_base)\n",
        "model.add(layers.GlobalMaxPooling2D(name=\"gap\"))\n",
        "# model.add(layers.Flatten(name=\"flatten\"))\n",
        "if dropout_rate > 0:\n",
        "    model.add(layers.Dropout(dropout_rate, name=\"dropout_out\"))\n",
        "# model.add(layers.Dense(256, activation='relu', name=\"fc1\"))\n",
        "model.add(layers.Dense(19, activation='softmax', name=\"fc_out\"))\n",
        "model.add(layers.Dense(1))"
      ],
      "metadata": {
        "id": "yWNKfQUt5rga"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "NadBB12251jh",
        "outputId": "551f99ad-46c4-4d0f-faf2-95888b718855",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " efficientnet-b0 (Functional  (None, 5, 5, 1280)       4049564   \n",
            " )                                                               \n",
            "                                                                 \n",
            " gap (GlobalMaxPooling2D)    (None, 1280)              0         \n",
            "                                                                 \n",
            " dropout_out (Dropout)       (None, 1280)              0         \n",
            "                                                                 \n",
            " fc_out (Dense)              (None, 19)                24339     \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1)                 20        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4,073,923\n",
            "Trainable params: 4,031,907\n",
            "Non-trainable params: 42,016\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('This is the number of trainable layers '\n",
        "      'before freezing the conv base:', len(model.trainable_weights))\n",
        "\n",
        "conv_base.trainable = False\n",
        "\n",
        "print('This is the number of trainable layers '\n",
        "      'after freezing the conv base:', len(model.trainable_weights))"
      ],
      "metadata": {
        "id": "GepWq3yy53t5",
        "outputId": "89c9f38e-72a9-4fad-e857-aa71ee3044d5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This is the number of trainable layers before freezing the conv base: 215\n",
            "This is the number of trainable layers after freezing the conv base: 4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "veq6Mp-GYE2V",
        "outputId": "5431b83b-2ed3-467d-92a5-325d93702875"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " efficientnet-b0 (Functional  (None, 5, 5, 1280)       4049564   \n",
            " )                                                               \n",
            "                                                                 \n",
            " gap (GlobalMaxPooling2D)    (None, 1280)              0         \n",
            "                                                                 \n",
            " dropout_out (Dropout)       (None, 1280)              0         \n",
            "                                                                 \n",
            " fc_out (Dense)              (None, 19)                24339     \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1)                 20        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4,073,923\n",
            "Trainable params: 24,359\n",
            "Non-trainable params: 4,049,564\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "conv_base.summary() #ดู Summary"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iD76D6c_79py",
        "outputId": "9e9ae9d1-9f79-4374-f9eb-2fe9002d6a1d"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"efficientnet-b0\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 150, 150, 3  0           []                               \n",
            "                                )]                                                                \n",
            "                                                                                                  \n",
            " conv2d (Conv2D)                (None, 75, 75, 32)   864         ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " batch_normalization (BatchNorm  (None, 75, 75, 32)  128         ['conv2d[0][0]']                 \n",
            " alization)                                                                                       \n",
            "                                                                                                  \n",
            " swish (Swish)                  (None, 75, 75, 32)   0           ['batch_normalization[0][0]']    \n",
            "                                                                                                  \n",
            " depthwise_conv2d (DepthwiseCon  (None, 75, 75, 32)  288         ['swish[0][0]']                  \n",
            " v2D)                                                                                             \n",
            "                                                                                                  \n",
            " batch_normalization_1 (BatchNo  (None, 75, 75, 32)  128         ['depthwise_conv2d[0][0]']       \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " swish_1 (Swish)                (None, 75, 75, 32)   0           ['batch_normalization_1[0][0]']  \n",
            "                                                                                                  \n",
            " lambda (Lambda)                (None, 1, 1, 32)     0           ['swish_1[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d_1 (Conv2D)              (None, 1, 1, 8)      264         ['lambda[0][0]']                 \n",
            "                                                                                                  \n",
            " swish_2 (Swish)                (None, 1, 1, 8)      0           ['conv2d_1[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_2 (Conv2D)              (None, 1, 1, 32)     288         ['swish_2[0][0]']                \n",
            "                                                                                                  \n",
            " activation (Activation)        (None, 1, 1, 32)     0           ['conv2d_2[0][0]']               \n",
            "                                                                                                  \n",
            " multiply (Multiply)            (None, 75, 75, 32)   0           ['activation[0][0]',             \n",
            "                                                                  'swish_1[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d_3 (Conv2D)              (None, 75, 75, 16)   512         ['multiply[0][0]']               \n",
            "                                                                                                  \n",
            " batch_normalization_2 (BatchNo  (None, 75, 75, 16)  64          ['conv2d_3[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv2d_4 (Conv2D)              (None, 75, 75, 96)   1536        ['batch_normalization_2[0][0]']  \n",
            "                                                                                                  \n",
            " batch_normalization_3 (BatchNo  (None, 75, 75, 96)  384         ['conv2d_4[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " swish_3 (Swish)                (None, 75, 75, 96)   0           ['batch_normalization_3[0][0]']  \n",
            "                                                                                                  \n",
            " depthwise_conv2d_1 (DepthwiseC  (None, 38, 38, 96)  864         ['swish_3[0][0]']                \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_4 (BatchNo  (None, 38, 38, 96)  384         ['depthwise_conv2d_1[0][0]']     \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " swish_4 (Swish)                (None, 38, 38, 96)   0           ['batch_normalization_4[0][0]']  \n",
            "                                                                                                  \n",
            " lambda_1 (Lambda)              (None, 1, 1, 96)     0           ['swish_4[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d_5 (Conv2D)              (None, 1, 1, 4)      388         ['lambda_1[0][0]']               \n",
            "                                                                                                  \n",
            " swish_5 (Swish)                (None, 1, 1, 4)      0           ['conv2d_5[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_6 (Conv2D)              (None, 1, 1, 96)     480         ['swish_5[0][0]']                \n",
            "                                                                                                  \n",
            " activation_1 (Activation)      (None, 1, 1, 96)     0           ['conv2d_6[0][0]']               \n",
            "                                                                                                  \n",
            " multiply_1 (Multiply)          (None, 38, 38, 96)   0           ['activation_1[0][0]',           \n",
            "                                                                  'swish_4[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d_7 (Conv2D)              (None, 38, 38, 24)   2304        ['multiply_1[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_5 (BatchNo  (None, 38, 38, 24)  96          ['conv2d_7[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv2d_8 (Conv2D)              (None, 38, 38, 144)  3456        ['batch_normalization_5[0][0]']  \n",
            "                                                                                                  \n",
            " batch_normalization_6 (BatchNo  (None, 38, 38, 144)  576        ['conv2d_8[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " swish_6 (Swish)                (None, 38, 38, 144)  0           ['batch_normalization_6[0][0]']  \n",
            "                                                                                                  \n",
            " depthwise_conv2d_2 (DepthwiseC  (None, 38, 38, 144)  1296       ['swish_6[0][0]']                \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_7 (BatchNo  (None, 38, 38, 144)  576        ['depthwise_conv2d_2[0][0]']     \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " swish_7 (Swish)                (None, 38, 38, 144)  0           ['batch_normalization_7[0][0]']  \n",
            "                                                                                                  \n",
            " lambda_2 (Lambda)              (None, 1, 1, 144)    0           ['swish_7[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d_9 (Conv2D)              (None, 1, 1, 6)      870         ['lambda_2[0][0]']               \n",
            "                                                                                                  \n",
            " swish_8 (Swish)                (None, 1, 1, 6)      0           ['conv2d_9[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_10 (Conv2D)             (None, 1, 1, 144)    1008        ['swish_8[0][0]']                \n",
            "                                                                                                  \n",
            " activation_2 (Activation)      (None, 1, 1, 144)    0           ['conv2d_10[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_2 (Multiply)          (None, 38, 38, 144)  0           ['activation_2[0][0]',           \n",
            "                                                                  'swish_7[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d_11 (Conv2D)             (None, 38, 38, 24)   3456        ['multiply_2[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_8 (BatchNo  (None, 38, 38, 24)  96          ['conv2d_11[0][0]']              \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " drop_connect (DropConnect)     (None, 38, 38, 24)   0           ['batch_normalization_8[0][0]']  \n",
            "                                                                                                  \n",
            " add (Add)                      (None, 38, 38, 24)   0           ['drop_connect[0][0]',           \n",
            "                                                                  'batch_normalization_5[0][0]']  \n",
            "                                                                                                  \n",
            " conv2d_12 (Conv2D)             (None, 38, 38, 144)  3456        ['add[0][0]']                    \n",
            "                                                                                                  \n",
            " batch_normalization_9 (BatchNo  (None, 38, 38, 144)  576        ['conv2d_12[0][0]']              \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " swish_9 (Swish)                (None, 38, 38, 144)  0           ['batch_normalization_9[0][0]']  \n",
            "                                                                                                  \n",
            " depthwise_conv2d_3 (DepthwiseC  (None, 19, 19, 144)  3600       ['swish_9[0][0]']                \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_10 (BatchN  (None, 19, 19, 144)  576        ['depthwise_conv2d_3[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_10 (Swish)               (None, 19, 19, 144)  0           ['batch_normalization_10[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_3 (Lambda)              (None, 1, 1, 144)    0           ['swish_10[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_13 (Conv2D)             (None, 1, 1, 6)      870         ['lambda_3[0][0]']               \n",
            "                                                                                                  \n",
            " swish_11 (Swish)               (None, 1, 1, 6)      0           ['conv2d_13[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_14 (Conv2D)             (None, 1, 1, 144)    1008        ['swish_11[0][0]']               \n",
            "                                                                                                  \n",
            " activation_3 (Activation)      (None, 1, 1, 144)    0           ['conv2d_14[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_3 (Multiply)          (None, 19, 19, 144)  0           ['activation_3[0][0]',           \n",
            "                                                                  'swish_10[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_15 (Conv2D)             (None, 19, 19, 40)   5760        ['multiply_3[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_11 (BatchN  (None, 19, 19, 40)  160         ['conv2d_15[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_16 (Conv2D)             (None, 19, 19, 240)  9600        ['batch_normalization_11[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_12 (BatchN  (None, 19, 19, 240)  960        ['conv2d_16[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_12 (Swish)               (None, 19, 19, 240)  0           ['batch_normalization_12[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_4 (DepthwiseC  (None, 19, 19, 240)  6000       ['swish_12[0][0]']               \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_13 (BatchN  (None, 19, 19, 240)  960        ['depthwise_conv2d_4[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_13 (Swish)               (None, 19, 19, 240)  0           ['batch_normalization_13[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_4 (Lambda)              (None, 1, 1, 240)    0           ['swish_13[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_17 (Conv2D)             (None, 1, 1, 10)     2410        ['lambda_4[0][0]']               \n",
            "                                                                                                  \n",
            " swish_14 (Swish)               (None, 1, 1, 10)     0           ['conv2d_17[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_18 (Conv2D)             (None, 1, 1, 240)    2640        ['swish_14[0][0]']               \n",
            "                                                                                                  \n",
            " activation_4 (Activation)      (None, 1, 1, 240)    0           ['conv2d_18[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_4 (Multiply)          (None, 19, 19, 240)  0           ['activation_4[0][0]',           \n",
            "                                                                  'swish_13[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_19 (Conv2D)             (None, 19, 19, 40)   9600        ['multiply_4[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_14 (BatchN  (None, 19, 19, 40)  160         ['conv2d_19[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_1 (DropConnect)   (None, 19, 19, 40)   0           ['batch_normalization_14[0][0]'] \n",
            "                                                                                                  \n",
            " add_1 (Add)                    (None, 19, 19, 40)   0           ['drop_connect_1[0][0]',         \n",
            "                                                                  'batch_normalization_11[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_20 (Conv2D)             (None, 19, 19, 240)  9600        ['add_1[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_15 (BatchN  (None, 19, 19, 240)  960        ['conv2d_20[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_15 (Swish)               (None, 19, 19, 240)  0           ['batch_normalization_15[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_5 (DepthwiseC  (None, 10, 10, 240)  2160       ['swish_15[0][0]']               \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_16 (BatchN  (None, 10, 10, 240)  960        ['depthwise_conv2d_5[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_16 (Swish)               (None, 10, 10, 240)  0           ['batch_normalization_16[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_5 (Lambda)              (None, 1, 1, 240)    0           ['swish_16[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_21 (Conv2D)             (None, 1, 1, 10)     2410        ['lambda_5[0][0]']               \n",
            "                                                                                                  \n",
            " swish_17 (Swish)               (None, 1, 1, 10)     0           ['conv2d_21[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_22 (Conv2D)             (None, 1, 1, 240)    2640        ['swish_17[0][0]']               \n",
            "                                                                                                  \n",
            " activation_5 (Activation)      (None, 1, 1, 240)    0           ['conv2d_22[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_5 (Multiply)          (None, 10, 10, 240)  0           ['activation_5[0][0]',           \n",
            "                                                                  'swish_16[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_23 (Conv2D)             (None, 10, 10, 80)   19200       ['multiply_5[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_17 (BatchN  (None, 10, 10, 80)  320         ['conv2d_23[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_24 (Conv2D)             (None, 10, 10, 480)  38400       ['batch_normalization_17[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_18 (BatchN  (None, 10, 10, 480)  1920       ['conv2d_24[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_18 (Swish)               (None, 10, 10, 480)  0           ['batch_normalization_18[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_6 (DepthwiseC  (None, 10, 10, 480)  4320       ['swish_18[0][0]']               \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_19 (BatchN  (None, 10, 10, 480)  1920       ['depthwise_conv2d_6[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_19 (Swish)               (None, 10, 10, 480)  0           ['batch_normalization_19[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_6 (Lambda)              (None, 1, 1, 480)    0           ['swish_19[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_25 (Conv2D)             (None, 1, 1, 20)     9620        ['lambda_6[0][0]']               \n",
            "                                                                                                  \n",
            " swish_20 (Swish)               (None, 1, 1, 20)     0           ['conv2d_25[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_26 (Conv2D)             (None, 1, 1, 480)    10080       ['swish_20[0][0]']               \n",
            "                                                                                                  \n",
            " activation_6 (Activation)      (None, 1, 1, 480)    0           ['conv2d_26[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_6 (Multiply)          (None, 10, 10, 480)  0           ['activation_6[0][0]',           \n",
            "                                                                  'swish_19[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_27 (Conv2D)             (None, 10, 10, 80)   38400       ['multiply_6[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_20 (BatchN  (None, 10, 10, 80)  320         ['conv2d_27[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_2 (DropConnect)   (None, 10, 10, 80)   0           ['batch_normalization_20[0][0]'] \n",
            "                                                                                                  \n",
            " add_2 (Add)                    (None, 10, 10, 80)   0           ['drop_connect_2[0][0]',         \n",
            "                                                                  'batch_normalization_17[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_28 (Conv2D)             (None, 10, 10, 480)  38400       ['add_2[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_21 (BatchN  (None, 10, 10, 480)  1920       ['conv2d_28[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_21 (Swish)               (None, 10, 10, 480)  0           ['batch_normalization_21[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_7 (DepthwiseC  (None, 10, 10, 480)  4320       ['swish_21[0][0]']               \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_22 (BatchN  (None, 10, 10, 480)  1920       ['depthwise_conv2d_7[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_22 (Swish)               (None, 10, 10, 480)  0           ['batch_normalization_22[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_7 (Lambda)              (None, 1, 1, 480)    0           ['swish_22[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_29 (Conv2D)             (None, 1, 1, 20)     9620        ['lambda_7[0][0]']               \n",
            "                                                                                                  \n",
            " swish_23 (Swish)               (None, 1, 1, 20)     0           ['conv2d_29[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_30 (Conv2D)             (None, 1, 1, 480)    10080       ['swish_23[0][0]']               \n",
            "                                                                                                  \n",
            " activation_7 (Activation)      (None, 1, 1, 480)    0           ['conv2d_30[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_7 (Multiply)          (None, 10, 10, 480)  0           ['activation_7[0][0]',           \n",
            "                                                                  'swish_22[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_31 (Conv2D)             (None, 10, 10, 80)   38400       ['multiply_7[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_23 (BatchN  (None, 10, 10, 80)  320         ['conv2d_31[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_3 (DropConnect)   (None, 10, 10, 80)   0           ['batch_normalization_23[0][0]'] \n",
            "                                                                                                  \n",
            " add_3 (Add)                    (None, 10, 10, 80)   0           ['drop_connect_3[0][0]',         \n",
            "                                                                  'add_2[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_32 (Conv2D)             (None, 10, 10, 480)  38400       ['add_3[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_24 (BatchN  (None, 10, 10, 480)  1920       ['conv2d_32[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_24 (Swish)               (None, 10, 10, 480)  0           ['batch_normalization_24[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_8 (DepthwiseC  (None, 10, 10, 480)  12000      ['swish_24[0][0]']               \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_25 (BatchN  (None, 10, 10, 480)  1920       ['depthwise_conv2d_8[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_25 (Swish)               (None, 10, 10, 480)  0           ['batch_normalization_25[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_8 (Lambda)              (None, 1, 1, 480)    0           ['swish_25[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_33 (Conv2D)             (None, 1, 1, 20)     9620        ['lambda_8[0][0]']               \n",
            "                                                                                                  \n",
            " swish_26 (Swish)               (None, 1, 1, 20)     0           ['conv2d_33[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_34 (Conv2D)             (None, 1, 1, 480)    10080       ['swish_26[0][0]']               \n",
            "                                                                                                  \n",
            " activation_8 (Activation)      (None, 1, 1, 480)    0           ['conv2d_34[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_8 (Multiply)          (None, 10, 10, 480)  0           ['activation_8[0][0]',           \n",
            "                                                                  'swish_25[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_35 (Conv2D)             (None, 10, 10, 112)  53760       ['multiply_8[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_26 (BatchN  (None, 10, 10, 112)  448        ['conv2d_35[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_36 (Conv2D)             (None, 10, 10, 672)  75264       ['batch_normalization_26[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_27 (BatchN  (None, 10, 10, 672)  2688       ['conv2d_36[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_27 (Swish)               (None, 10, 10, 672)  0           ['batch_normalization_27[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_9 (DepthwiseC  (None, 10, 10, 672)  16800      ['swish_27[0][0]']               \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_28 (BatchN  (None, 10, 10, 672)  2688       ['depthwise_conv2d_9[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_28 (Swish)               (None, 10, 10, 672)  0           ['batch_normalization_28[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_9 (Lambda)              (None, 1, 1, 672)    0           ['swish_28[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_37 (Conv2D)             (None, 1, 1, 28)     18844       ['lambda_9[0][0]']               \n",
            "                                                                                                  \n",
            " swish_29 (Swish)               (None, 1, 1, 28)     0           ['conv2d_37[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_38 (Conv2D)             (None, 1, 1, 672)    19488       ['swish_29[0][0]']               \n",
            "                                                                                                  \n",
            " activation_9 (Activation)      (None, 1, 1, 672)    0           ['conv2d_38[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_9 (Multiply)          (None, 10, 10, 672)  0           ['activation_9[0][0]',           \n",
            "                                                                  'swish_28[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_39 (Conv2D)             (None, 10, 10, 112)  75264       ['multiply_9[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_29 (BatchN  (None, 10, 10, 112)  448        ['conv2d_39[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_4 (DropConnect)   (None, 10, 10, 112)  0           ['batch_normalization_29[0][0]'] \n",
            "                                                                                                  \n",
            " add_4 (Add)                    (None, 10, 10, 112)  0           ['drop_connect_4[0][0]',         \n",
            "                                                                  'batch_normalization_26[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_40 (Conv2D)             (None, 10, 10, 672)  75264       ['add_4[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_30 (BatchN  (None, 10, 10, 672)  2688       ['conv2d_40[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_30 (Swish)               (None, 10, 10, 672)  0           ['batch_normalization_30[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_10 (Depthwise  (None, 10, 10, 672)  16800      ['swish_30[0][0]']               \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_31 (BatchN  (None, 10, 10, 672)  2688       ['depthwise_conv2d_10[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_31 (Swish)               (None, 10, 10, 672)  0           ['batch_normalization_31[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_10 (Lambda)             (None, 1, 1, 672)    0           ['swish_31[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_41 (Conv2D)             (None, 1, 1, 28)     18844       ['lambda_10[0][0]']              \n",
            "                                                                                                  \n",
            " swish_32 (Swish)               (None, 1, 1, 28)     0           ['conv2d_41[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_42 (Conv2D)             (None, 1, 1, 672)    19488       ['swish_32[0][0]']               \n",
            "                                                                                                  \n",
            " activation_10 (Activation)     (None, 1, 1, 672)    0           ['conv2d_42[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_10 (Multiply)         (None, 10, 10, 672)  0           ['activation_10[0][0]',          \n",
            "                                                                  'swish_31[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_43 (Conv2D)             (None, 10, 10, 112)  75264       ['multiply_10[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_32 (BatchN  (None, 10, 10, 112)  448        ['conv2d_43[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_5 (DropConnect)   (None, 10, 10, 112)  0           ['batch_normalization_32[0][0]'] \n",
            "                                                                                                  \n",
            " add_5 (Add)                    (None, 10, 10, 112)  0           ['drop_connect_5[0][0]',         \n",
            "                                                                  'add_4[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_44 (Conv2D)             (None, 10, 10, 672)  75264       ['add_5[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_33 (BatchN  (None, 10, 10, 672)  2688       ['conv2d_44[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_33 (Swish)               (None, 10, 10, 672)  0           ['batch_normalization_33[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_11 (Depthwise  (None, 5, 5, 672)   16800       ['swish_33[0][0]']               \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_34 (BatchN  (None, 5, 5, 672)   2688        ['depthwise_conv2d_11[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_34 (Swish)               (None, 5, 5, 672)    0           ['batch_normalization_34[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_11 (Lambda)             (None, 1, 1, 672)    0           ['swish_34[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_45 (Conv2D)             (None, 1, 1, 28)     18844       ['lambda_11[0][0]']              \n",
            "                                                                                                  \n",
            " swish_35 (Swish)               (None, 1, 1, 28)     0           ['conv2d_45[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_46 (Conv2D)             (None, 1, 1, 672)    19488       ['swish_35[0][0]']               \n",
            "                                                                                                  \n",
            " activation_11 (Activation)     (None, 1, 1, 672)    0           ['conv2d_46[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_11 (Multiply)         (None, 5, 5, 672)    0           ['activation_11[0][0]',          \n",
            "                                                                  'swish_34[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_47 (Conv2D)             (None, 5, 5, 192)    129024      ['multiply_11[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_35 (BatchN  (None, 5, 5, 192)   768         ['conv2d_47[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_48 (Conv2D)             (None, 5, 5, 1152)   221184      ['batch_normalization_35[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_36 (BatchN  (None, 5, 5, 1152)  4608        ['conv2d_48[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_36 (Swish)               (None, 5, 5, 1152)   0           ['batch_normalization_36[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_12 (Depthwise  (None, 5, 5, 1152)  28800       ['swish_36[0][0]']               \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_37 (BatchN  (None, 5, 5, 1152)  4608        ['depthwise_conv2d_12[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_37 (Swish)               (None, 5, 5, 1152)   0           ['batch_normalization_37[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_12 (Lambda)             (None, 1, 1, 1152)   0           ['swish_37[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_49 (Conv2D)             (None, 1, 1, 48)     55344       ['lambda_12[0][0]']              \n",
            "                                                                                                  \n",
            " swish_38 (Swish)               (None, 1, 1, 48)     0           ['conv2d_49[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_50 (Conv2D)             (None, 1, 1, 1152)   56448       ['swish_38[0][0]']               \n",
            "                                                                                                  \n",
            " activation_12 (Activation)     (None, 1, 1, 1152)   0           ['conv2d_50[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_12 (Multiply)         (None, 5, 5, 1152)   0           ['activation_12[0][0]',          \n",
            "                                                                  'swish_37[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_51 (Conv2D)             (None, 5, 5, 192)    221184      ['multiply_12[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_38 (BatchN  (None, 5, 5, 192)   768         ['conv2d_51[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_6 (DropConnect)   (None, 5, 5, 192)    0           ['batch_normalization_38[0][0]'] \n",
            "                                                                                                  \n",
            " add_6 (Add)                    (None, 5, 5, 192)    0           ['drop_connect_6[0][0]',         \n",
            "                                                                  'batch_normalization_35[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_52 (Conv2D)             (None, 5, 5, 1152)   221184      ['add_6[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_39 (BatchN  (None, 5, 5, 1152)  4608        ['conv2d_52[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_39 (Swish)               (None, 5, 5, 1152)   0           ['batch_normalization_39[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_13 (Depthwise  (None, 5, 5, 1152)  28800       ['swish_39[0][0]']               \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_40 (BatchN  (None, 5, 5, 1152)  4608        ['depthwise_conv2d_13[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_40 (Swish)               (None, 5, 5, 1152)   0           ['batch_normalization_40[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_13 (Lambda)             (None, 1, 1, 1152)   0           ['swish_40[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_53 (Conv2D)             (None, 1, 1, 48)     55344       ['lambda_13[0][0]']              \n",
            "                                                                                                  \n",
            " swish_41 (Swish)               (None, 1, 1, 48)     0           ['conv2d_53[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_54 (Conv2D)             (None, 1, 1, 1152)   56448       ['swish_41[0][0]']               \n",
            "                                                                                                  \n",
            " activation_13 (Activation)     (None, 1, 1, 1152)   0           ['conv2d_54[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_13 (Multiply)         (None, 5, 5, 1152)   0           ['activation_13[0][0]',          \n",
            "                                                                  'swish_40[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_55 (Conv2D)             (None, 5, 5, 192)    221184      ['multiply_13[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_41 (BatchN  (None, 5, 5, 192)   768         ['conv2d_55[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_7 (DropConnect)   (None, 5, 5, 192)    0           ['batch_normalization_41[0][0]'] \n",
            "                                                                                                  \n",
            " add_7 (Add)                    (None, 5, 5, 192)    0           ['drop_connect_7[0][0]',         \n",
            "                                                                  'add_6[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_56 (Conv2D)             (None, 5, 5, 1152)   221184      ['add_7[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_42 (BatchN  (None, 5, 5, 1152)  4608        ['conv2d_56[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_42 (Swish)               (None, 5, 5, 1152)   0           ['batch_normalization_42[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_14 (Depthwise  (None, 5, 5, 1152)  28800       ['swish_42[0][0]']               \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_43 (BatchN  (None, 5, 5, 1152)  4608        ['depthwise_conv2d_14[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_43 (Swish)               (None, 5, 5, 1152)   0           ['batch_normalization_43[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_14 (Lambda)             (None, 1, 1, 1152)   0           ['swish_43[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_57 (Conv2D)             (None, 1, 1, 48)     55344       ['lambda_14[0][0]']              \n",
            "                                                                                                  \n",
            " swish_44 (Swish)               (None, 1, 1, 48)     0           ['conv2d_57[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_58 (Conv2D)             (None, 1, 1, 1152)   56448       ['swish_44[0][0]']               \n",
            "                                                                                                  \n",
            " activation_14 (Activation)     (None, 1, 1, 1152)   0           ['conv2d_58[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_14 (Multiply)         (None, 5, 5, 1152)   0           ['activation_14[0][0]',          \n",
            "                                                                  'swish_43[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_59 (Conv2D)             (None, 5, 5, 192)    221184      ['multiply_14[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_44 (BatchN  (None, 5, 5, 192)   768         ['conv2d_59[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_8 (DropConnect)   (None, 5, 5, 192)    0           ['batch_normalization_44[0][0]'] \n",
            "                                                                                                  \n",
            " add_8 (Add)                    (None, 5, 5, 192)    0           ['drop_connect_8[0][0]',         \n",
            "                                                                  'add_7[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_60 (Conv2D)             (None, 5, 5, 1152)   221184      ['add_8[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_45 (BatchN  (None, 5, 5, 1152)  4608        ['conv2d_60[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_45 (Swish)               (None, 5, 5, 1152)   0           ['batch_normalization_45[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_15 (Depthwise  (None, 5, 5, 1152)  10368       ['swish_45[0][0]']               \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_46 (BatchN  (None, 5, 5, 1152)  4608        ['depthwise_conv2d_15[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_46 (Swish)               (None, 5, 5, 1152)   0           ['batch_normalization_46[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_15 (Lambda)             (None, 1, 1, 1152)   0           ['swish_46[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_61 (Conv2D)             (None, 1, 1, 48)     55344       ['lambda_15[0][0]']              \n",
            "                                                                                                  \n",
            " swish_47 (Swish)               (None, 1, 1, 48)     0           ['conv2d_61[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_62 (Conv2D)             (None, 1, 1, 1152)   56448       ['swish_47[0][0]']               \n",
            "                                                                                                  \n",
            " activation_15 (Activation)     (None, 1, 1, 1152)   0           ['conv2d_62[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_15 (Multiply)         (None, 5, 5, 1152)   0           ['activation_15[0][0]',          \n",
            "                                                                  'swish_46[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_63 (Conv2D)             (None, 5, 5, 320)    368640      ['multiply_15[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_47 (BatchN  (None, 5, 5, 320)   1280        ['conv2d_63[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_64 (Conv2D)             (None, 5, 5, 1280)   409600      ['batch_normalization_47[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_48 (BatchN  (None, 5, 5, 1280)  5120        ['conv2d_64[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_48 (Swish)               (None, 5, 5, 1280)   0           ['batch_normalization_48[0][0]'] \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 4,049,564\n",
            "Trainable params: 0\n",
            "Non-trainable params: 4,049,564\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#สร้างโฟลเดอร์ Train Valodation และ Test"
      ],
      "metadata": {
        "id": "J36J9EAE7qSB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv (r'/content/drive/MyDrive/cut_panoramic/Data/All_Re.csv')\n",
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "skoKhKJDngAZ",
        "outputId": "cc060d11-4db2-4378-c938-55334ab12804"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      Fig_Age  Fig_Person_Sex  Age(year) Class  Class_Re       Filename  \\\n",
              "0           1               1          7  Y07F         1         V1.jpg   \n",
              "1           2               1          7  Y07F         1    Flip_V1.jpg   \n",
              "2           3               2          7  Y07F         1         V2.jpg   \n",
              "3           4               2          7  Y07F         1    Flip_V2.jpg   \n",
              "4           5               3          7  Y07F         1         V3.jpg   \n",
              "...       ...             ...        ...   ...       ...            ...   \n",
              "4745      121              77         25  Y25M        19  Flip_J463.jpg   \n",
              "4746      122              78         25  Y25M        19       J464.jpg   \n",
              "4747      123              78         25  Y25M        19  Flip_J464.jpg   \n",
              "4748      124              79         25  Y25M        19       J465.jpg   \n",
              "4749      125              79         25  Y25M        19  Flip_J465.jpg   \n",
              "\n",
              "                                          Path_filename     Sex Floder  \n",
              "0     /content/drive/My Drive/TVT_Gender/train/Femal...  Female   Both  \n",
              "1     /content/drive/My Drive/TVT_Gender/train/Femal...  Female   Both  \n",
              "2     /content/drive/My Drive/TVT_Gender/train/Femal...  Female   Both  \n",
              "3     /content/drive/My Drive/TVT_Gender/train/Femal...  Female   Both  \n",
              "4     /content/drive/My Drive/TVT_Gender/train/Femal...  Female   Both  \n",
              "...                                                 ...     ...    ...  \n",
              "4745  /content/drive/My Drive/TVT_Gender/test/Male/F...    Male   Both  \n",
              "4746  /content/drive/My Drive/TVT_Gender/test/Male/J...    Male   Both  \n",
              "4747  /content/drive/My Drive/TVT_Gender/test/Male/F...    Male   Both  \n",
              "4748  /content/drive/My Drive/TVT_Gender/test/Male/J...    Male   Both  \n",
              "4749  /content/drive/My Drive/TVT_Gender/test/Male/F...    Male   Both  \n",
              "\n",
              "[4750 rows x 9 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6971ac63-a4b6-4a49-bb9e-377991d4a4e2\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Fig_Age</th>\n",
              "      <th>Fig_Person_Sex</th>\n",
              "      <th>Age(year)</th>\n",
              "      <th>Class</th>\n",
              "      <th>Class_Re</th>\n",
              "      <th>Filename</th>\n",
              "      <th>Path_filename</th>\n",
              "      <th>Sex</th>\n",
              "      <th>Floder</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>Y07F</td>\n",
              "      <td>1</td>\n",
              "      <td>V1.jpg</td>\n",
              "      <td>/content/drive/My Drive/TVT_Gender/train/Femal...</td>\n",
              "      <td>Female</td>\n",
              "      <td>Both</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>Y07F</td>\n",
              "      <td>1</td>\n",
              "      <td>Flip_V1.jpg</td>\n",
              "      <td>/content/drive/My Drive/TVT_Gender/train/Femal...</td>\n",
              "      <td>Female</td>\n",
              "      <td>Both</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>7</td>\n",
              "      <td>Y07F</td>\n",
              "      <td>1</td>\n",
              "      <td>V2.jpg</td>\n",
              "      <td>/content/drive/My Drive/TVT_Gender/train/Femal...</td>\n",
              "      <td>Female</td>\n",
              "      <td>Both</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>7</td>\n",
              "      <td>Y07F</td>\n",
              "      <td>1</td>\n",
              "      <td>Flip_V2.jpg</td>\n",
              "      <td>/content/drive/My Drive/TVT_Gender/train/Femal...</td>\n",
              "      <td>Female</td>\n",
              "      <td>Both</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>7</td>\n",
              "      <td>Y07F</td>\n",
              "      <td>1</td>\n",
              "      <td>V3.jpg</td>\n",
              "      <td>/content/drive/My Drive/TVT_Gender/train/Femal...</td>\n",
              "      <td>Female</td>\n",
              "      <td>Both</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4745</th>\n",
              "      <td>121</td>\n",
              "      <td>77</td>\n",
              "      <td>25</td>\n",
              "      <td>Y25M</td>\n",
              "      <td>19</td>\n",
              "      <td>Flip_J463.jpg</td>\n",
              "      <td>/content/drive/My Drive/TVT_Gender/test/Male/F...</td>\n",
              "      <td>Male</td>\n",
              "      <td>Both</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4746</th>\n",
              "      <td>122</td>\n",
              "      <td>78</td>\n",
              "      <td>25</td>\n",
              "      <td>Y25M</td>\n",
              "      <td>19</td>\n",
              "      <td>J464.jpg</td>\n",
              "      <td>/content/drive/My Drive/TVT_Gender/test/Male/J...</td>\n",
              "      <td>Male</td>\n",
              "      <td>Both</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4747</th>\n",
              "      <td>123</td>\n",
              "      <td>78</td>\n",
              "      <td>25</td>\n",
              "      <td>Y25M</td>\n",
              "      <td>19</td>\n",
              "      <td>Flip_J464.jpg</td>\n",
              "      <td>/content/drive/My Drive/TVT_Gender/test/Male/F...</td>\n",
              "      <td>Male</td>\n",
              "      <td>Both</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4748</th>\n",
              "      <td>124</td>\n",
              "      <td>79</td>\n",
              "      <td>25</td>\n",
              "      <td>Y25M</td>\n",
              "      <td>19</td>\n",
              "      <td>J465.jpg</td>\n",
              "      <td>/content/drive/My Drive/TVT_Gender/test/Male/J...</td>\n",
              "      <td>Male</td>\n",
              "      <td>Both</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4749</th>\n",
              "      <td>125</td>\n",
              "      <td>79</td>\n",
              "      <td>25</td>\n",
              "      <td>Y25M</td>\n",
              "      <td>19</td>\n",
              "      <td>Flip_J465.jpg</td>\n",
              "      <td>/content/drive/My Drive/TVT_Gender/test/Male/F...</td>\n",
              "      <td>Male</td>\n",
              "      <td>Both</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4750 rows × 9 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6971ac63-a4b6-4a49-bb9e-377991d4a4e2')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-6971ac63-a4b6-4a49-bb9e-377991d4a4e2 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-6971ac63-a4b6-4a49-bb9e-377991d4a4e2');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train = df[df['Fig_Age'].between(1,75)]\n",
        "val = df[df['Fig_Age'].between(76,100)]"
      ],
      "metadata": {
        "id": "Z1zBw01Gl8Ac"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DATA_PATH = \"/content/drive/My Drive/TVT_Gender\"\n",
        "os.chdir(DATA_PATH)\n",
        "train_dir = os.path.join(DATA_PATH, 'train')\n",
        "print(train_dir)\n",
        "validation_dir = os.path.join(DATA_PATH, 'validation')\n",
        "print(validation_dir)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QL0g-8iOnMC4",
        "outputId": "44f4bc23-899f-4416-d7dc-23f8e8d931bb"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/My Drive/TVT_Gender/train\n",
            "/content/drive/My Drive/TVT_Gender/validation\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "#Train"
      ],
      "metadata": {
        "id": "bWEnlTSwazL5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train ด้วย ImageDataGenerator ของ Keras ซึ่งจะเพิ่มข้อมูลเสริมระหว่างการฝึกเพื่อลดโอกาสเกิด overfitting\n",
        "#overfitting เกิดจากข้อมูลที่ซับซ้อนกันเกินไป\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "train_datagen = ImageDataGenerator(\n",
        "      rescale=1./255, #โมเดลส่วนใหญ่ต้องใช้ RGB ในช่วง 0–1\n",
        "      rotation_range=40,\n",
        "      width_shift_range=0.2,\n",
        "      height_shift_range=0.2,\n",
        "      shear_range=0.2,\n",
        "      zoom_range=0.2,\n",
        "      horizontal_flip=True,\n",
        "      fill_mode='nearest')\n",
        "\n",
        "# Note that the validation data should not be augmented!\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)"
      ],
      "metadata": {
        "id": "xGPrsn9no_pa"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_generator = train_datagen.flow_from_dataframe(\n",
        "        dataframe = train,\n",
        "        directory = train_dir,\n",
        "        x_col = 'Path_filename',\n",
        "        y_col = 'Class_Re',\n",
        "        class_mode = 'other',\n",
        "        target_size=(height, width),\n",
        "        batch_size=batch_size)\n",
        "\n",
        "validation_generator = test_datagen.flow_from_dataframe(\n",
        "        dataframe = val,\n",
        "        directory = validation_dir,\n",
        "        x_col = 'Path_filename',\n",
        "        y_col = 'Class_Re',\n",
        "        class_mode = 'other',\n",
        "        target_size=(height, width),\n",
        "        batch_size=batch_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8nVlmAszntK_",
        "outputId": "425af3c0-47ba-41fa-abb1-d556ff1ad10a"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 2850 validated image filenames.\n",
            "Found 950 validated image filenames.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='mse',\n",
        "          optimizer=Adam(learning_rate=1e-4),\n",
        "          metrics=['mae'])\n",
        "history = model.fit_generator(\n",
        "      train_generator,\n",
        "      steps_per_epoch= NUM_TRAIN //batch_size,\n",
        "      epochs=epochs,\n",
        "      validation_data=validation_generator,\n",
        "      validation_steps= NUM_TEST //batch_size,\n",
        "      verbose=1,\n",
        "      use_multiprocessing=True,\n",
        "      workers=4)"
      ],
      "metadata": {
        "id": "N6qUmmF856ZE",
        "outputId": "d8195e10-46ce-4961-8e6e-bab10e9c0f89",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-19-f59104fd3985>:4: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  history = model.fit_generator(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/250\n",
            "178/178 [==============================] - 339s 2s/step - loss: 121.9476 - mae: 9.5871 - val_loss: 118.7110 - val_mae: 9.4166\n",
            "Epoch 2/250\n",
            "178/178 [==============================] - 42s 235ms/step - loss: 118.6936 - mae: 9.4205 - val_loss: 118.1408 - val_mae: 9.3802\n",
            "Epoch 3/250\n",
            "178/178 [==============================] - 44s 246ms/step - loss: 117.5261 - mae: 9.3540 - val_loss: 117.3707 - val_mae: 9.3474\n",
            "Epoch 4/250\n",
            "178/178 [==============================] - 45s 248ms/step - loss: 116.9346 - mae: 9.3204 - val_loss: 116.6453 - val_mae: 9.2996\n",
            "Epoch 5/250\n",
            "178/178 [==============================] - 44s 245ms/step - loss: 116.3104 - mae: 9.2896 - val_loss: 115.9518 - val_mae: 9.2765\n",
            "Epoch 6/250\n",
            "178/178 [==============================] - 44s 246ms/step - loss: 115.9664 - mae: 9.2702 - val_loss: 115.3916 - val_mae: 9.2422\n",
            "Epoch 7/250\n",
            "178/178 [==============================] - 43s 235ms/step - loss: 115.0395 - mae: 9.2214 - val_loss: 114.6322 - val_mae: 9.1984\n",
            "Epoch 8/250\n",
            "178/178 [==============================] - 43s 238ms/step - loss: 114.5386 - mae: 9.1955 - val_loss: 114.1554 - val_mae: 9.1738\n",
            "Epoch 9/250\n",
            "178/178 [==============================] - 43s 241ms/step - loss: 113.6656 - mae: 9.1495 - val_loss: 113.9595 - val_mae: 9.1631\n",
            "Epoch 10/250\n",
            "178/178 [==============================] - 45s 248ms/step - loss: 112.8358 - mae: 9.1031 - val_loss: 112.8291 - val_mae: 9.1071\n",
            "Epoch 11/250\n",
            "178/178 [==============================] - 44s 246ms/step - loss: 112.6337 - mae: 9.0879 - val_loss: 111.6163 - val_mae: 9.0350\n",
            "Epoch 12/250\n",
            "178/178 [==============================] - 44s 245ms/step - loss: 111.6901 - mae: 9.0363 - val_loss: 111.0532 - val_mae: 9.0077\n",
            "Epoch 13/250\n",
            "178/178 [==============================] - 44s 244ms/step - loss: 111.1119 - mae: 9.0068 - val_loss: 111.1104 - val_mae: 9.0022\n",
            "Epoch 14/250\n",
            "178/178 [==============================] - 43s 238ms/step - loss: 110.6306 - mae: 8.9818 - val_loss: 109.9976 - val_mae: 8.9447\n",
            "Epoch 15/250\n",
            "178/178 [==============================] - 43s 234ms/step - loss: 109.9983 - mae: 8.9478 - val_loss: 109.7270 - val_mae: 8.9349\n",
            "Epoch 16/250\n",
            "178/178 [==============================] - 43s 237ms/step - loss: 109.3509 - mae: 8.9170 - val_loss: 109.0182 - val_mae: 8.9018\n",
            "Epoch 17/250\n",
            "178/178 [==============================] - 44s 243ms/step - loss: 108.7848 - mae: 8.8940 - val_loss: 108.8213 - val_mae: 8.8916\n",
            "Epoch 18/250\n",
            "178/178 [==============================] - 40s 221ms/step - loss: 108.1995 - mae: 8.8614 - val_loss: 107.7659 - val_mae: 8.8357\n",
            "Epoch 19/250\n",
            "178/178 [==============================] - 44s 243ms/step - loss: 107.4317 - mae: 8.8185 - val_loss: 107.2535 - val_mae: 8.8122\n",
            "Epoch 20/250\n",
            "178/178 [==============================] - 44s 244ms/step - loss: 106.6607 - mae: 8.7810 - val_loss: 106.9120 - val_mae: 8.7942\n",
            "Epoch 21/250\n",
            "178/178 [==============================] - 44s 246ms/step - loss: 106.4983 - mae: 8.7700 - val_loss: 105.8206 - val_mae: 8.7394\n",
            "Epoch 22/250\n",
            "178/178 [==============================] - 44s 245ms/step - loss: 105.6773 - mae: 8.7318 - val_loss: 105.3904 - val_mae: 8.7223\n",
            "Epoch 23/250\n",
            "178/178 [==============================] - 44s 246ms/step - loss: 105.0616 - mae: 8.6975 - val_loss: 104.7192 - val_mae: 8.6824\n",
            "Epoch 24/250\n",
            "178/178 [==============================] - 44s 245ms/step - loss: 104.3884 - mae: 8.6656 - val_loss: 104.7850 - val_mae: 8.6924\n",
            "Epoch 25/250\n",
            "178/178 [==============================] - 44s 241ms/step - loss: 104.1662 - mae: 8.6517 - val_loss: 104.0921 - val_mae: 8.6548\n",
            "Epoch 26/250\n",
            "178/178 [==============================] - 42s 235ms/step - loss: 103.4952 - mae: 8.6173 - val_loss: 103.2177 - val_mae: 8.6113\n",
            "Epoch 27/250\n",
            "178/178 [==============================] - 43s 235ms/step - loss: 102.6514 - mae: 8.5757 - val_loss: 102.3510 - val_mae: 8.5594\n",
            "Epoch 28/250\n",
            "178/178 [==============================] - 44s 245ms/step - loss: 102.1016 - mae: 8.5455 - val_loss: 101.4399 - val_mae: 8.5180\n",
            "Epoch 29/250\n",
            "178/178 [==============================] - 44s 246ms/step - loss: 101.3956 - mae: 8.5101 - val_loss: 101.6133 - val_mae: 8.5201\n",
            "Epoch 30/250\n",
            "178/178 [==============================] - 44s 246ms/step - loss: 101.0934 - mae: 8.4914 - val_loss: 100.7106 - val_mae: 8.4735\n",
            "Epoch 31/250\n",
            "178/178 [==============================] - 44s 246ms/step - loss: 100.4117 - mae: 8.4548 - val_loss: 100.1763 - val_mae: 8.4386\n",
            "Epoch 32/250\n",
            "178/178 [==============================] - 44s 242ms/step - loss: 99.9516 - mae: 8.4334 - val_loss: 99.5581 - val_mae: 8.4036\n",
            "Epoch 33/250\n",
            "178/178 [==============================] - 43s 235ms/step - loss: 98.9136 - mae: 8.3736 - val_loss: 99.0705 - val_mae: 8.3857\n",
            "Epoch 34/250\n",
            "178/178 [==============================] - 43s 235ms/step - loss: 98.8258 - mae: 8.3722 - val_loss: 98.5418 - val_mae: 8.3551\n",
            "Epoch 35/250\n",
            "178/178 [==============================] - 42s 233ms/step - loss: 98.1190 - mae: 8.3306 - val_loss: 97.9332 - val_mae: 8.3221\n",
            "Epoch 36/250\n",
            "178/178 [==============================] - 44s 245ms/step - loss: 97.5859 - mae: 8.3016 - val_loss: 97.1595 - val_mae: 8.2736\n",
            "Epoch 37/250\n",
            "178/178 [==============================] - 44s 246ms/step - loss: 96.7857 - mae: 8.2569 - val_loss: 96.5381 - val_mae: 8.2503\n",
            "Epoch 38/250\n",
            "178/178 [==============================] - 44s 246ms/step - loss: 96.5746 - mae: 8.2504 - val_loss: 95.9946 - val_mae: 8.2152\n",
            "Epoch 39/250\n",
            "178/178 [==============================] - 44s 247ms/step - loss: 96.0050 - mae: 8.2171 - val_loss: 95.8477 - val_mae: 8.2090\n",
            "Epoch 40/250\n",
            "178/178 [==============================] - 44s 244ms/step - loss: 95.3149 - mae: 8.1774 - val_loss: 94.9400 - val_mae: 8.1570\n",
            "Epoch 41/250\n",
            "178/178 [==============================] - 43s 237ms/step - loss: 94.8097 - mae: 8.1494 - val_loss: 94.3542 - val_mae: 8.1254\n",
            "Epoch 42/250\n",
            "178/178 [==============================] - 43s 233ms/step - loss: 94.2379 - mae: 8.1175 - val_loss: 93.6977 - val_mae: 8.0888\n",
            "Epoch 43/250\n",
            "178/178 [==============================] - 42s 234ms/step - loss: 93.7422 - mae: 8.0909 - val_loss: 93.0496 - val_mae: 8.0617\n",
            "Epoch 44/250\n",
            "178/178 [==============================] - 44s 242ms/step - loss: 93.1861 - mae: 8.0700 - val_loss: 92.9736 - val_mae: 8.0526\n",
            "Epoch 45/250\n",
            "178/178 [==============================] - 44s 246ms/step - loss: 92.6072 - mae: 8.0337 - val_loss: 92.5850 - val_mae: 8.0372\n",
            "Epoch 46/250\n",
            "178/178 [==============================] - 44s 246ms/step - loss: 91.8978 - mae: 8.0017 - val_loss: 91.6275 - val_mae: 7.9881\n",
            "Epoch 47/250\n",
            "178/178 [==============================] - 44s 246ms/step - loss: 91.5448 - mae: 7.9821 - val_loss: 91.6035 - val_mae: 7.9862\n",
            "Epoch 48/250\n",
            "178/178 [==============================] - 44s 245ms/step - loss: 90.7759 - mae: 7.9436 - val_loss: 90.6492 - val_mae: 7.9320\n",
            "Epoch 49/250\n",
            "178/178 [==============================] - 44s 246ms/step - loss: 90.3376 - mae: 7.9189 - val_loss: 89.8779 - val_mae: 7.8954\n",
            "Epoch 50/250\n",
            "178/178 [==============================] - 43s 237ms/step - loss: 89.9787 - mae: 7.9032 - val_loss: 89.7892 - val_mae: 7.8955\n",
            "Epoch 51/250\n",
            "178/178 [==============================] - 42s 234ms/step - loss: 89.4249 - mae: 7.8771 - val_loss: 89.3111 - val_mae: 7.8715\n",
            "Epoch 52/250\n",
            "178/178 [==============================] - 42s 235ms/step - loss: 88.9262 - mae: 7.8457 - val_loss: 89.0265 - val_mae: 7.8618\n",
            "Epoch 53/250\n",
            "178/178 [==============================] - 43s 239ms/step - loss: 88.1999 - mae: 7.8120 - val_loss: 88.2918 - val_mae: 7.8141\n",
            "Epoch 54/250\n",
            "178/178 [==============================] - 44s 246ms/step - loss: 87.8800 - mae: 7.7960 - val_loss: 87.1568 - val_mae: 7.7532\n",
            "Epoch 55/250\n",
            "178/178 [==============================] - 44s 245ms/step - loss: 87.3390 - mae: 7.7699 - val_loss: 87.2796 - val_mae: 7.7698\n",
            "Epoch 56/250\n",
            "178/178 [==============================] - 44s 246ms/step - loss: 86.5742 - mae: 7.7264 - val_loss: 86.4235 - val_mae: 7.7214\n",
            "Epoch 57/250\n",
            "178/178 [==============================] - 43s 240ms/step - loss: 86.2277 - mae: 7.7075 - val_loss: 86.0715 - val_mae: 7.6956\n",
            "Epoch 58/250\n",
            "178/178 [==============================] - 43s 237ms/step - loss: 85.5122 - mae: 7.6696 - val_loss: 85.6272 - val_mae: 7.6709\n",
            "Epoch 59/250\n",
            "178/178 [==============================] - 42s 236ms/step - loss: 85.1065 - mae: 7.6516 - val_loss: 85.0889 - val_mae: 7.6502\n",
            "Epoch 60/250\n",
            "178/178 [==============================] - 44s 243ms/step - loss: 84.6351 - mae: 7.6267 - val_loss: 84.5396 - val_mae: 7.6151\n",
            "Epoch 61/250\n",
            "178/178 [==============================] - 44s 246ms/step - loss: 83.9001 - mae: 7.5893 - val_loss: 83.6786 - val_mae: 7.5721\n",
            "Epoch 62/250\n",
            "178/178 [==============================] - 45s 247ms/step - loss: 83.6936 - mae: 7.5754 - val_loss: 83.5678 - val_mae: 7.5653\n",
            "Epoch 63/250\n",
            "178/178 [==============================] - 40s 224ms/step - loss: 83.2528 - mae: 7.5493 - val_loss: 82.8854 - val_mae: 7.5301\n",
            "Epoch 64/250\n",
            "178/178 [==============================] - 44s 246ms/step - loss: 82.8848 - mae: 7.5279 - val_loss: 82.1914 - val_mae: 7.4906\n",
            "Epoch 65/250\n",
            "178/178 [==============================] - 44s 247ms/step - loss: 82.3222 - mae: 7.5000 - val_loss: 81.6618 - val_mae: 7.4617\n",
            "Epoch 66/250\n",
            "178/178 [==============================] - 44s 246ms/step - loss: 81.6417 - mae: 7.4582 - val_loss: 81.6534 - val_mae: 7.4664\n",
            "Epoch 67/250\n",
            "178/178 [==============================] - 44s 247ms/step - loss: 81.3077 - mae: 7.4462 - val_loss: 80.9577 - val_mae: 7.4291\n",
            "Epoch 68/250\n",
            "178/178 [==============================] - 44s 242ms/step - loss: 80.8249 - mae: 7.4182 - val_loss: 80.6375 - val_mae: 7.4034\n",
            "Epoch 69/250\n",
            "178/178 [==============================] - 43s 237ms/step - loss: 80.3532 - mae: 7.3936 - val_loss: 79.8541 - val_mae: 7.3608\n",
            "Epoch 70/250\n",
            "178/178 [==============================] - 43s 236ms/step - loss: 79.9124 - mae: 7.3676 - val_loss: 79.9141 - val_mae: 7.3679\n",
            "Epoch 71/250\n",
            "178/178 [==============================] - 43s 237ms/step - loss: 79.0817 - mae: 7.3206 - val_loss: 79.0990 - val_mae: 7.3188\n",
            "Epoch 72/250\n",
            "178/178 [==============================] - 44s 249ms/step - loss: 78.9824 - mae: 7.3154 - val_loss: 78.7783 - val_mae: 7.3118\n",
            "Epoch 73/250\n",
            "178/178 [==============================] - 45s 246ms/step - loss: 78.2816 - mae: 7.2784 - val_loss: 78.0149 - val_mae: 7.2714\n",
            "Epoch 74/250\n",
            "178/178 [==============================] - 44s 245ms/step - loss: 77.8316 - mae: 7.2572 - val_loss: 77.4494 - val_mae: 7.2329\n",
            "Epoch 75/250\n",
            "178/178 [==============================] - 44s 246ms/step - loss: 77.3576 - mae: 7.2359 - val_loss: 77.1080 - val_mae: 7.2211\n",
            "Epoch 76/250\n",
            "178/178 [==============================] - 44s 245ms/step - loss: 76.9182 - mae: 7.2103 - val_loss: 76.8461 - val_mae: 7.2136\n",
            "Epoch 77/250\n",
            "178/178 [==============================] - 44s 241ms/step - loss: 76.4684 - mae: 7.1914 - val_loss: 75.5251 - val_mae: 7.1380\n",
            "Epoch 78/250\n",
            "178/178 [==============================] - 43s 234ms/step - loss: 76.0124 - mae: 7.1652 - val_loss: 76.0050 - val_mae: 7.1741\n",
            "Epoch 79/250\n",
            "178/178 [==============================] - 38s 211ms/step - loss: 75.4843 - mae: 7.1390 - val_loss: 75.4034 - val_mae: 7.1361\n",
            "Epoch 80/250\n",
            "178/178 [==============================] - 43s 236ms/step - loss: 75.3211 - mae: 7.1342 - val_loss: 75.0207 - val_mae: 7.1160\n",
            "Epoch 81/250\n",
            "178/178 [==============================] - 43s 239ms/step - loss: 74.6109 - mae: 7.0953 - val_loss: 74.3571 - val_mae: 7.0826\n",
            "Epoch 82/250\n",
            "178/178 [==============================] - 44s 245ms/step - loss: 74.1386 - mae: 7.0690 - val_loss: 74.3371 - val_mae: 7.0906\n",
            "Epoch 83/250\n",
            "178/178 [==============================] - 44s 244ms/step - loss: 73.6481 - mae: 7.0435 - val_loss: 73.9119 - val_mae: 7.0652\n",
            "Epoch 84/250\n",
            "178/178 [==============================] - 44s 246ms/step - loss: 73.2031 - mae: 7.0236 - val_loss: 72.9143 - val_mae: 7.0055\n",
            "Epoch 85/250\n",
            "178/178 [==============================] - 45s 247ms/step - loss: 72.9643 - mae: 7.0107 - val_loss: 72.4632 - val_mae: 6.9876\n",
            "Epoch 86/250\n",
            "178/178 [==============================] - 45s 247ms/step - loss: 72.2457 - mae: 6.9723 - val_loss: 72.2108 - val_mae: 6.9697\n",
            "Epoch 87/250\n",
            "178/178 [==============================] - 44s 240ms/step - loss: 72.0225 - mae: 6.9605 - val_loss: 71.5756 - val_mae: 6.9401\n",
            "Epoch 88/250\n",
            "178/178 [==============================] - 43s 237ms/step - loss: 71.3675 - mae: 6.9273 - val_loss: 71.5852 - val_mae: 6.9403\n",
            "Epoch 89/250\n",
            "178/178 [==============================] - 43s 237ms/step - loss: 71.0503 - mae: 6.9071 - val_loss: 70.8225 - val_mae: 6.8981\n",
            "Epoch 90/250\n",
            "178/178 [==============================] - 43s 236ms/step - loss: 70.5086 - mae: 6.8774 - val_loss: 70.1448 - val_mae: 6.8612\n",
            "Epoch 91/250\n",
            "178/178 [==============================] - 45s 250ms/step - loss: 70.2667 - mae: 6.8645 - val_loss: 70.0822 - val_mae: 6.8600\n",
            "Epoch 92/250\n",
            "178/178 [==============================] - 45s 249ms/step - loss: 69.7386 - mae: 6.8378 - val_loss: 69.5746 - val_mae: 6.8287\n",
            "Epoch 93/250\n",
            "178/178 [==============================] - 44s 246ms/step - loss: 69.2794 - mae: 6.8146 - val_loss: 69.2135 - val_mae: 6.8119\n",
            "Epoch 94/250\n",
            "178/178 [==============================] - 45s 248ms/step - loss: 69.0074 - mae: 6.7984 - val_loss: 68.8333 - val_mae: 6.7887\n",
            "Epoch 95/250\n",
            "178/178 [==============================] - 44s 245ms/step - loss: 68.4650 - mae: 6.7707 - val_loss: 68.2200 - val_mae: 6.7508\n",
            "Epoch 96/250\n",
            "178/178 [==============================] - 44s 240ms/step - loss: 68.1102 - mae: 6.7509 - val_loss: 67.8772 - val_mae: 6.7340\n",
            "Epoch 97/250\n",
            "178/178 [==============================] - 43s 233ms/step - loss: 67.8974 - mae: 6.7401 - val_loss: 67.4205 - val_mae: 6.7151\n",
            "Epoch 98/250\n",
            "178/178 [==============================] - 44s 242ms/step - loss: 67.3499 - mae: 6.7115 - val_loss: 67.0112 - val_mae: 6.6910\n",
            "Epoch 99/250\n",
            "178/178 [==============================] - 44s 246ms/step - loss: 66.8426 - mae: 6.6774 - val_loss: 66.5858 - val_mae: 6.6636\n",
            "Epoch 100/250\n",
            "178/178 [==============================] - 45s 249ms/step - loss: 66.5026 - mae: 6.6583 - val_loss: 66.1611 - val_mae: 6.6393\n",
            "Epoch 101/250\n",
            "178/178 [==============================] - 45s 247ms/step - loss: 65.9089 - mae: 6.6240 - val_loss: 66.1305 - val_mae: 6.6408\n",
            "Epoch 102/250\n",
            "178/178 [==============================] - 45s 248ms/step - loss: 65.6982 - mae: 6.6180 - val_loss: 65.7614 - val_mae: 6.6254\n",
            "Epoch 103/250\n",
            "178/178 [==============================] - 44s 239ms/step - loss: 65.2747 - mae: 6.5970 - val_loss: 65.3560 - val_mae: 6.6067\n",
            "Epoch 104/250\n",
            "178/178 [==============================] - 43s 236ms/step - loss: 64.7671 - mae: 6.5690 - val_loss: 64.6638 - val_mae: 6.5633\n",
            "Epoch 105/250\n",
            "178/178 [==============================] - 44s 246ms/step - loss: 64.5847 - mae: 6.5645 - val_loss: 64.4559 - val_mae: 6.5622\n",
            "Epoch 106/250\n",
            "178/178 [==============================] - 45s 250ms/step - loss: 64.0718 - mae: 6.5381 - val_loss: 63.9202 - val_mae: 6.5277\n",
            "Epoch 107/250\n",
            "178/178 [==============================] - 46s 253ms/step - loss: 63.6833 - mae: 6.5151 - val_loss: 63.3555 - val_mae: 6.4999\n",
            "Epoch 108/250\n",
            "178/178 [==============================] - 45s 246ms/step - loss: 63.1219 - mae: 6.4874 - val_loss: 63.0503 - val_mae: 6.4874\n",
            "Epoch 109/250\n",
            "178/178 [==============================] - 44s 240ms/step - loss: 62.6446 - mae: 6.4643 - val_loss: 62.4233 - val_mae: 6.4511\n",
            "Epoch 110/250\n",
            "178/178 [==============================] - 43s 240ms/step - loss: 62.6687 - mae: 6.4736 - val_loss: 62.2222 - val_mae: 6.4370\n",
            "Epoch 111/250\n",
            "178/178 [==============================] - 45s 251ms/step - loss: 61.9469 - mae: 6.4279 - val_loss: 61.7930 - val_mae: 6.4171\n",
            "Epoch 112/250\n",
            "178/178 [==============================] - 45s 250ms/step - loss: 61.6683 - mae: 6.4166 - val_loss: 61.5850 - val_mae: 6.4090\n",
            "Epoch 113/250\n",
            "178/178 [==============================] - 40s 223ms/step - loss: 61.2899 - mae: 6.3938 - val_loss: 60.9571 - val_mae: 6.3771\n",
            "Epoch 114/250\n",
            "178/178 [==============================] - 45s 247ms/step - loss: 61.1010 - mae: 6.3891 - val_loss: 60.6444 - val_mae: 6.3608\n",
            "Epoch 115/250\n",
            "178/178 [==============================] - 45s 247ms/step - loss: 60.7722 - mae: 6.3707 - val_loss: 60.4242 - val_mae: 6.3498\n",
            "Epoch 116/250\n",
            "178/178 [==============================] - 40s 222ms/step - loss: 60.0940 - mae: 6.3316 - val_loss: 59.7701 - val_mae: 6.3135\n",
            "Epoch 117/250\n",
            "178/178 [==============================] - 45s 246ms/step - loss: 59.9770 - mae: 6.3271 - val_loss: 59.6641 - val_mae: 6.3152\n",
            "Epoch 118/250\n",
            "178/178 [==============================] - 45s 249ms/step - loss: 59.6251 - mae: 6.3087 - val_loss: 59.4174 - val_mae: 6.2928\n",
            "Epoch 119/250\n",
            "178/178 [==============================] - 45s 247ms/step - loss: 59.2325 - mae: 6.2912 - val_loss: 58.8910 - val_mae: 6.2716\n",
            "Epoch 120/250\n",
            "178/178 [==============================] - 45s 250ms/step - loss: 58.8000 - mae: 6.2632 - val_loss: 58.6017 - val_mae: 6.2493\n",
            "Epoch 121/250\n",
            "178/178 [==============================] - 45s 250ms/step - loss: 58.5448 - mae: 6.2522 - val_loss: 58.2079 - val_mae: 6.2276\n",
            "Epoch 122/250\n",
            "178/178 [==============================] - 44s 245ms/step - loss: 58.0153 - mae: 6.2199 - val_loss: 57.7728 - val_mae: 6.2096\n",
            "Epoch 123/250\n",
            "178/178 [==============================] - 44s 240ms/step - loss: 57.7013 - mae: 6.2047 - val_loss: 57.7433 - val_mae: 6.2050\n",
            "Epoch 124/250\n",
            "178/178 [==============================] - 43s 236ms/step - loss: 57.3622 - mae: 6.1863 - val_loss: 57.2915 - val_mae: 6.1843\n",
            "Epoch 125/250\n",
            "178/178 [==============================] - 41s 225ms/step - loss: 57.2276 - mae: 6.1810 - val_loss: 57.0365 - val_mae: 6.1698\n",
            "Epoch 126/250\n",
            "178/178 [==============================] - 44s 241ms/step - loss: 56.7764 - mae: 6.1542 - val_loss: 56.5907 - val_mae: 6.1432\n",
            "Epoch 127/250\n",
            "178/178 [==============================] - 45s 248ms/step - loss: 56.3069 - mae: 6.1264 - val_loss: 56.4210 - val_mae: 6.1353\n",
            "Epoch 128/250\n",
            "178/178 [==============================] - 45s 248ms/step - loss: 56.0605 - mae: 6.1137 - val_loss: 55.8264 - val_mae: 6.0972\n",
            "Epoch 129/250\n",
            "178/178 [==============================] - 45s 249ms/step - loss: 55.7300 - mae: 6.0964 - val_loss: 55.2861 - val_mae: 6.0715\n",
            "Epoch 130/250\n",
            "178/178 [==============================] - 44s 245ms/step - loss: 55.3540 - mae: 6.0721 - val_loss: 55.0728 - val_mae: 6.0567\n",
            "Epoch 131/250\n",
            "178/178 [==============================] - 44s 238ms/step - loss: 55.0101 - mae: 6.0540 - val_loss: 54.8627 - val_mae: 6.0443\n",
            "Epoch 132/250\n",
            "178/178 [==============================] - 43s 236ms/step - loss: 54.7365 - mae: 6.0410 - val_loss: 54.4575 - val_mae: 6.0253\n",
            "Epoch 133/250\n",
            "178/178 [==============================] - 43s 236ms/step - loss: 54.2956 - mae: 6.0180 - val_loss: 54.0854 - val_mae: 6.0067\n",
            "Epoch 134/250\n",
            "178/178 [==============================] - 44s 241ms/step - loss: 54.0879 - mae: 6.0091 - val_loss: 53.7653 - val_mae: 5.9855\n",
            "Epoch 135/250\n",
            "178/178 [==============================] - 45s 248ms/step - loss: 53.7281 - mae: 5.9901 - val_loss: 53.7300 - val_mae: 5.9949\n",
            "Epoch 136/250\n",
            "178/178 [==============================] - 41s 224ms/step - loss: 53.4954 - mae: 5.9824 - val_loss: 53.2565 - val_mae: 5.9694\n",
            "Epoch 137/250\n",
            "178/178 [==============================] - 44s 246ms/step - loss: 53.0674 - mae: 5.9588 - val_loss: 52.9160 - val_mae: 5.9512\n",
            "Epoch 138/250\n",
            "178/178 [==============================] - 45s 249ms/step - loss: 52.5637 - mae: 5.9325 - val_loss: 52.8208 - val_mae: 5.9526\n",
            "Epoch 139/250\n",
            "178/178 [==============================] - 45s 249ms/step - loss: 52.2542 - mae: 5.9183 - val_loss: 52.5029 - val_mae: 5.9347\n",
            "Epoch 140/250\n",
            "178/178 [==============================] - 45s 247ms/step - loss: 52.0618 - mae: 5.9089 - val_loss: 51.9305 - val_mae: 5.8987\n",
            "Epoch 141/250\n",
            "178/178 [==============================] - 44s 241ms/step - loss: 51.8705 - mae: 5.9001 - val_loss: 51.6089 - val_mae: 5.8869\n",
            "Epoch 142/250\n",
            "178/178 [==============================] - 43s 237ms/step - loss: 51.3762 - mae: 5.8734 - val_loss: 51.4091 - val_mae: 5.8777\n",
            "Epoch 143/250\n",
            "178/178 [==============================] - 39s 215ms/step - loss: 51.1275 - mae: 5.8604 - val_loss: 50.9431 - val_mae: 5.8518\n",
            "Epoch 144/250\n",
            "178/178 [==============================] - 44s 237ms/step - loss: 51.0800 - mae: 5.8609 - val_loss: 50.7033 - val_mae: 5.8416\n",
            "Epoch 145/250\n",
            "178/178 [==============================] - 43s 239ms/step - loss: 50.7295 - mae: 5.8439 - val_loss: 50.7437 - val_mae: 5.8492\n",
            "Epoch 146/250\n",
            "178/178 [==============================] - 45s 248ms/step - loss: 50.1524 - mae: 5.8095 - val_loss: 50.1401 - val_mae: 5.8029\n",
            "Epoch 147/250\n",
            "178/178 [==============================] - 45s 248ms/step - loss: 50.0172 - mae: 5.8031 - val_loss: 50.0042 - val_mae: 5.8064\n",
            "Epoch 148/250\n",
            "178/178 [==============================] - 45s 249ms/step - loss: 49.7570 - mae: 5.7884 - val_loss: 49.4748 - val_mae: 5.7740\n",
            "Epoch 149/250\n",
            "178/178 [==============================] - 45s 250ms/step - loss: 49.4286 - mae: 5.7704 - val_loss: 49.2878 - val_mae: 5.7596\n",
            "Epoch 150/250\n",
            "178/178 [==============================] - 45s 243ms/step - loss: 49.2257 - mae: 5.7627 - val_loss: 49.1665 - val_mae: 5.7591\n",
            "Epoch 151/250\n",
            "178/178 [==============================] - 44s 239ms/step - loss: 48.9543 - mae: 5.7470 - val_loss: 48.5697 - val_mae: 5.7217\n",
            "Epoch 152/250\n",
            "178/178 [==============================] - 45s 247ms/step - loss: 48.5766 - mae: 5.7254 - val_loss: 48.3480 - val_mae: 5.7129\n",
            "Epoch 153/250\n",
            "178/178 [==============================] - 45s 252ms/step - loss: 48.3577 - mae: 5.7149 - val_loss: 48.0303 - val_mae: 5.6947\n",
            "Epoch 154/250\n",
            "178/178 [==============================] - 45s 249ms/step - loss: 48.0494 - mae: 5.6977 - val_loss: 47.8781 - val_mae: 5.6854\n",
            "Epoch 155/250\n",
            "178/178 [==============================] - 45s 249ms/step - loss: 47.8229 - mae: 5.6832 - val_loss: 47.4714 - val_mae: 5.6626\n",
            "Epoch 156/250\n",
            "178/178 [==============================] - 45s 247ms/step - loss: 47.4628 - mae: 5.6631 - val_loss: 47.3129 - val_mae: 5.6543\n",
            "Epoch 157/250\n",
            "178/178 [==============================] - 44s 240ms/step - loss: 47.2994 - mae: 5.6559 - val_loss: 47.1443 - val_mae: 5.6431\n",
            "Epoch 158/250\n",
            "178/178 [==============================] - 44s 239ms/step - loss: 47.0314 - mae: 5.6416 - val_loss: 46.5532 - val_mae: 5.6053\n",
            "Epoch 159/250\n",
            "178/178 [==============================] - 44s 242ms/step - loss: 46.6797 - mae: 5.6178 - val_loss: 46.6296 - val_mae: 5.6128\n",
            "Epoch 160/250\n",
            "178/178 [==============================] - 45s 248ms/step - loss: 46.4395 - mae: 5.6062 - val_loss: 46.0253 - val_mae: 5.5750\n",
            "Epoch 161/250\n",
            "178/178 [==============================] - 45s 249ms/step - loss: 45.9910 - mae: 5.5758 - val_loss: 46.0858 - val_mae: 5.5831\n",
            "Epoch 162/250\n",
            "178/178 [==============================] - 45s 249ms/step - loss: 45.8301 - mae: 5.5695 - val_loss: 45.7755 - val_mae: 5.5699\n",
            "Epoch 163/250\n",
            "178/178 [==============================] - 45s 249ms/step - loss: 45.6182 - mae: 5.5614 - val_loss: 45.3190 - val_mae: 5.5413\n",
            "Epoch 164/250\n",
            "178/178 [==============================] - 44s 245ms/step - loss: 45.3572 - mae: 5.5472 - val_loss: 45.4331 - val_mae: 5.5578\n",
            "Epoch 165/250\n",
            "178/178 [==============================] - 43s 236ms/step - loss: 45.1834 - mae: 5.5441 - val_loss: 44.9815 - val_mae: 5.5360\n",
            "Epoch 166/250\n",
            "178/178 [==============================] - 44s 246ms/step - loss: 44.7440 - mae: 5.5169 - val_loss: 44.9008 - val_mae: 5.5305\n",
            "Epoch 167/250\n",
            "178/178 [==============================] - 45s 249ms/step - loss: 44.5571 - mae: 5.5083 - val_loss: 44.4928 - val_mae: 5.5071\n",
            "Epoch 168/250\n",
            "178/178 [==============================] - 46s 253ms/step - loss: 44.4379 - mae: 5.5060 - val_loss: 44.3903 - val_mae: 5.5049\n",
            "Epoch 169/250\n",
            "178/178 [==============================] - 45s 249ms/step - loss: 44.0875 - mae: 5.4831 - val_loss: 44.2060 - val_mae: 5.4974\n",
            "Epoch 170/250\n",
            "178/178 [==============================] - 46s 253ms/step - loss: 43.9621 - mae: 5.4856 - val_loss: 43.7796 - val_mae: 5.4733\n",
            "Epoch 171/250\n",
            "178/178 [==============================] - 43s 236ms/step - loss: 43.7292 - mae: 5.4713 - val_loss: 43.6460 - val_mae: 5.4661\n",
            "Epoch 172/250\n",
            "178/178 [==============================] - 44s 241ms/step - loss: 43.4744 - mae: 5.4586 - val_loss: 43.5147 - val_mae: 5.4655\n",
            "Epoch 173/250\n",
            "178/178 [==============================] - 45s 249ms/step - loss: 43.1879 - mae: 5.4444 - val_loss: 43.0716 - val_mae: 5.4368\n",
            "Epoch 174/250\n",
            "178/178 [==============================] - 44s 246ms/step - loss: 42.8998 - mae: 5.4258 - val_loss: 42.7115 - val_mae: 5.4173\n",
            "Epoch 175/250\n",
            "178/178 [==============================] - 44s 246ms/step - loss: 42.7170 - mae: 5.4174 - val_loss: 42.5256 - val_mae: 5.4078\n",
            "Epoch 176/250\n",
            "178/178 [==============================] - 44s 245ms/step - loss: 42.5427 - mae: 5.4096 - val_loss: 42.6031 - val_mae: 5.4183\n",
            "Epoch 177/250\n",
            "178/178 [==============================] - 44s 240ms/step - loss: 42.4301 - mae: 5.4084 - val_loss: 42.0394 - val_mae: 5.3803\n",
            "Epoch 178/250\n",
            "178/178 [==============================] - 43s 237ms/step - loss: 42.0358 - mae: 5.3824 - val_loss: 42.0669 - val_mae: 5.3875\n",
            "Epoch 179/250\n",
            "178/178 [==============================] - 43s 236ms/step - loss: 41.7941 - mae: 5.3691 - val_loss: 41.6485 - val_mae: 5.3611\n",
            "Epoch 180/250\n",
            "178/178 [==============================] - 47s 258ms/step - loss: 41.6503 - mae: 5.3605 - val_loss: 41.6323 - val_mae: 5.3620\n",
            "Epoch 181/250\n",
            "178/178 [==============================] - 45s 247ms/step - loss: 41.4428 - mae: 5.3512 - val_loss: 41.3997 - val_mae: 5.3491\n",
            "Epoch 182/250\n",
            "178/178 [==============================] - 45s 249ms/step - loss: 41.2437 - mae: 5.3422 - val_loss: 41.0646 - val_mae: 5.3282\n",
            "Epoch 183/250\n",
            "178/178 [==============================] - 45s 250ms/step - loss: 40.9827 - mae: 5.3241 - val_loss: 40.7830 - val_mae: 5.3103\n",
            "Epoch 184/250\n",
            "178/178 [==============================] - 45s 248ms/step - loss: 40.7838 - mae: 5.3152 - val_loss: 40.7607 - val_mae: 5.3140\n",
            "Epoch 185/250\n",
            "178/178 [==============================] - 44s 246ms/step - loss: 40.6803 - mae: 5.3130 - val_loss: 40.3210 - val_mae: 5.2862\n",
            "Epoch 186/250\n",
            "178/178 [==============================] - 43s 237ms/step - loss: 40.3627 - mae: 5.2905 - val_loss: 40.3906 - val_mae: 5.2934\n",
            "Epoch 187/250\n",
            "178/178 [==============================] - 44s 243ms/step - loss: 40.1637 - mae: 5.2809 - val_loss: 39.9107 - val_mae: 5.2627\n",
            "Epoch 188/250\n",
            "178/178 [==============================] - 45s 246ms/step - loss: 39.9887 - mae: 5.2651 - val_loss: 39.9569 - val_mae: 5.2670\n",
            "Epoch 189/250\n",
            "178/178 [==============================] - 45s 248ms/step - loss: 39.7271 - mae: 5.2535 - val_loss: 39.7568 - val_mae: 5.2525\n",
            "Epoch 190/250\n",
            "178/178 [==============================] - 40s 224ms/step - loss: 39.6694 - mae: 5.2517 - val_loss: 39.5160 - val_mae: 5.2450\n",
            "Epoch 191/250\n",
            "178/178 [==============================] - 45s 247ms/step - loss: 39.4246 - mae: 5.2377 - val_loss: 39.1898 - val_mae: 5.2200\n",
            "Epoch 192/250\n",
            "178/178 [==============================] - 44s 246ms/step - loss: 39.2574 - mae: 5.2271 - val_loss: 39.2460 - val_mae: 5.2245\n",
            "Epoch 193/250\n",
            "178/178 [==============================] - 45s 247ms/step - loss: 39.0887 - mae: 5.2154 - val_loss: 38.9903 - val_mae: 5.2152\n",
            "Epoch 194/250\n",
            "178/178 [==============================] - 47s 259ms/step - loss: 38.8546 - mae: 5.2017 - val_loss: 38.7753 - val_mae: 5.1995\n",
            "Epoch 195/250\n",
            "178/178 [==============================] - 44s 245ms/step - loss: 38.6627 - mae: 5.1959 - val_loss: 38.5596 - val_mae: 5.1905\n",
            "Epoch 196/250\n",
            "178/178 [==============================] - 43s 237ms/step - loss: 38.5114 - mae: 5.1876 - val_loss: 38.3083 - val_mae: 5.1784\n",
            "Epoch 197/250\n",
            "178/178 [==============================] - 43s 236ms/step - loss: 38.3449 - mae: 5.1793 - val_loss: 38.2110 - val_mae: 5.1773\n",
            "Epoch 198/250\n",
            "178/178 [==============================] - 43s 241ms/step - loss: 38.1367 - mae: 5.1709 - val_loss: 38.1181 - val_mae: 5.1702\n",
            "Epoch 199/250\n",
            "178/178 [==============================] - 44s 244ms/step - loss: 37.9501 - mae: 5.1612 - val_loss: 37.7493 - val_mae: 5.1507\n",
            "Epoch 200/250\n",
            "178/178 [==============================] - 45s 247ms/step - loss: 37.6978 - mae: 5.1475 - val_loss: 37.7389 - val_mae: 5.1523\n",
            "Epoch 201/250\n",
            "178/178 [==============================] - 44s 246ms/step - loss: 37.6722 - mae: 5.1515 - val_loss: 37.4224 - val_mae: 5.1328\n",
            "Epoch 202/250\n",
            "178/178 [==============================] - 46s 256ms/step - loss: 37.5332 - mae: 5.1456 - val_loss: 37.2893 - val_mae: 5.1292\n",
            "Epoch 203/250\n",
            "178/178 [==============================] - 43s 237ms/step - loss: 37.3565 - mae: 5.1371 - val_loss: 37.2468 - val_mae: 5.1280\n",
            "Epoch 204/250\n",
            "178/178 [==============================] - 43s 235ms/step - loss: 37.1787 - mae: 5.1283 - val_loss: 37.1854 - val_mae: 5.1290\n",
            "Epoch 205/250\n",
            "178/178 [==============================] - 43s 240ms/step - loss: 36.9574 - mae: 5.1126 - val_loss: 36.9534 - val_mae: 5.1178\n",
            "Epoch 206/250\n",
            "178/178 [==============================] - 44s 244ms/step - loss: 36.8860 - mae: 5.1111 - val_loss: 36.8848 - val_mae: 5.1129\n",
            "Epoch 207/250\n",
            "178/178 [==============================] - 47s 259ms/step - loss: 36.5894 - mae: 5.0942 - val_loss: 36.6493 - val_mae: 5.0999\n",
            "Epoch 208/250\n",
            "178/178 [==============================] - 45s 248ms/step - loss: 36.5209 - mae: 5.0915 - val_loss: 36.4296 - val_mae: 5.0868\n",
            "Epoch 209/250\n",
            "178/178 [==============================] - 45s 248ms/step - loss: 36.4293 - mae: 5.0885 - val_loss: 36.0451 - val_mae: 5.0610\n",
            "Epoch 210/250\n",
            "178/178 [==============================] - 48s 264ms/step - loss: 36.1680 - mae: 5.0729 - val_loss: 36.1729 - val_mae: 5.0712\n",
            "Epoch 211/250\n",
            "178/178 [==============================] - 44s 245ms/step - loss: 36.1037 - mae: 5.0700 - val_loss: 35.7769 - val_mae: 5.0464\n",
            "Epoch 212/250\n",
            "178/178 [==============================] - 43s 237ms/step - loss: 35.9939 - mae: 5.0673 - val_loss: 36.0131 - val_mae: 5.0714\n",
            "Epoch 213/250\n",
            "178/178 [==============================] - 44s 244ms/step - loss: 35.7650 - mae: 5.0512 - val_loss: 35.6677 - val_mae: 5.0493\n",
            "Epoch 214/250\n",
            "178/178 [==============================] - 45s 250ms/step - loss: 35.6658 - mae: 5.0469 - val_loss: 35.6311 - val_mae: 5.0458\n",
            "Epoch 215/250\n",
            "178/178 [==============================] - 45s 249ms/step - loss: 35.4656 - mae: 5.0333 - val_loss: 35.3630 - val_mae: 5.0258\n",
            "Epoch 216/250\n",
            "178/178 [==============================] - 45s 250ms/step - loss: 35.3444 - mae: 5.0298 - val_loss: 35.3231 - val_mae: 5.0305\n",
            "Epoch 217/250\n",
            "178/178 [==============================] - 46s 254ms/step - loss: 35.2196 - mae: 5.0208 - val_loss: 35.2358 - val_mae: 5.0252\n",
            "Epoch 218/250\n",
            "178/178 [==============================] - 46s 253ms/step - loss: 35.1211 - mae: 5.0163 - val_loss: 35.0398 - val_mae: 5.0069\n",
            "Epoch 219/250\n",
            "178/178 [==============================] - 44s 241ms/step - loss: 35.0044 - mae: 5.0091 - val_loss: 34.7798 - val_mae: 4.9952\n",
            "Epoch 220/250\n",
            "178/178 [==============================] - 43s 238ms/step - loss: 34.8750 - mae: 5.0030 - val_loss: 34.7468 - val_mae: 4.9942\n",
            "Epoch 221/250\n",
            "178/178 [==============================] - 45s 251ms/step - loss: 34.7221 - mae: 4.9915 - val_loss: 34.6629 - val_mae: 4.9883\n",
            "Epoch 222/250\n",
            "178/178 [==============================] - 45s 249ms/step - loss: 34.6450 - mae: 4.9880 - val_loss: 34.5754 - val_mae: 4.9863\n",
            "Epoch 223/250\n",
            "178/178 [==============================] - 45s 250ms/step - loss: 34.5262 - mae: 4.9820 - val_loss: 34.3987 - val_mae: 4.9738\n",
            "Epoch 224/250\n",
            "178/178 [==============================] - 46s 249ms/step - loss: 34.3924 - mae: 4.9737 - val_loss: 34.3765 - val_mae: 4.9737\n",
            "Epoch 225/250\n",
            "178/178 [==============================] - 45s 245ms/step - loss: 34.2855 - mae: 4.9656 - val_loss: 34.3180 - val_mae: 4.9727\n",
            "Epoch 226/250\n",
            "178/178 [==============================] - 43s 237ms/step - loss: 34.1361 - mae: 4.9526 - val_loss: 34.0085 - val_mae: 4.9464\n",
            "Epoch 227/250\n",
            "178/178 [==============================] - 43s 237ms/step - loss: 33.9833 - mae: 4.9451 - val_loss: 33.9835 - val_mae: 4.9462\n",
            "Epoch 228/250\n",
            "178/178 [==============================] - 44s 243ms/step - loss: 33.9622 - mae: 4.9471 - val_loss: 33.8185 - val_mae: 4.9356\n",
            "Epoch 229/250\n",
            "178/178 [==============================] - 45s 250ms/step - loss: 33.7856 - mae: 4.9378 - val_loss: 33.6494 - val_mae: 4.9249\n",
            "Epoch 230/250\n",
            "178/178 [==============================] - 45s 251ms/step - loss: 33.6533 - mae: 4.9324 - val_loss: 33.5746 - val_mae: 4.9305\n",
            "Epoch 231/250\n",
            "178/178 [==============================] - 45s 248ms/step - loss: 33.6234 - mae: 4.9335 - val_loss: 33.5074 - val_mae: 4.9234\n",
            "Epoch 232/250\n",
            "178/178 [==============================] - 45s 252ms/step - loss: 33.4528 - mae: 4.9202 - val_loss: 33.4010 - val_mae: 4.9197\n",
            "Epoch 233/250\n",
            "178/178 [==============================] - 45s 252ms/step - loss: 33.3960 - mae: 4.9215 - val_loss: 33.4846 - val_mae: 4.9310\n",
            "Epoch 234/250\n",
            "178/178 [==============================] - 45s 246ms/step - loss: 33.2508 - mae: 4.9145 - val_loss: 33.2191 - val_mae: 4.9162\n",
            "Epoch 235/250\n",
            "178/178 [==============================] - 44s 239ms/step - loss: 33.1839 - mae: 4.9129 - val_loss: 33.2539 - val_mae: 4.9184\n",
            "Epoch 236/250\n",
            "178/178 [==============================] - 43s 238ms/step - loss: 33.0786 - mae: 4.9076 - val_loss: 33.0517 - val_mae: 4.9030\n",
            "Epoch 237/250\n",
            "178/178 [==============================] - 45s 251ms/step - loss: 33.0090 - mae: 4.9042 - val_loss: 32.9500 - val_mae: 4.8998\n",
            "Epoch 238/250\n",
            "178/178 [==============================] - 45s 249ms/step - loss: 32.9438 - mae: 4.9024 - val_loss: 32.8961 - val_mae: 4.9008\n",
            "Epoch 239/250\n",
            "178/178 [==============================] - 45s 251ms/step - loss: 32.7772 - mae: 4.8915 - val_loss: 32.7495 - val_mae: 4.8888\n",
            "Epoch 240/250\n",
            "178/178 [==============================] - 45s 248ms/step - loss: 32.7767 - mae: 4.8955 - val_loss: 32.6208 - val_mae: 4.8821\n",
            "Epoch 241/250\n",
            "178/178 [==============================] - 44s 241ms/step - loss: 32.7236 - mae: 4.8941 - val_loss: 32.7078 - val_mae: 4.8950\n",
            "Epoch 242/250\n",
            "178/178 [==============================] - 44s 241ms/step - loss: 32.6289 - mae: 4.8893 - val_loss: 32.5478 - val_mae: 4.8865\n",
            "Epoch 243/250\n",
            "178/178 [==============================] - 51s 284ms/step - loss: 32.5602 - mae: 4.8865 - val_loss: 32.4867 - val_mae: 4.8818\n",
            "Epoch 244/250\n",
            "178/178 [==============================] - 46s 253ms/step - loss: 32.3611 - mae: 4.8716 - val_loss: 32.3882 - val_mae: 4.8736\n",
            "Epoch 245/250\n",
            "178/178 [==============================] - 45s 249ms/step - loss: 32.3599 - mae: 4.8731 - val_loss: 32.3460 - val_mae: 4.8717\n",
            "Epoch 246/250\n",
            "178/178 [==============================] - 45s 248ms/step - loss: 32.2387 - mae: 4.8667 - val_loss: 32.2611 - val_mae: 4.8699\n",
            "Epoch 247/250\n",
            "178/178 [==============================] - 45s 250ms/step - loss: 32.2039 - mae: 4.8647 - val_loss: 32.2669 - val_mae: 4.8712\n",
            "Epoch 248/250\n",
            "178/178 [==============================] - 44s 244ms/step - loss: 32.1013 - mae: 4.8593 - val_loss: 32.1231 - val_mae: 4.8629\n",
            "Epoch 249/250\n",
            "178/178 [==============================] - 44s 241ms/step - loss: 32.0854 - mae: 4.8607 - val_loss: 32.0831 - val_mae: 4.8631\n",
            "Epoch 250/250\n",
            "178/178 [==============================] - 43s 236ms/step - loss: 31.9332 - mae: 4.8490 - val_loss: 32.0138 - val_mae: 4.8555\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "mae = history.history['mae']\n",
        "val_mae = history.history['val_mae']\n",
        "\n",
        "\n",
        "epochs_x = range(len(loss))\n",
        "\n",
        "\n",
        "# plt.plot(epochs_x, mae, 'go', label='Training MAE')\n",
        "plt.plot(epochs_x, mae, 'o', color ='darkviolet', label='Training MAE')\n",
        "plt.plot(epochs_x, val_mae, 'k', label='Validation MAE')\n",
        "plt.title('Training and validation MeanAbsoluteError')\n",
        "plt.legend()\n",
        "\n",
        "plt.figure()\n",
        "# plt.plot(epochs_x, loss, 'go', label='Training loss')\n",
        "plt.plot(epochs_x, loss, 'o', color ='darkviolet', label='Training loss')\n",
        "plt.plot(epochs_x, val_loss, 'k', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Y3K89-CM-dfg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545
        },
        "outputId": "305ef500-f778-4d8d-aa6f-a53764cfcd93"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "epochs_x"
      ],
      "metadata": {
        "id": "N_sP_ZmSY-Jv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "78e505f8-daf6-4166-c4fa-5d70a37aee07"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "range(0, 250)"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Download the model\n"
      ],
      "metadata": {
        "id": "R19IJQSYoW7J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "os.makedirs('/content/drive/My Drive/cut_panoramic/Model', exist_ok=True)\n",
        "model.save('/content/drive/My Drive/cut_panoramic/Model/1Re_All_1G_1e-4_16_0.2_250.h5')"
      ],
      "metadata": {
        "id": "Zed4TdFcG2iJ"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "n5YxZ-5QjQ0-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# from google.colab import files\n",
        "# files.download('/content/drive/My Drive/cut_panoramic/Model/1.1_รอบแรก_Flimpano_Male125_250.h5')"
      ],
      "metadata": {
        "id": "P5eMxm1NV-oY"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "wY_pDlxkRwxS"
      },
      "execution_count": 23,
      "outputs": []
    }
  ]
}