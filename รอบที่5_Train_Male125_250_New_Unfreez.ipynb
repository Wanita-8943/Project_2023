{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Wanita-8943/Project_2023/blob/main/%E0%B8%A3%E0%B8%AD%E0%B8%9A%E0%B8%97%E0%B8%B5%E0%B9%885_Train_Male125_250_New_Unfreez.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "KKSs7cyoPHcD"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import shutil"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7LoeZxmVPMxp",
        "outputId": "313f0db8-fe62-4296-c13a-3d919a5c5542"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import models\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import optimizers\n",
        "import os\n",
        "import glob\n",
        "import shutil\n",
        "import sys\n",
        "import numpy as np\n",
        "from skimage.io import imread\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import Image\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "1pX9g1HxPM2f"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 16\n",
        "width = 150\n",
        "height = 150\n",
        "epochs = 250\n",
        "NUM_TRAIN = 1425\n",
        "NUM_TEST = 475\n",
        "dropout_rate = 0.2\n",
        "input_shape = (height, width, 3)"
      ],
      "metadata": {
        "id": "eSFtvGyvPM6O"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#ดึงข้อมูลใน Github มาใช้\n",
        "import os\n",
        "%cd /content\n",
        "if not os.path.isdir(\"efficientnet_keras_transfer_learning\"):\n",
        " !git clone https://github.com/Wanita-8943/efficientnet_keras_transfer_learning\n",
        "%cd efficientnet_keras_transfer_learning/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lb4K4CsMPNAW",
        "outputId": "c8e6b7cf-d8b4-4c47-aa0f-7a5208ce9244"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "Cloning into 'efficientnet_keras_transfer_learning'...\n",
            "remote: Enumerating objects: 837, done.\u001b[K\n",
            "remote: Counting objects: 100% (359/359), done.\u001b[K\n",
            "remote: Compressing objects: 100% (124/124), done.\u001b[K\n",
            "remote: Total 837 (delta 255), reused 328 (delta 235), pack-reused 478\u001b[K\n",
            "Receiving objects: 100% (837/837), 13.82 MiB | 29.42 MiB/s, done.\n",
            "Resolving deltas: 100% (495/495), done.\n",
            "/content/efficientnet_keras_transfer_learning\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Options: EfficientNetB0, EfficientNetB1, EfficientNetB2, EfficientNetB3\n",
        "# Higher the number, the more complex the model is.\n",
        "from efficientnet import EfficientNetB0 as Net\n",
        "from efficientnet import center_crop_and_resize, preprocess_input"
      ],
      "metadata": {
        "id": "eyBg0dLKPND3"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# loading pretrained conv base model\n",
        "# โหลดโมเดล มาโดยตัด output ของโมเดลออก เเต่ยังใช้ input อันเดิม\n",
        "# เเละโหลด weight ของโมเดล มาด้วยที่ชื่อว่า imagenet\n",
        "conv_base = Net(weights='imagenet', include_top=False, input_shape=input_shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DoxI-q8-1giK",
        "outputId": "6954be14-6e17-4a14-e2a4-6a92d5f177fc"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
            "Instructions for updating:\n",
            "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://github.com/qubvel/efficientnet/releases/download/v0.0.1/efficientnet-b0_imagenet_1000_notop.h5\n",
            "16717576/16717576 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "conv_base.summary() #ดู Summary"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "od4Lp6dD1lWK",
        "outputId": "6edbc3d0-1088-4a06-da20-f462483b2003"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"efficientnet-b0\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 150, 150, 3  0           []                               \n",
            "                                )]                                                                \n",
            "                                                                                                  \n",
            " conv2d (Conv2D)                (None, 75, 75, 32)   864         ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " batch_normalization (BatchNorm  (None, 75, 75, 32)  128         ['conv2d[0][0]']                 \n",
            " alization)                                                                                       \n",
            "                                                                                                  \n",
            " swish (Swish)                  (None, 75, 75, 32)   0           ['batch_normalization[0][0]']    \n",
            "                                                                                                  \n",
            " depthwise_conv2d (DepthwiseCon  (None, 75, 75, 32)  288         ['swish[0][0]']                  \n",
            " v2D)                                                                                             \n",
            "                                                                                                  \n",
            " batch_normalization_1 (BatchNo  (None, 75, 75, 32)  128         ['depthwise_conv2d[0][0]']       \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " swish_1 (Swish)                (None, 75, 75, 32)   0           ['batch_normalization_1[0][0]']  \n",
            "                                                                                                  \n",
            " lambda (Lambda)                (None, 1, 1, 32)     0           ['swish_1[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d_1 (Conv2D)              (None, 1, 1, 8)      264         ['lambda[0][0]']                 \n",
            "                                                                                                  \n",
            " swish_2 (Swish)                (None, 1, 1, 8)      0           ['conv2d_1[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_2 (Conv2D)              (None, 1, 1, 32)     288         ['swish_2[0][0]']                \n",
            "                                                                                                  \n",
            " activation (Activation)        (None, 1, 1, 32)     0           ['conv2d_2[0][0]']               \n",
            "                                                                                                  \n",
            " multiply (Multiply)            (None, 75, 75, 32)   0           ['activation[0][0]',             \n",
            "                                                                  'swish_1[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d_3 (Conv2D)              (None, 75, 75, 16)   512         ['multiply[0][0]']               \n",
            "                                                                                                  \n",
            " batch_normalization_2 (BatchNo  (None, 75, 75, 16)  64          ['conv2d_3[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv2d_4 (Conv2D)              (None, 75, 75, 96)   1536        ['batch_normalization_2[0][0]']  \n",
            "                                                                                                  \n",
            " batch_normalization_3 (BatchNo  (None, 75, 75, 96)  384         ['conv2d_4[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " swish_3 (Swish)                (None, 75, 75, 96)   0           ['batch_normalization_3[0][0]']  \n",
            "                                                                                                  \n",
            " depthwise_conv2d_1 (DepthwiseC  (None, 38, 38, 96)  864         ['swish_3[0][0]']                \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_4 (BatchNo  (None, 38, 38, 96)  384         ['depthwise_conv2d_1[0][0]']     \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " swish_4 (Swish)                (None, 38, 38, 96)   0           ['batch_normalization_4[0][0]']  \n",
            "                                                                                                  \n",
            " lambda_1 (Lambda)              (None, 1, 1, 96)     0           ['swish_4[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d_5 (Conv2D)              (None, 1, 1, 4)      388         ['lambda_1[0][0]']               \n",
            "                                                                                                  \n",
            " swish_5 (Swish)                (None, 1, 1, 4)      0           ['conv2d_5[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_6 (Conv2D)              (None, 1, 1, 96)     480         ['swish_5[0][0]']                \n",
            "                                                                                                  \n",
            " activation_1 (Activation)      (None, 1, 1, 96)     0           ['conv2d_6[0][0]']               \n",
            "                                                                                                  \n",
            " multiply_1 (Multiply)          (None, 38, 38, 96)   0           ['activation_1[0][0]',           \n",
            "                                                                  'swish_4[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d_7 (Conv2D)              (None, 38, 38, 24)   2304        ['multiply_1[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_5 (BatchNo  (None, 38, 38, 24)  96          ['conv2d_7[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv2d_8 (Conv2D)              (None, 38, 38, 144)  3456        ['batch_normalization_5[0][0]']  \n",
            "                                                                                                  \n",
            " batch_normalization_6 (BatchNo  (None, 38, 38, 144)  576        ['conv2d_8[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " swish_6 (Swish)                (None, 38, 38, 144)  0           ['batch_normalization_6[0][0]']  \n",
            "                                                                                                  \n",
            " depthwise_conv2d_2 (DepthwiseC  (None, 38, 38, 144)  1296       ['swish_6[0][0]']                \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_7 (BatchNo  (None, 38, 38, 144)  576        ['depthwise_conv2d_2[0][0]']     \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " swish_7 (Swish)                (None, 38, 38, 144)  0           ['batch_normalization_7[0][0]']  \n",
            "                                                                                                  \n",
            " lambda_2 (Lambda)              (None, 1, 1, 144)    0           ['swish_7[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d_9 (Conv2D)              (None, 1, 1, 6)      870         ['lambda_2[0][0]']               \n",
            "                                                                                                  \n",
            " swish_8 (Swish)                (None, 1, 1, 6)      0           ['conv2d_9[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_10 (Conv2D)             (None, 1, 1, 144)    1008        ['swish_8[0][0]']                \n",
            "                                                                                                  \n",
            " activation_2 (Activation)      (None, 1, 1, 144)    0           ['conv2d_10[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_2 (Multiply)          (None, 38, 38, 144)  0           ['activation_2[0][0]',           \n",
            "                                                                  'swish_7[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d_11 (Conv2D)             (None, 38, 38, 24)   3456        ['multiply_2[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_8 (BatchNo  (None, 38, 38, 24)  96          ['conv2d_11[0][0]']              \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " drop_connect (DropConnect)     (None, 38, 38, 24)   0           ['batch_normalization_8[0][0]']  \n",
            "                                                                                                  \n",
            " add (Add)                      (None, 38, 38, 24)   0           ['drop_connect[0][0]',           \n",
            "                                                                  'batch_normalization_5[0][0]']  \n",
            "                                                                                                  \n",
            " conv2d_12 (Conv2D)             (None, 38, 38, 144)  3456        ['add[0][0]']                    \n",
            "                                                                                                  \n",
            " batch_normalization_9 (BatchNo  (None, 38, 38, 144)  576        ['conv2d_12[0][0]']              \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " swish_9 (Swish)                (None, 38, 38, 144)  0           ['batch_normalization_9[0][0]']  \n",
            "                                                                                                  \n",
            " depthwise_conv2d_3 (DepthwiseC  (None, 19, 19, 144)  3600       ['swish_9[0][0]']                \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_10 (BatchN  (None, 19, 19, 144)  576        ['depthwise_conv2d_3[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_10 (Swish)               (None, 19, 19, 144)  0           ['batch_normalization_10[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_3 (Lambda)              (None, 1, 1, 144)    0           ['swish_10[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_13 (Conv2D)             (None, 1, 1, 6)      870         ['lambda_3[0][0]']               \n",
            "                                                                                                  \n",
            " swish_11 (Swish)               (None, 1, 1, 6)      0           ['conv2d_13[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_14 (Conv2D)             (None, 1, 1, 144)    1008        ['swish_11[0][0]']               \n",
            "                                                                                                  \n",
            " activation_3 (Activation)      (None, 1, 1, 144)    0           ['conv2d_14[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_3 (Multiply)          (None, 19, 19, 144)  0           ['activation_3[0][0]',           \n",
            "                                                                  'swish_10[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_15 (Conv2D)             (None, 19, 19, 40)   5760        ['multiply_3[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_11 (BatchN  (None, 19, 19, 40)  160         ['conv2d_15[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_16 (Conv2D)             (None, 19, 19, 240)  9600        ['batch_normalization_11[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_12 (BatchN  (None, 19, 19, 240)  960        ['conv2d_16[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_12 (Swish)               (None, 19, 19, 240)  0           ['batch_normalization_12[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_4 (DepthwiseC  (None, 19, 19, 240)  6000       ['swish_12[0][0]']               \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_13 (BatchN  (None, 19, 19, 240)  960        ['depthwise_conv2d_4[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_13 (Swish)               (None, 19, 19, 240)  0           ['batch_normalization_13[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_4 (Lambda)              (None, 1, 1, 240)    0           ['swish_13[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_17 (Conv2D)             (None, 1, 1, 10)     2410        ['lambda_4[0][0]']               \n",
            "                                                                                                  \n",
            " swish_14 (Swish)               (None, 1, 1, 10)     0           ['conv2d_17[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_18 (Conv2D)             (None, 1, 1, 240)    2640        ['swish_14[0][0]']               \n",
            "                                                                                                  \n",
            " activation_4 (Activation)      (None, 1, 1, 240)    0           ['conv2d_18[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_4 (Multiply)          (None, 19, 19, 240)  0           ['activation_4[0][0]',           \n",
            "                                                                  'swish_13[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_19 (Conv2D)             (None, 19, 19, 40)   9600        ['multiply_4[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_14 (BatchN  (None, 19, 19, 40)  160         ['conv2d_19[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_1 (DropConnect)   (None, 19, 19, 40)   0           ['batch_normalization_14[0][0]'] \n",
            "                                                                                                  \n",
            " add_1 (Add)                    (None, 19, 19, 40)   0           ['drop_connect_1[0][0]',         \n",
            "                                                                  'batch_normalization_11[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_20 (Conv2D)             (None, 19, 19, 240)  9600        ['add_1[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_15 (BatchN  (None, 19, 19, 240)  960        ['conv2d_20[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_15 (Swish)               (None, 19, 19, 240)  0           ['batch_normalization_15[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_5 (DepthwiseC  (None, 10, 10, 240)  2160       ['swish_15[0][0]']               \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_16 (BatchN  (None, 10, 10, 240)  960        ['depthwise_conv2d_5[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_16 (Swish)               (None, 10, 10, 240)  0           ['batch_normalization_16[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_5 (Lambda)              (None, 1, 1, 240)    0           ['swish_16[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_21 (Conv2D)             (None, 1, 1, 10)     2410        ['lambda_5[0][0]']               \n",
            "                                                                                                  \n",
            " swish_17 (Swish)               (None, 1, 1, 10)     0           ['conv2d_21[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_22 (Conv2D)             (None, 1, 1, 240)    2640        ['swish_17[0][0]']               \n",
            "                                                                                                  \n",
            " activation_5 (Activation)      (None, 1, 1, 240)    0           ['conv2d_22[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_5 (Multiply)          (None, 10, 10, 240)  0           ['activation_5[0][0]',           \n",
            "                                                                  'swish_16[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_23 (Conv2D)             (None, 10, 10, 80)   19200       ['multiply_5[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_17 (BatchN  (None, 10, 10, 80)  320         ['conv2d_23[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_24 (Conv2D)             (None, 10, 10, 480)  38400       ['batch_normalization_17[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_18 (BatchN  (None, 10, 10, 480)  1920       ['conv2d_24[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_18 (Swish)               (None, 10, 10, 480)  0           ['batch_normalization_18[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_6 (DepthwiseC  (None, 10, 10, 480)  4320       ['swish_18[0][0]']               \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_19 (BatchN  (None, 10, 10, 480)  1920       ['depthwise_conv2d_6[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_19 (Swish)               (None, 10, 10, 480)  0           ['batch_normalization_19[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_6 (Lambda)              (None, 1, 1, 480)    0           ['swish_19[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_25 (Conv2D)             (None, 1, 1, 20)     9620        ['lambda_6[0][0]']               \n",
            "                                                                                                  \n",
            " swish_20 (Swish)               (None, 1, 1, 20)     0           ['conv2d_25[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_26 (Conv2D)             (None, 1, 1, 480)    10080       ['swish_20[0][0]']               \n",
            "                                                                                                  \n",
            " activation_6 (Activation)      (None, 1, 1, 480)    0           ['conv2d_26[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_6 (Multiply)          (None, 10, 10, 480)  0           ['activation_6[0][0]',           \n",
            "                                                                  'swish_19[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_27 (Conv2D)             (None, 10, 10, 80)   38400       ['multiply_6[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_20 (BatchN  (None, 10, 10, 80)  320         ['conv2d_27[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_2 (DropConnect)   (None, 10, 10, 80)   0           ['batch_normalization_20[0][0]'] \n",
            "                                                                                                  \n",
            " add_2 (Add)                    (None, 10, 10, 80)   0           ['drop_connect_2[0][0]',         \n",
            "                                                                  'batch_normalization_17[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_28 (Conv2D)             (None, 10, 10, 480)  38400       ['add_2[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_21 (BatchN  (None, 10, 10, 480)  1920       ['conv2d_28[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_21 (Swish)               (None, 10, 10, 480)  0           ['batch_normalization_21[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_7 (DepthwiseC  (None, 10, 10, 480)  4320       ['swish_21[0][0]']               \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_22 (BatchN  (None, 10, 10, 480)  1920       ['depthwise_conv2d_7[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_22 (Swish)               (None, 10, 10, 480)  0           ['batch_normalization_22[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_7 (Lambda)              (None, 1, 1, 480)    0           ['swish_22[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_29 (Conv2D)             (None, 1, 1, 20)     9620        ['lambda_7[0][0]']               \n",
            "                                                                                                  \n",
            " swish_23 (Swish)               (None, 1, 1, 20)     0           ['conv2d_29[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_30 (Conv2D)             (None, 1, 1, 480)    10080       ['swish_23[0][0]']               \n",
            "                                                                                                  \n",
            " activation_7 (Activation)      (None, 1, 1, 480)    0           ['conv2d_30[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_7 (Multiply)          (None, 10, 10, 480)  0           ['activation_7[0][0]',           \n",
            "                                                                  'swish_22[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_31 (Conv2D)             (None, 10, 10, 80)   38400       ['multiply_7[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_23 (BatchN  (None, 10, 10, 80)  320         ['conv2d_31[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_3 (DropConnect)   (None, 10, 10, 80)   0           ['batch_normalization_23[0][0]'] \n",
            "                                                                                                  \n",
            " add_3 (Add)                    (None, 10, 10, 80)   0           ['drop_connect_3[0][0]',         \n",
            "                                                                  'add_2[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_32 (Conv2D)             (None, 10, 10, 480)  38400       ['add_3[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_24 (BatchN  (None, 10, 10, 480)  1920       ['conv2d_32[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_24 (Swish)               (None, 10, 10, 480)  0           ['batch_normalization_24[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_8 (DepthwiseC  (None, 10, 10, 480)  12000      ['swish_24[0][0]']               \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_25 (BatchN  (None, 10, 10, 480)  1920       ['depthwise_conv2d_8[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_25 (Swish)               (None, 10, 10, 480)  0           ['batch_normalization_25[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_8 (Lambda)              (None, 1, 1, 480)    0           ['swish_25[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_33 (Conv2D)             (None, 1, 1, 20)     9620        ['lambda_8[0][0]']               \n",
            "                                                                                                  \n",
            " swish_26 (Swish)               (None, 1, 1, 20)     0           ['conv2d_33[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_34 (Conv2D)             (None, 1, 1, 480)    10080       ['swish_26[0][0]']               \n",
            "                                                                                                  \n",
            " activation_8 (Activation)      (None, 1, 1, 480)    0           ['conv2d_34[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_8 (Multiply)          (None, 10, 10, 480)  0           ['activation_8[0][0]',           \n",
            "                                                                  'swish_25[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_35 (Conv2D)             (None, 10, 10, 112)  53760       ['multiply_8[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_26 (BatchN  (None, 10, 10, 112)  448        ['conv2d_35[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_36 (Conv2D)             (None, 10, 10, 672)  75264       ['batch_normalization_26[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_27 (BatchN  (None, 10, 10, 672)  2688       ['conv2d_36[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_27 (Swish)               (None, 10, 10, 672)  0           ['batch_normalization_27[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_9 (DepthwiseC  (None, 10, 10, 672)  16800      ['swish_27[0][0]']               \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_28 (BatchN  (None, 10, 10, 672)  2688       ['depthwise_conv2d_9[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_28 (Swish)               (None, 10, 10, 672)  0           ['batch_normalization_28[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_9 (Lambda)              (None, 1, 1, 672)    0           ['swish_28[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_37 (Conv2D)             (None, 1, 1, 28)     18844       ['lambda_9[0][0]']               \n",
            "                                                                                                  \n",
            " swish_29 (Swish)               (None, 1, 1, 28)     0           ['conv2d_37[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_38 (Conv2D)             (None, 1, 1, 672)    19488       ['swish_29[0][0]']               \n",
            "                                                                                                  \n",
            " activation_9 (Activation)      (None, 1, 1, 672)    0           ['conv2d_38[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_9 (Multiply)          (None, 10, 10, 672)  0           ['activation_9[0][0]',           \n",
            "                                                                  'swish_28[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_39 (Conv2D)             (None, 10, 10, 112)  75264       ['multiply_9[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_29 (BatchN  (None, 10, 10, 112)  448        ['conv2d_39[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_4 (DropConnect)   (None, 10, 10, 112)  0           ['batch_normalization_29[0][0]'] \n",
            "                                                                                                  \n",
            " add_4 (Add)                    (None, 10, 10, 112)  0           ['drop_connect_4[0][0]',         \n",
            "                                                                  'batch_normalization_26[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_40 (Conv2D)             (None, 10, 10, 672)  75264       ['add_4[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_30 (BatchN  (None, 10, 10, 672)  2688       ['conv2d_40[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_30 (Swish)               (None, 10, 10, 672)  0           ['batch_normalization_30[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_10 (Depthwise  (None, 10, 10, 672)  16800      ['swish_30[0][0]']               \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_31 (BatchN  (None, 10, 10, 672)  2688       ['depthwise_conv2d_10[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_31 (Swish)               (None, 10, 10, 672)  0           ['batch_normalization_31[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_10 (Lambda)             (None, 1, 1, 672)    0           ['swish_31[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_41 (Conv2D)             (None, 1, 1, 28)     18844       ['lambda_10[0][0]']              \n",
            "                                                                                                  \n",
            " swish_32 (Swish)               (None, 1, 1, 28)     0           ['conv2d_41[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_42 (Conv2D)             (None, 1, 1, 672)    19488       ['swish_32[0][0]']               \n",
            "                                                                                                  \n",
            " activation_10 (Activation)     (None, 1, 1, 672)    0           ['conv2d_42[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_10 (Multiply)         (None, 10, 10, 672)  0           ['activation_10[0][0]',          \n",
            "                                                                  'swish_31[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_43 (Conv2D)             (None, 10, 10, 112)  75264       ['multiply_10[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_32 (BatchN  (None, 10, 10, 112)  448        ['conv2d_43[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_5 (DropConnect)   (None, 10, 10, 112)  0           ['batch_normalization_32[0][0]'] \n",
            "                                                                                                  \n",
            " add_5 (Add)                    (None, 10, 10, 112)  0           ['drop_connect_5[0][0]',         \n",
            "                                                                  'add_4[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_44 (Conv2D)             (None, 10, 10, 672)  75264       ['add_5[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_33 (BatchN  (None, 10, 10, 672)  2688       ['conv2d_44[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_33 (Swish)               (None, 10, 10, 672)  0           ['batch_normalization_33[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_11 (Depthwise  (None, 5, 5, 672)   16800       ['swish_33[0][0]']               \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_34 (BatchN  (None, 5, 5, 672)   2688        ['depthwise_conv2d_11[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_34 (Swish)               (None, 5, 5, 672)    0           ['batch_normalization_34[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_11 (Lambda)             (None, 1, 1, 672)    0           ['swish_34[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_45 (Conv2D)             (None, 1, 1, 28)     18844       ['lambda_11[0][0]']              \n",
            "                                                                                                  \n",
            " swish_35 (Swish)               (None, 1, 1, 28)     0           ['conv2d_45[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_46 (Conv2D)             (None, 1, 1, 672)    19488       ['swish_35[0][0]']               \n",
            "                                                                                                  \n",
            " activation_11 (Activation)     (None, 1, 1, 672)    0           ['conv2d_46[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_11 (Multiply)         (None, 5, 5, 672)    0           ['activation_11[0][0]',          \n",
            "                                                                  'swish_34[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_47 (Conv2D)             (None, 5, 5, 192)    129024      ['multiply_11[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_35 (BatchN  (None, 5, 5, 192)   768         ['conv2d_47[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_48 (Conv2D)             (None, 5, 5, 1152)   221184      ['batch_normalization_35[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_36 (BatchN  (None, 5, 5, 1152)  4608        ['conv2d_48[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_36 (Swish)               (None, 5, 5, 1152)   0           ['batch_normalization_36[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_12 (Depthwise  (None, 5, 5, 1152)  28800       ['swish_36[0][0]']               \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_37 (BatchN  (None, 5, 5, 1152)  4608        ['depthwise_conv2d_12[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_37 (Swish)               (None, 5, 5, 1152)   0           ['batch_normalization_37[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_12 (Lambda)             (None, 1, 1, 1152)   0           ['swish_37[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_49 (Conv2D)             (None, 1, 1, 48)     55344       ['lambda_12[0][0]']              \n",
            "                                                                                                  \n",
            " swish_38 (Swish)               (None, 1, 1, 48)     0           ['conv2d_49[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_50 (Conv2D)             (None, 1, 1, 1152)   56448       ['swish_38[0][0]']               \n",
            "                                                                                                  \n",
            " activation_12 (Activation)     (None, 1, 1, 1152)   0           ['conv2d_50[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_12 (Multiply)         (None, 5, 5, 1152)   0           ['activation_12[0][0]',          \n",
            "                                                                  'swish_37[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_51 (Conv2D)             (None, 5, 5, 192)    221184      ['multiply_12[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_38 (BatchN  (None, 5, 5, 192)   768         ['conv2d_51[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_6 (DropConnect)   (None, 5, 5, 192)    0           ['batch_normalization_38[0][0]'] \n",
            "                                                                                                  \n",
            " add_6 (Add)                    (None, 5, 5, 192)    0           ['drop_connect_6[0][0]',         \n",
            "                                                                  'batch_normalization_35[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_52 (Conv2D)             (None, 5, 5, 1152)   221184      ['add_6[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_39 (BatchN  (None, 5, 5, 1152)  4608        ['conv2d_52[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_39 (Swish)               (None, 5, 5, 1152)   0           ['batch_normalization_39[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_13 (Depthwise  (None, 5, 5, 1152)  28800       ['swish_39[0][0]']               \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_40 (BatchN  (None, 5, 5, 1152)  4608        ['depthwise_conv2d_13[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_40 (Swish)               (None, 5, 5, 1152)   0           ['batch_normalization_40[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_13 (Lambda)             (None, 1, 1, 1152)   0           ['swish_40[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_53 (Conv2D)             (None, 1, 1, 48)     55344       ['lambda_13[0][0]']              \n",
            "                                                                                                  \n",
            " swish_41 (Swish)               (None, 1, 1, 48)     0           ['conv2d_53[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_54 (Conv2D)             (None, 1, 1, 1152)   56448       ['swish_41[0][0]']               \n",
            "                                                                                                  \n",
            " activation_13 (Activation)     (None, 1, 1, 1152)   0           ['conv2d_54[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_13 (Multiply)         (None, 5, 5, 1152)   0           ['activation_13[0][0]',          \n",
            "                                                                  'swish_40[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_55 (Conv2D)             (None, 5, 5, 192)    221184      ['multiply_13[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_41 (BatchN  (None, 5, 5, 192)   768         ['conv2d_55[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_7 (DropConnect)   (None, 5, 5, 192)    0           ['batch_normalization_41[0][0]'] \n",
            "                                                                                                  \n",
            " add_7 (Add)                    (None, 5, 5, 192)    0           ['drop_connect_7[0][0]',         \n",
            "                                                                  'add_6[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_56 (Conv2D)             (None, 5, 5, 1152)   221184      ['add_7[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_42 (BatchN  (None, 5, 5, 1152)  4608        ['conv2d_56[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_42 (Swish)               (None, 5, 5, 1152)   0           ['batch_normalization_42[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_14 (Depthwise  (None, 5, 5, 1152)  28800       ['swish_42[0][0]']               \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_43 (BatchN  (None, 5, 5, 1152)  4608        ['depthwise_conv2d_14[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_43 (Swish)               (None, 5, 5, 1152)   0           ['batch_normalization_43[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_14 (Lambda)             (None, 1, 1, 1152)   0           ['swish_43[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_57 (Conv2D)             (None, 1, 1, 48)     55344       ['lambda_14[0][0]']              \n",
            "                                                                                                  \n",
            " swish_44 (Swish)               (None, 1, 1, 48)     0           ['conv2d_57[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_58 (Conv2D)             (None, 1, 1, 1152)   56448       ['swish_44[0][0]']               \n",
            "                                                                                                  \n",
            " activation_14 (Activation)     (None, 1, 1, 1152)   0           ['conv2d_58[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_14 (Multiply)         (None, 5, 5, 1152)   0           ['activation_14[0][0]',          \n",
            "                                                                  'swish_43[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_59 (Conv2D)             (None, 5, 5, 192)    221184      ['multiply_14[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_44 (BatchN  (None, 5, 5, 192)   768         ['conv2d_59[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_8 (DropConnect)   (None, 5, 5, 192)    0           ['batch_normalization_44[0][0]'] \n",
            "                                                                                                  \n",
            " add_8 (Add)                    (None, 5, 5, 192)    0           ['drop_connect_8[0][0]',         \n",
            "                                                                  'add_7[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_60 (Conv2D)             (None, 5, 5, 1152)   221184      ['add_8[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_45 (BatchN  (None, 5, 5, 1152)  4608        ['conv2d_60[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_45 (Swish)               (None, 5, 5, 1152)   0           ['batch_normalization_45[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_15 (Depthwise  (None, 5, 5, 1152)  10368       ['swish_45[0][0]']               \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_46 (BatchN  (None, 5, 5, 1152)  4608        ['depthwise_conv2d_15[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_46 (Swish)               (None, 5, 5, 1152)   0           ['batch_normalization_46[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_15 (Lambda)             (None, 1, 1, 1152)   0           ['swish_46[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_61 (Conv2D)             (None, 1, 1, 48)     55344       ['lambda_15[0][0]']              \n",
            "                                                                                                  \n",
            " swish_47 (Swish)               (None, 1, 1, 48)     0           ['conv2d_61[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_62 (Conv2D)             (None, 1, 1, 1152)   56448       ['swish_47[0][0]']               \n",
            "                                                                                                  \n",
            " activation_15 (Activation)     (None, 1, 1, 1152)   0           ['conv2d_62[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_15 (Multiply)         (None, 5, 5, 1152)   0           ['activation_15[0][0]',          \n",
            "                                                                  'swish_46[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_63 (Conv2D)             (None, 5, 5, 320)    368640      ['multiply_15[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_47 (BatchN  (None, 5, 5, 320)   1280        ['conv2d_63[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_64 (Conv2D)             (None, 5, 5, 1280)   409600      ['batch_normalization_47[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_48 (BatchN  (None, 5, 5, 1280)  5120        ['conv2d_64[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_48 (Swish)               (None, 5, 5, 1280)   0           ['batch_normalization_48[0][0]'] \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 4,049,564\n",
            "Trainable params: 4,007,548\n",
            "Non-trainable params: 42,016\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "base_dir = '/content/drive/MyDrive/TVT_Male125'\n",
        "os.makedirs(base_dir, exist_ok=True)\n",
        "\n",
        "# Directories for our training,\n",
        "# validation and test splits\n",
        "train_dir = os.path.join(base_dir, 'train')\n",
        "os.makedirs(train_dir, exist_ok=True)\n",
        "validation_dir = os.path.join(base_dir, 'validation')\n",
        "os.makedirs(validation_dir, exist_ok=True)\n",
        "test_dir = os.path.join(base_dir, 'test')\n",
        "os.makedirs(test_dir, exist_ok=True)"
      ],
      "metadata": {
        "id": "Jwpq_-KvPef8"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#load model"
      ],
      "metadata": {
        "id": "od-ZSNm5PoGy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.append('/content/drive/MyDrive/cut_panoramic/Model/Classification/Male/44_รอบที่4_Flimpano_Male125_250_New_Unfreez.h5')\n",
        "\n",
        "from efficientnet.layers import Swish, DropConnect\n",
        "from efficientnet.model import ConvKernalInitializer\n",
        "from tensorflow.keras.utils import get_custom_objects\n",
        "\n",
        "get_custom_objects().update({\n",
        "    'ConvKernalInitializer': ConvKernalInitializer,\n",
        "    'Swish': Swish,\n",
        "    'DropConnect':DropConnect\n",
        "})"
      ],
      "metadata": {
        "id": "n5iPL5MNPkhE"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#load model \n",
        "from tensorflow.keras.models import load_model\n",
        "model = load_model('/content/drive/MyDrive/cut_panoramic/Model/Classification/Male/44_รอบที่4_Flimpano_Male125_250_New_Unfreez.h5')\n",
        "height = width = model.input_shape[1]"
      ],
      "metadata": {
        "id": "plYz49xMPkly",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "181fa283-0cc4-40ca-b02d-48d7450e26ae"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z6IOPBflFbvc",
        "outputId": "c1f2a3f6-7d46-4c37-c54c-62c44cc65b0d"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " efficientnet-b0 (Functional  (None, 5, 5, 1280)       4049564   \n",
            " )                                                               \n",
            "                                                                 \n",
            " gap (GlobalMaxPooling2D)    (None, 1280)              0         \n",
            "                                                                 \n",
            " dropout_out (Dropout)       (None, 1280)              0         \n",
            "                                                                 \n",
            " fc_out (Dense)              (None, 19)                24339     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4,073,903\n",
            "Trainable params: 4,031,887\n",
            "Non-trainable params: 42,016\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train ด้วย ImageDataGenerator ของ Keras ซึ่งจะเพิ่มข้อมูลเสริมระหว่างการฝึกเพื่อลดโอกาสเกิด overfitting\n",
        "#overfitting เกิดจากข้อมูลที่ซับซ้อนกันเกินไป\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "train_datagen = ImageDataGenerator(\n",
        "      rescale=1./255, #โมเดลส่วนใหญ่ต้องใช้ RGB ในช่วง 0–1\n",
        "      rotation_range=40,\n",
        "      width_shift_range=0.2,\n",
        "      height_shift_range=0.2,\n",
        "      shear_range=0.2,\n",
        "      zoom_range=0.2,\n",
        "      horizontal_flip=True,\n",
        "      fill_mode='nearest')\n",
        "\n",
        "# Note that the validation data should not be augmented!\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "        # This is the target directory #ไดเรกเป้าหมาย\n",
        "        train_dir,\n",
        "        # รูปภาพทั้งหมดจะถูกปรับขนาดตามความสูงและความกว้างของเป้าหมาย\n",
        "        target_size=(height, width),\n",
        "        batch_size=batch_size,\n",
        "        # Since we use categorical_crossentropy loss, we need categorical labels\n",
        "        #เนื่องจากเราใช้ categorical_crossentropy loss เราจึงต้องมีป้ายกำกับตามหมวดหมู่\n",
        "        class_mode='categorical')\n",
        "\n",
        "validation_generator = test_datagen.flow_from_directory( #การดึงภาพจาก Directory มาเข้าโมเดล \n",
        "        validation_dir,\n",
        "        target_size=(height, width),\n",
        "        batch_size=batch_size,\n",
        "        class_mode='categorical')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KBMZbdr2Pgw4",
        "outputId": "62f19c5e-0f9c-4cfc-f3af-a4204579c97e"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1425 images belonging to 19 classes.\n",
            "Found 475 images belonging to 19 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit_generator(\n",
        "      train_generator,\n",
        "      steps_per_epoch= NUM_TRAIN //batch_size,\n",
        "      epochs=epochs,\n",
        "      validation_data=validation_generator,\n",
        "      validation_steps= NUM_TEST //batch_size,\n",
        "      verbose=1,\n",
        "      use_multiprocessing=True,\n",
        "      workers=4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C9Cf1dwyP1PD",
        "outputId": "8bac6937-b4f2-4c5c-f823-199609652b80"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-14-caa7b37242a8>:1: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  history = model.fit_generator(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/250\n",
            "89/89 [==============================] - 120s 1s/step - loss: 33.6069 - acc: 0.0561 - val_loss: 6.9919 - val_acc: 0.0754\n",
            "Epoch 2/250\n",
            "89/89 [==============================] - 28s 312ms/step - loss: 19.5475 - acc: 0.0518 - val_loss: 11.9958 - val_acc: 0.0711\n",
            "Epoch 3/250\n",
            "89/89 [==============================] - 28s 311ms/step - loss: 8.2906 - acc: 0.0901 - val_loss: 11.0673 - val_acc: 0.0603\n",
            "Epoch 4/250\n",
            "89/89 [==============================] - 24s 260ms/step - loss: 4.8120 - acc: 0.1320 - val_loss: 10.5817 - val_acc: 0.0819\n",
            "Epoch 5/250\n",
            "89/89 [==============================] - 27s 293ms/step - loss: 4.0194 - acc: 0.1384 - val_loss: 9.9191 - val_acc: 0.0711\n",
            "Epoch 6/250\n",
            "89/89 [==============================] - 24s 260ms/step - loss: 3.7204 - acc: 0.1441 - val_loss: 8.7175 - val_acc: 0.0690\n",
            "Epoch 7/250\n",
            "89/89 [==============================] - 27s 291ms/step - loss: 3.4698 - acc: 0.1455 - val_loss: 6.5375 - val_acc: 0.0948\n",
            "Epoch 8/250\n",
            "89/89 [==============================] - 22s 242ms/step - loss: 3.3921 - acc: 0.1611 - val_loss: 4.4108 - val_acc: 0.1185\n",
            "Epoch 9/250\n",
            "89/89 [==============================] - 28s 312ms/step - loss: 3.3956 - acc: 0.1419 - val_loss: 4.0374 - val_acc: 0.1379\n",
            "Epoch 10/250\n",
            "89/89 [==============================] - 28s 310ms/step - loss: 3.1765 - acc: 0.1568 - val_loss: 3.9784 - val_acc: 0.1444\n",
            "Epoch 11/250\n",
            "89/89 [==============================] - 24s 261ms/step - loss: 3.0527 - acc: 0.1774 - val_loss: 3.7069 - val_acc: 0.1681\n",
            "Epoch 12/250\n",
            "89/89 [==============================] - 29s 319ms/step - loss: 3.0599 - acc: 0.1753 - val_loss: 3.8127 - val_acc: 0.1509\n",
            "Epoch 13/250\n",
            "89/89 [==============================] - 29s 311ms/step - loss: 3.0072 - acc: 0.1746 - val_loss: 3.9190 - val_acc: 0.1379\n",
            "Epoch 14/250\n",
            "89/89 [==============================] - 29s 308ms/step - loss: 2.8620 - acc: 0.1852 - val_loss: 3.7067 - val_acc: 0.1530\n",
            "Epoch 15/250\n",
            "89/89 [==============================] - 28s 299ms/step - loss: 2.7436 - acc: 0.1881 - val_loss: 3.7626 - val_acc: 0.1358\n",
            "Epoch 16/250\n",
            "89/89 [==============================] - 27s 297ms/step - loss: 2.7510 - acc: 0.1803 - val_loss: 3.7395 - val_acc: 0.1401\n",
            "Epoch 17/250\n",
            "89/89 [==============================] - 30s 327ms/step - loss: 2.7007 - acc: 0.1732 - val_loss: 3.7414 - val_acc: 0.1379\n",
            "Epoch 18/250\n",
            "89/89 [==============================] - 27s 302ms/step - loss: 2.5295 - acc: 0.1909 - val_loss: 3.7934 - val_acc: 0.1379\n",
            "Epoch 19/250\n",
            "89/89 [==============================] - 28s 312ms/step - loss: 2.6065 - acc: 0.2271 - val_loss: 3.6545 - val_acc: 0.1422\n",
            "Epoch 20/250\n",
            "89/89 [==============================] - 29s 322ms/step - loss: 2.4315 - acc: 0.2413 - val_loss: 3.5444 - val_acc: 0.1422\n",
            "Epoch 21/250\n",
            "89/89 [==============================] - 29s 321ms/step - loss: 2.4327 - acc: 0.2186 - val_loss: 3.4404 - val_acc: 0.1487\n",
            "Epoch 22/250\n",
            "89/89 [==============================] - 29s 313ms/step - loss: 2.4163 - acc: 0.2115 - val_loss: 3.4512 - val_acc: 0.1530\n",
            "Epoch 23/250\n",
            "89/89 [==============================] - 24s 260ms/step - loss: 2.4267 - acc: 0.2186 - val_loss: 3.4518 - val_acc: 0.1509\n",
            "Epoch 24/250\n",
            "89/89 [==============================] - 24s 266ms/step - loss: 2.3617 - acc: 0.2236 - val_loss: 3.4537 - val_acc: 0.1444\n",
            "Epoch 25/250\n",
            "89/89 [==============================] - 29s 321ms/step - loss: 2.3244 - acc: 0.2399 - val_loss: 3.4360 - val_acc: 0.1466\n",
            "Epoch 26/250\n",
            "89/89 [==============================] - 29s 320ms/step - loss: 2.2578 - acc: 0.2370 - val_loss: 3.4613 - val_acc: 0.1509\n",
            "Epoch 27/250\n",
            "89/89 [==============================] - 31s 339ms/step - loss: 2.2412 - acc: 0.2356 - val_loss: 3.3627 - val_acc: 0.1509\n",
            "Epoch 28/250\n",
            "89/89 [==============================] - 28s 311ms/step - loss: 2.2070 - acc: 0.2413 - val_loss: 3.3797 - val_acc: 0.1444\n",
            "Epoch 29/250\n",
            "89/89 [==============================] - 29s 321ms/step - loss: 2.1709 - acc: 0.2583 - val_loss: 3.3699 - val_acc: 0.1552\n",
            "Epoch 30/250\n",
            "89/89 [==============================] - 29s 318ms/step - loss: 2.1837 - acc: 0.2569 - val_loss: 3.3849 - val_acc: 0.1466\n",
            "Epoch 31/250\n",
            "89/89 [==============================] - 29s 327ms/step - loss: 2.1715 - acc: 0.2541 - val_loss: 3.4084 - val_acc: 0.1401\n",
            "Epoch 32/250\n",
            "89/89 [==============================] - 29s 315ms/step - loss: 2.1315 - acc: 0.2548 - val_loss: 3.2456 - val_acc: 0.1530\n",
            "Epoch 33/250\n",
            "89/89 [==============================] - 29s 320ms/step - loss: 2.1263 - acc: 0.2555 - val_loss: 3.3443 - val_acc: 0.1466\n",
            "Epoch 34/250\n",
            "89/89 [==============================] - 25s 269ms/step - loss: 2.1093 - acc: 0.2732 - val_loss: 3.5328 - val_acc: 0.1293\n",
            "Epoch 35/250\n",
            "89/89 [==============================] - 27s 299ms/step - loss: 2.1242 - acc: 0.2413 - val_loss: 3.4182 - val_acc: 0.1466\n",
            "Epoch 36/250\n",
            "89/89 [==============================] - 27s 293ms/step - loss: 2.1192 - acc: 0.2477 - val_loss: 3.2287 - val_acc: 0.1444\n",
            "Epoch 37/250\n",
            "89/89 [==============================] - 32s 348ms/step - loss: 2.0721 - acc: 0.2732 - val_loss: 3.2622 - val_acc: 0.1552\n",
            "Epoch 38/250\n",
            "89/89 [==============================] - 28s 309ms/step - loss: 2.1088 - acc: 0.2697 - val_loss: 3.3610 - val_acc: 0.1401\n",
            "Epoch 39/250\n",
            "89/89 [==============================] - 28s 312ms/step - loss: 2.0854 - acc: 0.2647 - val_loss: 3.2476 - val_acc: 0.1466\n",
            "Epoch 40/250\n",
            "89/89 [==============================] - 29s 319ms/step - loss: 2.0086 - acc: 0.2924 - val_loss: 3.3176 - val_acc: 0.1487\n",
            "Epoch 41/250\n",
            "89/89 [==============================] - 29s 322ms/step - loss: 1.9675 - acc: 0.2903 - val_loss: 3.3738 - val_acc: 0.1530\n",
            "Epoch 42/250\n",
            "89/89 [==============================] - 27s 295ms/step - loss: 2.0059 - acc: 0.2967 - val_loss: 3.4038 - val_acc: 0.1530\n",
            "Epoch 43/250\n",
            "89/89 [==============================] - 29s 319ms/step - loss: 2.0122 - acc: 0.2960 - val_loss: 3.2604 - val_acc: 0.1616\n",
            "Epoch 44/250\n",
            "89/89 [==============================] - 30s 324ms/step - loss: 1.9827 - acc: 0.2967 - val_loss: 3.1341 - val_acc: 0.1681\n",
            "Epoch 45/250\n",
            "89/89 [==============================] - 29s 320ms/step - loss: 1.9812 - acc: 0.3144 - val_loss: 3.0791 - val_acc: 0.1638\n",
            "Epoch 46/250\n",
            "89/89 [==============================] - 30s 326ms/step - loss: 1.9506 - acc: 0.2981 - val_loss: 3.1125 - val_acc: 0.1638\n",
            "Epoch 47/250\n",
            "89/89 [==============================] - 29s 317ms/step - loss: 1.9289 - acc: 0.3109 - val_loss: 3.1280 - val_acc: 0.1573\n",
            "Epoch 48/250\n",
            "89/89 [==============================] - 29s 323ms/step - loss: 1.9001 - acc: 0.3151 - val_loss: 3.2744 - val_acc: 0.1573\n",
            "Epoch 49/250\n",
            "89/89 [==============================] - 28s 308ms/step - loss: 1.8978 - acc: 0.3300 - val_loss: 3.2067 - val_acc: 0.1595\n",
            "Epoch 50/250\n",
            "89/89 [==============================] - 29s 319ms/step - loss: 1.8601 - acc: 0.3414 - val_loss: 3.2965 - val_acc: 0.1530\n",
            "Epoch 51/250\n",
            "89/89 [==============================] - 31s 341ms/step - loss: 1.8867 - acc: 0.3243 - val_loss: 3.2147 - val_acc: 0.1638\n",
            "Epoch 52/250\n",
            "89/89 [==============================] - 29s 313ms/step - loss: 1.8820 - acc: 0.3442 - val_loss: 3.2453 - val_acc: 0.1595\n",
            "Epoch 53/250\n",
            "89/89 [==============================] - 29s 314ms/step - loss: 1.8820 - acc: 0.3293 - val_loss: 3.1649 - val_acc: 0.1703\n",
            "Epoch 54/250\n",
            "89/89 [==============================] - 24s 264ms/step - loss: 1.8092 - acc: 0.3322 - val_loss: 3.2163 - val_acc: 0.1659\n",
            "Epoch 55/250\n",
            "89/89 [==============================] - 29s 315ms/step - loss: 1.8227 - acc: 0.3463 - val_loss: 3.2340 - val_acc: 0.1595\n",
            "Epoch 56/250\n",
            "89/89 [==============================] - 31s 339ms/step - loss: 1.8348 - acc: 0.3336 - val_loss: 3.1353 - val_acc: 0.1767\n",
            "Epoch 57/250\n",
            "89/89 [==============================] - 25s 271ms/step - loss: 1.7767 - acc: 0.3584 - val_loss: 3.3817 - val_acc: 0.1659\n",
            "Epoch 58/250\n",
            "89/89 [==============================] - 29s 318ms/step - loss: 1.8257 - acc: 0.3506 - val_loss: 3.3513 - val_acc: 0.1616\n",
            "Epoch 59/250\n",
            "89/89 [==============================] - 30s 326ms/step - loss: 1.8146 - acc: 0.3499 - val_loss: 3.3121 - val_acc: 0.1659\n",
            "Epoch 60/250\n",
            "89/89 [==============================] - 29s 316ms/step - loss: 1.7886 - acc: 0.3492 - val_loss: 3.3090 - val_acc: 0.1638\n",
            "Epoch 61/250\n",
            "89/89 [==============================] - 31s 338ms/step - loss: 1.8317 - acc: 0.3371 - val_loss: 3.1463 - val_acc: 0.1746\n",
            "Epoch 62/250\n",
            "89/89 [==============================] - 29s 320ms/step - loss: 1.7461 - acc: 0.3705 - val_loss: 3.2609 - val_acc: 0.1616\n",
            "Epoch 63/250\n",
            "89/89 [==============================] - 28s 300ms/step - loss: 1.7354 - acc: 0.3563 - val_loss: 3.1120 - val_acc: 0.1703\n",
            "Epoch 64/250\n",
            "89/89 [==============================] - 28s 305ms/step - loss: 1.7308 - acc: 0.3769 - val_loss: 3.1879 - val_acc: 0.1724\n",
            "Epoch 65/250\n",
            "89/89 [==============================] - 27s 300ms/step - loss: 1.6777 - acc: 0.3762 - val_loss: 3.2067 - val_acc: 0.1703\n",
            "Epoch 66/250\n",
            "89/89 [==============================] - 27s 295ms/step - loss: 1.7269 - acc: 0.3797 - val_loss: 3.1634 - val_acc: 0.1724\n",
            "Epoch 67/250\n",
            "89/89 [==============================] - 30s 327ms/step - loss: 1.6965 - acc: 0.3996 - val_loss: 3.1324 - val_acc: 0.1659\n",
            "Epoch 68/250\n",
            "89/89 [==============================] - 29s 318ms/step - loss: 1.7603 - acc: 0.3698 - val_loss: 3.0883 - val_acc: 0.1746\n",
            "Epoch 69/250\n",
            "89/89 [==============================] - 29s 316ms/step - loss: 1.7259 - acc: 0.3762 - val_loss: 3.0815 - val_acc: 0.1767\n",
            "Epoch 70/250\n",
            "89/89 [==============================] - 29s 319ms/step - loss: 1.6687 - acc: 0.3967 - val_loss: 3.0587 - val_acc: 0.1853\n",
            "Epoch 71/250\n",
            "89/89 [==============================] - 31s 337ms/step - loss: 1.6939 - acc: 0.3882 - val_loss: 3.1927 - val_acc: 0.1746\n",
            "Epoch 72/250\n",
            "89/89 [==============================] - 23s 248ms/step - loss: 1.6526 - acc: 0.3989 - val_loss: 3.1446 - val_acc: 0.1767\n",
            "Epoch 73/250\n",
            "89/89 [==============================] - 30s 326ms/step - loss: 1.6818 - acc: 0.3875 - val_loss: 3.1472 - val_acc: 0.1789\n",
            "Epoch 74/250\n",
            "89/89 [==============================] - 29s 321ms/step - loss: 1.6711 - acc: 0.3967 - val_loss: 3.1718 - val_acc: 0.1681\n",
            "Epoch 75/250\n",
            "89/89 [==============================] - 29s 316ms/step - loss: 1.6214 - acc: 0.4202 - val_loss: 3.1718 - val_acc: 0.1853\n",
            "Epoch 76/250\n",
            "89/89 [==============================] - 31s 343ms/step - loss: 1.6196 - acc: 0.4230 - val_loss: 3.1339 - val_acc: 0.1853\n",
            "Epoch 77/250\n",
            "89/89 [==============================] - 28s 310ms/step - loss: 1.6302 - acc: 0.4060 - val_loss: 3.2353 - val_acc: 0.1724\n",
            "Epoch 78/250\n",
            "89/89 [==============================] - 28s 309ms/step - loss: 1.6050 - acc: 0.4237 - val_loss: 3.2730 - val_acc: 0.1746\n",
            "Epoch 79/250\n",
            "89/89 [==============================] - 30s 334ms/step - loss: 1.5936 - acc: 0.4251 - val_loss: 3.2855 - val_acc: 0.1703\n",
            "Epoch 80/250\n",
            "89/89 [==============================] - 24s 266ms/step - loss: 1.6287 - acc: 0.4265 - val_loss: 3.1561 - val_acc: 0.1724\n",
            "Epoch 81/250\n",
            "89/89 [==============================] - 23s 254ms/step - loss: 1.6019 - acc: 0.4067 - val_loss: 3.2441 - val_acc: 0.1767\n",
            "Epoch 82/250\n",
            "89/89 [==============================] - 30s 319ms/step - loss: 1.5361 - acc: 0.4443 - val_loss: 3.3343 - val_acc: 0.1703\n",
            "Epoch 83/250\n",
            "89/89 [==============================] - 27s 296ms/step - loss: 1.5471 - acc: 0.4407 - val_loss: 3.2250 - val_acc: 0.1746\n",
            "Epoch 84/250\n",
            "89/89 [==============================] - 27s 299ms/step - loss: 1.5663 - acc: 0.4393 - val_loss: 3.2111 - val_acc: 0.1810\n",
            "Epoch 85/250\n",
            "89/89 [==============================] - 29s 322ms/step - loss: 1.5489 - acc: 0.4237 - val_loss: 3.1949 - val_acc: 0.1832\n",
            "Epoch 86/250\n",
            "89/89 [==============================] - 29s 316ms/step - loss: 1.5605 - acc: 0.4414 - val_loss: 3.2105 - val_acc: 0.1789\n",
            "Epoch 87/250\n",
            "89/89 [==============================] - 29s 320ms/step - loss: 1.5151 - acc: 0.4414 - val_loss: 3.2527 - val_acc: 0.1767\n",
            "Epoch 88/250\n",
            "89/89 [==============================] - 30s 320ms/step - loss: 1.5263 - acc: 0.4585 - val_loss: 3.2329 - val_acc: 0.1746\n",
            "Epoch 89/250\n",
            "89/89 [==============================] - 29s 321ms/step - loss: 1.5255 - acc: 0.4471 - val_loss: 3.2419 - val_acc: 0.1810\n",
            "Epoch 90/250\n",
            "89/89 [==============================] - 24s 265ms/step - loss: 1.5026 - acc: 0.4578 - val_loss: 3.2468 - val_acc: 0.1767\n",
            "Epoch 91/250\n",
            "89/89 [==============================] - 27s 299ms/step - loss: 1.4667 - acc: 0.4642 - val_loss: 3.1766 - val_acc: 0.1789\n",
            "Epoch 92/250\n",
            "89/89 [==============================] - 25s 272ms/step - loss: 1.4499 - acc: 0.4720 - val_loss: 3.2473 - val_acc: 0.1810\n",
            "Epoch 93/250\n",
            "89/89 [==============================] - 29s 318ms/step - loss: 1.5131 - acc: 0.4549 - val_loss: 3.2871 - val_acc: 0.1789\n",
            "Epoch 94/250\n",
            "89/89 [==============================] - 27s 295ms/step - loss: 1.4754 - acc: 0.4663 - val_loss: 3.3402 - val_acc: 0.1789\n",
            "Epoch 95/250\n",
            "89/89 [==============================] - 28s 312ms/step - loss: 1.4717 - acc: 0.4691 - val_loss: 3.3062 - val_acc: 0.1832\n",
            "Epoch 96/250\n",
            "89/89 [==============================] - 30s 328ms/step - loss: 1.4304 - acc: 0.4954 - val_loss: 3.3173 - val_acc: 0.1832\n",
            "Epoch 97/250\n",
            "89/89 [==============================] - 29s 322ms/step - loss: 1.4329 - acc: 0.4819 - val_loss: 3.4907 - val_acc: 0.1724\n",
            "Epoch 98/250\n",
            "89/89 [==============================] - 29s 319ms/step - loss: 1.4155 - acc: 0.4869 - val_loss: 3.4115 - val_acc: 0.1832\n",
            "Epoch 99/250\n",
            "89/89 [==============================] - 26s 288ms/step - loss: 1.4518 - acc: 0.4720 - val_loss: 3.4128 - val_acc: 0.1746\n",
            "Epoch 100/250\n",
            "89/89 [==============================] - 27s 294ms/step - loss: 1.4272 - acc: 0.4819 - val_loss: 3.2941 - val_acc: 0.1832\n",
            "Epoch 101/250\n",
            "89/89 [==============================] - 28s 305ms/step - loss: 1.3417 - acc: 0.5138 - val_loss: 3.3492 - val_acc: 0.1810\n",
            "Epoch 102/250\n",
            "89/89 [==============================] - 29s 316ms/step - loss: 1.3937 - acc: 0.4918 - val_loss: 3.3488 - val_acc: 0.1918\n",
            "Epoch 103/250\n",
            "89/89 [==============================] - 24s 265ms/step - loss: 1.3593 - acc: 0.4954 - val_loss: 3.4578 - val_acc: 0.1875\n",
            "Epoch 104/250\n",
            "89/89 [==============================] - 27s 298ms/step - loss: 1.3739 - acc: 0.5124 - val_loss: 3.3554 - val_acc: 0.1940\n",
            "Epoch 105/250\n",
            "89/89 [==============================] - 24s 262ms/step - loss: 1.3693 - acc: 0.4890 - val_loss: 3.3835 - val_acc: 0.1961\n",
            "Epoch 106/250\n",
            "89/89 [==============================] - 28s 301ms/step - loss: 1.3441 - acc: 0.5309 - val_loss: 3.3550 - val_acc: 0.1875\n",
            "Epoch 107/250\n",
            "89/89 [==============================] - 23s 254ms/step - loss: 1.3268 - acc: 0.5231 - val_loss: 3.4081 - val_acc: 0.1897\n",
            "Epoch 108/250\n",
            "89/89 [==============================] - 28s 310ms/step - loss: 1.2836 - acc: 0.5408 - val_loss: 3.4862 - val_acc: 0.1810\n",
            "Epoch 109/250\n",
            "89/89 [==============================] - 28s 309ms/step - loss: 1.3258 - acc: 0.5231 - val_loss: 3.5662 - val_acc: 0.1853\n",
            "Epoch 110/250\n",
            "89/89 [==============================] - 29s 313ms/step - loss: 1.3162 - acc: 0.5259 - val_loss: 3.4935 - val_acc: 0.1853\n",
            "Epoch 111/250\n",
            "89/89 [==============================] - 29s 318ms/step - loss: 1.3227 - acc: 0.5266 - val_loss: 3.4232 - val_acc: 0.1853\n",
            "Epoch 112/250\n",
            "89/89 [==============================] - 29s 318ms/step - loss: 1.2841 - acc: 0.5515 - val_loss: 3.3680 - val_acc: 0.1918\n",
            "Epoch 113/250\n",
            "89/89 [==============================] - 29s 318ms/step - loss: 1.2793 - acc: 0.5309 - val_loss: 3.5366 - val_acc: 0.1810\n",
            "Epoch 114/250\n",
            "89/89 [==============================] - 29s 320ms/step - loss: 1.2758 - acc: 0.5557 - val_loss: 3.5638 - val_acc: 0.1918\n",
            "Epoch 115/250\n",
            "89/89 [==============================] - 29s 320ms/step - loss: 1.2749 - acc: 0.5536 - val_loss: 3.5477 - val_acc: 0.1940\n",
            "Epoch 116/250\n",
            "89/89 [==============================] - 29s 319ms/step - loss: 1.2655 - acc: 0.5628 - val_loss: 3.3931 - val_acc: 0.1918\n",
            "Epoch 117/250\n",
            "89/89 [==============================] - 29s 319ms/step - loss: 1.2329 - acc: 0.5571 - val_loss: 3.3756 - val_acc: 0.1767\n",
            "Epoch 118/250\n",
            "89/89 [==============================] - 29s 316ms/step - loss: 1.1940 - acc: 0.5649 - val_loss: 3.6563 - val_acc: 0.1724\n",
            "Epoch 119/250\n",
            "89/89 [==============================] - 29s 316ms/step - loss: 1.2349 - acc: 0.5486 - val_loss: 3.6538 - val_acc: 0.1724\n",
            "Epoch 120/250\n",
            "89/89 [==============================] - 29s 325ms/step - loss: 1.2062 - acc: 0.5834 - val_loss: 3.6651 - val_acc: 0.1724\n",
            "Epoch 121/250\n",
            "89/89 [==============================] - 24s 261ms/step - loss: 1.2033 - acc: 0.5685 - val_loss: 3.6678 - val_acc: 0.1746\n",
            "Epoch 122/250\n",
            "89/89 [==============================] - 29s 325ms/step - loss: 1.2115 - acc: 0.5536 - val_loss: 3.5842 - val_acc: 0.1789\n",
            "Epoch 123/250\n",
            "89/89 [==============================] - 24s 257ms/step - loss: 1.1737 - acc: 0.5798 - val_loss: 3.6957 - val_acc: 0.1767\n",
            "Epoch 124/250\n",
            "89/89 [==============================] - 29s 321ms/step - loss: 1.1505 - acc: 0.5891 - val_loss: 3.7436 - val_acc: 0.1832\n",
            "Epoch 125/250\n",
            "89/89 [==============================] - 29s 318ms/step - loss: 1.1691 - acc: 0.5862 - val_loss: 3.6880 - val_acc: 0.1918\n",
            "Epoch 126/250\n",
            "89/89 [==============================] - 29s 327ms/step - loss: 1.1170 - acc: 0.5969 - val_loss: 3.7557 - val_acc: 0.1853\n",
            "Epoch 127/250\n",
            "89/89 [==============================] - 29s 318ms/step - loss: 1.1201 - acc: 0.6068 - val_loss: 3.7098 - val_acc: 0.1897\n",
            "Epoch 128/250\n",
            "89/89 [==============================] - 29s 318ms/step - loss: 1.1249 - acc: 0.5933 - val_loss: 3.7605 - val_acc: 0.1961\n",
            "Epoch 129/250\n",
            "89/89 [==============================] - 29s 322ms/step - loss: 1.1264 - acc: 0.5933 - val_loss: 3.7160 - val_acc: 0.1832\n",
            "Epoch 130/250\n",
            "89/89 [==============================] - 29s 321ms/step - loss: 1.1469 - acc: 0.6033 - val_loss: 3.6885 - val_acc: 0.1897\n",
            "Epoch 131/250\n",
            "89/89 [==============================] - 30s 326ms/step - loss: 1.1221 - acc: 0.6047 - val_loss: 3.8562 - val_acc: 0.1875\n",
            "Epoch 132/250\n",
            "89/89 [==============================] - 29s 321ms/step - loss: 1.0906 - acc: 0.6196 - val_loss: 3.7146 - val_acc: 0.1897\n",
            "Epoch 133/250\n",
            "89/89 [==============================] - 29s 317ms/step - loss: 1.1074 - acc: 0.6281 - val_loss: 3.8401 - val_acc: 0.1918\n",
            "Epoch 134/250\n",
            "89/89 [==============================] - 24s 259ms/step - loss: 1.0907 - acc: 0.6153 - val_loss: 3.7748 - val_acc: 0.1918\n",
            "Epoch 135/250\n",
            "89/89 [==============================] - 28s 307ms/step - loss: 1.0496 - acc: 0.6331 - val_loss: 3.8445 - val_acc: 0.1983\n",
            "Epoch 136/250\n",
            "89/89 [==============================] - 29s 327ms/step - loss: 1.1060 - acc: 0.6146 - val_loss: 3.8668 - val_acc: 0.1961\n",
            "Epoch 137/250\n",
            "89/89 [==============================] - 29s 323ms/step - loss: 1.1064 - acc: 0.6061 - val_loss: 3.8164 - val_acc: 0.1853\n",
            "Epoch 138/250\n",
            "89/89 [==============================] - 29s 323ms/step - loss: 1.0729 - acc: 0.6189 - val_loss: 3.8451 - val_acc: 0.1897\n",
            "Epoch 139/250\n",
            "89/89 [==============================] - 29s 321ms/step - loss: 1.0292 - acc: 0.6352 - val_loss: 3.8510 - val_acc: 0.1961\n",
            "Epoch 140/250\n",
            "89/89 [==============================] - 29s 319ms/step - loss: 1.0813 - acc: 0.6153 - val_loss: 3.8010 - val_acc: 0.1961\n",
            "Epoch 141/250\n",
            "89/89 [==============================] - 25s 267ms/step - loss: 1.0285 - acc: 0.6331 - val_loss: 3.8071 - val_acc: 0.1961\n",
            "Epoch 142/250\n",
            "89/89 [==============================] - 27s 297ms/step - loss: 0.9719 - acc: 0.6643 - val_loss: 3.6990 - val_acc: 0.2026\n",
            "Epoch 143/250\n",
            "89/89 [==============================] - 28s 312ms/step - loss: 1.0302 - acc: 0.6366 - val_loss: 3.8261 - val_acc: 0.2069\n",
            "Epoch 144/250\n",
            "89/89 [==============================] - 28s 310ms/step - loss: 0.9969 - acc: 0.6437 - val_loss: 3.8570 - val_acc: 0.2004\n",
            "Epoch 145/250\n",
            "89/89 [==============================] - 29s 315ms/step - loss: 0.9681 - acc: 0.6671 - val_loss: 3.9711 - val_acc: 0.1961\n",
            "Epoch 146/250\n",
            "89/89 [==============================] - 25s 269ms/step - loss: 0.9665 - acc: 0.6671 - val_loss: 4.0154 - val_acc: 0.2004\n",
            "Epoch 147/250\n",
            "89/89 [==============================] - 22s 243ms/step - loss: 1.0126 - acc: 0.6359 - val_loss: 3.9746 - val_acc: 0.1918\n",
            "Epoch 148/250\n",
            "89/89 [==============================] - 29s 312ms/step - loss: 1.0123 - acc: 0.6487 - val_loss: 3.9086 - val_acc: 0.1961\n",
            "Epoch 149/250\n",
            "89/89 [==============================] - 30s 325ms/step - loss: 0.9786 - acc: 0.6522 - val_loss: 3.9968 - val_acc: 0.1918\n",
            "Epoch 150/250\n",
            "89/89 [==============================] - 29s 317ms/step - loss: 0.9740 - acc: 0.6572 - val_loss: 3.8732 - val_acc: 0.1940\n",
            "Epoch 151/250\n",
            "89/89 [==============================] - 29s 322ms/step - loss: 0.9423 - acc: 0.6847 - val_loss: 3.9325 - val_acc: 0.1875\n",
            "Epoch 152/250\n",
            "89/89 [==============================] - 24s 266ms/step - loss: 0.9641 - acc: 0.6636 - val_loss: 3.9383 - val_acc: 0.1983\n",
            "Epoch 153/250\n",
            "89/89 [==============================] - 28s 306ms/step - loss: 0.9336 - acc: 0.6615 - val_loss: 3.9165 - val_acc: 0.1918\n",
            "Epoch 154/250\n",
            "89/89 [==============================] - 24s 262ms/step - loss: 0.8831 - acc: 0.6771 - val_loss: 3.9641 - val_acc: 0.1940\n",
            "Epoch 155/250\n",
            "89/89 [==============================] - 28s 298ms/step - loss: 0.9030 - acc: 0.6799 - val_loss: 3.9709 - val_acc: 0.1983\n",
            "Epoch 156/250\n",
            "89/89 [==============================] - 22s 243ms/step - loss: 0.8762 - acc: 0.6969 - val_loss: 3.9525 - val_acc: 0.2047\n",
            "Epoch 157/250\n",
            "89/89 [==============================] - 28s 305ms/step - loss: 0.8558 - acc: 0.7026 - val_loss: 4.1269 - val_acc: 0.2026\n",
            "Epoch 158/250\n",
            "89/89 [==============================] - 30s 324ms/step - loss: 0.8750 - acc: 0.6977 - val_loss: 4.1281 - val_acc: 0.1983\n",
            "Epoch 159/250\n",
            "89/89 [==============================] - 29s 323ms/step - loss: 0.8840 - acc: 0.6977 - val_loss: 4.0304 - val_acc: 0.1940\n",
            "Epoch 160/250\n",
            "89/89 [==============================] - 29s 321ms/step - loss: 0.8742 - acc: 0.7040 - val_loss: 4.1513 - val_acc: 0.1918\n",
            "Epoch 161/250\n",
            "89/89 [==============================] - 29s 321ms/step - loss: 0.8600 - acc: 0.6906 - val_loss: 4.2151 - val_acc: 0.2004\n",
            "Epoch 162/250\n",
            "89/89 [==============================] - 25s 270ms/step - loss: 0.8331 - acc: 0.7097 - val_loss: 4.2563 - val_acc: 0.1875\n",
            "Epoch 163/250\n",
            "89/89 [==============================] - 23s 254ms/step - loss: 0.8286 - acc: 0.7040 - val_loss: 4.2759 - val_acc: 0.1940\n",
            "Epoch 164/250\n",
            "89/89 [==============================] - 28s 310ms/step - loss: 0.8179 - acc: 0.7069 - val_loss: 4.3128 - val_acc: 0.1897\n",
            "Epoch 165/250\n",
            "89/89 [==============================] - 29s 319ms/step - loss: 0.9051 - acc: 0.6735 - val_loss: 4.2663 - val_acc: 0.1983\n",
            "Epoch 166/250\n",
            "89/89 [==============================] - 29s 314ms/step - loss: 0.7492 - acc: 0.7466 - val_loss: 4.3425 - val_acc: 0.1983\n",
            "Epoch 167/250\n",
            "89/89 [==============================] - 29s 318ms/step - loss: 0.8140 - acc: 0.7140 - val_loss: 4.4738 - val_acc: 0.2026\n",
            "Epoch 168/250\n",
            "89/89 [==============================] - 29s 319ms/step - loss: 0.8351 - acc: 0.7005 - val_loss: 4.3122 - val_acc: 0.1940\n",
            "Epoch 169/250\n",
            "89/89 [==============================] - 29s 322ms/step - loss: 0.7880 - acc: 0.7339 - val_loss: 4.3048 - val_acc: 0.1940\n",
            "Epoch 170/250\n",
            "89/89 [==============================] - 29s 322ms/step - loss: 0.7795 - acc: 0.7303 - val_loss: 4.4386 - val_acc: 0.1875\n",
            "Epoch 171/250\n",
            "89/89 [==============================] - 25s 271ms/step - loss: 0.8186 - acc: 0.7019 - val_loss: 4.4349 - val_acc: 0.1940\n",
            "Epoch 172/250\n",
            "89/89 [==============================] - 28s 309ms/step - loss: 0.7874 - acc: 0.7289 - val_loss: 4.4766 - val_acc: 0.1940\n",
            "Epoch 173/250\n",
            "89/89 [==============================] - 29s 320ms/step - loss: 0.7935 - acc: 0.7197 - val_loss: 4.6364 - val_acc: 0.1940\n",
            "Epoch 174/250\n",
            "89/89 [==============================] - 30s 325ms/step - loss: 0.7686 - acc: 0.7374 - val_loss: 4.5019 - val_acc: 0.1875\n",
            "Epoch 175/250\n",
            "89/89 [==============================] - 29s 320ms/step - loss: 0.7833 - acc: 0.7175 - val_loss: 4.4591 - val_acc: 0.1875\n",
            "Epoch 176/250\n",
            "89/89 [==============================] - 30s 327ms/step - loss: 0.7014 - acc: 0.7516 - val_loss: 4.4702 - val_acc: 0.1940\n",
            "Epoch 177/250\n",
            "89/89 [==============================] - 30s 326ms/step - loss: 0.7104 - acc: 0.7523 - val_loss: 4.5280 - val_acc: 0.1983\n",
            "Epoch 178/250\n",
            "89/89 [==============================] - 29s 319ms/step - loss: 0.7434 - acc: 0.7339 - val_loss: 4.6897 - val_acc: 0.2026\n",
            "Epoch 179/250\n",
            "89/89 [==============================] - 29s 314ms/step - loss: 0.7072 - acc: 0.7580 - val_loss: 4.7481 - val_acc: 0.1918\n",
            "Epoch 180/250\n",
            "89/89 [==============================] - 29s 319ms/step - loss: 0.7066 - acc: 0.7580 - val_loss: 4.6868 - val_acc: 0.1983\n",
            "Epoch 181/250\n",
            "89/89 [==============================] - 29s 313ms/step - loss: 0.6857 - acc: 0.7573 - val_loss: 4.6850 - val_acc: 0.1940\n",
            "Epoch 182/250\n",
            "89/89 [==============================] - 29s 313ms/step - loss: 0.7073 - acc: 0.7502 - val_loss: 4.6232 - val_acc: 0.2047\n",
            "Epoch 183/250\n",
            "89/89 [==============================] - 29s 314ms/step - loss: 0.6681 - acc: 0.7672 - val_loss: 4.6048 - val_acc: 0.1983\n",
            "Epoch 184/250\n",
            "89/89 [==============================] - 28s 297ms/step - loss: 0.7015 - acc: 0.7544 - val_loss: 4.7237 - val_acc: 0.1918\n",
            "Epoch 185/250\n",
            "89/89 [==============================] - 27s 301ms/step - loss: 0.7075 - acc: 0.7580 - val_loss: 4.8663 - val_acc: 0.1875\n",
            "Epoch 186/250\n",
            "89/89 [==============================] - 27s 295ms/step - loss: 0.7173 - acc: 0.7509 - val_loss: 4.8040 - val_acc: 0.1961\n",
            "Epoch 187/250\n",
            "89/89 [==============================] - 28s 310ms/step - loss: 0.6521 - acc: 0.7807 - val_loss: 4.9970 - val_acc: 0.1918\n",
            "Epoch 188/250\n",
            "89/89 [==============================] - 30s 324ms/step - loss: 0.6897 - acc: 0.7594 - val_loss: 4.7007 - val_acc: 0.1983\n",
            "Epoch 189/250\n",
            "89/89 [==============================] - 29s 318ms/step - loss: 0.6889 - acc: 0.7544 - val_loss: 4.7837 - val_acc: 0.2047\n",
            "Epoch 190/250\n",
            "89/89 [==============================] - 29s 324ms/step - loss: 0.6773 - acc: 0.7587 - val_loss: 4.8025 - val_acc: 0.2026\n",
            "Epoch 191/250\n",
            "89/89 [==============================] - 30s 326ms/step - loss: 0.6443 - acc: 0.7892 - val_loss: 4.8769 - val_acc: 0.2004\n",
            "Epoch 192/250\n",
            "89/89 [==============================] - 29s 319ms/step - loss: 0.6142 - acc: 0.7857 - val_loss: 4.9118 - val_acc: 0.1961\n",
            "Epoch 193/250\n",
            "89/89 [==============================] - 29s 318ms/step - loss: 0.6164 - acc: 0.7899 - val_loss: 4.9410 - val_acc: 0.1918\n",
            "Epoch 194/250\n",
            "89/89 [==============================] - 29s 319ms/step - loss: 0.6317 - acc: 0.7857 - val_loss: 4.9115 - val_acc: 0.1875\n",
            "Epoch 195/250\n",
            "89/89 [==============================] - 28s 310ms/step - loss: 0.6162 - acc: 0.7814 - val_loss: 4.9609 - val_acc: 0.1875\n",
            "Epoch 196/250\n",
            "89/89 [==============================] - 24s 258ms/step - loss: 0.6270 - acc: 0.7729 - val_loss: 5.0005 - val_acc: 0.1875\n",
            "Epoch 197/250\n",
            "89/89 [==============================] - 29s 314ms/step - loss: 0.5866 - acc: 0.7977 - val_loss: 4.9308 - val_acc: 0.1897\n",
            "Epoch 198/250\n",
            "89/89 [==============================] - 29s 311ms/step - loss: 0.6212 - acc: 0.7828 - val_loss: 5.0007 - val_acc: 0.1918\n",
            "Epoch 199/250\n",
            "89/89 [==============================] - 28s 300ms/step - loss: 0.5615 - acc: 0.7963 - val_loss: 4.9679 - val_acc: 0.1961\n",
            "Epoch 200/250\n",
            "89/89 [==============================] - 28s 297ms/step - loss: 0.6087 - acc: 0.7885 - val_loss: 4.9984 - val_acc: 0.1940\n",
            "Epoch 201/250\n",
            "89/89 [==============================] - 28s 307ms/step - loss: 0.5995 - acc: 0.7878 - val_loss: 4.8815 - val_acc: 0.1918\n",
            "Epoch 202/250\n",
            "89/89 [==============================] - 27s 294ms/step - loss: 0.5905 - acc: 0.8020 - val_loss: 4.9451 - val_acc: 0.1853\n",
            "Epoch 203/250\n",
            "89/89 [==============================] - 29s 320ms/step - loss: 0.5815 - acc: 0.7970 - val_loss: 5.0186 - val_acc: 0.1875\n",
            "Epoch 204/250\n",
            "89/89 [==============================] - 29s 321ms/step - loss: 0.5657 - acc: 0.7977 - val_loss: 5.0998 - val_acc: 0.2004\n",
            "Epoch 205/250\n",
            "89/89 [==============================] - 29s 321ms/step - loss: 0.5863 - acc: 0.7857 - val_loss: 5.2096 - val_acc: 0.2004\n",
            "Epoch 206/250\n",
            "89/89 [==============================] - 30s 326ms/step - loss: 0.5630 - acc: 0.8020 - val_loss: 5.1638 - val_acc: 0.1897\n",
            "Epoch 207/250\n",
            "89/89 [==============================] - 24s 264ms/step - loss: 0.5833 - acc: 0.7942 - val_loss: 5.0443 - val_acc: 0.1875\n",
            "Epoch 208/250\n",
            "89/89 [==============================] - 29s 322ms/step - loss: 0.5704 - acc: 0.8013 - val_loss: 5.0306 - val_acc: 0.1832\n",
            "Epoch 209/250\n",
            "89/89 [==============================] - 29s 322ms/step - loss: 0.5550 - acc: 0.8162 - val_loss: 5.0984 - val_acc: 0.1875\n",
            "Epoch 210/250\n",
            "89/89 [==============================] - 29s 317ms/step - loss: 0.5284 - acc: 0.8126 - val_loss: 4.9698 - val_acc: 0.1961\n",
            "Epoch 211/250\n",
            "89/89 [==============================] - 29s 316ms/step - loss: 0.5605 - acc: 0.8204 - val_loss: 5.0803 - val_acc: 0.1832\n",
            "Epoch 212/250\n",
            "89/89 [==============================] - 30s 331ms/step - loss: 0.5592 - acc: 0.8048 - val_loss: 5.1436 - val_acc: 0.1897\n",
            "Epoch 213/250\n",
            "89/89 [==============================] - 29s 318ms/step - loss: 0.5216 - acc: 0.8169 - val_loss: 5.0879 - val_acc: 0.1853\n",
            "Epoch 214/250\n",
            "89/89 [==============================] - 30s 327ms/step - loss: 0.5091 - acc: 0.8325 - val_loss: 5.2535 - val_acc: 0.1767\n",
            "Epoch 215/250\n",
            "89/89 [==============================] - 30s 319ms/step - loss: 0.4709 - acc: 0.8368 - val_loss: 5.3212 - val_acc: 0.1832\n",
            "Epoch 216/250\n",
            "89/89 [==============================] - 29s 309ms/step - loss: 0.5178 - acc: 0.8148 - val_loss: 5.2847 - val_acc: 0.1853\n",
            "Epoch 217/250\n",
            "89/89 [==============================] - 24s 253ms/step - loss: 0.5349 - acc: 0.8204 - val_loss: 5.2090 - val_acc: 0.1832\n",
            "Epoch 218/250\n",
            "89/89 [==============================] - 30s 320ms/step - loss: 0.5215 - acc: 0.8240 - val_loss: 5.2778 - val_acc: 0.1875\n",
            "Epoch 219/250\n",
            "89/89 [==============================] - 25s 263ms/step - loss: 0.5184 - acc: 0.8119 - val_loss: 5.1556 - val_acc: 0.1853\n",
            "Epoch 220/250\n",
            "89/89 [==============================] - 30s 325ms/step - loss: 0.4866 - acc: 0.8304 - val_loss: 5.1792 - val_acc: 0.1897\n",
            "Epoch 221/250\n",
            "89/89 [==============================] - 30s 324ms/step - loss: 0.4464 - acc: 0.8474 - val_loss: 5.3798 - val_acc: 0.1875\n",
            "Epoch 222/250\n",
            "89/89 [==============================] - 25s 266ms/step - loss: 0.4776 - acc: 0.8368 - val_loss: 5.3333 - val_acc: 0.1897\n",
            "Epoch 223/250\n",
            "89/89 [==============================] - 24s 262ms/step - loss: 0.5261 - acc: 0.8233 - val_loss: 5.4032 - val_acc: 0.1897\n",
            "Epoch 224/250\n",
            "89/89 [==============================] - 29s 320ms/step - loss: 0.4833 - acc: 0.8382 - val_loss: 5.3606 - val_acc: 0.1961\n",
            "Epoch 225/250\n",
            "89/89 [==============================] - 29s 320ms/step - loss: 0.4529 - acc: 0.8488 - val_loss: 5.4481 - val_acc: 0.1832\n",
            "Epoch 226/250\n",
            "89/89 [==============================] - 30s 329ms/step - loss: 0.4400 - acc: 0.8517 - val_loss: 5.4020 - val_acc: 0.1897\n",
            "Epoch 227/250\n",
            "89/89 [==============================] - 30s 326ms/step - loss: 0.4865 - acc: 0.8311 - val_loss: 5.3710 - val_acc: 0.1940\n",
            "Epoch 228/250\n",
            "89/89 [==============================] - 30s 328ms/step - loss: 0.4901 - acc: 0.8382 - val_loss: 5.5021 - val_acc: 0.1897\n",
            "Epoch 229/250\n",
            "89/89 [==============================] - 29s 322ms/step - loss: 0.4331 - acc: 0.8538 - val_loss: 5.3751 - val_acc: 0.1897\n",
            "Epoch 230/250\n",
            "89/89 [==============================] - 30s 325ms/step - loss: 0.4643 - acc: 0.8502 - val_loss: 5.3012 - val_acc: 0.1961\n",
            "Epoch 231/250\n",
            "89/89 [==============================] - 29s 320ms/step - loss: 0.4578 - acc: 0.8325 - val_loss: 5.5018 - val_acc: 0.1940\n",
            "Epoch 232/250\n",
            "89/89 [==============================] - 30s 329ms/step - loss: 0.4510 - acc: 0.8559 - val_loss: 5.4954 - val_acc: 0.1940\n",
            "Epoch 233/250\n",
            "89/89 [==============================] - 29s 307ms/step - loss: 0.4589 - acc: 0.8417 - val_loss: 5.3989 - val_acc: 0.1961\n",
            "Epoch 234/250\n",
            "89/89 [==============================] - 28s 303ms/step - loss: 0.4286 - acc: 0.8474 - val_loss: 5.3818 - val_acc: 0.2047\n",
            "Epoch 235/250\n",
            "89/89 [==============================] - 29s 312ms/step - loss: 0.4169 - acc: 0.8602 - val_loss: 5.3785 - val_acc: 0.1918\n",
            "Epoch 236/250\n",
            "89/89 [==============================] - 29s 314ms/step - loss: 0.4249 - acc: 0.8502 - val_loss: 5.6050 - val_acc: 0.1940\n",
            "Epoch 237/250\n",
            "89/89 [==============================] - 30s 330ms/step - loss: 0.4314 - acc: 0.8495 - val_loss: 5.5445 - val_acc: 0.1961\n",
            "Epoch 238/250\n",
            "89/89 [==============================] - 29s 314ms/step - loss: 0.4006 - acc: 0.8559 - val_loss: 5.5565 - val_acc: 0.1961\n",
            "Epoch 239/250\n",
            "89/89 [==============================] - 29s 321ms/step - loss: 0.3769 - acc: 0.8680 - val_loss: 5.6692 - val_acc: 0.1789\n",
            "Epoch 240/250\n",
            "89/89 [==============================] - 30s 327ms/step - loss: 0.4387 - acc: 0.8488 - val_loss: 5.6589 - val_acc: 0.1875\n",
            "Epoch 241/250\n",
            "89/89 [==============================] - 25s 277ms/step - loss: 0.4365 - acc: 0.8460 - val_loss: 5.7895 - val_acc: 0.1832\n",
            "Epoch 242/250\n",
            "89/89 [==============================] - 23s 251ms/step - loss: 0.4211 - acc: 0.8502 - val_loss: 5.7241 - val_acc: 0.1897\n",
            "Epoch 243/250\n",
            "89/89 [==============================] - 29s 320ms/step - loss: 0.4186 - acc: 0.8715 - val_loss: 5.5634 - val_acc: 0.1983\n",
            "Epoch 244/250\n",
            "89/89 [==============================] - 29s 320ms/step - loss: 0.3954 - acc: 0.8581 - val_loss: 5.6113 - val_acc: 0.1918\n",
            "Epoch 245/250\n",
            "89/89 [==============================] - 30s 334ms/step - loss: 0.3788 - acc: 0.8637 - val_loss: 5.5673 - val_acc: 0.2004\n",
            "Epoch 246/250\n",
            "89/89 [==============================] - 29s 314ms/step - loss: 0.3838 - acc: 0.8666 - val_loss: 5.5354 - val_acc: 0.1853\n",
            "Epoch 247/250\n",
            "89/89 [==============================] - 30s 325ms/step - loss: 0.3232 - acc: 0.8914 - val_loss: 5.5584 - val_acc: 0.1832\n",
            "Epoch 248/250\n",
            "89/89 [==============================] - 30s 334ms/step - loss: 0.3825 - acc: 0.8793 - val_loss: 5.7183 - val_acc: 0.1875\n",
            "Epoch 249/250\n",
            "89/89 [==============================] - 30s 328ms/step - loss: 0.3768 - acc: 0.8772 - val_loss: 5.7823 - val_acc: 0.1897\n",
            "Epoch 250/250\n",
            "89/89 [==============================] - 30s 323ms/step - loss: 0.3577 - acc: 0.8715 - val_loss: 5.7915 - val_acc: 0.1875\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "acc = history.history['acc']\n",
        "val_acc = history.history['val_acc']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs_x = range(len(acc))\n",
        "\n",
        "plt.plot(epochs_x, acc, 'co', label='Training acc')\n",
        "plt.plot(epochs_x, val_acc, 'k', label='Validation acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.figure()\n",
        "\n",
        "plt.plot(epochs_x, loss, 'co', label='Training loss')\n",
        "plt.plot(epochs_x, val_loss, 'k', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "kwylTJpTP5XI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545
        },
        "outputId": "1c69d95c-5ea6-48df-8279-09548f58d231"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Download the model"
      ],
      "metadata": {
        "id": "lD-vKaoHQAFd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "os.makedirs('/content/drive/My Drive/cut_panoramic/Model/Classification', exist_ok=True)\n",
        "model.save('/content/drive/My Drive/cut_panoramic/Model/Classification/Male/55_รอบที่5_Flimpano_Male125_250_New_Unfreez.h5')"
      ],
      "metadata": {
        "id": "74dL7-HLP_Sh"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from google.colab import files\n",
        "# files.download('/content/drive/My Drive/cut_panoramic/Model/33_รอบที่3_Flimpano_Male125_250.h5')"
      ],
      "metadata": {
        "id": "qcPW-brHQDpc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "P4pe9URV1vBB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}