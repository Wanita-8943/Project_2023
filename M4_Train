{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Wanita-8943/Project_2023/blob/main/M4_Train\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "KKSs7cyoPHcD"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import shutil"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7LoeZxmVPMxp",
        "outputId": "8c4b9163-26fb-4466-b85f-b316e76cdcb4"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import models\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import optimizers\n",
        "import os\n",
        "import glob\n",
        "import shutil\n",
        "import sys\n",
        "import numpy as np\n",
        "from skimage.io import imread\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import Image\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "1pX9g1HxPM2f"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 16\n",
        "width = 150\n",
        "height = 150\n",
        "epochs = 250\n",
        "NUM_TRAIN = 1425\n",
        "NUM_TEST = 475\n",
        "dropout_rate = 0.2\n",
        "input_shape = (height, width, 3)"
      ],
      "metadata": {
        "id": "eSFtvGyvPM6O"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#ดึงข้อมูลใน Github มาใช้\n",
        "import os\n",
        "%cd /content\n",
        "if not os.path.isdir(\"efficientnet_keras_transfer_learning\"):\n",
        " !git clone https://github.com/Wanita-8943/efficientnet_keras_transfer_learning\n",
        "%cd efficientnet_keras_transfer_learning/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lb4K4CsMPNAW",
        "outputId": "6a0be314-5ee5-4bd4-a0aa-17d27b038c23"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "Cloning into 'efficientnet_keras_transfer_learning'...\n",
            "remote: Enumerating objects: 837, done.\u001b[K\n",
            "remote: Counting objects: 100% (359/359), done.\u001b[K\n",
            "remote: Compressing objects: 100% (124/124), done.\u001b[K\n",
            "remote: Total 837 (delta 255), reused 328 (delta 235), pack-reused 478\u001b[K\n",
            "Receiving objects: 100% (837/837), 13.82 MiB | 34.26 MiB/s, done.\n",
            "Resolving deltas: 100% (495/495), done.\n",
            "/content/efficientnet_keras_transfer_learning\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Options: EfficientNetB0, EfficientNetB1, EfficientNetB2, EfficientNetB3\n",
        "# Higher the number, the more complex the model is.\n",
        "from efficientnet import EfficientNetB0 as Net\n",
        "from efficientnet import center_crop_and_resize, preprocess_input"
      ],
      "metadata": {
        "id": "eyBg0dLKPND3"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# loading pretrained conv base model\n",
        "# โหลดโมเดล มาโดยตัด output ของโมเดลออก เเต่ยังใช้ input อันเดิม\n",
        "# เเละโหลด weight ของโมเดล มาด้วยที่ชื่อว่า imagenet\n",
        "conv_base = Net(weights='imagenet', include_top=False, input_shape=input_shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DoxI-q8-1giK",
        "outputId": "0d9b4439-f442-405f-f778-60cacf95ad95"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
            "Instructions for updating:\n",
            "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://github.com/qubvel/efficientnet/releases/download/v0.0.1/efficientnet-b0_imagenet_1000_notop.h5\n",
            "16717576/16717576 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "conv_base.summary() #ดู Summary"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "od4Lp6dD1lWK",
        "outputId": "52104493-800e-4790-a659-e59960bbc9ae"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"efficientnet-b0\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 150, 150, 3  0           []                               \n",
            "                                )]                                                                \n",
            "                                                                                                  \n",
            " conv2d (Conv2D)                (None, 75, 75, 32)   864         ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " batch_normalization (BatchNorm  (None, 75, 75, 32)  128         ['conv2d[0][0]']                 \n",
            " alization)                                                                                       \n",
            "                                                                                                  \n",
            " swish (Swish)                  (None, 75, 75, 32)   0           ['batch_normalization[0][0]']    \n",
            "                                                                                                  \n",
            " depthwise_conv2d (DepthwiseCon  (None, 75, 75, 32)  288         ['swish[0][0]']                  \n",
            " v2D)                                                                                             \n",
            "                                                                                                  \n",
            " batch_normalization_1 (BatchNo  (None, 75, 75, 32)  128         ['depthwise_conv2d[0][0]']       \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " swish_1 (Swish)                (None, 75, 75, 32)   0           ['batch_normalization_1[0][0]']  \n",
            "                                                                                                  \n",
            " lambda (Lambda)                (None, 1, 1, 32)     0           ['swish_1[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d_1 (Conv2D)              (None, 1, 1, 8)      264         ['lambda[0][0]']                 \n",
            "                                                                                                  \n",
            " swish_2 (Swish)                (None, 1, 1, 8)      0           ['conv2d_1[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_2 (Conv2D)              (None, 1, 1, 32)     288         ['swish_2[0][0]']                \n",
            "                                                                                                  \n",
            " activation (Activation)        (None, 1, 1, 32)     0           ['conv2d_2[0][0]']               \n",
            "                                                                                                  \n",
            " multiply (Multiply)            (None, 75, 75, 32)   0           ['activation[0][0]',             \n",
            "                                                                  'swish_1[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d_3 (Conv2D)              (None, 75, 75, 16)   512         ['multiply[0][0]']               \n",
            "                                                                                                  \n",
            " batch_normalization_2 (BatchNo  (None, 75, 75, 16)  64          ['conv2d_3[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv2d_4 (Conv2D)              (None, 75, 75, 96)   1536        ['batch_normalization_2[0][0]']  \n",
            "                                                                                                  \n",
            " batch_normalization_3 (BatchNo  (None, 75, 75, 96)  384         ['conv2d_4[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " swish_3 (Swish)                (None, 75, 75, 96)   0           ['batch_normalization_3[0][0]']  \n",
            "                                                                                                  \n",
            " depthwise_conv2d_1 (DepthwiseC  (None, 38, 38, 96)  864         ['swish_3[0][0]']                \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_4 (BatchNo  (None, 38, 38, 96)  384         ['depthwise_conv2d_1[0][0]']     \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " swish_4 (Swish)                (None, 38, 38, 96)   0           ['batch_normalization_4[0][0]']  \n",
            "                                                                                                  \n",
            " lambda_1 (Lambda)              (None, 1, 1, 96)     0           ['swish_4[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d_5 (Conv2D)              (None, 1, 1, 4)      388         ['lambda_1[0][0]']               \n",
            "                                                                                                  \n",
            " swish_5 (Swish)                (None, 1, 1, 4)      0           ['conv2d_5[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_6 (Conv2D)              (None, 1, 1, 96)     480         ['swish_5[0][0]']                \n",
            "                                                                                                  \n",
            " activation_1 (Activation)      (None, 1, 1, 96)     0           ['conv2d_6[0][0]']               \n",
            "                                                                                                  \n",
            " multiply_1 (Multiply)          (None, 38, 38, 96)   0           ['activation_1[0][0]',           \n",
            "                                                                  'swish_4[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d_7 (Conv2D)              (None, 38, 38, 24)   2304        ['multiply_1[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_5 (BatchNo  (None, 38, 38, 24)  96          ['conv2d_7[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv2d_8 (Conv2D)              (None, 38, 38, 144)  3456        ['batch_normalization_5[0][0]']  \n",
            "                                                                                                  \n",
            " batch_normalization_6 (BatchNo  (None, 38, 38, 144)  576        ['conv2d_8[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " swish_6 (Swish)                (None, 38, 38, 144)  0           ['batch_normalization_6[0][0]']  \n",
            "                                                                                                  \n",
            " depthwise_conv2d_2 (DepthwiseC  (None, 38, 38, 144)  1296       ['swish_6[0][0]']                \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_7 (BatchNo  (None, 38, 38, 144)  576        ['depthwise_conv2d_2[0][0]']     \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " swish_7 (Swish)                (None, 38, 38, 144)  0           ['batch_normalization_7[0][0]']  \n",
            "                                                                                                  \n",
            " lambda_2 (Lambda)              (None, 1, 1, 144)    0           ['swish_7[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d_9 (Conv2D)              (None, 1, 1, 6)      870         ['lambda_2[0][0]']               \n",
            "                                                                                                  \n",
            " swish_8 (Swish)                (None, 1, 1, 6)      0           ['conv2d_9[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_10 (Conv2D)             (None, 1, 1, 144)    1008        ['swish_8[0][0]']                \n",
            "                                                                                                  \n",
            " activation_2 (Activation)      (None, 1, 1, 144)    0           ['conv2d_10[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_2 (Multiply)          (None, 38, 38, 144)  0           ['activation_2[0][0]',           \n",
            "                                                                  'swish_7[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d_11 (Conv2D)             (None, 38, 38, 24)   3456        ['multiply_2[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_8 (BatchNo  (None, 38, 38, 24)  96          ['conv2d_11[0][0]']              \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " drop_connect (DropConnect)     (None, 38, 38, 24)   0           ['batch_normalization_8[0][0]']  \n",
            "                                                                                                  \n",
            " add (Add)                      (None, 38, 38, 24)   0           ['drop_connect[0][0]',           \n",
            "                                                                  'batch_normalization_5[0][0]']  \n",
            "                                                                                                  \n",
            " conv2d_12 (Conv2D)             (None, 38, 38, 144)  3456        ['add[0][0]']                    \n",
            "                                                                                                  \n",
            " batch_normalization_9 (BatchNo  (None, 38, 38, 144)  576        ['conv2d_12[0][0]']              \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " swish_9 (Swish)                (None, 38, 38, 144)  0           ['batch_normalization_9[0][0]']  \n",
            "                                                                                                  \n",
            " depthwise_conv2d_3 (DepthwiseC  (None, 19, 19, 144)  3600       ['swish_9[0][0]']                \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_10 (BatchN  (None, 19, 19, 144)  576        ['depthwise_conv2d_3[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_10 (Swish)               (None, 19, 19, 144)  0           ['batch_normalization_10[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_3 (Lambda)              (None, 1, 1, 144)    0           ['swish_10[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_13 (Conv2D)             (None, 1, 1, 6)      870         ['lambda_3[0][0]']               \n",
            "                                                                                                  \n",
            " swish_11 (Swish)               (None, 1, 1, 6)      0           ['conv2d_13[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_14 (Conv2D)             (None, 1, 1, 144)    1008        ['swish_11[0][0]']               \n",
            "                                                                                                  \n",
            " activation_3 (Activation)      (None, 1, 1, 144)    0           ['conv2d_14[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_3 (Multiply)          (None, 19, 19, 144)  0           ['activation_3[0][0]',           \n",
            "                                                                  'swish_10[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_15 (Conv2D)             (None, 19, 19, 40)   5760        ['multiply_3[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_11 (BatchN  (None, 19, 19, 40)  160         ['conv2d_15[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_16 (Conv2D)             (None, 19, 19, 240)  9600        ['batch_normalization_11[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_12 (BatchN  (None, 19, 19, 240)  960        ['conv2d_16[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_12 (Swish)               (None, 19, 19, 240)  0           ['batch_normalization_12[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_4 (DepthwiseC  (None, 19, 19, 240)  6000       ['swish_12[0][0]']               \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_13 (BatchN  (None, 19, 19, 240)  960        ['depthwise_conv2d_4[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_13 (Swish)               (None, 19, 19, 240)  0           ['batch_normalization_13[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_4 (Lambda)              (None, 1, 1, 240)    0           ['swish_13[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_17 (Conv2D)             (None, 1, 1, 10)     2410        ['lambda_4[0][0]']               \n",
            "                                                                                                  \n",
            " swish_14 (Swish)               (None, 1, 1, 10)     0           ['conv2d_17[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_18 (Conv2D)             (None, 1, 1, 240)    2640        ['swish_14[0][0]']               \n",
            "                                                                                                  \n",
            " activation_4 (Activation)      (None, 1, 1, 240)    0           ['conv2d_18[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_4 (Multiply)          (None, 19, 19, 240)  0           ['activation_4[0][0]',           \n",
            "                                                                  'swish_13[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_19 (Conv2D)             (None, 19, 19, 40)   9600        ['multiply_4[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_14 (BatchN  (None, 19, 19, 40)  160         ['conv2d_19[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_1 (DropConnect)   (None, 19, 19, 40)   0           ['batch_normalization_14[0][0]'] \n",
            "                                                                                                  \n",
            " add_1 (Add)                    (None, 19, 19, 40)   0           ['drop_connect_1[0][0]',         \n",
            "                                                                  'batch_normalization_11[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_20 (Conv2D)             (None, 19, 19, 240)  9600        ['add_1[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_15 (BatchN  (None, 19, 19, 240)  960        ['conv2d_20[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_15 (Swish)               (None, 19, 19, 240)  0           ['batch_normalization_15[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_5 (DepthwiseC  (None, 10, 10, 240)  2160       ['swish_15[0][0]']               \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_16 (BatchN  (None, 10, 10, 240)  960        ['depthwise_conv2d_5[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_16 (Swish)               (None, 10, 10, 240)  0           ['batch_normalization_16[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_5 (Lambda)              (None, 1, 1, 240)    0           ['swish_16[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_21 (Conv2D)             (None, 1, 1, 10)     2410        ['lambda_5[0][0]']               \n",
            "                                                                                                  \n",
            " swish_17 (Swish)               (None, 1, 1, 10)     0           ['conv2d_21[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_22 (Conv2D)             (None, 1, 1, 240)    2640        ['swish_17[0][0]']               \n",
            "                                                                                                  \n",
            " activation_5 (Activation)      (None, 1, 1, 240)    0           ['conv2d_22[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_5 (Multiply)          (None, 10, 10, 240)  0           ['activation_5[0][0]',           \n",
            "                                                                  'swish_16[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_23 (Conv2D)             (None, 10, 10, 80)   19200       ['multiply_5[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_17 (BatchN  (None, 10, 10, 80)  320         ['conv2d_23[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_24 (Conv2D)             (None, 10, 10, 480)  38400       ['batch_normalization_17[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_18 (BatchN  (None, 10, 10, 480)  1920       ['conv2d_24[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_18 (Swish)               (None, 10, 10, 480)  0           ['batch_normalization_18[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_6 (DepthwiseC  (None, 10, 10, 480)  4320       ['swish_18[0][0]']               \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_19 (BatchN  (None, 10, 10, 480)  1920       ['depthwise_conv2d_6[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_19 (Swish)               (None, 10, 10, 480)  0           ['batch_normalization_19[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_6 (Lambda)              (None, 1, 1, 480)    0           ['swish_19[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_25 (Conv2D)             (None, 1, 1, 20)     9620        ['lambda_6[0][0]']               \n",
            "                                                                                                  \n",
            " swish_20 (Swish)               (None, 1, 1, 20)     0           ['conv2d_25[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_26 (Conv2D)             (None, 1, 1, 480)    10080       ['swish_20[0][0]']               \n",
            "                                                                                                  \n",
            " activation_6 (Activation)      (None, 1, 1, 480)    0           ['conv2d_26[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_6 (Multiply)          (None, 10, 10, 480)  0           ['activation_6[0][0]',           \n",
            "                                                                  'swish_19[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_27 (Conv2D)             (None, 10, 10, 80)   38400       ['multiply_6[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_20 (BatchN  (None, 10, 10, 80)  320         ['conv2d_27[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_2 (DropConnect)   (None, 10, 10, 80)   0           ['batch_normalization_20[0][0]'] \n",
            "                                                                                                  \n",
            " add_2 (Add)                    (None, 10, 10, 80)   0           ['drop_connect_2[0][0]',         \n",
            "                                                                  'batch_normalization_17[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_28 (Conv2D)             (None, 10, 10, 480)  38400       ['add_2[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_21 (BatchN  (None, 10, 10, 480)  1920       ['conv2d_28[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_21 (Swish)               (None, 10, 10, 480)  0           ['batch_normalization_21[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_7 (DepthwiseC  (None, 10, 10, 480)  4320       ['swish_21[0][0]']               \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_22 (BatchN  (None, 10, 10, 480)  1920       ['depthwise_conv2d_7[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_22 (Swish)               (None, 10, 10, 480)  0           ['batch_normalization_22[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_7 (Lambda)              (None, 1, 1, 480)    0           ['swish_22[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_29 (Conv2D)             (None, 1, 1, 20)     9620        ['lambda_7[0][0]']               \n",
            "                                                                                                  \n",
            " swish_23 (Swish)               (None, 1, 1, 20)     0           ['conv2d_29[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_30 (Conv2D)             (None, 1, 1, 480)    10080       ['swish_23[0][0]']               \n",
            "                                                                                                  \n",
            " activation_7 (Activation)      (None, 1, 1, 480)    0           ['conv2d_30[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_7 (Multiply)          (None, 10, 10, 480)  0           ['activation_7[0][0]',           \n",
            "                                                                  'swish_22[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_31 (Conv2D)             (None, 10, 10, 80)   38400       ['multiply_7[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_23 (BatchN  (None, 10, 10, 80)  320         ['conv2d_31[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_3 (DropConnect)   (None, 10, 10, 80)   0           ['batch_normalization_23[0][0]'] \n",
            "                                                                                                  \n",
            " add_3 (Add)                    (None, 10, 10, 80)   0           ['drop_connect_3[0][0]',         \n",
            "                                                                  'add_2[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_32 (Conv2D)             (None, 10, 10, 480)  38400       ['add_3[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_24 (BatchN  (None, 10, 10, 480)  1920       ['conv2d_32[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_24 (Swish)               (None, 10, 10, 480)  0           ['batch_normalization_24[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_8 (DepthwiseC  (None, 10, 10, 480)  12000      ['swish_24[0][0]']               \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_25 (BatchN  (None, 10, 10, 480)  1920       ['depthwise_conv2d_8[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_25 (Swish)               (None, 10, 10, 480)  0           ['batch_normalization_25[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_8 (Lambda)              (None, 1, 1, 480)    0           ['swish_25[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_33 (Conv2D)             (None, 1, 1, 20)     9620        ['lambda_8[0][0]']               \n",
            "                                                                                                  \n",
            " swish_26 (Swish)               (None, 1, 1, 20)     0           ['conv2d_33[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_34 (Conv2D)             (None, 1, 1, 480)    10080       ['swish_26[0][0]']               \n",
            "                                                                                                  \n",
            " activation_8 (Activation)      (None, 1, 1, 480)    0           ['conv2d_34[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_8 (Multiply)          (None, 10, 10, 480)  0           ['activation_8[0][0]',           \n",
            "                                                                  'swish_25[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_35 (Conv2D)             (None, 10, 10, 112)  53760       ['multiply_8[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_26 (BatchN  (None, 10, 10, 112)  448        ['conv2d_35[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_36 (Conv2D)             (None, 10, 10, 672)  75264       ['batch_normalization_26[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_27 (BatchN  (None, 10, 10, 672)  2688       ['conv2d_36[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_27 (Swish)               (None, 10, 10, 672)  0           ['batch_normalization_27[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_9 (DepthwiseC  (None, 10, 10, 672)  16800      ['swish_27[0][0]']               \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_28 (BatchN  (None, 10, 10, 672)  2688       ['depthwise_conv2d_9[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_28 (Swish)               (None, 10, 10, 672)  0           ['batch_normalization_28[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_9 (Lambda)              (None, 1, 1, 672)    0           ['swish_28[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_37 (Conv2D)             (None, 1, 1, 28)     18844       ['lambda_9[0][0]']               \n",
            "                                                                                                  \n",
            " swish_29 (Swish)               (None, 1, 1, 28)     0           ['conv2d_37[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_38 (Conv2D)             (None, 1, 1, 672)    19488       ['swish_29[0][0]']               \n",
            "                                                                                                  \n",
            " activation_9 (Activation)      (None, 1, 1, 672)    0           ['conv2d_38[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_9 (Multiply)          (None, 10, 10, 672)  0           ['activation_9[0][0]',           \n",
            "                                                                  'swish_28[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_39 (Conv2D)             (None, 10, 10, 112)  75264       ['multiply_9[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_29 (BatchN  (None, 10, 10, 112)  448        ['conv2d_39[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_4 (DropConnect)   (None, 10, 10, 112)  0           ['batch_normalization_29[0][0]'] \n",
            "                                                                                                  \n",
            " add_4 (Add)                    (None, 10, 10, 112)  0           ['drop_connect_4[0][0]',         \n",
            "                                                                  'batch_normalization_26[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_40 (Conv2D)             (None, 10, 10, 672)  75264       ['add_4[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_30 (BatchN  (None, 10, 10, 672)  2688       ['conv2d_40[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_30 (Swish)               (None, 10, 10, 672)  0           ['batch_normalization_30[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_10 (Depthwise  (None, 10, 10, 672)  16800      ['swish_30[0][0]']               \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_31 (BatchN  (None, 10, 10, 672)  2688       ['depthwise_conv2d_10[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_31 (Swish)               (None, 10, 10, 672)  0           ['batch_normalization_31[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_10 (Lambda)             (None, 1, 1, 672)    0           ['swish_31[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_41 (Conv2D)             (None, 1, 1, 28)     18844       ['lambda_10[0][0]']              \n",
            "                                                                                                  \n",
            " swish_32 (Swish)               (None, 1, 1, 28)     0           ['conv2d_41[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_42 (Conv2D)             (None, 1, 1, 672)    19488       ['swish_32[0][0]']               \n",
            "                                                                                                  \n",
            " activation_10 (Activation)     (None, 1, 1, 672)    0           ['conv2d_42[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_10 (Multiply)         (None, 10, 10, 672)  0           ['activation_10[0][0]',          \n",
            "                                                                  'swish_31[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_43 (Conv2D)             (None, 10, 10, 112)  75264       ['multiply_10[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_32 (BatchN  (None, 10, 10, 112)  448        ['conv2d_43[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_5 (DropConnect)   (None, 10, 10, 112)  0           ['batch_normalization_32[0][0]'] \n",
            "                                                                                                  \n",
            " add_5 (Add)                    (None, 10, 10, 112)  0           ['drop_connect_5[0][0]',         \n",
            "                                                                  'add_4[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_44 (Conv2D)             (None, 10, 10, 672)  75264       ['add_5[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_33 (BatchN  (None, 10, 10, 672)  2688       ['conv2d_44[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_33 (Swish)               (None, 10, 10, 672)  0           ['batch_normalization_33[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_11 (Depthwise  (None, 5, 5, 672)   16800       ['swish_33[0][0]']               \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_34 (BatchN  (None, 5, 5, 672)   2688        ['depthwise_conv2d_11[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_34 (Swish)               (None, 5, 5, 672)    0           ['batch_normalization_34[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_11 (Lambda)             (None, 1, 1, 672)    0           ['swish_34[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_45 (Conv2D)             (None, 1, 1, 28)     18844       ['lambda_11[0][0]']              \n",
            "                                                                                                  \n",
            " swish_35 (Swish)               (None, 1, 1, 28)     0           ['conv2d_45[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_46 (Conv2D)             (None, 1, 1, 672)    19488       ['swish_35[0][0]']               \n",
            "                                                                                                  \n",
            " activation_11 (Activation)     (None, 1, 1, 672)    0           ['conv2d_46[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_11 (Multiply)         (None, 5, 5, 672)    0           ['activation_11[0][0]',          \n",
            "                                                                  'swish_34[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_47 (Conv2D)             (None, 5, 5, 192)    129024      ['multiply_11[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_35 (BatchN  (None, 5, 5, 192)   768         ['conv2d_47[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_48 (Conv2D)             (None, 5, 5, 1152)   221184      ['batch_normalization_35[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_36 (BatchN  (None, 5, 5, 1152)  4608        ['conv2d_48[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_36 (Swish)               (None, 5, 5, 1152)   0           ['batch_normalization_36[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_12 (Depthwise  (None, 5, 5, 1152)  28800       ['swish_36[0][0]']               \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_37 (BatchN  (None, 5, 5, 1152)  4608        ['depthwise_conv2d_12[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_37 (Swish)               (None, 5, 5, 1152)   0           ['batch_normalization_37[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_12 (Lambda)             (None, 1, 1, 1152)   0           ['swish_37[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_49 (Conv2D)             (None, 1, 1, 48)     55344       ['lambda_12[0][0]']              \n",
            "                                                                                                  \n",
            " swish_38 (Swish)               (None, 1, 1, 48)     0           ['conv2d_49[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_50 (Conv2D)             (None, 1, 1, 1152)   56448       ['swish_38[0][0]']               \n",
            "                                                                                                  \n",
            " activation_12 (Activation)     (None, 1, 1, 1152)   0           ['conv2d_50[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_12 (Multiply)         (None, 5, 5, 1152)   0           ['activation_12[0][0]',          \n",
            "                                                                  'swish_37[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_51 (Conv2D)             (None, 5, 5, 192)    221184      ['multiply_12[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_38 (BatchN  (None, 5, 5, 192)   768         ['conv2d_51[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_6 (DropConnect)   (None, 5, 5, 192)    0           ['batch_normalization_38[0][0]'] \n",
            "                                                                                                  \n",
            " add_6 (Add)                    (None, 5, 5, 192)    0           ['drop_connect_6[0][0]',         \n",
            "                                                                  'batch_normalization_35[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_52 (Conv2D)             (None, 5, 5, 1152)   221184      ['add_6[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_39 (BatchN  (None, 5, 5, 1152)  4608        ['conv2d_52[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_39 (Swish)               (None, 5, 5, 1152)   0           ['batch_normalization_39[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_13 (Depthwise  (None, 5, 5, 1152)  28800       ['swish_39[0][0]']               \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_40 (BatchN  (None, 5, 5, 1152)  4608        ['depthwise_conv2d_13[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_40 (Swish)               (None, 5, 5, 1152)   0           ['batch_normalization_40[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_13 (Lambda)             (None, 1, 1, 1152)   0           ['swish_40[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_53 (Conv2D)             (None, 1, 1, 48)     55344       ['lambda_13[0][0]']              \n",
            "                                                                                                  \n",
            " swish_41 (Swish)               (None, 1, 1, 48)     0           ['conv2d_53[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_54 (Conv2D)             (None, 1, 1, 1152)   56448       ['swish_41[0][0]']               \n",
            "                                                                                                  \n",
            " activation_13 (Activation)     (None, 1, 1, 1152)   0           ['conv2d_54[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_13 (Multiply)         (None, 5, 5, 1152)   0           ['activation_13[0][0]',          \n",
            "                                                                  'swish_40[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_55 (Conv2D)             (None, 5, 5, 192)    221184      ['multiply_13[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_41 (BatchN  (None, 5, 5, 192)   768         ['conv2d_55[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_7 (DropConnect)   (None, 5, 5, 192)    0           ['batch_normalization_41[0][0]'] \n",
            "                                                                                                  \n",
            " add_7 (Add)                    (None, 5, 5, 192)    0           ['drop_connect_7[0][0]',         \n",
            "                                                                  'add_6[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_56 (Conv2D)             (None, 5, 5, 1152)   221184      ['add_7[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_42 (BatchN  (None, 5, 5, 1152)  4608        ['conv2d_56[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_42 (Swish)               (None, 5, 5, 1152)   0           ['batch_normalization_42[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_14 (Depthwise  (None, 5, 5, 1152)  28800       ['swish_42[0][0]']               \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_43 (BatchN  (None, 5, 5, 1152)  4608        ['depthwise_conv2d_14[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_43 (Swish)               (None, 5, 5, 1152)   0           ['batch_normalization_43[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_14 (Lambda)             (None, 1, 1, 1152)   0           ['swish_43[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_57 (Conv2D)             (None, 1, 1, 48)     55344       ['lambda_14[0][0]']              \n",
            "                                                                                                  \n",
            " swish_44 (Swish)               (None, 1, 1, 48)     0           ['conv2d_57[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_58 (Conv2D)             (None, 1, 1, 1152)   56448       ['swish_44[0][0]']               \n",
            "                                                                                                  \n",
            " activation_14 (Activation)     (None, 1, 1, 1152)   0           ['conv2d_58[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_14 (Multiply)         (None, 5, 5, 1152)   0           ['activation_14[0][0]',          \n",
            "                                                                  'swish_43[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_59 (Conv2D)             (None, 5, 5, 192)    221184      ['multiply_14[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_44 (BatchN  (None, 5, 5, 192)   768         ['conv2d_59[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_8 (DropConnect)   (None, 5, 5, 192)    0           ['batch_normalization_44[0][0]'] \n",
            "                                                                                                  \n",
            " add_8 (Add)                    (None, 5, 5, 192)    0           ['drop_connect_8[0][0]',         \n",
            "                                                                  'add_7[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_60 (Conv2D)             (None, 5, 5, 1152)   221184      ['add_8[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_45 (BatchN  (None, 5, 5, 1152)  4608        ['conv2d_60[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_45 (Swish)               (None, 5, 5, 1152)   0           ['batch_normalization_45[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_15 (Depthwise  (None, 5, 5, 1152)  10368       ['swish_45[0][0]']               \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_46 (BatchN  (None, 5, 5, 1152)  4608        ['depthwise_conv2d_15[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_46 (Swish)               (None, 5, 5, 1152)   0           ['batch_normalization_46[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_15 (Lambda)             (None, 1, 1, 1152)   0           ['swish_46[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_61 (Conv2D)             (None, 1, 1, 48)     55344       ['lambda_15[0][0]']              \n",
            "                                                                                                  \n",
            " swish_47 (Swish)               (None, 1, 1, 48)     0           ['conv2d_61[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_62 (Conv2D)             (None, 1, 1, 1152)   56448       ['swish_47[0][0]']               \n",
            "                                                                                                  \n",
            " activation_15 (Activation)     (None, 1, 1, 1152)   0           ['conv2d_62[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_15 (Multiply)         (None, 5, 5, 1152)   0           ['activation_15[0][0]',          \n",
            "                                                                  'swish_46[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_63 (Conv2D)             (None, 5, 5, 320)    368640      ['multiply_15[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_47 (BatchN  (None, 5, 5, 320)   1280        ['conv2d_63[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_64 (Conv2D)             (None, 5, 5, 1280)   409600      ['batch_normalization_47[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_48 (BatchN  (None, 5, 5, 1280)  5120        ['conv2d_64[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_48 (Swish)               (None, 5, 5, 1280)   0           ['batch_normalization_48[0][0]'] \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 4,049,564\n",
            "Trainable params: 4,007,548\n",
            "Non-trainable params: 42,016\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "base_dir = '/content/drive/MyDrive/TVT_Male125'\n",
        "os.makedirs(base_dir, exist_ok=True)\n",
        "\n",
        "# Directories for our training,\n",
        "# validation and test splits\n",
        "train_dir = os.path.join(base_dir, 'train')\n",
        "os.makedirs(train_dir, exist_ok=True)\n",
        "validation_dir = os.path.join(base_dir, 'validation')\n",
        "os.makedirs(validation_dir, exist_ok=True)\n",
        "test_dir = os.path.join(base_dir, 'test')\n",
        "os.makedirs(test_dir, exist_ok=True)"
      ],
      "metadata": {
        "id": "Jwpq_-KvPef8"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#load model"
      ],
      "metadata": {
        "id": "od-ZSNm5PoGy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.append('/content/drive/MyDrive/cut_panoramic/Model/Classification/Male/33_รอบที่3_Flimpano_Male125_250.h5')\n",
        "\n",
        "from efficientnet.layers import Swish, DropConnect\n",
        "from efficientnet.model import ConvKernalInitializer\n",
        "from tensorflow.keras.utils import get_custom_objects\n",
        "\n",
        "get_custom_objects().update({\n",
        "    'ConvKernalInitializer': ConvKernalInitializer,\n",
        "    'Swish': Swish,\n",
        "    'DropConnect':DropConnect\n",
        "})"
      ],
      "metadata": {
        "id": "n5iPL5MNPkhE"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#load model \n",
        "from tensorflow.keras.models import load_model\n",
        "model = load_model('/content/drive/MyDrive/cut_panoramic/Model/Classification/Male/33_รอบที่3_Flimpano_Male125_250.h5')\n",
        "height = width = model.input_shape[1]"
      ],
      "metadata": {
        "id": "plYz49xMPkly"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z6IOPBflFbvc",
        "outputId": "4f0c5eaa-be51-4ac4-9037-9b5bcbc3b098"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " efficientnet-b0 (Functional  (None, 5, 5, 1280)       4049564   \n",
            " )                                                               \n",
            "                                                                 \n",
            " gap (GlobalMaxPooling2D)    (None, 1280)              0         \n",
            "                                                                 \n",
            " dropout_out (Dropout)       (None, 1280)              0         \n",
            "                                                                 \n",
            " fc_out (Dense)              (None, 19)                24339     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4,073,903\n",
            "Trainable params: 24,339\n",
            "Non-trainable params: 4,049,564\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train ด้วย ImageDataGenerator ของ Keras ซึ่งจะเพิ่มข้อมูลเสริมระหว่างการฝึกเพื่อลดโอกาสเกิด overfitting\n",
        "#overfitting เกิดจากข้อมูลที่ซับซ้อนกันเกินไป\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "train_datagen = ImageDataGenerator(\n",
        "      rescale=1./255, #โมเดลส่วนใหญ่ต้องใช้ RGB ในช่วง 0–1\n",
        "      rotation_range=40,\n",
        "      width_shift_range=0.2,\n",
        "      height_shift_range=0.2,\n",
        "      shear_range=0.2,\n",
        "      zoom_range=0.2,\n",
        "      horizontal_flip=True,\n",
        "      fill_mode='nearest')\n",
        "\n",
        "# Note that the validation data should not be augmented!\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "        # This is the target directory #ไดเรกเป้าหมาย\n",
        "        train_dir,\n",
        "        # รูปภาพทั้งหมดจะถูกปรับขนาดตามความสูงและความกว้างของเป้าหมาย\n",
        "        target_size=(height, width),\n",
        "        batch_size=batch_size,\n",
        "        # Since we use categorical_crossentropy loss, we need categorical labels\n",
        "        #เนื่องจากเราใช้ categorical_crossentropy loss เราจึงต้องมีป้ายกำกับตามหมวดหมู่\n",
        "        class_mode='categorical')\n",
        "\n",
        "validation_generator = test_datagen.flow_from_directory( #การดึงภาพจาก Directory มาเข้าโมเดล \n",
        "        validation_dir,\n",
        "        target_size=(height, width),\n",
        "        batch_size=batch_size,\n",
        "        class_mode='categorical')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KBMZbdr2Pgw4",
        "outputId": "adba895b-7a73-4667-e894-d5d12287b278"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1425 images belonging to 19 classes.\n",
            "Found 475 images belonging to 19 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# multiply_16\n",
        "# set 'multiply_16' and following layers trainable\n",
        "model.trainable = True\n",
        "\n",
        "set_trainable = False\n",
        "for layer in conv_base.layers:\n",
        "    if layer.name == 'multiply_16':\n",
        "        set_trainable = True\n",
        "    if set_trainable:\n",
        "        layer.trainable = True\n",
        "    else:\n",
        "        layer.trainable = False  "
      ],
      "metadata": {
        "id": "2SmWJJlZ0K0g"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gqOZnbxjGmFY",
        "outputId": "c1d30814-0f1f-4a28-e3ae-32dd008ad63c"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " efficientnet-b0 (Functional  (None, 5, 5, 1280)       4049564   \n",
            " )                                                               \n",
            "                                                                 \n",
            " gap (GlobalMaxPooling2D)    (None, 1280)              0         \n",
            "                                                                 \n",
            " dropout_out (Dropout)       (None, 1280)              0         \n",
            "                                                                 \n",
            " fc_out (Dense)              (None, 19)                24339     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4,073,903\n",
            "Trainable params: 4,031,887\n",
            "Non-trainable params: 42,016\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=optimizers.RMSprop(learning_rate=2e-5),\n",
        "              metrics=['acc'])\n",
        "history = model.fit_generator(\n",
        "      train_generator,\n",
        "      steps_per_epoch= NUM_TRAIN //batch_size,\n",
        "      epochs=epochs,\n",
        "      validation_data=validation_generator,\n",
        "      validation_steps= NUM_TEST //batch_size,\n",
        "      verbose=1,\n",
        "      use_multiprocessing=True,\n",
        "      workers=4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C9Cf1dwyP1PD",
        "outputId": "fe0a7da6-eaf9-4b5f-c39d-aa61e6842a2e"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-16-95ae5648fc7b>:4: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  history = model.fit_generator(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/250\n",
            "89/89 [==============================] - 127s 937ms/step - loss: 23.9664 - acc: 0.0476 - val_loss: 5.5500 - val_acc: 0.1013\n",
            "Epoch 2/250\n",
            "89/89 [==============================] - 27s 299ms/step - loss: 12.7928 - acc: 0.0731 - val_loss: 9.3033 - val_acc: 0.0754\n",
            "Epoch 3/250\n",
            "89/89 [==============================] - 28s 307ms/step - loss: 6.6349 - acc: 0.1029 - val_loss: 8.9663 - val_acc: 0.0711\n",
            "Epoch 4/250\n",
            "89/89 [==============================] - 29s 318ms/step - loss: 4.4961 - acc: 0.1207 - val_loss: 8.4618 - val_acc: 0.0733\n",
            "Epoch 5/250\n",
            "89/89 [==============================] - 29s 321ms/step - loss: 4.0123 - acc: 0.1348 - val_loss: 7.9458 - val_acc: 0.0754\n",
            "Epoch 6/250\n",
            "89/89 [==============================] - 29s 324ms/step - loss: 3.7570 - acc: 0.1391 - val_loss: 7.4583 - val_acc: 0.0819\n",
            "Epoch 7/250\n",
            "89/89 [==============================] - 29s 324ms/step - loss: 3.5475 - acc: 0.1498 - val_loss: 6.0847 - val_acc: 0.1013\n",
            "Epoch 8/250\n",
            "89/89 [==============================] - 29s 319ms/step - loss: 3.4741 - acc: 0.1568 - val_loss: 4.5057 - val_acc: 0.1293\n",
            "Epoch 9/250\n",
            "89/89 [==============================] - 29s 318ms/step - loss: 3.3601 - acc: 0.1583 - val_loss: 4.0954 - val_acc: 0.1487\n",
            "Epoch 10/250\n",
            "89/89 [==============================] - 29s 318ms/step - loss: 3.2958 - acc: 0.1647 - val_loss: 3.8856 - val_acc: 0.1444\n",
            "Epoch 11/250\n",
            "89/89 [==============================] - 25s 270ms/step - loss: 3.1988 - acc: 0.1732 - val_loss: 3.9493 - val_acc: 0.1573\n",
            "Epoch 12/250\n",
            "89/89 [==============================] - 25s 275ms/step - loss: 3.0746 - acc: 0.1710 - val_loss: 4.0237 - val_acc: 0.1422\n",
            "Epoch 13/250\n",
            "89/89 [==============================] - 29s 323ms/step - loss: 2.9243 - acc: 0.1824 - val_loss: 4.0960 - val_acc: 0.1401\n",
            "Epoch 14/250\n",
            "89/89 [==============================] - 30s 325ms/step - loss: 2.9681 - acc: 0.1753 - val_loss: 3.9827 - val_acc: 0.1358\n",
            "Epoch 15/250\n",
            "89/89 [==============================] - 24s 264ms/step - loss: 2.8651 - acc: 0.1930 - val_loss: 3.8367 - val_acc: 0.1336\n",
            "Epoch 16/250\n",
            "89/89 [==============================] - 29s 321ms/step - loss: 2.8384 - acc: 0.1909 - val_loss: 3.8004 - val_acc: 0.1293\n",
            "Epoch 17/250\n",
            "89/89 [==============================] - 29s 320ms/step - loss: 2.7792 - acc: 0.1902 - val_loss: 3.7803 - val_acc: 0.1422\n",
            "Epoch 18/250\n",
            "89/89 [==============================] - 25s 267ms/step - loss: 2.7058 - acc: 0.2101 - val_loss: 3.7405 - val_acc: 0.1466\n",
            "Epoch 19/250\n",
            "89/89 [==============================] - 25s 271ms/step - loss: 2.6477 - acc: 0.2051 - val_loss: 3.7007 - val_acc: 0.1401\n",
            "Epoch 20/250\n",
            "89/89 [==============================] - 29s 317ms/step - loss: 2.5926 - acc: 0.1994 - val_loss: 3.7111 - val_acc: 0.1358\n",
            "Epoch 21/250\n",
            "89/89 [==============================] - 29s 320ms/step - loss: 2.5200 - acc: 0.2143 - val_loss: 3.6012 - val_acc: 0.1358\n",
            "Epoch 22/250\n",
            "89/89 [==============================] - 29s 319ms/step - loss: 2.5306 - acc: 0.2278 - val_loss: 3.4922 - val_acc: 0.1466\n",
            "Epoch 23/250\n",
            "89/89 [==============================] - 30s 325ms/step - loss: 2.4200 - acc: 0.2378 - val_loss: 3.4697 - val_acc: 0.1422\n",
            "Epoch 24/250\n",
            "89/89 [==============================] - 29s 320ms/step - loss: 2.3978 - acc: 0.2221 - val_loss: 3.4017 - val_acc: 0.1530\n",
            "Epoch 25/250\n",
            "89/89 [==============================] - 29s 317ms/step - loss: 2.3773 - acc: 0.2300 - val_loss: 3.4047 - val_acc: 0.1573\n",
            "Epoch 26/250\n",
            "89/89 [==============================] - 29s 313ms/step - loss: 2.3358 - acc: 0.2420 - val_loss: 3.3961 - val_acc: 0.1509\n",
            "Epoch 27/250\n",
            "89/89 [==============================] - 29s 305ms/step - loss: 2.3803 - acc: 0.2129 - val_loss: 3.2523 - val_acc: 0.1487\n",
            "Epoch 28/250\n",
            "89/89 [==============================] - 29s 308ms/step - loss: 2.3397 - acc: 0.2427 - val_loss: 3.2354 - val_acc: 0.1530\n",
            "Epoch 29/250\n",
            "89/89 [==============================] - 28s 296ms/step - loss: 2.2589 - acc: 0.2250 - val_loss: 3.2567 - val_acc: 0.1530\n",
            "Epoch 30/250\n",
            "89/89 [==============================] - 23s 244ms/step - loss: 2.2193 - acc: 0.2441 - val_loss: 3.2402 - val_acc: 0.1509\n",
            "Epoch 31/250\n",
            "89/89 [==============================] - 24s 261ms/step - loss: 2.2356 - acc: 0.2434 - val_loss: 3.2668 - val_acc: 0.1466\n",
            "Epoch 32/250\n",
            "89/89 [==============================] - 28s 298ms/step - loss: 2.2276 - acc: 0.2413 - val_loss: 3.1979 - val_acc: 0.1509\n",
            "Epoch 33/250\n",
            "89/89 [==============================] - 28s 308ms/step - loss: 2.2310 - acc: 0.2427 - val_loss: 3.1459 - val_acc: 0.1638\n",
            "Epoch 34/250\n",
            "89/89 [==============================] - 28s 309ms/step - loss: 2.1639 - acc: 0.2413 - val_loss: 3.0677 - val_acc: 0.1552\n",
            "Epoch 35/250\n",
            "89/89 [==============================] - 29s 322ms/step - loss: 2.1144 - acc: 0.2697 - val_loss: 3.0844 - val_acc: 0.1616\n",
            "Epoch 36/250\n",
            "89/89 [==============================] - 25s 273ms/step - loss: 2.1744 - acc: 0.2520 - val_loss: 3.0550 - val_acc: 0.1595\n",
            "Epoch 37/250\n",
            "89/89 [==============================] - 29s 323ms/step - loss: 2.0720 - acc: 0.2789 - val_loss: 3.0249 - val_acc: 0.1595\n",
            "Epoch 38/250\n",
            "89/89 [==============================] - 29s 321ms/step - loss: 2.0944 - acc: 0.2725 - val_loss: 3.0001 - val_acc: 0.1659\n",
            "Epoch 39/250\n",
            "89/89 [==============================] - 29s 323ms/step - loss: 2.0327 - acc: 0.2910 - val_loss: 2.9979 - val_acc: 0.1638\n",
            "Epoch 40/250\n",
            "89/89 [==============================] - 29s 323ms/step - loss: 2.0566 - acc: 0.2796 - val_loss: 2.9206 - val_acc: 0.1638\n",
            "Epoch 41/250\n",
            "89/89 [==============================] - 29s 317ms/step - loss: 2.0856 - acc: 0.2718 - val_loss: 2.8848 - val_acc: 0.1616\n",
            "Epoch 42/250\n",
            "89/89 [==============================] - 24s 262ms/step - loss: 2.0357 - acc: 0.2846 - val_loss: 2.8969 - val_acc: 0.1832\n",
            "Epoch 43/250\n",
            "89/89 [==============================] - 29s 313ms/step - loss: 2.0280 - acc: 0.2860 - val_loss: 2.9515 - val_acc: 0.1746\n",
            "Epoch 44/250\n",
            "89/89 [==============================] - 29s 310ms/step - loss: 1.9902 - acc: 0.3031 - val_loss: 2.9415 - val_acc: 0.1659\n",
            "Epoch 45/250\n",
            "89/89 [==============================] - 27s 296ms/step - loss: 1.9902 - acc: 0.3059 - val_loss: 2.9694 - val_acc: 0.1681\n",
            "Epoch 46/250\n",
            "89/89 [==============================] - 27s 294ms/step - loss: 1.9737 - acc: 0.2988 - val_loss: 3.0267 - val_acc: 0.1573\n",
            "Epoch 47/250\n",
            "89/89 [==============================] - 28s 310ms/step - loss: 1.9708 - acc: 0.3201 - val_loss: 2.9655 - val_acc: 0.1659\n",
            "Epoch 48/250\n",
            "89/89 [==============================] - 29s 323ms/step - loss: 1.8832 - acc: 0.3293 - val_loss: 3.0899 - val_acc: 0.1616\n",
            "Epoch 49/250\n",
            "89/89 [==============================] - 24s 262ms/step - loss: 1.9557 - acc: 0.3016 - val_loss: 3.0739 - val_acc: 0.1724\n",
            "Epoch 50/250\n",
            "89/89 [==============================] - 27s 297ms/step - loss: 1.9176 - acc: 0.3059 - val_loss: 3.1350 - val_acc: 0.1530\n",
            "Epoch 51/250\n",
            "89/89 [==============================] - 23s 247ms/step - loss: 1.8979 - acc: 0.3222 - val_loss: 3.0910 - val_acc: 0.1595\n",
            "Epoch 52/250\n",
            "89/89 [==============================] - 29s 309ms/step - loss: 1.8899 - acc: 0.3002 - val_loss: 3.0521 - val_acc: 0.1681\n",
            "Epoch 53/250\n",
            "89/89 [==============================] - 30s 321ms/step - loss: 1.9052 - acc: 0.3201 - val_loss: 3.0903 - val_acc: 0.1638\n",
            "Epoch 54/250\n",
            "89/89 [==============================] - 28s 302ms/step - loss: 1.8570 - acc: 0.3414 - val_loss: 3.0839 - val_acc: 0.1595\n",
            "Epoch 55/250\n",
            "89/89 [==============================] - 23s 246ms/step - loss: 1.8392 - acc: 0.3471 - val_loss: 3.0495 - val_acc: 0.1509\n",
            "Epoch 56/250\n",
            "89/89 [==============================] - 28s 304ms/step - loss: 1.8817 - acc: 0.3258 - val_loss: 3.0590 - val_acc: 0.1616\n",
            "Epoch 57/250\n",
            "89/89 [==============================] - 30s 323ms/step - loss: 1.8321 - acc: 0.3549 - val_loss: 3.0896 - val_acc: 0.1573\n",
            "Epoch 58/250\n",
            "89/89 [==============================] - 30s 324ms/step - loss: 1.8196 - acc: 0.3513 - val_loss: 3.0271 - val_acc: 0.1552\n",
            "Epoch 59/250\n",
            "89/89 [==============================] - 30s 324ms/step - loss: 1.8165 - acc: 0.3462 - val_loss: 2.9902 - val_acc: 0.1638\n",
            "Epoch 60/250\n",
            "89/89 [==============================] - 29s 323ms/step - loss: 1.8494 - acc: 0.3406 - val_loss: 3.1487 - val_acc: 0.1638\n",
            "Epoch 61/250\n",
            "89/89 [==============================] - 30s 329ms/step - loss: 1.8133 - acc: 0.3485 - val_loss: 3.0728 - val_acc: 0.1681\n",
            "Epoch 62/250\n",
            "89/89 [==============================] - 30s 324ms/step - loss: 1.7995 - acc: 0.3520 - val_loss: 3.0548 - val_acc: 0.1552\n",
            "Epoch 63/250\n",
            "89/89 [==============================] - 29s 320ms/step - loss: 1.7573 - acc: 0.3818 - val_loss: 3.1385 - val_acc: 0.1595\n",
            "Epoch 64/250\n",
            "89/89 [==============================] - 29s 323ms/step - loss: 1.7226 - acc: 0.3974 - val_loss: 3.0616 - val_acc: 0.1767\n",
            "Epoch 65/250\n",
            "89/89 [==============================] - 30s 327ms/step - loss: 1.7417 - acc: 0.3588 - val_loss: 2.9865 - val_acc: 0.1746\n",
            "Epoch 66/250\n",
            "89/89 [==============================] - 23s 247ms/step - loss: 1.7424 - acc: 0.3868 - val_loss: 2.9886 - val_acc: 0.1703\n",
            "Epoch 67/250\n",
            "89/89 [==============================] - 28s 309ms/step - loss: 1.7612 - acc: 0.3584 - val_loss: 3.1487 - val_acc: 0.1703\n",
            "Epoch 68/250\n",
            "89/89 [==============================] - 28s 301ms/step - loss: 1.7220 - acc: 0.3818 - val_loss: 3.2026 - val_acc: 0.1595\n",
            "Epoch 69/250\n",
            "89/89 [==============================] - 24s 264ms/step - loss: 1.6937 - acc: 0.3854 - val_loss: 3.1902 - val_acc: 0.1638\n",
            "Epoch 70/250\n",
            "89/89 [==============================] - 30s 326ms/step - loss: 1.7338 - acc: 0.3811 - val_loss: 3.0097 - val_acc: 0.1746\n",
            "Epoch 71/250\n",
            "89/89 [==============================] - 25s 271ms/step - loss: 1.7349 - acc: 0.3797 - val_loss: 2.9913 - val_acc: 0.1703\n",
            "Epoch 72/250\n",
            "89/89 [==============================] - 30s 328ms/step - loss: 1.7147 - acc: 0.3818 - val_loss: 2.9783 - val_acc: 0.1724\n",
            "Epoch 73/250\n",
            "89/89 [==============================] - 29s 322ms/step - loss: 1.6414 - acc: 0.4180 - val_loss: 2.8845 - val_acc: 0.1789\n",
            "Epoch 74/250\n",
            "89/89 [==============================] - 30s 323ms/step - loss: 1.7066 - acc: 0.3896 - val_loss: 2.9801 - val_acc: 0.1724\n",
            "Epoch 75/250\n",
            "89/89 [==============================] - 29s 322ms/step - loss: 1.6397 - acc: 0.3925 - val_loss: 3.0073 - val_acc: 0.1832\n",
            "Epoch 76/250\n",
            "89/89 [==============================] - 30s 326ms/step - loss: 1.6188 - acc: 0.4209 - val_loss: 3.0113 - val_acc: 0.1746\n",
            "Epoch 77/250\n",
            "89/89 [==============================] - 30s 326ms/step - loss: 1.5897 - acc: 0.4351 - val_loss: 2.9914 - val_acc: 0.1789\n",
            "Epoch 78/250\n",
            "89/89 [==============================] - 30s 326ms/step - loss: 1.6179 - acc: 0.4223 - val_loss: 3.0422 - val_acc: 0.1832\n",
            "Epoch 79/250\n",
            "89/89 [==============================] - 29s 321ms/step - loss: 1.6085 - acc: 0.4301 - val_loss: 3.0968 - val_acc: 0.1767\n",
            "Epoch 80/250\n",
            "89/89 [==============================] - 30s 325ms/step - loss: 1.6206 - acc: 0.4145 - val_loss: 3.1161 - val_acc: 0.1832\n",
            "Epoch 81/250\n",
            "89/89 [==============================] - 25s 271ms/step - loss: 1.5602 - acc: 0.4315 - val_loss: 3.1832 - val_acc: 0.1810\n",
            "Epoch 82/250\n",
            "89/89 [==============================] - 28s 310ms/step - loss: 1.5708 - acc: 0.4429 - val_loss: 3.1226 - val_acc: 0.1832\n",
            "Epoch 83/250\n",
            "89/89 [==============================] - 29s 318ms/step - loss: 1.5976 - acc: 0.4202 - val_loss: 3.1066 - val_acc: 0.1746\n",
            "Epoch 84/250\n",
            "89/89 [==============================] - 30s 331ms/step - loss: 1.5506 - acc: 0.4315 - val_loss: 3.0383 - val_acc: 0.1767\n",
            "Epoch 85/250\n",
            "89/89 [==============================] - 29s 321ms/step - loss: 1.5574 - acc: 0.4372 - val_loss: 3.1101 - val_acc: 0.1789\n",
            "Epoch 86/250\n",
            "89/89 [==============================] - 29s 321ms/step - loss: 1.5607 - acc: 0.4414 - val_loss: 3.1908 - val_acc: 0.1789\n",
            "Epoch 87/250\n",
            "89/89 [==============================] - 25s 270ms/step - loss: 1.5595 - acc: 0.4521 - val_loss: 3.1799 - val_acc: 0.1767\n",
            "Epoch 88/250\n",
            "89/89 [==============================] - 27s 300ms/step - loss: 1.5400 - acc: 0.4414 - val_loss: 3.1428 - val_acc: 0.1810\n",
            "Epoch 89/250\n",
            "89/89 [==============================] - 29s 313ms/step - loss: 1.5002 - acc: 0.4613 - val_loss: 2.9998 - val_acc: 0.1897\n",
            "Epoch 90/250\n",
            "89/89 [==============================] - 29s 314ms/step - loss: 1.5117 - acc: 0.4464 - val_loss: 3.0952 - val_acc: 0.1789\n",
            "Epoch 91/250\n",
            "89/89 [==============================] - 30s 325ms/step - loss: 1.5115 - acc: 0.4762 - val_loss: 3.1197 - val_acc: 0.1897\n",
            "Epoch 92/250\n",
            "89/89 [==============================] - 29s 323ms/step - loss: 1.4968 - acc: 0.4634 - val_loss: 3.0631 - val_acc: 0.1875\n",
            "Epoch 93/250\n",
            "89/89 [==============================] - 29s 323ms/step - loss: 1.4551 - acc: 0.4791 - val_loss: 3.1613 - val_acc: 0.1810\n",
            "Epoch 94/250\n",
            "89/89 [==============================] - 25s 268ms/step - loss: 1.4710 - acc: 0.4762 - val_loss: 3.1282 - val_acc: 0.1810\n",
            "Epoch 95/250\n",
            "89/89 [==============================] - 25s 268ms/step - loss: 1.4607 - acc: 0.4791 - val_loss: 3.1878 - val_acc: 0.1789\n",
            "Epoch 96/250\n",
            "89/89 [==============================] - 28s 303ms/step - loss: 1.4852 - acc: 0.4585 - val_loss: 3.1494 - val_acc: 0.1681\n",
            "Epoch 97/250\n",
            "89/89 [==============================] - 28s 306ms/step - loss: 1.4802 - acc: 0.4507 - val_loss: 3.1971 - val_acc: 0.1746\n",
            "Epoch 98/250\n",
            "89/89 [==============================] - 29s 313ms/step - loss: 1.4623 - acc: 0.4805 - val_loss: 3.1959 - val_acc: 0.1724\n",
            "Epoch 99/250\n",
            "89/89 [==============================] - 30s 331ms/step - loss: 1.4194 - acc: 0.5039 - val_loss: 3.1441 - val_acc: 0.1853\n",
            "Epoch 100/250\n",
            "89/89 [==============================] - 30s 326ms/step - loss: 1.4299 - acc: 0.4925 - val_loss: 3.1762 - val_acc: 0.1789\n",
            "Epoch 101/250\n",
            "89/89 [==============================] - 30s 324ms/step - loss: 1.4114 - acc: 0.4968 - val_loss: 3.1994 - val_acc: 0.1832\n",
            "Epoch 102/250\n",
            "89/89 [==============================] - 30s 329ms/step - loss: 1.3957 - acc: 0.4996 - val_loss: 3.2750 - val_acc: 0.1832\n",
            "Epoch 103/250\n",
            "89/89 [==============================] - 30s 326ms/step - loss: 1.4063 - acc: 0.5004 - val_loss: 3.1854 - val_acc: 0.1940\n",
            "Epoch 104/250\n",
            "89/89 [==============================] - 29s 322ms/step - loss: 1.4261 - acc: 0.4940 - val_loss: 3.1883 - val_acc: 0.1681\n",
            "Epoch 105/250\n",
            "89/89 [==============================] - 29s 320ms/step - loss: 1.3477 - acc: 0.5330 - val_loss: 3.2807 - val_acc: 0.1746\n",
            "Epoch 106/250\n",
            "89/89 [==============================] - 30s 321ms/step - loss: 1.3665 - acc: 0.5202 - val_loss: 3.3495 - val_acc: 0.1832\n",
            "Epoch 107/250\n",
            "89/89 [==============================] - 24s 248ms/step - loss: 1.3789 - acc: 0.5160 - val_loss: 3.3482 - val_acc: 0.1853\n",
            "Epoch 108/250\n",
            "89/89 [==============================] - 24s 266ms/step - loss: 1.3296 - acc: 0.5096 - val_loss: 3.2437 - val_acc: 0.1940\n",
            "Epoch 109/250\n",
            "89/89 [==============================] - 29s 318ms/step - loss: 1.3187 - acc: 0.5302 - val_loss: 3.2469 - val_acc: 0.1853\n",
            "Epoch 110/250\n",
            "89/89 [==============================] - 24s 266ms/step - loss: 1.2931 - acc: 0.5373 - val_loss: 3.2766 - val_acc: 0.1918\n",
            "Epoch 111/250\n",
            "89/89 [==============================] - 29s 321ms/step - loss: 1.3248 - acc: 0.5273 - val_loss: 3.2527 - val_acc: 0.2047\n",
            "Epoch 112/250\n",
            "89/89 [==============================] - 29s 321ms/step - loss: 1.2845 - acc: 0.5287 - val_loss: 3.2927 - val_acc: 0.2026\n",
            "Epoch 113/250\n",
            "89/89 [==============================] - 30s 326ms/step - loss: 1.2482 - acc: 0.5635 - val_loss: 3.3451 - val_acc: 0.1961\n",
            "Epoch 114/250\n",
            "89/89 [==============================] - 29s 313ms/step - loss: 1.2801 - acc: 0.5394 - val_loss: 3.3093 - val_acc: 0.2047\n",
            "Epoch 115/250\n",
            "89/89 [==============================] - 29s 319ms/step - loss: 1.2425 - acc: 0.5593 - val_loss: 3.3972 - val_acc: 0.1897\n",
            "Epoch 116/250\n",
            "89/89 [==============================] - 29s 320ms/step - loss: 1.2877 - acc: 0.5373 - val_loss: 3.3266 - val_acc: 0.1961\n",
            "Epoch 117/250\n",
            "89/89 [==============================] - 30s 321ms/step - loss: 1.2505 - acc: 0.5351 - val_loss: 3.3869 - val_acc: 0.1961\n",
            "Epoch 118/250\n",
            "89/89 [==============================] - 29s 304ms/step - loss: 1.2184 - acc: 0.5756 - val_loss: 3.4400 - val_acc: 0.2112\n",
            "Epoch 119/250\n",
            "89/89 [==============================] - 23s 254ms/step - loss: 1.2293 - acc: 0.5685 - val_loss: 3.4469 - val_acc: 0.2069\n",
            "Epoch 120/250\n",
            "89/89 [==============================] - 25s 270ms/step - loss: 1.1951 - acc: 0.5671 - val_loss: 3.4072 - val_acc: 0.2069\n",
            "Epoch 121/250\n",
            "89/89 [==============================] - 29s 322ms/step - loss: 1.1926 - acc: 0.5600 - val_loss: 3.4991 - val_acc: 0.2069\n",
            "Epoch 122/250\n",
            "89/89 [==============================] - 29s 322ms/step - loss: 1.1659 - acc: 0.6167 - val_loss: 3.4175 - val_acc: 0.2091\n",
            "Epoch 123/250\n",
            "89/89 [==============================] - 29s 322ms/step - loss: 1.1928 - acc: 0.5685 - val_loss: 3.3876 - val_acc: 0.2091\n",
            "Epoch 124/250\n",
            "89/89 [==============================] - 29s 314ms/step - loss: 1.1393 - acc: 0.5955 - val_loss: 3.5297 - val_acc: 0.1940\n",
            "Epoch 125/250\n",
            "89/89 [==============================] - 29s 322ms/step - loss: 1.1849 - acc: 0.5820 - val_loss: 3.4528 - val_acc: 0.1961\n",
            "Epoch 126/250\n",
            "89/89 [==============================] - 29s 321ms/step - loss: 1.1641 - acc: 0.5919 - val_loss: 3.3852 - val_acc: 0.2091\n",
            "Epoch 127/250\n",
            "89/89 [==============================] - 29s 314ms/step - loss: 1.1801 - acc: 0.5834 - val_loss: 3.4574 - val_acc: 0.1940\n",
            "Epoch 128/250\n",
            "89/89 [==============================] - 29s 313ms/step - loss: 1.2217 - acc: 0.5720 - val_loss: 3.4043 - val_acc: 0.1940\n",
            "Epoch 129/250\n",
            "89/89 [==============================] - 24s 261ms/step - loss: 1.1343 - acc: 0.6061 - val_loss: 3.4528 - val_acc: 0.1897\n",
            "Epoch 130/250\n",
            "89/89 [==============================] - 30s 321ms/step - loss: 1.1405 - acc: 0.5862 - val_loss: 3.4893 - val_acc: 0.2004\n",
            "Epoch 131/250\n",
            "89/89 [==============================] - 29s 311ms/step - loss: 1.1132 - acc: 0.5912 - val_loss: 3.4805 - val_acc: 0.2047\n",
            "Epoch 132/250\n",
            "89/89 [==============================] - 28s 303ms/step - loss: 1.1413 - acc: 0.5813 - val_loss: 3.5929 - val_acc: 0.2069\n",
            "Epoch 133/250\n",
            "89/89 [==============================] - 28s 311ms/step - loss: 1.1262 - acc: 0.6082 - val_loss: 3.6270 - val_acc: 0.1961\n",
            "Epoch 134/250\n",
            "89/89 [==============================] - 30s 324ms/step - loss: 1.1291 - acc: 0.5940 - val_loss: 3.7165 - val_acc: 0.1810\n",
            "Epoch 135/250\n",
            "89/89 [==============================] - 30s 323ms/step - loss: 1.0727 - acc: 0.6210 - val_loss: 3.8269 - val_acc: 0.1853\n",
            "Epoch 136/250\n",
            "89/89 [==============================] - 26s 279ms/step - loss: 1.0805 - acc: 0.6260 - val_loss: 3.6365 - val_acc: 0.2004\n",
            "Epoch 137/250\n",
            "89/89 [==============================] - 23s 248ms/step - loss: 1.0574 - acc: 0.6238 - val_loss: 3.6422 - val_acc: 0.1983\n",
            "Epoch 138/250\n",
            "89/89 [==============================] - 25s 270ms/step - loss: 1.0557 - acc: 0.6167 - val_loss: 3.6358 - val_acc: 0.1961\n",
            "Epoch 139/250\n",
            "89/89 [==============================] - 28s 301ms/step - loss: 1.0234 - acc: 0.6473 - val_loss: 3.7222 - val_acc: 0.1897\n",
            "Epoch 140/250\n",
            "89/89 [==============================] - 28s 305ms/step - loss: 1.0572 - acc: 0.6210 - val_loss: 3.7794 - val_acc: 0.1918\n",
            "Epoch 141/250\n",
            "89/89 [==============================] - 29s 323ms/step - loss: 1.0661 - acc: 0.6210 - val_loss: 3.6597 - val_acc: 0.1918\n",
            "Epoch 142/250\n",
            "89/89 [==============================] - 25s 268ms/step - loss: 1.0033 - acc: 0.6515 - val_loss: 3.6141 - val_acc: 0.1853\n",
            "Epoch 143/250\n",
            "89/89 [==============================] - 30s 330ms/step - loss: 1.0468 - acc: 0.6260 - val_loss: 3.5600 - val_acc: 0.1897\n",
            "Epoch 144/250\n",
            "89/89 [==============================] - 30s 332ms/step - loss: 1.0069 - acc: 0.6537 - val_loss: 3.7083 - val_acc: 0.1832\n",
            "Epoch 145/250\n",
            "89/89 [==============================] - 30s 325ms/step - loss: 0.9567 - acc: 0.6735 - val_loss: 3.8372 - val_acc: 0.1875\n",
            "Epoch 146/250\n",
            "89/89 [==============================] - 30s 323ms/step - loss: 1.0234 - acc: 0.6551 - val_loss: 3.8868 - val_acc: 0.1767\n",
            "Epoch 147/250\n",
            "89/89 [==============================] - 24s 266ms/step - loss: 0.9958 - acc: 0.6444 - val_loss: 3.8748 - val_acc: 0.1789\n",
            "Epoch 148/250\n",
            "89/89 [==============================] - 30s 330ms/step - loss: 0.9685 - acc: 0.6728 - val_loss: 3.8791 - val_acc: 0.1853\n",
            "Epoch 149/250\n",
            "89/89 [==============================] - 29s 318ms/step - loss: 0.9267 - acc: 0.6735 - val_loss: 3.8229 - val_acc: 0.1940\n",
            "Epoch 150/250\n",
            "89/89 [==============================] - 29s 319ms/step - loss: 0.9504 - acc: 0.6522 - val_loss: 3.8944 - val_acc: 0.1875\n",
            "Epoch 151/250\n",
            "89/89 [==============================] - 29s 316ms/step - loss: 0.9401 - acc: 0.6650 - val_loss: 3.7739 - val_acc: 0.1961\n",
            "Epoch 152/250\n",
            "89/89 [==============================] - 29s 321ms/step - loss: 0.9184 - acc: 0.6650 - val_loss: 3.7947 - val_acc: 0.1983\n",
            "Epoch 153/250\n",
            "89/89 [==============================] - 25s 273ms/step - loss: 0.9728 - acc: 0.6572 - val_loss: 3.8959 - val_acc: 0.1918\n",
            "Epoch 154/250\n",
            "89/89 [==============================] - 29s 322ms/step - loss: 0.9327 - acc: 0.6749 - val_loss: 3.9035 - val_acc: 0.1918\n",
            "Epoch 155/250\n",
            "89/89 [==============================] - 29s 317ms/step - loss: 0.9391 - acc: 0.6650 - val_loss: 3.9252 - val_acc: 0.1897\n",
            "Epoch 156/250\n",
            "89/89 [==============================] - 29s 317ms/step - loss: 0.9022 - acc: 0.6714 - val_loss: 3.9141 - val_acc: 0.1810\n",
            "Epoch 157/250\n",
            "89/89 [==============================] - 30s 322ms/step - loss: 0.8760 - acc: 0.7005 - val_loss: 3.9386 - val_acc: 0.1853\n",
            "Epoch 158/250\n",
            "89/89 [==============================] - 24s 256ms/step - loss: 0.8517 - acc: 0.7090 - val_loss: 4.0845 - val_acc: 0.1746\n",
            "Epoch 159/250\n",
            "89/89 [==============================] - 28s 300ms/step - loss: 0.8753 - acc: 0.6906 - val_loss: 4.0547 - val_acc: 0.1832\n",
            "Epoch 160/250\n",
            "89/89 [==============================] - 23s 252ms/step - loss: 0.8983 - acc: 0.6785 - val_loss: 4.0231 - val_acc: 0.1853\n",
            "Epoch 161/250\n",
            "89/89 [==============================] - 24s 258ms/step - loss: 0.8493 - acc: 0.7048 - val_loss: 4.0550 - val_acc: 0.1789\n",
            "Epoch 162/250\n",
            "89/89 [==============================] - 29s 324ms/step - loss: 0.8321 - acc: 0.7083 - val_loss: 4.0705 - val_acc: 0.1767\n",
            "Epoch 163/250\n",
            "89/89 [==============================] - 30s 332ms/step - loss: 0.8564 - acc: 0.6828 - val_loss: 4.0118 - val_acc: 0.1961\n",
            "Epoch 164/250\n",
            "89/89 [==============================] - 29s 320ms/step - loss: 0.8550 - acc: 0.7026 - val_loss: 4.0530 - val_acc: 0.1789\n",
            "Epoch 165/250\n",
            "89/89 [==============================] - 29s 322ms/step - loss: 0.8215 - acc: 0.7097 - val_loss: 4.1960 - val_acc: 0.1918\n",
            "Epoch 166/250\n",
            "89/89 [==============================] - 30s 327ms/step - loss: 0.7949 - acc: 0.7204 - val_loss: 4.2437 - val_acc: 0.1853\n",
            "Epoch 167/250\n",
            "89/89 [==============================] - 30s 329ms/step - loss: 0.8086 - acc: 0.7459 - val_loss: 4.3019 - val_acc: 0.1767\n",
            "Epoch 168/250\n",
            "89/89 [==============================] - 30s 325ms/step - loss: 0.8074 - acc: 0.7076 - val_loss: 4.2797 - val_acc: 0.1767\n",
            "Epoch 169/250\n",
            "89/89 [==============================] - 26s 279ms/step - loss: 0.8436 - acc: 0.7062 - val_loss: 4.3012 - val_acc: 0.1853\n",
            "Epoch 170/250\n",
            "89/89 [==============================] - 29s 321ms/step - loss: 0.7434 - acc: 0.7424 - val_loss: 4.2318 - val_acc: 0.1810\n",
            "Epoch 171/250\n",
            "89/89 [==============================] - 30s 324ms/step - loss: 0.8130 - acc: 0.7197 - val_loss: 4.1964 - val_acc: 0.1897\n",
            "Epoch 172/250\n",
            "89/89 [==============================] - 26s 282ms/step - loss: 0.8058 - acc: 0.7168 - val_loss: 4.1901 - val_acc: 0.1875\n",
            "Epoch 173/250\n",
            "89/89 [==============================] - 29s 316ms/step - loss: 0.7981 - acc: 0.7303 - val_loss: 4.2886 - val_acc: 0.1746\n",
            "Epoch 174/250\n",
            "89/89 [==============================] - 30s 325ms/step - loss: 0.7870 - acc: 0.7140 - val_loss: 4.4143 - val_acc: 0.1767\n",
            "Epoch 175/250\n",
            "89/89 [==============================] - 30s 324ms/step - loss: 0.7368 - acc: 0.7530 - val_loss: 4.3510 - val_acc: 0.1853\n",
            "Epoch 176/250\n",
            "89/89 [==============================] - 30s 327ms/step - loss: 0.7029 - acc: 0.7608 - val_loss: 4.3902 - val_acc: 0.1875\n",
            "Epoch 177/250\n",
            "89/89 [==============================] - 29s 322ms/step - loss: 0.7425 - acc: 0.7424 - val_loss: 4.5875 - val_acc: 0.1724\n",
            "Epoch 178/250\n",
            "89/89 [==============================] - 29s 321ms/step - loss: 0.7223 - acc: 0.7488 - val_loss: 4.6405 - val_acc: 0.1832\n",
            "Epoch 179/250\n",
            "89/89 [==============================] - 29s 322ms/step - loss: 0.7129 - acc: 0.7516 - val_loss: 4.5387 - val_acc: 0.1810\n",
            "Epoch 180/250\n",
            "89/89 [==============================] - 29s 318ms/step - loss: 0.7133 - acc: 0.7523 - val_loss: 4.5366 - val_acc: 0.1940\n",
            "Epoch 181/250\n",
            "89/89 [==============================] - 29s 313ms/step - loss: 0.7240 - acc: 0.7445 - val_loss: 4.4470 - val_acc: 0.1832\n",
            "Epoch 182/250\n",
            "89/89 [==============================] - 29s 313ms/step - loss: 0.7667 - acc: 0.7275 - val_loss: 4.3912 - val_acc: 0.1832\n",
            "Epoch 183/250\n",
            "89/89 [==============================] - 30s 320ms/step - loss: 0.6934 - acc: 0.7480 - val_loss: 4.2570 - val_acc: 0.1832\n",
            "Epoch 184/250\n",
            "89/89 [==============================] - 29s 312ms/step - loss: 0.6771 - acc: 0.7630 - val_loss: 4.4010 - val_acc: 0.1746\n",
            "Epoch 185/250\n",
            "89/89 [==============================] - 29s 304ms/step - loss: 0.6766 - acc: 0.7615 - val_loss: 4.4219 - val_acc: 0.1746\n",
            "Epoch 186/250\n",
            "89/89 [==============================] - 27s 298ms/step - loss: 0.6694 - acc: 0.7757 - val_loss: 4.5202 - val_acc: 0.1767\n",
            "Epoch 187/250\n",
            "89/89 [==============================] - 28s 303ms/step - loss: 0.6730 - acc: 0.7644 - val_loss: 4.5517 - val_acc: 0.1810\n",
            "Epoch 188/250\n",
            "89/89 [==============================] - 29s 315ms/step - loss: 0.6262 - acc: 0.7793 - val_loss: 4.4894 - val_acc: 0.1875\n",
            "Epoch 189/250\n",
            "89/89 [==============================] - 30s 324ms/step - loss: 0.6453 - acc: 0.7892 - val_loss: 4.6048 - val_acc: 0.1897\n",
            "Epoch 190/250\n",
            "89/89 [==============================] - 29s 320ms/step - loss: 0.6452 - acc: 0.7786 - val_loss: 4.7250 - val_acc: 0.1897\n",
            "Epoch 191/250\n",
            "89/89 [==============================] - 29s 324ms/step - loss: 0.6538 - acc: 0.7679 - val_loss: 4.7256 - val_acc: 0.1832\n",
            "Epoch 192/250\n",
            "89/89 [==============================] - 25s 270ms/step - loss: 0.6555 - acc: 0.7658 - val_loss: 4.6948 - val_acc: 0.1724\n",
            "Epoch 193/250\n",
            "89/89 [==============================] - 28s 302ms/step - loss: 0.6122 - acc: 0.7842 - val_loss: 4.6012 - val_acc: 0.1789\n",
            "Epoch 194/250\n",
            "89/89 [==============================] - 28s 309ms/step - loss: 0.6240 - acc: 0.7878 - val_loss: 4.7302 - val_acc: 0.1659\n",
            "Epoch 195/250\n",
            "89/89 [==============================] - 31s 336ms/step - loss: 0.6233 - acc: 0.7857 - val_loss: 4.8088 - val_acc: 0.1767\n",
            "Epoch 196/250\n",
            "89/89 [==============================] - 28s 311ms/step - loss: 0.6474 - acc: 0.7686 - val_loss: 4.8900 - val_acc: 0.1724\n",
            "Epoch 197/250\n",
            "89/89 [==============================] - 29s 312ms/step - loss: 0.5922 - acc: 0.7864 - val_loss: 5.0102 - val_acc: 0.1767\n",
            "Epoch 198/250\n",
            "89/89 [==============================] - 29s 319ms/step - loss: 0.6319 - acc: 0.7800 - val_loss: 4.9740 - val_acc: 0.1724\n",
            "Epoch 199/250\n",
            "89/89 [==============================] - 25s 270ms/step - loss: 0.5970 - acc: 0.7977 - val_loss: 4.9337 - val_acc: 0.1918\n",
            "Epoch 200/250\n",
            "89/89 [==============================] - 28s 303ms/step - loss: 0.5769 - acc: 0.7956 - val_loss: 4.8527 - val_acc: 0.1810\n",
            "Epoch 201/250\n",
            "89/89 [==============================] - 27s 299ms/step - loss: 0.5872 - acc: 0.8119 - val_loss: 4.8254 - val_acc: 0.1767\n",
            "Epoch 202/250\n",
            "89/89 [==============================] - 28s 308ms/step - loss: 0.5624 - acc: 0.8034 - val_loss: 4.8063 - val_acc: 0.1789\n",
            "Epoch 203/250\n",
            "89/89 [==============================] - 30s 325ms/step - loss: 0.6157 - acc: 0.7722 - val_loss: 4.8570 - val_acc: 0.1832\n",
            "Epoch 204/250\n",
            "89/89 [==============================] - 29s 328ms/step - loss: 0.5274 - acc: 0.8183 - val_loss: 4.8871 - val_acc: 0.1832\n",
            "Epoch 205/250\n",
            "89/89 [==============================] - 30s 325ms/step - loss: 0.5255 - acc: 0.8233 - val_loss: 4.9482 - val_acc: 0.1789\n",
            "Epoch 206/250\n",
            "89/89 [==============================] - 30s 323ms/step - loss: 0.5421 - acc: 0.8133 - val_loss: 4.9346 - val_acc: 0.1832\n",
            "Epoch 207/250\n",
            "89/89 [==============================] - 30s 323ms/step - loss: 0.5490 - acc: 0.8062 - val_loss: 4.8136 - val_acc: 0.1789\n",
            "Epoch 208/250\n",
            "89/89 [==============================] - 30s 323ms/step - loss: 0.5359 - acc: 0.8197 - val_loss: 4.8479 - val_acc: 0.1875\n",
            "Epoch 209/250\n",
            "89/89 [==============================] - 29s 323ms/step - loss: 0.5008 - acc: 0.8318 - val_loss: 4.9651 - val_acc: 0.1810\n",
            "Epoch 210/250\n",
            "89/89 [==============================] - 29s 317ms/step - loss: 0.5268 - acc: 0.8275 - val_loss: 4.8400 - val_acc: 0.1897\n",
            "Epoch 211/250\n",
            "89/89 [==============================] - 30s 324ms/step - loss: 0.5380 - acc: 0.8070 - val_loss: 5.0199 - val_acc: 0.1832\n",
            "Epoch 212/250\n",
            "89/89 [==============================] - 30s 325ms/step - loss: 0.5548 - acc: 0.8041 - val_loss: 4.8776 - val_acc: 0.1853\n",
            "Epoch 213/250\n",
            "89/89 [==============================] - 30s 329ms/step - loss: 0.5291 - acc: 0.8183 - val_loss: 4.8335 - val_acc: 0.1832\n",
            "Epoch 214/250\n",
            "89/89 [==============================] - 30s 326ms/step - loss: 0.5011 - acc: 0.8247 - val_loss: 4.9813 - val_acc: 0.1724\n",
            "Epoch 215/250\n",
            "89/89 [==============================] - 30s 324ms/step - loss: 0.5084 - acc: 0.8290 - val_loss: 4.7807 - val_acc: 0.1853\n",
            "Epoch 216/250\n",
            "89/89 [==============================] - 29s 312ms/step - loss: 0.4772 - acc: 0.8254 - val_loss: 4.9143 - val_acc: 0.1767\n",
            "Epoch 217/250\n",
            "89/89 [==============================] - 26s 277ms/step - loss: 0.4648 - acc: 0.8382 - val_loss: 4.8975 - val_acc: 0.1767\n",
            "Epoch 218/250\n",
            "89/89 [==============================] - 28s 296ms/step - loss: 0.5110 - acc: 0.8275 - val_loss: 5.0415 - val_acc: 0.1832\n",
            "Epoch 219/250\n",
            "89/89 [==============================] - 23s 248ms/step - loss: 0.4961 - acc: 0.8275 - val_loss: 4.9987 - val_acc: 0.1810\n",
            "Epoch 220/250\n",
            "89/89 [==============================] - 28s 310ms/step - loss: 0.5123 - acc: 0.8211 - val_loss: 5.0012 - val_acc: 0.1832\n",
            "Epoch 221/250\n",
            "89/89 [==============================] - 29s 318ms/step - loss: 0.4931 - acc: 0.8311 - val_loss: 5.0856 - val_acc: 0.1703\n",
            "Epoch 222/250\n",
            "89/89 [==============================] - 30s 327ms/step - loss: 0.4787 - acc: 0.8353 - val_loss: 5.0236 - val_acc: 0.1810\n",
            "Epoch 223/250\n",
            "89/89 [==============================] - 30s 332ms/step - loss: 0.4200 - acc: 0.8588 - val_loss: 5.2531 - val_acc: 0.1746\n",
            "Epoch 224/250\n",
            "89/89 [==============================] - 30s 327ms/step - loss: 0.4502 - acc: 0.8410 - val_loss: 5.0743 - val_acc: 0.1724\n",
            "Epoch 225/250\n",
            "89/89 [==============================] - 30s 327ms/step - loss: 0.4489 - acc: 0.8297 - val_loss: 5.2243 - val_acc: 0.1789\n",
            "Epoch 226/250\n",
            "89/89 [==============================] - 30s 328ms/step - loss: 0.4290 - acc: 0.8524 - val_loss: 5.3347 - val_acc: 0.1746\n",
            "Epoch 227/250\n",
            "89/89 [==============================] - 25s 274ms/step - loss: 0.4566 - acc: 0.8467 - val_loss: 5.2561 - val_acc: 0.1746\n",
            "Epoch 228/250\n",
            "89/89 [==============================] - 30s 324ms/step - loss: 0.4821 - acc: 0.8375 - val_loss: 5.2205 - val_acc: 0.1832\n",
            "Epoch 229/250\n",
            "89/89 [==============================] - 25s 266ms/step - loss: 0.4597 - acc: 0.8460 - val_loss: 5.2592 - val_acc: 0.1875\n",
            "Epoch 230/250\n",
            "89/89 [==============================] - 25s 274ms/step - loss: 0.4388 - acc: 0.8410 - val_loss: 5.4359 - val_acc: 0.1810\n",
            "Epoch 231/250\n",
            "89/89 [==============================] - 25s 271ms/step - loss: 0.4811 - acc: 0.8368 - val_loss: 5.3744 - val_acc: 0.1746\n",
            "Epoch 232/250\n",
            "89/89 [==============================] - 28s 303ms/step - loss: 0.4644 - acc: 0.8439 - val_loss: 5.3595 - val_acc: 0.1832\n",
            "Epoch 233/250\n",
            "89/89 [==============================] - 29s 313ms/step - loss: 0.4277 - acc: 0.8623 - val_loss: 5.4241 - val_acc: 0.1746\n",
            "Epoch 234/250\n",
            "89/89 [==============================] - 29s 316ms/step - loss: 0.4264 - acc: 0.8495 - val_loss: 5.2826 - val_acc: 0.1746\n",
            "Epoch 235/250\n",
            "89/89 [==============================] - 30s 325ms/step - loss: 0.4307 - acc: 0.8517 - val_loss: 5.4543 - val_acc: 0.1853\n",
            "Epoch 236/250\n",
            "89/89 [==============================] - 30s 325ms/step - loss: 0.4176 - acc: 0.8545 - val_loss: 5.4093 - val_acc: 0.1767\n",
            "Epoch 237/250\n",
            "89/89 [==============================] - 30s 325ms/step - loss: 0.4382 - acc: 0.8510 - val_loss: 5.3637 - val_acc: 0.1832\n",
            "Epoch 238/250\n",
            "89/89 [==============================] - 30s 326ms/step - loss: 0.4094 - acc: 0.8588 - val_loss: 5.3358 - val_acc: 0.1832\n",
            "Epoch 239/250\n",
            "89/89 [==============================] - 29s 318ms/step - loss: 0.4177 - acc: 0.8616 - val_loss: 5.3989 - val_acc: 0.1875\n",
            "Epoch 240/250\n",
            "89/89 [==============================] - 29s 322ms/step - loss: 0.4158 - acc: 0.8609 - val_loss: 5.5152 - val_acc: 0.1832\n",
            "Epoch 241/250\n",
            "89/89 [==============================] - 29s 321ms/step - loss: 0.3726 - acc: 0.8616 - val_loss: 5.5452 - val_acc: 0.1810\n",
            "Epoch 242/250\n",
            "89/89 [==============================] - 30s 330ms/step - loss: 0.4031 - acc: 0.8609 - val_loss: 5.6241 - val_acc: 0.1832\n",
            "Epoch 243/250\n",
            "89/89 [==============================] - 29s 305ms/step - loss: 0.3928 - acc: 0.8595 - val_loss: 5.5719 - val_acc: 0.1767\n",
            "Epoch 244/250\n",
            "89/89 [==============================] - 28s 304ms/step - loss: 0.3964 - acc: 0.8609 - val_loss: 5.2027 - val_acc: 0.1789\n",
            "Epoch 245/250\n",
            "89/89 [==============================] - 28s 309ms/step - loss: 0.3715 - acc: 0.8680 - val_loss: 5.3817 - val_acc: 0.1724\n",
            "Epoch 246/250\n",
            "89/89 [==============================] - 28s 310ms/step - loss: 0.3920 - acc: 0.8701 - val_loss: 5.4976 - val_acc: 0.1810\n",
            "Epoch 247/250\n",
            "89/89 [==============================] - 30s 326ms/step - loss: 0.4092 - acc: 0.8545 - val_loss: 5.7076 - val_acc: 0.1832\n",
            "Epoch 248/250\n",
            "89/89 [==============================] - 29s 322ms/step - loss: 0.3672 - acc: 0.8722 - val_loss: 5.6611 - val_acc: 0.1810\n",
            "Epoch 249/250\n",
            "89/89 [==============================] - 30s 329ms/step - loss: 0.3317 - acc: 0.8857 - val_loss: 5.7197 - val_acc: 0.1703\n",
            "Epoch 250/250\n",
            "89/89 [==============================] - 30s 328ms/step - loss: 0.3631 - acc: 0.8751 - val_loss: 5.7690 - val_acc: 0.1767\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "acc = history.history['acc']\n",
        "val_acc = history.history['val_acc']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs_x = range(len(acc))\n",
        "\n",
        "plt.plot(epochs_x, acc, 'co', label='Training acc')\n",
        "plt.plot(epochs_x, val_acc, 'k', label='Validation acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.figure()\n",
        "\n",
        "plt.plot(epochs_x, loss, 'co', label='Training loss')\n",
        "plt.plot(epochs_x, val_loss, 'k', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "kwylTJpTP5XI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545
        },
        "outputId": "4265c2bc-e2a1-41d7-8036-4f2bf02dd4ad"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Download the model"
      ],
      "metadata": {
        "id": "lD-vKaoHQAFd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "os.makedirs('/content/drive/My Drive/cut_panoramic/Model/Classification', exist_ok=True)\n",
        "model.save('/content/drive/My Drive/cut_panoramic/Model/Classification/Male/New_44_รอบที่4_Flimpano_Male125_250_New_Unfreez.h5')"
      ],
      "metadata": {
        "id": "74dL7-HLP_Sh"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from google.colab import files\n",
        "# files.download('/content/drive/My Drive/cut_panoramic/Model/33_รอบที่3_Flimpano_Male125_250.h5')"
      ],
      "metadata": {
        "id": "qcPW-brHQDpc"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "P4pe9URV1vBB"
      },
      "execution_count": 19,
      "outputs": []
    }
  ]
}