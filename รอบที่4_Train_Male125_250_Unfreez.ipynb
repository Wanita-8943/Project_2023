{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Wanita-8943/Project_2023/blob/main/%E0%B8%A3%E0%B8%AD%E0%B8%9A%E0%B8%97%E0%B8%B5%E0%B9%884_Train_Male125_250_Unfreez.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "KKSs7cyoPHcD"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import shutil"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7LoeZxmVPMxp",
        "outputId": "beab4c6b-9a8a-4535-a1ef-717db6dd3600"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import models\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import optimizers\n",
        "import os\n",
        "import glob\n",
        "import shutil\n",
        "import sys\n",
        "import numpy as np\n",
        "from skimage.io import imread\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import Image\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "1pX9g1HxPM2f"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 16\n",
        "width = 150\n",
        "height = 150\n",
        "epochs = 250\n",
        "NUM_TRAIN = 1425\n",
        "NUM_TEST = 475\n",
        "dropout_rate = 0.2\n",
        "input_shape = (height, width, 3)"
      ],
      "metadata": {
        "id": "eSFtvGyvPM6O"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#ดึงข้อมูลใน Github มาใช้\n",
        "import os\n",
        "%cd /content\n",
        "if not os.path.isdir(\"efficientnet_keras_transfer_learning\"):\n",
        " !git clone https://github.com/Wanita-8943/efficientnet_keras_transfer_learning\n",
        "%cd efficientnet_keras_transfer_learning/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lb4K4CsMPNAW",
        "outputId": "21b1da96-f1dd-4eb1-a0ae-b696dc7a0f09"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "Cloning into 'efficientnet_keras_transfer_learning'...\n",
            "remote: Enumerating objects: 834, done.\u001b[K\n",
            "remote: Counting objects: 100% (356/356), done.\u001b[K\n",
            "remote: Compressing objects: 100% (169/169), done.\u001b[K\n",
            "remote: Total 834 (delta 251), reused 248 (delta 187), pack-reused 478\u001b[K\n",
            "Receiving objects: 100% (834/834), 13.77 MiB | 17.42 MiB/s, done.\n",
            "Resolving deltas: 100% (491/491), done.\n",
            "/content/efficientnet_keras_transfer_learning\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Options: EfficientNetB0, EfficientNetB1, EfficientNetB2, EfficientNetB3\n",
        "# Higher the number, the more complex the model is.\n",
        "from efficientnet import EfficientNetB0 as Net\n",
        "from efficientnet import center_crop_and_resize, preprocess_input"
      ],
      "metadata": {
        "id": "eyBg0dLKPND3"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# loading pretrained conv base model\n",
        "# โหลดโมเดล มาโดยตัด output ของโมเดลออก เเต่ยังใช้ input อันเดิม\n",
        "# เเละโหลด weight ของโมเดล มาด้วยที่ชื่อว่า imagenet\n",
        "conv_base = Net(weights='imagenet', include_top=False, input_shape=input_shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DoxI-q8-1giK",
        "outputId": "d925518f-1f78-4189-8fb5-e8874f2f1ac2"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://github.com/qubvel/efficientnet/releases/download/v0.0.1/efficientnet-b0_imagenet_1000_notop.h5\n",
            "16717576/16717576 [==============================] - 2s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "conv_base.summary() #ดู Summary"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "od4Lp6dD1lWK",
        "outputId": "cacd1702-c0b0-4754-e9fe-a6106e8a6796"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"efficientnet-b0\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 150, 150, 3  0           []                               \n",
            "                                )]                                                                \n",
            "                                                                                                  \n",
            " conv2d (Conv2D)                (None, 75, 75, 32)   864         ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " batch_normalization (BatchNorm  (None, 75, 75, 32)  128         ['conv2d[0][0]']                 \n",
            " alization)                                                                                       \n",
            "                                                                                                  \n",
            " swish (Swish)                  (None, 75, 75, 32)   0           ['batch_normalization[0][0]']    \n",
            "                                                                                                  \n",
            " depthwise_conv2d (DepthwiseCon  (None, 75, 75, 32)  288         ['swish[0][0]']                  \n",
            " v2D)                                                                                             \n",
            "                                                                                                  \n",
            " batch_normalization_1 (BatchNo  (None, 75, 75, 32)  128         ['depthwise_conv2d[0][0]']       \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " swish_1 (Swish)                (None, 75, 75, 32)   0           ['batch_normalization_1[0][0]']  \n",
            "                                                                                                  \n",
            " lambda (Lambda)                (None, 1, 1, 32)     0           ['swish_1[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d_1 (Conv2D)              (None, 1, 1, 8)      264         ['lambda[0][0]']                 \n",
            "                                                                                                  \n",
            " swish_2 (Swish)                (None, 1, 1, 8)      0           ['conv2d_1[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_2 (Conv2D)              (None, 1, 1, 32)     288         ['swish_2[0][0]']                \n",
            "                                                                                                  \n",
            " activation (Activation)        (None, 1, 1, 32)     0           ['conv2d_2[0][0]']               \n",
            "                                                                                                  \n",
            " multiply (Multiply)            (None, 75, 75, 32)   0           ['activation[0][0]',             \n",
            "                                                                  'swish_1[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d_3 (Conv2D)              (None, 75, 75, 16)   512         ['multiply[0][0]']               \n",
            "                                                                                                  \n",
            " batch_normalization_2 (BatchNo  (None, 75, 75, 16)  64          ['conv2d_3[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv2d_4 (Conv2D)              (None, 75, 75, 96)   1536        ['batch_normalization_2[0][0]']  \n",
            "                                                                                                  \n",
            " batch_normalization_3 (BatchNo  (None, 75, 75, 96)  384         ['conv2d_4[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " swish_3 (Swish)                (None, 75, 75, 96)   0           ['batch_normalization_3[0][0]']  \n",
            "                                                                                                  \n",
            " depthwise_conv2d_1 (DepthwiseC  (None, 38, 38, 96)  864         ['swish_3[0][0]']                \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_4 (BatchNo  (None, 38, 38, 96)  384         ['depthwise_conv2d_1[0][0]']     \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " swish_4 (Swish)                (None, 38, 38, 96)   0           ['batch_normalization_4[0][0]']  \n",
            "                                                                                                  \n",
            " lambda_1 (Lambda)              (None, 1, 1, 96)     0           ['swish_4[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d_5 (Conv2D)              (None, 1, 1, 4)      388         ['lambda_1[0][0]']               \n",
            "                                                                                                  \n",
            " swish_5 (Swish)                (None, 1, 1, 4)      0           ['conv2d_5[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_6 (Conv2D)              (None, 1, 1, 96)     480         ['swish_5[0][0]']                \n",
            "                                                                                                  \n",
            " activation_1 (Activation)      (None, 1, 1, 96)     0           ['conv2d_6[0][0]']               \n",
            "                                                                                                  \n",
            " multiply_1 (Multiply)          (None, 38, 38, 96)   0           ['activation_1[0][0]',           \n",
            "                                                                  'swish_4[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d_7 (Conv2D)              (None, 38, 38, 24)   2304        ['multiply_1[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_5 (BatchNo  (None, 38, 38, 24)  96          ['conv2d_7[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv2d_8 (Conv2D)              (None, 38, 38, 144)  3456        ['batch_normalization_5[0][0]']  \n",
            "                                                                                                  \n",
            " batch_normalization_6 (BatchNo  (None, 38, 38, 144)  576        ['conv2d_8[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " swish_6 (Swish)                (None, 38, 38, 144)  0           ['batch_normalization_6[0][0]']  \n",
            "                                                                                                  \n",
            " depthwise_conv2d_2 (DepthwiseC  (None, 38, 38, 144)  1296       ['swish_6[0][0]']                \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_7 (BatchNo  (None, 38, 38, 144)  576        ['depthwise_conv2d_2[0][0]']     \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " swish_7 (Swish)                (None, 38, 38, 144)  0           ['batch_normalization_7[0][0]']  \n",
            "                                                                                                  \n",
            " lambda_2 (Lambda)              (None, 1, 1, 144)    0           ['swish_7[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d_9 (Conv2D)              (None, 1, 1, 6)      870         ['lambda_2[0][0]']               \n",
            "                                                                                                  \n",
            " swish_8 (Swish)                (None, 1, 1, 6)      0           ['conv2d_9[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_10 (Conv2D)             (None, 1, 1, 144)    1008        ['swish_8[0][0]']                \n",
            "                                                                                                  \n",
            " activation_2 (Activation)      (None, 1, 1, 144)    0           ['conv2d_10[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_2 (Multiply)          (None, 38, 38, 144)  0           ['activation_2[0][0]',           \n",
            "                                                                  'swish_7[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d_11 (Conv2D)             (None, 38, 38, 24)   3456        ['multiply_2[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_8 (BatchNo  (None, 38, 38, 24)  96          ['conv2d_11[0][0]']              \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " drop_connect (DropConnect)     (None, 38, 38, 24)   0           ['batch_normalization_8[0][0]']  \n",
            "                                                                                                  \n",
            " add (Add)                      (None, 38, 38, 24)   0           ['drop_connect[0][0]',           \n",
            "                                                                  'batch_normalization_5[0][0]']  \n",
            "                                                                                                  \n",
            " conv2d_12 (Conv2D)             (None, 38, 38, 144)  3456        ['add[0][0]']                    \n",
            "                                                                                                  \n",
            " batch_normalization_9 (BatchNo  (None, 38, 38, 144)  576        ['conv2d_12[0][0]']              \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " swish_9 (Swish)                (None, 38, 38, 144)  0           ['batch_normalization_9[0][0]']  \n",
            "                                                                                                  \n",
            " depthwise_conv2d_3 (DepthwiseC  (None, 19, 19, 144)  3600       ['swish_9[0][0]']                \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_10 (BatchN  (None, 19, 19, 144)  576        ['depthwise_conv2d_3[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_10 (Swish)               (None, 19, 19, 144)  0           ['batch_normalization_10[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_3 (Lambda)              (None, 1, 1, 144)    0           ['swish_10[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_13 (Conv2D)             (None, 1, 1, 6)      870         ['lambda_3[0][0]']               \n",
            "                                                                                                  \n",
            " swish_11 (Swish)               (None, 1, 1, 6)      0           ['conv2d_13[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_14 (Conv2D)             (None, 1, 1, 144)    1008        ['swish_11[0][0]']               \n",
            "                                                                                                  \n",
            " activation_3 (Activation)      (None, 1, 1, 144)    0           ['conv2d_14[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_3 (Multiply)          (None, 19, 19, 144)  0           ['activation_3[0][0]',           \n",
            "                                                                  'swish_10[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_15 (Conv2D)             (None, 19, 19, 40)   5760        ['multiply_3[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_11 (BatchN  (None, 19, 19, 40)  160         ['conv2d_15[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_16 (Conv2D)             (None, 19, 19, 240)  9600        ['batch_normalization_11[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_12 (BatchN  (None, 19, 19, 240)  960        ['conv2d_16[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_12 (Swish)               (None, 19, 19, 240)  0           ['batch_normalization_12[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_4 (DepthwiseC  (None, 19, 19, 240)  6000       ['swish_12[0][0]']               \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_13 (BatchN  (None, 19, 19, 240)  960        ['depthwise_conv2d_4[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_13 (Swish)               (None, 19, 19, 240)  0           ['batch_normalization_13[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_4 (Lambda)              (None, 1, 1, 240)    0           ['swish_13[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_17 (Conv2D)             (None, 1, 1, 10)     2410        ['lambda_4[0][0]']               \n",
            "                                                                                                  \n",
            " swish_14 (Swish)               (None, 1, 1, 10)     0           ['conv2d_17[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_18 (Conv2D)             (None, 1, 1, 240)    2640        ['swish_14[0][0]']               \n",
            "                                                                                                  \n",
            " activation_4 (Activation)      (None, 1, 1, 240)    0           ['conv2d_18[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_4 (Multiply)          (None, 19, 19, 240)  0           ['activation_4[0][0]',           \n",
            "                                                                  'swish_13[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_19 (Conv2D)             (None, 19, 19, 40)   9600        ['multiply_4[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_14 (BatchN  (None, 19, 19, 40)  160         ['conv2d_19[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_1 (DropConnect)   (None, 19, 19, 40)   0           ['batch_normalization_14[0][0]'] \n",
            "                                                                                                  \n",
            " add_1 (Add)                    (None, 19, 19, 40)   0           ['drop_connect_1[0][0]',         \n",
            "                                                                  'batch_normalization_11[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_20 (Conv2D)             (None, 19, 19, 240)  9600        ['add_1[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_15 (BatchN  (None, 19, 19, 240)  960        ['conv2d_20[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_15 (Swish)               (None, 19, 19, 240)  0           ['batch_normalization_15[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_5 (DepthwiseC  (None, 10, 10, 240)  2160       ['swish_15[0][0]']               \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_16 (BatchN  (None, 10, 10, 240)  960        ['depthwise_conv2d_5[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_16 (Swish)               (None, 10, 10, 240)  0           ['batch_normalization_16[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_5 (Lambda)              (None, 1, 1, 240)    0           ['swish_16[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_21 (Conv2D)             (None, 1, 1, 10)     2410        ['lambda_5[0][0]']               \n",
            "                                                                                                  \n",
            " swish_17 (Swish)               (None, 1, 1, 10)     0           ['conv2d_21[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_22 (Conv2D)             (None, 1, 1, 240)    2640        ['swish_17[0][0]']               \n",
            "                                                                                                  \n",
            " activation_5 (Activation)      (None, 1, 1, 240)    0           ['conv2d_22[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_5 (Multiply)          (None, 10, 10, 240)  0           ['activation_5[0][0]',           \n",
            "                                                                  'swish_16[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_23 (Conv2D)             (None, 10, 10, 80)   19200       ['multiply_5[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_17 (BatchN  (None, 10, 10, 80)  320         ['conv2d_23[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_24 (Conv2D)             (None, 10, 10, 480)  38400       ['batch_normalization_17[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_18 (BatchN  (None, 10, 10, 480)  1920       ['conv2d_24[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_18 (Swish)               (None, 10, 10, 480)  0           ['batch_normalization_18[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_6 (DepthwiseC  (None, 10, 10, 480)  4320       ['swish_18[0][0]']               \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_19 (BatchN  (None, 10, 10, 480)  1920       ['depthwise_conv2d_6[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_19 (Swish)               (None, 10, 10, 480)  0           ['batch_normalization_19[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_6 (Lambda)              (None, 1, 1, 480)    0           ['swish_19[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_25 (Conv2D)             (None, 1, 1, 20)     9620        ['lambda_6[0][0]']               \n",
            "                                                                                                  \n",
            " swish_20 (Swish)               (None, 1, 1, 20)     0           ['conv2d_25[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_26 (Conv2D)             (None, 1, 1, 480)    10080       ['swish_20[0][0]']               \n",
            "                                                                                                  \n",
            " activation_6 (Activation)      (None, 1, 1, 480)    0           ['conv2d_26[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_6 (Multiply)          (None, 10, 10, 480)  0           ['activation_6[0][0]',           \n",
            "                                                                  'swish_19[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_27 (Conv2D)             (None, 10, 10, 80)   38400       ['multiply_6[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_20 (BatchN  (None, 10, 10, 80)  320         ['conv2d_27[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_2 (DropConnect)   (None, 10, 10, 80)   0           ['batch_normalization_20[0][0]'] \n",
            "                                                                                                  \n",
            " add_2 (Add)                    (None, 10, 10, 80)   0           ['drop_connect_2[0][0]',         \n",
            "                                                                  'batch_normalization_17[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_28 (Conv2D)             (None, 10, 10, 480)  38400       ['add_2[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_21 (BatchN  (None, 10, 10, 480)  1920       ['conv2d_28[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_21 (Swish)               (None, 10, 10, 480)  0           ['batch_normalization_21[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_7 (DepthwiseC  (None, 10, 10, 480)  4320       ['swish_21[0][0]']               \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_22 (BatchN  (None, 10, 10, 480)  1920       ['depthwise_conv2d_7[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_22 (Swish)               (None, 10, 10, 480)  0           ['batch_normalization_22[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_7 (Lambda)              (None, 1, 1, 480)    0           ['swish_22[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_29 (Conv2D)             (None, 1, 1, 20)     9620        ['lambda_7[0][0]']               \n",
            "                                                                                                  \n",
            " swish_23 (Swish)               (None, 1, 1, 20)     0           ['conv2d_29[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_30 (Conv2D)             (None, 1, 1, 480)    10080       ['swish_23[0][0]']               \n",
            "                                                                                                  \n",
            " activation_7 (Activation)      (None, 1, 1, 480)    0           ['conv2d_30[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_7 (Multiply)          (None, 10, 10, 480)  0           ['activation_7[0][0]',           \n",
            "                                                                  'swish_22[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_31 (Conv2D)             (None, 10, 10, 80)   38400       ['multiply_7[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_23 (BatchN  (None, 10, 10, 80)  320         ['conv2d_31[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_3 (DropConnect)   (None, 10, 10, 80)   0           ['batch_normalization_23[0][0]'] \n",
            "                                                                                                  \n",
            " add_3 (Add)                    (None, 10, 10, 80)   0           ['drop_connect_3[0][0]',         \n",
            "                                                                  'add_2[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_32 (Conv2D)             (None, 10, 10, 480)  38400       ['add_3[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_24 (BatchN  (None, 10, 10, 480)  1920       ['conv2d_32[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_24 (Swish)               (None, 10, 10, 480)  0           ['batch_normalization_24[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_8 (DepthwiseC  (None, 10, 10, 480)  12000      ['swish_24[0][0]']               \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_25 (BatchN  (None, 10, 10, 480)  1920       ['depthwise_conv2d_8[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_25 (Swish)               (None, 10, 10, 480)  0           ['batch_normalization_25[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_8 (Lambda)              (None, 1, 1, 480)    0           ['swish_25[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_33 (Conv2D)             (None, 1, 1, 20)     9620        ['lambda_8[0][0]']               \n",
            "                                                                                                  \n",
            " swish_26 (Swish)               (None, 1, 1, 20)     0           ['conv2d_33[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_34 (Conv2D)             (None, 1, 1, 480)    10080       ['swish_26[0][0]']               \n",
            "                                                                                                  \n",
            " activation_8 (Activation)      (None, 1, 1, 480)    0           ['conv2d_34[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_8 (Multiply)          (None, 10, 10, 480)  0           ['activation_8[0][0]',           \n",
            "                                                                  'swish_25[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_35 (Conv2D)             (None, 10, 10, 112)  53760       ['multiply_8[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_26 (BatchN  (None, 10, 10, 112)  448        ['conv2d_35[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_36 (Conv2D)             (None, 10, 10, 672)  75264       ['batch_normalization_26[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_27 (BatchN  (None, 10, 10, 672)  2688       ['conv2d_36[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_27 (Swish)               (None, 10, 10, 672)  0           ['batch_normalization_27[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_9 (DepthwiseC  (None, 10, 10, 672)  16800      ['swish_27[0][0]']               \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_28 (BatchN  (None, 10, 10, 672)  2688       ['depthwise_conv2d_9[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_28 (Swish)               (None, 10, 10, 672)  0           ['batch_normalization_28[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_9 (Lambda)              (None, 1, 1, 672)    0           ['swish_28[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_37 (Conv2D)             (None, 1, 1, 28)     18844       ['lambda_9[0][0]']               \n",
            "                                                                                                  \n",
            " swish_29 (Swish)               (None, 1, 1, 28)     0           ['conv2d_37[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_38 (Conv2D)             (None, 1, 1, 672)    19488       ['swish_29[0][0]']               \n",
            "                                                                                                  \n",
            " activation_9 (Activation)      (None, 1, 1, 672)    0           ['conv2d_38[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_9 (Multiply)          (None, 10, 10, 672)  0           ['activation_9[0][0]',           \n",
            "                                                                  'swish_28[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_39 (Conv2D)             (None, 10, 10, 112)  75264       ['multiply_9[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_29 (BatchN  (None, 10, 10, 112)  448        ['conv2d_39[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_4 (DropConnect)   (None, 10, 10, 112)  0           ['batch_normalization_29[0][0]'] \n",
            "                                                                                                  \n",
            " add_4 (Add)                    (None, 10, 10, 112)  0           ['drop_connect_4[0][0]',         \n",
            "                                                                  'batch_normalization_26[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_40 (Conv2D)             (None, 10, 10, 672)  75264       ['add_4[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_30 (BatchN  (None, 10, 10, 672)  2688       ['conv2d_40[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_30 (Swish)               (None, 10, 10, 672)  0           ['batch_normalization_30[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_10 (Depthwise  (None, 10, 10, 672)  16800      ['swish_30[0][0]']               \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_31 (BatchN  (None, 10, 10, 672)  2688       ['depthwise_conv2d_10[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_31 (Swish)               (None, 10, 10, 672)  0           ['batch_normalization_31[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_10 (Lambda)             (None, 1, 1, 672)    0           ['swish_31[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_41 (Conv2D)             (None, 1, 1, 28)     18844       ['lambda_10[0][0]']              \n",
            "                                                                                                  \n",
            " swish_32 (Swish)               (None, 1, 1, 28)     0           ['conv2d_41[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_42 (Conv2D)             (None, 1, 1, 672)    19488       ['swish_32[0][0]']               \n",
            "                                                                                                  \n",
            " activation_10 (Activation)     (None, 1, 1, 672)    0           ['conv2d_42[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_10 (Multiply)         (None, 10, 10, 672)  0           ['activation_10[0][0]',          \n",
            "                                                                  'swish_31[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_43 (Conv2D)             (None, 10, 10, 112)  75264       ['multiply_10[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_32 (BatchN  (None, 10, 10, 112)  448        ['conv2d_43[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_5 (DropConnect)   (None, 10, 10, 112)  0           ['batch_normalization_32[0][0]'] \n",
            "                                                                                                  \n",
            " add_5 (Add)                    (None, 10, 10, 112)  0           ['drop_connect_5[0][0]',         \n",
            "                                                                  'add_4[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_44 (Conv2D)             (None, 10, 10, 672)  75264       ['add_5[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_33 (BatchN  (None, 10, 10, 672)  2688       ['conv2d_44[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_33 (Swish)               (None, 10, 10, 672)  0           ['batch_normalization_33[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_11 (Depthwise  (None, 5, 5, 672)   16800       ['swish_33[0][0]']               \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_34 (BatchN  (None, 5, 5, 672)   2688        ['depthwise_conv2d_11[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_34 (Swish)               (None, 5, 5, 672)    0           ['batch_normalization_34[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_11 (Lambda)             (None, 1, 1, 672)    0           ['swish_34[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_45 (Conv2D)             (None, 1, 1, 28)     18844       ['lambda_11[0][0]']              \n",
            "                                                                                                  \n",
            " swish_35 (Swish)               (None, 1, 1, 28)     0           ['conv2d_45[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_46 (Conv2D)             (None, 1, 1, 672)    19488       ['swish_35[0][0]']               \n",
            "                                                                                                  \n",
            " activation_11 (Activation)     (None, 1, 1, 672)    0           ['conv2d_46[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_11 (Multiply)         (None, 5, 5, 672)    0           ['activation_11[0][0]',          \n",
            "                                                                  'swish_34[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_47 (Conv2D)             (None, 5, 5, 192)    129024      ['multiply_11[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_35 (BatchN  (None, 5, 5, 192)   768         ['conv2d_47[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_48 (Conv2D)             (None, 5, 5, 1152)   221184      ['batch_normalization_35[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_36 (BatchN  (None, 5, 5, 1152)  4608        ['conv2d_48[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_36 (Swish)               (None, 5, 5, 1152)   0           ['batch_normalization_36[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_12 (Depthwise  (None, 5, 5, 1152)  28800       ['swish_36[0][0]']               \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_37 (BatchN  (None, 5, 5, 1152)  4608        ['depthwise_conv2d_12[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_37 (Swish)               (None, 5, 5, 1152)   0           ['batch_normalization_37[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_12 (Lambda)             (None, 1, 1, 1152)   0           ['swish_37[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_49 (Conv2D)             (None, 1, 1, 48)     55344       ['lambda_12[0][0]']              \n",
            "                                                                                                  \n",
            " swish_38 (Swish)               (None, 1, 1, 48)     0           ['conv2d_49[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_50 (Conv2D)             (None, 1, 1, 1152)   56448       ['swish_38[0][0]']               \n",
            "                                                                                                  \n",
            " activation_12 (Activation)     (None, 1, 1, 1152)   0           ['conv2d_50[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_12 (Multiply)         (None, 5, 5, 1152)   0           ['activation_12[0][0]',          \n",
            "                                                                  'swish_37[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_51 (Conv2D)             (None, 5, 5, 192)    221184      ['multiply_12[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_38 (BatchN  (None, 5, 5, 192)   768         ['conv2d_51[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_6 (DropConnect)   (None, 5, 5, 192)    0           ['batch_normalization_38[0][0]'] \n",
            "                                                                                                  \n",
            " add_6 (Add)                    (None, 5, 5, 192)    0           ['drop_connect_6[0][0]',         \n",
            "                                                                  'batch_normalization_35[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_52 (Conv2D)             (None, 5, 5, 1152)   221184      ['add_6[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_39 (BatchN  (None, 5, 5, 1152)  4608        ['conv2d_52[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_39 (Swish)               (None, 5, 5, 1152)   0           ['batch_normalization_39[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_13 (Depthwise  (None, 5, 5, 1152)  28800       ['swish_39[0][0]']               \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_40 (BatchN  (None, 5, 5, 1152)  4608        ['depthwise_conv2d_13[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_40 (Swish)               (None, 5, 5, 1152)   0           ['batch_normalization_40[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_13 (Lambda)             (None, 1, 1, 1152)   0           ['swish_40[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_53 (Conv2D)             (None, 1, 1, 48)     55344       ['lambda_13[0][0]']              \n",
            "                                                                                                  \n",
            " swish_41 (Swish)               (None, 1, 1, 48)     0           ['conv2d_53[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_54 (Conv2D)             (None, 1, 1, 1152)   56448       ['swish_41[0][0]']               \n",
            "                                                                                                  \n",
            " activation_13 (Activation)     (None, 1, 1, 1152)   0           ['conv2d_54[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_13 (Multiply)         (None, 5, 5, 1152)   0           ['activation_13[0][0]',          \n",
            "                                                                  'swish_40[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_55 (Conv2D)             (None, 5, 5, 192)    221184      ['multiply_13[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_41 (BatchN  (None, 5, 5, 192)   768         ['conv2d_55[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_7 (DropConnect)   (None, 5, 5, 192)    0           ['batch_normalization_41[0][0]'] \n",
            "                                                                                                  \n",
            " add_7 (Add)                    (None, 5, 5, 192)    0           ['drop_connect_7[0][0]',         \n",
            "                                                                  'add_6[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_56 (Conv2D)             (None, 5, 5, 1152)   221184      ['add_7[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_42 (BatchN  (None, 5, 5, 1152)  4608        ['conv2d_56[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_42 (Swish)               (None, 5, 5, 1152)   0           ['batch_normalization_42[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_14 (Depthwise  (None, 5, 5, 1152)  28800       ['swish_42[0][0]']               \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_43 (BatchN  (None, 5, 5, 1152)  4608        ['depthwise_conv2d_14[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_43 (Swish)               (None, 5, 5, 1152)   0           ['batch_normalization_43[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_14 (Lambda)             (None, 1, 1, 1152)   0           ['swish_43[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_57 (Conv2D)             (None, 1, 1, 48)     55344       ['lambda_14[0][0]']              \n",
            "                                                                                                  \n",
            " swish_44 (Swish)               (None, 1, 1, 48)     0           ['conv2d_57[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_58 (Conv2D)             (None, 1, 1, 1152)   56448       ['swish_44[0][0]']               \n",
            "                                                                                                  \n",
            " activation_14 (Activation)     (None, 1, 1, 1152)   0           ['conv2d_58[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_14 (Multiply)         (None, 5, 5, 1152)   0           ['activation_14[0][0]',          \n",
            "                                                                  'swish_43[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_59 (Conv2D)             (None, 5, 5, 192)    221184      ['multiply_14[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_44 (BatchN  (None, 5, 5, 192)   768         ['conv2d_59[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_8 (DropConnect)   (None, 5, 5, 192)    0           ['batch_normalization_44[0][0]'] \n",
            "                                                                                                  \n",
            " add_8 (Add)                    (None, 5, 5, 192)    0           ['drop_connect_8[0][0]',         \n",
            "                                                                  'add_7[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_60 (Conv2D)             (None, 5, 5, 1152)   221184      ['add_8[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_45 (BatchN  (None, 5, 5, 1152)  4608        ['conv2d_60[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_45 (Swish)               (None, 5, 5, 1152)   0           ['batch_normalization_45[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_15 (Depthwise  (None, 5, 5, 1152)  10368       ['swish_45[0][0]']               \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_46 (BatchN  (None, 5, 5, 1152)  4608        ['depthwise_conv2d_15[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_46 (Swish)               (None, 5, 5, 1152)   0           ['batch_normalization_46[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_15 (Lambda)             (None, 1, 1, 1152)   0           ['swish_46[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_61 (Conv2D)             (None, 1, 1, 48)     55344       ['lambda_15[0][0]']              \n",
            "                                                                                                  \n",
            " swish_47 (Swish)               (None, 1, 1, 48)     0           ['conv2d_61[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_62 (Conv2D)             (None, 1, 1, 1152)   56448       ['swish_47[0][0]']               \n",
            "                                                                                                  \n",
            " activation_15 (Activation)     (None, 1, 1, 1152)   0           ['conv2d_62[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_15 (Multiply)         (None, 5, 5, 1152)   0           ['activation_15[0][0]',          \n",
            "                                                                  'swish_46[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_63 (Conv2D)             (None, 5, 5, 320)    368640      ['multiply_15[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_47 (BatchN  (None, 5, 5, 320)   1280        ['conv2d_63[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_64 (Conv2D)             (None, 5, 5, 1280)   409600      ['batch_normalization_47[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_48 (BatchN  (None, 5, 5, 1280)  5120        ['conv2d_64[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_48 (Swish)               (None, 5, 5, 1280)   0           ['batch_normalization_48[0][0]'] \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 4,049,564\n",
            "Trainable params: 4,007,548\n",
            "Non-trainable params: 42,016\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "base_dir = '/content/drive/MyDrive/TVT_Male125'\n",
        "os.makedirs(base_dir, exist_ok=True)\n",
        "\n",
        "# Directories for our training,\n",
        "# validation and test splits\n",
        "train_dir = os.path.join(base_dir, 'train')\n",
        "os.makedirs(train_dir, exist_ok=True)\n",
        "validation_dir = os.path.join(base_dir, 'validation')\n",
        "os.makedirs(validation_dir, exist_ok=True)\n",
        "test_dir = os.path.join(base_dir, 'test')\n",
        "os.makedirs(test_dir, exist_ok=True)"
      ],
      "metadata": {
        "id": "Jwpq_-KvPef8"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#load model"
      ],
      "metadata": {
        "id": "od-ZSNm5PoGy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.append('/content/drive/MyDrive/cut_panoramic/Model/Classification/33_รอบที่3_Flimpano_Male125_250.h5')\n",
        "\n",
        "from efficientnet.layers import Swish, DropConnect\n",
        "from efficientnet.model import ConvKernalInitializer\n",
        "from tensorflow.keras.utils import get_custom_objects\n",
        "\n",
        "get_custom_objects().update({\n",
        "    'ConvKernalInitializer': ConvKernalInitializer,\n",
        "    'Swish': Swish,\n",
        "    'DropConnect':DropConnect\n",
        "})"
      ],
      "metadata": {
        "id": "n5iPL5MNPkhE"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#load model \n",
        "from tensorflow.keras.models import load_model\n",
        "model = load_model('/content/drive/MyDrive/cut_panoramic/Model/Classification/33_รอบที่3_Flimpano_Male125_250.h5')\n",
        "height = width = model.input_shape[1]"
      ],
      "metadata": {
        "id": "plYz49xMPkly"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z6IOPBflFbvc",
        "outputId": "269f39c4-8861-4090-a7d3-3591081dcbb9"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " efficientnet-b0 (Functional  (None, 5, 5, 1280)       4049564   \n",
            " )                                                               \n",
            "                                                                 \n",
            " gap (GlobalMaxPooling2D)    (None, 1280)              0         \n",
            "                                                                 \n",
            " dropout_out (Dropout)       (None, 1280)              0         \n",
            "                                                                 \n",
            " fc_out (Dense)              (None, 19)                24339     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4,073,903\n",
            "Trainable params: 24,339\n",
            "Non-trainable params: 4,049,564\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train ด้วย ImageDataGenerator ของ Keras ซึ่งจะเพิ่มข้อมูลเสริมระหว่างการฝึกเพื่อลดโอกาสเกิด overfitting\n",
        "#overfitting เกิดจากข้อมูลที่ซับซ้อนกันเกินไป\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "train_datagen = ImageDataGenerator(\n",
        "      rescale=1./255, #โมเดลส่วนใหญ่ต้องใช้ RGB ในช่วง 0–1\n",
        "      rotation_range=40,\n",
        "      width_shift_range=0.2,\n",
        "      height_shift_range=0.2,\n",
        "      shear_range=0.2,\n",
        "      zoom_range=0.2,\n",
        "      horizontal_flip=True,\n",
        "      fill_mode='nearest')\n",
        "\n",
        "# Note that the validation data should not be augmented!\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "        # This is the target directory #ไดเรกเป้าหมาย\n",
        "        train_dir,\n",
        "        # รูปภาพทั้งหมดจะถูกปรับขนาดตามความสูงและความกว้างของเป้าหมาย\n",
        "        target_size=(height, width),\n",
        "        batch_size=batch_size,\n",
        "        # Since we use categorical_crossentropy loss, we need categorical labels\n",
        "        #เนื่องจากเราใช้ categorical_crossentropy loss เราจึงต้องมีป้ายกำกับตามหมวดหมู่\n",
        "        class_mode='categorical')\n",
        "\n",
        "validation_generator = test_datagen.flow_from_directory( #การดึงภาพจาก Directory มาเข้าโมเดล \n",
        "        validation_dir,\n",
        "        target_size=(height, width),\n",
        "        batch_size=batch_size,\n",
        "        class_mode='categorical')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KBMZbdr2Pgw4",
        "outputId": "6e4cf709-89b0-492d-88ac-f17311593aca"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1425 images belonging to 19 classes.\n",
            "Found 475 images belonging to 19 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# multiply_16\n",
        "# set 'multiply_16' and following layers trainable\n",
        "conv_base.trainable = True\n",
        "\n",
        "set_trainable = False\n",
        "for layer in conv_base.layers:\n",
        "    if layer.name == 'multiply_16':\n",
        "        set_trainable = True\n",
        "    if set_trainable:\n",
        "        layer.trainable = True\n",
        "    else:\n",
        "        layer.trainable = False  "
      ],
      "metadata": {
        "id": "2SmWJJlZ0K0g"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit_generator(\n",
        "      train_generator,\n",
        "      steps_per_epoch= NUM_TRAIN //batch_size,\n",
        "      epochs=epochs,\n",
        "      validation_data=validation_generator,\n",
        "      validation_steps= NUM_TEST //batch_size,\n",
        "      verbose=1,\n",
        "      use_multiprocessing=True,\n",
        "      workers=4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C9Cf1dwyP1PD",
        "outputId": "27c29d53-b13c-4695-d6a2-aea993f48f36"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-23-caa7b37242a8>:1: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  history = model.fit_generator(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/250\n",
            "89/89 [==============================] - 234s 2s/step - loss: 2.1816 - acc: 0.2463 - val_loss: 2.7035 - val_acc: 0.1616\n",
            "Epoch 2/250\n",
            "89/89 [==============================] - 29s 319ms/step - loss: 2.2112 - acc: 0.2555 - val_loss: 2.7001 - val_acc: 0.1659\n",
            "Epoch 3/250\n",
            "89/89 [==============================] - 27s 294ms/step - loss: 2.2019 - acc: 0.2683 - val_loss: 2.6830 - val_acc: 0.1573\n",
            "Epoch 4/250\n",
            "89/89 [==============================] - 25s 276ms/step - loss: 2.2705 - acc: 0.2441 - val_loss: 2.6986 - val_acc: 0.1659\n",
            "Epoch 5/250\n",
            "89/89 [==============================] - 27s 295ms/step - loss: 2.2076 - acc: 0.2626 - val_loss: 2.6899 - val_acc: 0.1616\n",
            "Epoch 6/250\n",
            "89/89 [==============================] - 25s 275ms/step - loss: 2.1599 - acc: 0.2697 - val_loss: 2.6852 - val_acc: 0.1466\n",
            "Epoch 7/250\n",
            "89/89 [==============================] - 20s 220ms/step - loss: 2.2136 - acc: 0.2427 - val_loss: 2.7106 - val_acc: 0.1595\n",
            "Epoch 8/250\n",
            "89/89 [==============================] - 28s 303ms/step - loss: 2.1966 - acc: 0.2548 - val_loss: 2.7059 - val_acc: 0.1509\n",
            "Epoch 9/250\n",
            "89/89 [==============================] - 28s 307ms/step - loss: 2.2195 - acc: 0.2434 - val_loss: 2.7128 - val_acc: 0.1573\n",
            "Epoch 10/250\n",
            "89/89 [==============================] - 29s 317ms/step - loss: 2.2232 - acc: 0.2527 - val_loss: 2.7158 - val_acc: 0.1552\n",
            "Epoch 11/250\n",
            "89/89 [==============================] - 26s 280ms/step - loss: 2.2086 - acc: 0.2406 - val_loss: 2.7024 - val_acc: 0.1530\n",
            "Epoch 12/250\n",
            "89/89 [==============================] - 26s 291ms/step - loss: 2.2171 - acc: 0.2626 - val_loss: 2.7030 - val_acc: 0.1659\n",
            "Epoch 13/250\n",
            "89/89 [==============================] - 27s 294ms/step - loss: 2.1896 - acc: 0.2520 - val_loss: 2.7089 - val_acc: 0.1552\n",
            "Epoch 14/250\n",
            "89/89 [==============================] - 22s 245ms/step - loss: 2.2025 - acc: 0.2463 - val_loss: 2.7114 - val_acc: 0.1638\n",
            "Epoch 15/250\n",
            "89/89 [==============================] - 21s 228ms/step - loss: 2.1884 - acc: 0.2626 - val_loss: 2.7011 - val_acc: 0.1595\n",
            "Epoch 16/250\n",
            "89/89 [==============================] - 27s 302ms/step - loss: 2.2261 - acc: 0.2378 - val_loss: 2.7015 - val_acc: 0.1638\n",
            "Epoch 17/250\n",
            "89/89 [==============================] - 26s 283ms/step - loss: 2.2031 - acc: 0.2590 - val_loss: 2.6863 - val_acc: 0.1616\n",
            "Epoch 18/250\n",
            "89/89 [==============================] - 27s 293ms/step - loss: 2.1904 - acc: 0.2612 - val_loss: 2.6822 - val_acc: 0.1487\n",
            "Epoch 19/250\n",
            "89/89 [==============================] - 26s 287ms/step - loss: 2.2246 - acc: 0.2576 - val_loss: 2.6802 - val_acc: 0.1595\n",
            "Epoch 20/250\n",
            "89/89 [==============================] - 22s 243ms/step - loss: 2.2117 - acc: 0.2654 - val_loss: 2.7081 - val_acc: 0.1573\n",
            "Epoch 21/250\n",
            "89/89 [==============================] - 26s 290ms/step - loss: 2.2069 - acc: 0.2619 - val_loss: 2.6869 - val_acc: 0.1595\n",
            "Epoch 22/250\n",
            "89/89 [==============================] - 22s 243ms/step - loss: 2.2249 - acc: 0.2569 - val_loss: 2.7136 - val_acc: 0.1573\n",
            "Epoch 23/250\n",
            "89/89 [==============================] - 22s 227ms/step - loss: 2.1652 - acc: 0.2683 - val_loss: 2.7137 - val_acc: 0.1681\n",
            "Epoch 24/250\n",
            "89/89 [==============================] - 28s 306ms/step - loss: 2.2262 - acc: 0.2378 - val_loss: 2.7024 - val_acc: 0.1616\n",
            "Epoch 25/250\n",
            "89/89 [==============================] - 26s 280ms/step - loss: 2.2472 - acc: 0.2534 - val_loss: 2.6708 - val_acc: 0.1638\n",
            "Epoch 26/250\n",
            "89/89 [==============================] - 27s 291ms/step - loss: 2.2115 - acc: 0.2512 - val_loss: 2.7078 - val_acc: 0.1552\n",
            "Epoch 27/250\n",
            "89/89 [==============================] - 26s 282ms/step - loss: 2.2004 - acc: 0.2484 - val_loss: 2.7125 - val_acc: 0.1573\n",
            "Epoch 28/250\n",
            "89/89 [==============================] - 28s 297ms/step - loss: 2.2237 - acc: 0.2548 - val_loss: 2.7113 - val_acc: 0.1638\n",
            "Epoch 29/250\n",
            "89/89 [==============================] - 28s 306ms/step - loss: 2.1957 - acc: 0.2527 - val_loss: 2.7124 - val_acc: 0.1509\n",
            "Epoch 30/250\n",
            "89/89 [==============================] - 28s 307ms/step - loss: 2.2050 - acc: 0.2512 - val_loss: 2.6930 - val_acc: 0.1552\n",
            "Epoch 31/250\n",
            "89/89 [==============================] - 30s 326ms/step - loss: 2.2045 - acc: 0.2626 - val_loss: 2.7150 - val_acc: 0.1530\n",
            "Epoch 32/250\n",
            "89/89 [==============================] - 23s 251ms/step - loss: 2.1710 - acc: 0.2605 - val_loss: 2.7312 - val_acc: 0.1444\n",
            "Epoch 33/250\n",
            "89/89 [==============================] - 28s 305ms/step - loss: 2.1798 - acc: 0.2569 - val_loss: 2.7026 - val_acc: 0.1509\n",
            "Epoch 34/250\n",
            "89/89 [==============================] - 26s 287ms/step - loss: 2.2042 - acc: 0.2470 - val_loss: 2.7181 - val_acc: 0.1509\n",
            "Epoch 35/250\n",
            "89/89 [==============================] - 26s 281ms/step - loss: 2.2050 - acc: 0.2527 - val_loss: 2.7061 - val_acc: 0.1487\n",
            "Epoch 36/250\n",
            "89/89 [==============================] - 26s 286ms/step - loss: 2.2006 - acc: 0.2505 - val_loss: 2.7234 - val_acc: 0.1509\n",
            "Epoch 37/250\n",
            "89/89 [==============================] - 26s 286ms/step - loss: 2.2191 - acc: 0.2505 - val_loss: 2.7057 - val_acc: 0.1487\n",
            "Epoch 38/250\n",
            "89/89 [==============================] - 26s 284ms/step - loss: 2.2521 - acc: 0.2243 - val_loss: 2.7089 - val_acc: 0.1552\n",
            "Epoch 39/250\n",
            "89/89 [==============================] - 29s 323ms/step - loss: 2.1728 - acc: 0.2676 - val_loss: 2.7117 - val_acc: 0.1616\n",
            "Epoch 40/250\n",
            "89/89 [==============================] - 27s 292ms/step - loss: 2.1929 - acc: 0.2548 - val_loss: 2.7337 - val_acc: 0.1552\n",
            "Epoch 41/250\n",
            "89/89 [==============================] - 27s 292ms/step - loss: 2.2043 - acc: 0.2676 - val_loss: 2.7336 - val_acc: 0.1595\n",
            "Epoch 42/250\n",
            "89/89 [==============================] - 27s 291ms/step - loss: 2.1959 - acc: 0.2534 - val_loss: 2.7339 - val_acc: 0.1552\n",
            "Epoch 43/250\n",
            "89/89 [==============================] - 22s 235ms/step - loss: 2.1983 - acc: 0.2512 - val_loss: 2.7128 - val_acc: 0.1573\n",
            "Epoch 44/250\n",
            "89/89 [==============================] - 23s 252ms/step - loss: 2.1708 - acc: 0.2590 - val_loss: 2.7199 - val_acc: 0.1616\n",
            "Epoch 45/250\n",
            "89/89 [==============================] - 27s 292ms/step - loss: 2.1880 - acc: 0.2690 - val_loss: 2.7288 - val_acc: 0.1595\n",
            "Epoch 46/250\n",
            "89/89 [==============================] - 22s 234ms/step - loss: 2.2334 - acc: 0.2463 - val_loss: 2.7330 - val_acc: 0.1530\n",
            "Epoch 47/250\n",
            "89/89 [==============================] - 27s 295ms/step - loss: 2.1884 - acc: 0.2498 - val_loss: 2.6884 - val_acc: 0.1681\n",
            "Epoch 48/250\n",
            "89/89 [==============================] - 27s 292ms/step - loss: 2.1882 - acc: 0.2512 - val_loss: 2.7277 - val_acc: 0.1659\n",
            "Epoch 49/250\n",
            "89/89 [==============================] - 22s 241ms/step - loss: 2.1933 - acc: 0.2434 - val_loss: 2.7585 - val_acc: 0.1530\n",
            "Epoch 50/250\n",
            "89/89 [==============================] - 28s 295ms/step - loss: 2.1534 - acc: 0.2583 - val_loss: 2.7199 - val_acc: 0.1659\n",
            "Epoch 51/250\n",
            "89/89 [==============================] - 28s 299ms/step - loss: 2.2264 - acc: 0.2541 - val_loss: 2.7001 - val_acc: 0.1616\n",
            "Epoch 52/250\n",
            "89/89 [==============================] - 29s 314ms/step - loss: 2.1541 - acc: 0.2683 - val_loss: 2.7120 - val_acc: 0.1638\n",
            "Epoch 53/250\n",
            "89/89 [==============================] - 28s 306ms/step - loss: 2.2122 - acc: 0.2619 - val_loss: 2.7195 - val_acc: 0.1659\n",
            "Epoch 54/250\n",
            "89/89 [==============================] - 24s 257ms/step - loss: 2.1843 - acc: 0.2612 - val_loss: 2.6999 - val_acc: 0.1681\n",
            "Epoch 55/250\n",
            "89/89 [==============================] - 26s 285ms/step - loss: 2.1964 - acc: 0.2633 - val_loss: 2.7256 - val_acc: 0.1595\n",
            "Epoch 56/250\n",
            "89/89 [==============================] - 26s 287ms/step - loss: 2.2017 - acc: 0.2484 - val_loss: 2.7340 - val_acc: 0.1616\n",
            "Epoch 57/250\n",
            "89/89 [==============================] - 28s 309ms/step - loss: 2.2175 - acc: 0.2512 - val_loss: 2.7151 - val_acc: 0.1530\n",
            "Epoch 58/250\n",
            "89/89 [==============================] - 29s 318ms/step - loss: 2.1731 - acc: 0.2548 - val_loss: 2.7229 - val_acc: 0.1595\n",
            "Epoch 59/250\n",
            "89/89 [==============================] - 28s 305ms/step - loss: 2.1972 - acc: 0.2647 - val_loss: 2.7160 - val_acc: 0.1616\n",
            "Epoch 60/250\n",
            "89/89 [==============================] - 27s 303ms/step - loss: 2.2291 - acc: 0.2583 - val_loss: 2.7061 - val_acc: 0.1466\n",
            "Epoch 61/250\n",
            "89/89 [==============================] - 27s 294ms/step - loss: 2.1758 - acc: 0.2690 - val_loss: 2.7126 - val_acc: 0.1509\n",
            "Epoch 62/250\n",
            "89/89 [==============================] - 27s 295ms/step - loss: 2.1696 - acc: 0.2541 - val_loss: 2.7266 - val_acc: 0.1616\n",
            "Epoch 63/250\n",
            "89/89 [==============================] - 27s 294ms/step - loss: 2.1980 - acc: 0.2661 - val_loss: 2.7386 - val_acc: 0.1530\n",
            "Epoch 64/250\n",
            "89/89 [==============================] - 27s 292ms/step - loss: 2.1472 - acc: 0.2647 - val_loss: 2.7275 - val_acc: 0.1616\n",
            "Epoch 65/250\n",
            "89/89 [==============================] - 27s 297ms/step - loss: 2.2302 - acc: 0.2569 - val_loss: 2.7364 - val_acc: 0.1595\n",
            "Epoch 66/250\n",
            "89/89 [==============================] - 27s 297ms/step - loss: 2.1899 - acc: 0.2590 - val_loss: 2.7255 - val_acc: 0.1573\n",
            "Epoch 67/250\n",
            "89/89 [==============================] - 26s 288ms/step - loss: 2.1695 - acc: 0.2640 - val_loss: 2.7140 - val_acc: 0.1573\n",
            "Epoch 68/250\n",
            "89/89 [==============================] - 26s 280ms/step - loss: 2.2002 - acc: 0.2598 - val_loss: 2.7271 - val_acc: 0.1616\n",
            "Epoch 69/250\n",
            "89/89 [==============================] - 27s 291ms/step - loss: 2.1846 - acc: 0.2640 - val_loss: 2.7335 - val_acc: 0.1509\n",
            "Epoch 70/250\n",
            "89/89 [==============================] - 27s 301ms/step - loss: 2.1529 - acc: 0.2803 - val_loss: 2.7046 - val_acc: 0.1573\n",
            "Epoch 71/250\n",
            "89/89 [==============================] - 21s 225ms/step - loss: 2.1837 - acc: 0.2704 - val_loss: 2.7053 - val_acc: 0.1595\n",
            "Epoch 72/250\n",
            "89/89 [==============================] - 27s 287ms/step - loss: 2.1608 - acc: 0.2683 - val_loss: 2.6975 - val_acc: 0.1616\n",
            "Epoch 73/250\n",
            "89/89 [==============================] - 27s 293ms/step - loss: 2.1663 - acc: 0.2654 - val_loss: 2.7139 - val_acc: 0.1573\n",
            "Epoch 74/250\n",
            "89/89 [==============================] - 27s 302ms/step - loss: 2.1713 - acc: 0.2647 - val_loss: 2.7282 - val_acc: 0.1573\n",
            "Epoch 75/250\n",
            "89/89 [==============================] - 28s 303ms/step - loss: 2.1879 - acc: 0.2789 - val_loss: 2.7161 - val_acc: 0.1595\n",
            "Epoch 76/250\n",
            "89/89 [==============================] - 27s 296ms/step - loss: 2.2006 - acc: 0.2456 - val_loss: 2.7038 - val_acc: 0.1659\n",
            "Epoch 77/250\n",
            "89/89 [==============================] - 22s 242ms/step - loss: 2.2003 - acc: 0.2669 - val_loss: 2.7081 - val_acc: 0.1509\n",
            "Epoch 78/250\n",
            "89/89 [==============================] - 26s 285ms/step - loss: 2.1986 - acc: 0.2541 - val_loss: 2.7060 - val_acc: 0.1616\n",
            "Epoch 79/250\n",
            "89/89 [==============================] - 21s 231ms/step - loss: 2.1819 - acc: 0.2562 - val_loss: 2.6891 - val_acc: 0.1703\n",
            "Epoch 80/250\n",
            "89/89 [==============================] - 30s 329ms/step - loss: 2.2033 - acc: 0.2520 - val_loss: 2.6989 - val_acc: 0.1703\n",
            "Epoch 81/250\n",
            "89/89 [==============================] - 24s 258ms/step - loss: 2.2241 - acc: 0.2754 - val_loss: 2.7247 - val_acc: 0.1659\n",
            "Epoch 82/250\n",
            "89/89 [==============================] - 26s 285ms/step - loss: 2.1581 - acc: 0.2811 - val_loss: 2.6945 - val_acc: 0.1595\n",
            "Epoch 83/250\n",
            "89/89 [==============================] - 26s 292ms/step - loss: 2.2095 - acc: 0.2470 - val_loss: 2.7077 - val_acc: 0.1573\n",
            "Epoch 84/250\n",
            "89/89 [==============================] - 27s 300ms/step - loss: 2.1922 - acc: 0.2633 - val_loss: 2.7295 - val_acc: 0.1530\n",
            "Epoch 85/250\n",
            "89/89 [==============================] - 27s 300ms/step - loss: 2.1659 - acc: 0.2839 - val_loss: 2.7276 - val_acc: 0.1509\n",
            "Epoch 86/250\n",
            "89/89 [==============================] - 27s 296ms/step - loss: 2.1674 - acc: 0.2605 - val_loss: 2.7085 - val_acc: 0.1616\n",
            "Epoch 87/250\n",
            "89/89 [==============================] - 26s 289ms/step - loss: 2.1507 - acc: 0.2740 - val_loss: 2.7096 - val_acc: 0.1616\n",
            "Epoch 88/250\n",
            "89/89 [==============================] - 22s 237ms/step - loss: 2.1933 - acc: 0.2704 - val_loss: 2.7224 - val_acc: 0.1616\n",
            "Epoch 89/250\n",
            "89/89 [==============================] - 28s 306ms/step - loss: 2.2083 - acc: 0.2647 - val_loss: 2.7318 - val_acc: 0.1616\n",
            "Epoch 90/250\n",
            "89/89 [==============================] - 28s 307ms/step - loss: 2.2035 - acc: 0.2683 - val_loss: 2.7167 - val_acc: 0.1573\n",
            "Epoch 91/250\n",
            "89/89 [==============================] - 29s 320ms/step - loss: 2.1677 - acc: 0.2732 - val_loss: 2.7095 - val_acc: 0.1595\n",
            "Epoch 92/250\n",
            "89/89 [==============================] - 29s 315ms/step - loss: 2.1621 - acc: 0.2725 - val_loss: 2.7210 - val_acc: 0.1659\n",
            "Epoch 93/250\n",
            "89/89 [==============================] - 28s 315ms/step - loss: 2.2022 - acc: 0.2598 - val_loss: 2.7093 - val_acc: 0.1638\n",
            "Epoch 94/250\n",
            "89/89 [==============================] - 29s 316ms/step - loss: 2.1684 - acc: 0.2690 - val_loss: 2.6937 - val_acc: 0.1681\n",
            "Epoch 95/250\n",
            "89/89 [==============================] - 21s 234ms/step - loss: 2.2071 - acc: 0.2583 - val_loss: 2.6871 - val_acc: 0.1638\n",
            "Epoch 96/250\n",
            "89/89 [==============================] - 28s 302ms/step - loss: 2.1905 - acc: 0.2832 - val_loss: 2.7085 - val_acc: 0.1552\n",
            "Epoch 97/250\n",
            "89/89 [==============================] - 28s 302ms/step - loss: 2.1227 - acc: 0.2661 - val_loss: 2.7289 - val_acc: 0.1616\n",
            "Epoch 98/250\n",
            "89/89 [==============================] - 28s 298ms/step - loss: 2.1763 - acc: 0.2725 - val_loss: 2.7148 - val_acc: 0.1595\n",
            "Epoch 99/250\n",
            "89/89 [==============================] - 27s 294ms/step - loss: 2.1726 - acc: 0.2619 - val_loss: 2.7074 - val_acc: 0.1724\n",
            "Epoch 100/250\n",
            "89/89 [==============================] - 28s 300ms/step - loss: 2.1716 - acc: 0.2669 - val_loss: 2.7021 - val_acc: 0.1595\n",
            "Epoch 101/250\n",
            "89/89 [==============================] - 27s 293ms/step - loss: 2.1636 - acc: 0.2647 - val_loss: 2.7038 - val_acc: 0.1724\n",
            "Epoch 102/250\n",
            "89/89 [==============================] - 27s 287ms/step - loss: 2.2274 - acc: 0.2654 - val_loss: 2.7031 - val_acc: 0.1616\n",
            "Epoch 103/250\n",
            "89/89 [==============================] - 28s 305ms/step - loss: 2.1860 - acc: 0.2505 - val_loss: 2.7341 - val_acc: 0.1595\n",
            "Epoch 104/250\n",
            "89/89 [==============================] - 28s 312ms/step - loss: 2.1632 - acc: 0.2718 - val_loss: 2.7077 - val_acc: 0.1595\n",
            "Epoch 105/250\n",
            "89/89 [==============================] - 23s 250ms/step - loss: 2.2082 - acc: 0.2747 - val_loss: 2.7312 - val_acc: 0.1616\n",
            "Epoch 106/250\n",
            "89/89 [==============================] - 26s 284ms/step - loss: 2.1879 - acc: 0.2640 - val_loss: 2.7232 - val_acc: 0.1681\n",
            "Epoch 107/250\n",
            "89/89 [==============================] - 28s 307ms/step - loss: 2.1397 - acc: 0.2747 - val_loss: 2.7439 - val_acc: 0.1444\n",
            "Epoch 108/250\n",
            "89/89 [==============================] - 26s 284ms/step - loss: 2.1956 - acc: 0.2548 - val_loss: 2.7199 - val_acc: 0.1573\n",
            "Epoch 109/250\n",
            "89/89 [==============================] - 26s 287ms/step - loss: 2.1507 - acc: 0.2740 - val_loss: 2.7042 - val_acc: 0.1659\n",
            "Epoch 110/250\n",
            "89/89 [==============================] - 26s 289ms/step - loss: 2.1734 - acc: 0.2619 - val_loss: 2.7149 - val_acc: 0.1638\n",
            "Epoch 111/250\n",
            "89/89 [==============================] - 27s 299ms/step - loss: 2.1611 - acc: 0.2619 - val_loss: 2.7102 - val_acc: 0.1681\n",
            "Epoch 112/250\n",
            "89/89 [==============================] - 27s 300ms/step - loss: 2.1382 - acc: 0.2903 - val_loss: 2.6936 - val_acc: 0.1681\n",
            "Epoch 113/250\n",
            "89/89 [==============================] - 29s 319ms/step - loss: 2.1691 - acc: 0.2661 - val_loss: 2.7132 - val_acc: 0.1703\n",
            "Epoch 114/250\n",
            "89/89 [==============================] - 21s 228ms/step - loss: 2.1924 - acc: 0.2661 - val_loss: 2.7231 - val_acc: 0.1681\n",
            "Epoch 115/250\n",
            "89/89 [==============================] - 28s 302ms/step - loss: 2.1111 - acc: 0.2796 - val_loss: 2.7406 - val_acc: 0.1681\n",
            "Epoch 116/250\n",
            "89/89 [==============================] - 28s 303ms/step - loss: 2.1610 - acc: 0.2520 - val_loss: 2.7082 - val_acc: 0.1595\n",
            "Epoch 117/250\n",
            "89/89 [==============================] - 28s 308ms/step - loss: 2.1454 - acc: 0.2711 - val_loss: 2.7386 - val_acc: 0.1595\n",
            "Epoch 118/250\n",
            "89/89 [==============================] - 26s 290ms/step - loss: 2.2232 - acc: 0.2697 - val_loss: 2.7266 - val_acc: 0.1595\n",
            "Epoch 119/250\n",
            "89/89 [==============================] - 25s 276ms/step - loss: 2.1632 - acc: 0.2690 - val_loss: 2.7100 - val_acc: 0.1659\n",
            "Epoch 120/250\n",
            "89/89 [==============================] - 27s 295ms/step - loss: 2.1729 - acc: 0.2725 - val_loss: 2.7042 - val_acc: 0.1616\n",
            "Epoch 121/250\n",
            "89/89 [==============================] - 27s 300ms/step - loss: 2.1582 - acc: 0.2626 - val_loss: 2.7189 - val_acc: 0.1552\n",
            "Epoch 122/250\n",
            "89/89 [==============================] - 27s 298ms/step - loss: 2.1749 - acc: 0.2747 - val_loss: 2.7276 - val_acc: 0.1509\n",
            "Epoch 123/250\n",
            "89/89 [==============================] - 22s 244ms/step - loss: 2.2100 - acc: 0.2477 - val_loss: 2.7409 - val_acc: 0.1573\n",
            "Epoch 124/250\n",
            "89/89 [==============================] - 26s 285ms/step - loss: 2.1942 - acc: 0.2569 - val_loss: 2.7534 - val_acc: 0.1530\n",
            "Epoch 125/250\n",
            "89/89 [==============================] - 26s 289ms/step - loss: 2.1567 - acc: 0.2775 - val_loss: 2.7204 - val_acc: 0.1659\n",
            "Epoch 126/250\n",
            "89/89 [==============================] - 27s 292ms/step - loss: 2.1422 - acc: 0.2789 - val_loss: 2.7341 - val_acc: 0.1638\n",
            "Epoch 127/250\n",
            "89/89 [==============================] - 28s 309ms/step - loss: 2.1815 - acc: 0.2626 - val_loss: 2.7333 - val_acc: 0.1616\n",
            "Epoch 128/250\n",
            "89/89 [==============================] - 26s 288ms/step - loss: 2.1386 - acc: 0.2718 - val_loss: 2.7574 - val_acc: 0.1573\n",
            "Epoch 129/250\n",
            "89/89 [==============================] - 26s 289ms/step - loss: 2.1622 - acc: 0.2569 - val_loss: 2.7558 - val_acc: 0.1530\n",
            "Epoch 130/250\n",
            "89/89 [==============================] - 26s 286ms/step - loss: 2.1670 - acc: 0.2775 - val_loss: 2.7684 - val_acc: 0.1530\n",
            "Epoch 131/250\n",
            "89/89 [==============================] - 27s 293ms/step - loss: 2.1677 - acc: 0.2619 - val_loss: 2.7707 - val_acc: 0.1573\n",
            "Epoch 132/250\n",
            "89/89 [==============================] - 26s 287ms/step - loss: 2.1812 - acc: 0.2718 - val_loss: 2.7482 - val_acc: 0.1573\n",
            "Epoch 133/250\n",
            "89/89 [==============================] - 26s 286ms/step - loss: 2.1493 - acc: 0.2732 - val_loss: 2.7543 - val_acc: 0.1509\n",
            "Epoch 134/250\n",
            "89/89 [==============================] - 26s 284ms/step - loss: 2.1883 - acc: 0.2683 - val_loss: 2.7466 - val_acc: 0.1595\n",
            "Epoch 135/250\n",
            "89/89 [==============================] - 26s 280ms/step - loss: 2.1434 - acc: 0.2619 - val_loss: 2.7417 - val_acc: 0.1595\n",
            "Epoch 136/250\n",
            "89/89 [==============================] - 26s 285ms/step - loss: 2.1996 - acc: 0.2342 - val_loss: 2.7253 - val_acc: 0.1552\n",
            "Epoch 137/250\n",
            "89/89 [==============================] - 26s 286ms/step - loss: 2.1890 - acc: 0.2612 - val_loss: 2.7318 - val_acc: 0.1659\n",
            "Epoch 138/250\n",
            "89/89 [==============================] - 26s 286ms/step - loss: 2.1634 - acc: 0.2825 - val_loss: 2.7451 - val_acc: 0.1595\n",
            "Epoch 139/250\n",
            "89/89 [==============================] - 21s 232ms/step - loss: 2.1651 - acc: 0.2555 - val_loss: 2.7190 - val_acc: 0.1616\n",
            "Epoch 140/250\n",
            "89/89 [==============================] - 28s 308ms/step - loss: 2.1543 - acc: 0.2704 - val_loss: 2.7271 - val_acc: 0.1659\n",
            "Epoch 141/250\n",
            "89/89 [==============================] - 28s 309ms/step - loss: 2.1483 - acc: 0.2683 - val_loss: 2.7120 - val_acc: 0.1638\n",
            "Epoch 142/250\n",
            "89/89 [==============================] - 29s 323ms/step - loss: 2.1679 - acc: 0.2647 - val_loss: 2.7597 - val_acc: 0.1616\n",
            "Epoch 143/250\n",
            "89/89 [==============================] - 26s 287ms/step - loss: 2.1947 - acc: 0.2484 - val_loss: 2.7340 - val_acc: 0.1573\n",
            "Epoch 144/250\n",
            "89/89 [==============================] - 26s 284ms/step - loss: 2.1740 - acc: 0.2612 - val_loss: 2.7315 - val_acc: 0.1681\n",
            "Epoch 145/250\n",
            "89/89 [==============================] - 27s 291ms/step - loss: 2.1865 - acc: 0.2647 - val_loss: 2.7245 - val_acc: 0.1703\n",
            "Epoch 146/250\n",
            "89/89 [==============================] - 27s 293ms/step - loss: 2.1498 - acc: 0.2491 - val_loss: 2.7479 - val_acc: 0.1638\n",
            "Epoch 147/250\n",
            "89/89 [==============================] - 26s 288ms/step - loss: 2.1171 - acc: 0.2974 - val_loss: 2.7207 - val_acc: 0.1703\n",
            "Epoch 148/250\n",
            "89/89 [==============================] - 29s 316ms/step - loss: 2.1120 - acc: 0.2860 - val_loss: 2.7143 - val_acc: 0.1681\n",
            "Epoch 149/250\n",
            "89/89 [==============================] - 26s 287ms/step - loss: 2.1581 - acc: 0.2676 - val_loss: 2.7106 - val_acc: 0.1616\n",
            "Epoch 150/250\n",
            "89/89 [==============================] - 27s 293ms/step - loss: 2.1189 - acc: 0.2874 - val_loss: 2.7295 - val_acc: 0.1659\n",
            "Epoch 151/250\n",
            "89/89 [==============================] - 26s 279ms/step - loss: 2.1977 - acc: 0.2548 - val_loss: 2.7243 - val_acc: 0.1552\n",
            "Epoch 152/250\n",
            "89/89 [==============================] - 27s 292ms/step - loss: 2.1748 - acc: 0.2534 - val_loss: 2.7304 - val_acc: 0.1703\n",
            "Epoch 153/250\n",
            "89/89 [==============================] - 26s 286ms/step - loss: 2.1586 - acc: 0.2811 - val_loss: 2.7172 - val_acc: 0.1509\n",
            "Epoch 154/250\n",
            "89/89 [==============================] - 28s 303ms/step - loss: 2.1595 - acc: 0.2711 - val_loss: 2.7017 - val_acc: 0.1703\n",
            "Epoch 155/250\n",
            "89/89 [==============================] - 27s 297ms/step - loss: 2.1362 - acc: 0.2732 - val_loss: 2.7091 - val_acc: 0.1681\n",
            "Epoch 156/250\n",
            "89/89 [==============================] - 27s 294ms/step - loss: 2.1410 - acc: 0.2704 - val_loss: 2.7143 - val_acc: 0.1703\n",
            "Epoch 157/250\n",
            "89/89 [==============================] - 26s 289ms/step - loss: 2.1866 - acc: 0.2512 - val_loss: 2.7308 - val_acc: 0.1659\n",
            "Epoch 158/250\n",
            "89/89 [==============================] - 27s 301ms/step - loss: 2.1671 - acc: 0.2789 - val_loss: 2.7315 - val_acc: 0.1616\n",
            "Epoch 159/250\n",
            "89/89 [==============================] - 27s 300ms/step - loss: 2.1557 - acc: 0.2598 - val_loss: 2.7498 - val_acc: 0.1659\n",
            "Epoch 160/250\n",
            "89/89 [==============================] - 27s 301ms/step - loss: 2.1374 - acc: 0.2640 - val_loss: 2.7516 - val_acc: 0.1659\n",
            "Epoch 161/250\n",
            "89/89 [==============================] - 28s 311ms/step - loss: 2.1753 - acc: 0.2789 - val_loss: 2.7303 - val_acc: 0.1703\n",
            "Epoch 162/250\n",
            "89/89 [==============================] - 21s 230ms/step - loss: 2.1231 - acc: 0.2775 - val_loss: 2.7320 - val_acc: 0.1681\n",
            "Epoch 163/250\n",
            "89/89 [==============================] - 26s 282ms/step - loss: 2.1260 - acc: 0.2853 - val_loss: 2.7213 - val_acc: 0.1638\n",
            "Epoch 164/250\n",
            "89/89 [==============================] - 27s 299ms/step - loss: 2.1093 - acc: 0.2761 - val_loss: 2.7546 - val_acc: 0.1616\n",
            "Epoch 165/250\n",
            "89/89 [==============================] - 27s 294ms/step - loss: 2.1498 - acc: 0.2718 - val_loss: 2.7459 - val_acc: 0.1573\n",
            "Epoch 166/250\n",
            "89/89 [==============================] - 28s 314ms/step - loss: 2.1634 - acc: 0.2598 - val_loss: 2.7346 - val_acc: 0.1573\n",
            "Epoch 167/250\n",
            "89/89 [==============================] - 30s 330ms/step - loss: 2.1597 - acc: 0.2718 - val_loss: 2.7269 - val_acc: 0.1573\n",
            "Epoch 168/250\n",
            "89/89 [==============================] - 28s 308ms/step - loss: 2.1652 - acc: 0.2697 - val_loss: 2.7636 - val_acc: 0.1616\n",
            "Epoch 169/250\n",
            "89/89 [==============================] - 27s 292ms/step - loss: 2.1180 - acc: 0.2697 - val_loss: 2.7369 - val_acc: 0.1703\n",
            "Epoch 170/250\n",
            "89/89 [==============================] - 28s 305ms/step - loss: 2.1760 - acc: 0.2569 - val_loss: 2.7475 - val_acc: 0.1595\n",
            "Epoch 171/250\n",
            "89/89 [==============================] - 27s 298ms/step - loss: 2.1147 - acc: 0.2704 - val_loss: 2.7336 - val_acc: 0.1552\n",
            "Epoch 172/250\n",
            "89/89 [==============================] - 26s 289ms/step - loss: 2.1620 - acc: 0.2514 - val_loss: 2.7203 - val_acc: 0.1616\n",
            "Epoch 173/250\n",
            "89/89 [==============================] - 28s 306ms/step - loss: 2.1707 - acc: 0.2690 - val_loss: 2.7214 - val_acc: 0.1681\n",
            "Epoch 174/250\n",
            "89/89 [==============================] - 27s 297ms/step - loss: 2.1753 - acc: 0.2690 - val_loss: 2.7251 - val_acc: 0.1616\n",
            "Epoch 175/250\n",
            "89/89 [==============================] - 29s 322ms/step - loss: 2.1691 - acc: 0.2449 - val_loss: 2.7262 - val_acc: 0.1659\n",
            "Epoch 176/250\n",
            "89/89 [==============================] - 26s 286ms/step - loss: 2.1732 - acc: 0.2498 - val_loss: 2.7227 - val_acc: 0.1573\n",
            "Epoch 177/250\n",
            "89/89 [==============================] - 27s 295ms/step - loss: 2.1416 - acc: 0.2590 - val_loss: 2.7337 - val_acc: 0.1552\n",
            "Epoch 178/250\n",
            "89/89 [==============================] - 26s 288ms/step - loss: 2.1519 - acc: 0.2669 - val_loss: 2.7153 - val_acc: 0.1530\n",
            "Epoch 179/250\n",
            "89/89 [==============================] - 28s 305ms/step - loss: 2.1867 - acc: 0.2697 - val_loss: 2.7153 - val_acc: 0.1573\n",
            "Epoch 180/250\n",
            "89/89 [==============================] - 28s 304ms/step - loss: 2.1887 - acc: 0.2520 - val_loss: 2.7271 - val_acc: 0.1659\n",
            "Epoch 181/250\n",
            "89/89 [==============================] - 28s 307ms/step - loss: 2.1306 - acc: 0.2768 - val_loss: 2.7082 - val_acc: 0.1638\n",
            "Epoch 182/250\n",
            "89/89 [==============================] - 27s 297ms/step - loss: 2.1621 - acc: 0.2633 - val_loss: 2.7175 - val_acc: 0.1703\n",
            "Epoch 183/250\n",
            "89/89 [==============================] - 21s 229ms/step - loss: 2.1542 - acc: 0.2931 - val_loss: 2.7209 - val_acc: 0.1659\n",
            "Epoch 184/250\n",
            "89/89 [==============================] - 28s 303ms/step - loss: 2.1337 - acc: 0.2803 - val_loss: 2.7114 - val_acc: 0.1616\n",
            "Epoch 185/250\n",
            "89/89 [==============================] - 23s 249ms/step - loss: 2.1622 - acc: 0.2548 - val_loss: 2.7137 - val_acc: 0.1681\n",
            "Epoch 186/250\n",
            "89/89 [==============================] - 26s 289ms/step - loss: 2.1409 - acc: 0.2740 - val_loss: 2.7245 - val_acc: 0.1638\n",
            "Epoch 187/250\n",
            "89/89 [==============================] - 27s 298ms/step - loss: 2.1511 - acc: 0.2796 - val_loss: 2.7155 - val_acc: 0.1724\n",
            "Epoch 188/250\n",
            "89/89 [==============================] - 28s 316ms/step - loss: 2.1141 - acc: 0.2811 - val_loss: 2.7259 - val_acc: 0.1638\n",
            "Epoch 189/250\n",
            "89/89 [==============================] - 27s 298ms/step - loss: 2.1578 - acc: 0.2647 - val_loss: 2.7318 - val_acc: 0.1659\n",
            "Epoch 190/250\n",
            "89/89 [==============================] - 28s 297ms/step - loss: 2.1454 - acc: 0.2825 - val_loss: 2.7393 - val_acc: 0.1552\n",
            "Epoch 191/250\n",
            "89/89 [==============================] - 22s 238ms/step - loss: 2.1507 - acc: 0.2782 - val_loss: 2.7397 - val_acc: 0.1681\n",
            "Epoch 192/250\n",
            "89/89 [==============================] - 27s 291ms/step - loss: 2.1485 - acc: 0.2740 - val_loss: 2.7173 - val_acc: 0.1573\n",
            "Epoch 193/250\n",
            "89/89 [==============================] - 26s 284ms/step - loss: 2.1009 - acc: 0.2782 - val_loss: 2.7313 - val_acc: 0.1595\n",
            "Epoch 194/250\n",
            "89/89 [==============================] - 26s 290ms/step - loss: 2.1849 - acc: 0.2612 - val_loss: 2.7341 - val_acc: 0.1616\n",
            "Epoch 195/250\n",
            "89/89 [==============================] - 26s 288ms/step - loss: 2.0974 - acc: 0.2945 - val_loss: 2.7312 - val_acc: 0.1659\n",
            "Epoch 196/250\n",
            "89/89 [==============================] - 21s 226ms/step - loss: 2.1599 - acc: 0.2768 - val_loss: 2.7480 - val_acc: 0.1595\n",
            "Epoch 197/250\n",
            "89/89 [==============================] - 29s 316ms/step - loss: 2.1357 - acc: 0.2725 - val_loss: 2.7179 - val_acc: 0.1638\n",
            "Epoch 198/250\n",
            "89/89 [==============================] - 28s 313ms/step - loss: 2.2093 - acc: 0.2484 - val_loss: 2.7390 - val_acc: 0.1595\n",
            "Epoch 199/250\n",
            "89/89 [==============================] - 29s 316ms/step - loss: 2.1681 - acc: 0.2555 - val_loss: 2.7551 - val_acc: 0.1573\n",
            "Epoch 200/250\n",
            "89/89 [==============================] - 28s 310ms/step - loss: 2.1900 - acc: 0.2534 - val_loss: 2.7576 - val_acc: 0.1595\n",
            "Epoch 201/250\n",
            "89/89 [==============================] - 27s 298ms/step - loss: 2.1290 - acc: 0.2583 - val_loss: 2.7454 - val_acc: 0.1659\n",
            "Epoch 202/250\n",
            "89/89 [==============================] - 26s 289ms/step - loss: 2.1448 - acc: 0.2846 - val_loss: 2.7717 - val_acc: 0.1638\n",
            "Epoch 203/250\n",
            "89/89 [==============================] - 26s 281ms/step - loss: 2.1760 - acc: 0.2683 - val_loss: 2.7452 - val_acc: 0.1681\n",
            "Epoch 204/250\n",
            "89/89 [==============================] - 26s 282ms/step - loss: 2.1453 - acc: 0.2626 - val_loss: 2.7708 - val_acc: 0.1595\n",
            "Epoch 205/250\n",
            "89/89 [==============================] - 27s 292ms/step - loss: 2.0865 - acc: 0.2839 - val_loss: 2.7453 - val_acc: 0.1659\n",
            "Epoch 206/250\n",
            "89/89 [==============================] - 26s 284ms/step - loss: 2.1380 - acc: 0.2740 - val_loss: 2.7529 - val_acc: 0.1659\n",
            "Epoch 207/250\n",
            "89/89 [==============================] - 26s 288ms/step - loss: 2.1827 - acc: 0.2796 - val_loss: 2.7475 - val_acc: 0.1659\n",
            "Epoch 208/250\n",
            "89/89 [==============================] - 26s 286ms/step - loss: 2.1643 - acc: 0.2747 - val_loss: 2.7560 - val_acc: 0.1681\n",
            "Epoch 209/250\n",
            "89/89 [==============================] - 26s 291ms/step - loss: 2.1678 - acc: 0.2633 - val_loss: 2.7437 - val_acc: 0.1616\n",
            "Epoch 210/250\n",
            "89/89 [==============================] - 28s 307ms/step - loss: 2.1543 - acc: 0.2768 - val_loss: 2.7344 - val_acc: 0.1573\n",
            "Epoch 211/250\n",
            "89/89 [==============================] - 30s 327ms/step - loss: 2.1242 - acc: 0.2818 - val_loss: 2.7558 - val_acc: 0.1746\n",
            "Epoch 212/250\n",
            "89/89 [==============================] - 27s 294ms/step - loss: 2.1376 - acc: 0.2803 - val_loss: 2.7379 - val_acc: 0.1616\n",
            "Epoch 213/250\n",
            "89/89 [==============================] - 27s 300ms/step - loss: 2.1064 - acc: 0.2874 - val_loss: 2.7433 - val_acc: 0.1681\n",
            "Epoch 214/250\n",
            "89/89 [==============================] - 27s 298ms/step - loss: 2.1469 - acc: 0.2768 - val_loss: 2.7369 - val_acc: 0.1616\n",
            "Epoch 215/250\n",
            "89/89 [==============================] - 27s 294ms/step - loss: 2.1470 - acc: 0.2669 - val_loss: 2.7173 - val_acc: 0.1638\n",
            "Epoch 216/250\n",
            "89/89 [==============================] - 27s 299ms/step - loss: 2.0988 - acc: 0.2718 - val_loss: 2.7415 - val_acc: 0.1552\n",
            "Epoch 217/250\n",
            "89/89 [==============================] - 26s 289ms/step - loss: 2.0953 - acc: 0.2853 - val_loss: 2.7377 - val_acc: 0.1681\n",
            "Epoch 218/250\n",
            "89/89 [==============================] - 28s 310ms/step - loss: 2.1427 - acc: 0.2839 - val_loss: 2.7381 - val_acc: 0.1552\n",
            "Epoch 219/250\n",
            "89/89 [==============================] - 21s 232ms/step - loss: 2.1441 - acc: 0.2626 - val_loss: 2.7352 - val_acc: 0.1616\n",
            "Epoch 220/250\n",
            "89/89 [==============================] - 28s 296ms/step - loss: 2.1742 - acc: 0.2676 - val_loss: 2.7695 - val_acc: 0.1595\n",
            "Epoch 221/250\n",
            "89/89 [==============================] - 22s 242ms/step - loss: 2.1451 - acc: 0.2789 - val_loss: 2.7628 - val_acc: 0.1552\n",
            "Epoch 222/250\n",
            "89/89 [==============================] - 26s 282ms/step - loss: 2.1261 - acc: 0.2903 - val_loss: 2.7476 - val_acc: 0.1616\n",
            "Epoch 223/250\n",
            "89/89 [==============================] - 21s 233ms/step - loss: 2.1478 - acc: 0.2576 - val_loss: 2.7568 - val_acc: 0.1616\n",
            "Epoch 224/250\n",
            "89/89 [==============================] - 26s 288ms/step - loss: 2.1446 - acc: 0.2583 - val_loss: 2.7403 - val_acc: 0.1638\n",
            "Epoch 225/250\n",
            "89/89 [==============================] - 26s 280ms/step - loss: 2.1497 - acc: 0.2754 - val_loss: 2.7621 - val_acc: 0.1616\n",
            "Epoch 226/250\n",
            "89/89 [==============================] - 30s 329ms/step - loss: 2.1724 - acc: 0.2562 - val_loss: 2.7733 - val_acc: 0.1530\n",
            "Epoch 227/250\n",
            "89/89 [==============================] - 26s 287ms/step - loss: 2.1163 - acc: 0.2896 - val_loss: 2.7751 - val_acc: 0.1552\n",
            "Epoch 228/250\n",
            "89/89 [==============================] - 27s 300ms/step - loss: 2.1686 - acc: 0.2718 - val_loss: 2.7419 - val_acc: 0.1638\n",
            "Epoch 229/250\n",
            "89/89 [==============================] - 26s 289ms/step - loss: 2.1652 - acc: 0.2761 - val_loss: 2.7307 - val_acc: 0.1595\n",
            "Epoch 230/250\n",
            "89/89 [==============================] - 26s 285ms/step - loss: 2.1829 - acc: 0.2626 - val_loss: 2.7543 - val_acc: 0.1573\n",
            "Epoch 231/250\n",
            "89/89 [==============================] - 26s 285ms/step - loss: 2.1546 - acc: 0.2889 - val_loss: 2.7353 - val_acc: 0.1616\n",
            "Epoch 232/250\n",
            "89/89 [==============================] - 21s 229ms/step - loss: 2.1028 - acc: 0.2811 - val_loss: 2.7533 - val_acc: 0.1573\n",
            "Epoch 233/250\n",
            "89/89 [==============================] - 28s 309ms/step - loss: 2.1277 - acc: 0.2761 - val_loss: 2.7371 - val_acc: 0.1638\n",
            "Epoch 234/250\n",
            "89/89 [==============================] - 27s 297ms/step - loss: 2.1833 - acc: 0.2576 - val_loss: 2.7586 - val_acc: 0.1573\n",
            "Epoch 235/250\n",
            "89/89 [==============================] - 28s 304ms/step - loss: 2.1305 - acc: 0.2903 - val_loss: 2.7664 - val_acc: 0.1595\n",
            "Epoch 236/250\n",
            "89/89 [==============================] - 27s 300ms/step - loss: 2.1571 - acc: 0.2754 - val_loss: 2.7504 - val_acc: 0.1638\n",
            "Epoch 237/250\n",
            "89/89 [==============================] - 27s 301ms/step - loss: 2.1570 - acc: 0.2811 - val_loss: 2.7424 - val_acc: 0.1638\n",
            "Epoch 238/250\n",
            "89/89 [==============================] - 26s 289ms/step - loss: 2.1472 - acc: 0.2683 - val_loss: 2.7441 - val_acc: 0.1724\n",
            "Epoch 239/250\n",
            "89/89 [==============================] - 26s 283ms/step - loss: 2.1445 - acc: 0.2768 - val_loss: 2.7617 - val_acc: 0.1681\n",
            "Epoch 240/250\n",
            "89/89 [==============================] - 26s 291ms/step - loss: 2.1261 - acc: 0.2761 - val_loss: 2.7623 - val_acc: 0.1616\n",
            "Epoch 241/250\n",
            "89/89 [==============================] - 29s 319ms/step - loss: 2.1171 - acc: 0.2732 - val_loss: 2.7222 - val_acc: 0.1616\n",
            "Epoch 242/250\n",
            "89/89 [==============================] - 26s 285ms/step - loss: 2.1710 - acc: 0.2456 - val_loss: 2.7629 - val_acc: 0.1595\n",
            "Epoch 243/250\n",
            "89/89 [==============================] - 26s 282ms/step - loss: 2.1466 - acc: 0.2768 - val_loss: 2.7491 - val_acc: 0.1573\n",
            "Epoch 244/250\n",
            "89/89 [==============================] - 22s 241ms/step - loss: 2.1550 - acc: 0.2633 - val_loss: 2.7534 - val_acc: 0.1573\n",
            "Epoch 245/250\n",
            "89/89 [==============================] - 26s 285ms/step - loss: 2.0992 - acc: 0.2789 - val_loss: 2.7299 - val_acc: 0.1595\n",
            "Epoch 246/250\n",
            "89/89 [==============================] - 21s 226ms/step - loss: 2.1701 - acc: 0.2683 - val_loss: 2.7363 - val_acc: 0.1595\n",
            "Epoch 247/250\n",
            "89/89 [==============================] - 28s 311ms/step - loss: 2.1565 - acc: 0.2661 - val_loss: 2.7554 - val_acc: 0.1616\n",
            "Epoch 248/250\n",
            "89/89 [==============================] - 27s 302ms/step - loss: 2.1046 - acc: 0.2761 - val_loss: 2.7453 - val_acc: 0.1595\n",
            "Epoch 249/250\n",
            "89/89 [==============================] - 29s 324ms/step - loss: 2.1181 - acc: 0.2761 - val_loss: 2.7031 - val_acc: 0.1595\n",
            "Epoch 250/250\n",
            "89/89 [==============================] - 26s 286ms/step - loss: 2.1205 - acc: 0.2775 - val_loss: 2.7500 - val_acc: 0.1595\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "acc = history.history['acc']\n",
        "val_acc = history.history['val_acc']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs_x = range(len(acc))\n",
        "\n",
        "plt.plot(epochs_x, acc, 'co', label='Training acc')\n",
        "plt.plot(epochs_x, val_acc, 'k', label='Validation acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.figure()\n",
        "\n",
        "plt.plot(epochs_x, loss, 'co', label='Training loss')\n",
        "plt.plot(epochs_x, val_loss, 'k', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "kwylTJpTP5XI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545
        },
        "outputId": "547ef8f6-aff8-4232-c7bd-102b4f3f25cc"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAEICAYAAABRSj9aAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOydeXhV1dW435UEwhAGCRCECAG+BAIiU5hFUfErDj8oilVEBrFSpzrVtlht7WfLp1WraNUqzlIstciHWMEJQVECggoqBhKIAcIQIExhSkiyf3/cew7n3pxz77lThut+n4eH3DOus88+a6+99tpri1IKjUaj0cQvCXUtgEaj0Whii1b0Go1GE+doRa/RaDRxjlb0Go1GE+doRa/RaDRxjlb0Go1GE+doRf8jRESWisjUaB9bl4hIkYiMjsF1lYj8l/fv50Tk926ODeM+k0Tkg3Dl1GgCITqOvmEgIkctP5sB5UCV9/cvlFLzal+q+oOIFAE/V0p9FOXrKiBTKbUlWseKSAbwA9BIKVUZDTk1mkAk1bUAGncopVKMvwMpNRFJ0spDU1/Q9bF+oF03DRwRGSUixSLyWxHZA7wiImeIyH9EZJ+IHPT+nW45Z4WI/Nz79zQR+UxEHvMe+4OIXBLmsV1F5FMRKRORj0TkGRH5h4PcbmT8k4h87r3eByLS1rJ/sohsE5FSEbkvQPkMEZE9IpJo2TZeRL7x/j1YRHJF5JCI7BaRp0WkscO1XhWRP1t+/9p7zi4Rme537GUi8rWIHBGRHSLyR8vuT73/HxKRoyIyzChby/nDRWStiBz2/j/cbdmEWM5tROQV7zMcFJFFln3jRGS99xm2isgY73YfN5mI/NF4zyKS4XVh3SAi24GPvdv/7X0Ph711pLfl/KYi8lfv+zzsrWNNReRdEfml3/N8IyLj7Z5V44xW9PFBB6AN0AWYgee9vuL93Rk4ATwd4PwhwGagLfAI8JKISBjHvgF8AaQCfwQmB7inGxmvBa4H2gONgXsARKQX8Hfv9Tt675eODUqpNcAx4EK/677h/bsKuMv7PMOAi4BbAsiNV4YxXnkuBjIB//GBY8AUoDVwGXCziPzUu+887/+tlVIpSqlcv2u3Ad4FnvI+2+PAuyKS6vcMNcrGhmDlPBePK7C391pPeGUYDLwO/Nr7DOcBRU7lYcP5QDbwE+/vpXjKqT3wFWB1NT4GDASG46nHvwGqgdeA64yDRKQv0AlP2WhCQSml/zWwf3g+uNHev0cBFUCTAMf3Aw5afq/A4/oBmAZssexrBiigQyjH4lEilUAzy/5/AP9w+Ux2Mt5v+X0L8J737z8A8y37mnvLYLTDtf8MvOz9uwUeJdzF4dg7gf+z/FbAf3n/fhX4s/fvl4GHLcdlWY+1ue5s4Anv3xneY5Ms+6cBn3n/ngx84Xd+LjAtWNmEUs7AmXgU6hk2xz1vyBuo/nl//9F4z5Zn6xZAhtbeY1rhaYhOAH1tjmsCHMQz7gGeBuHZ2v7e4uGftujjg31KqZPGDxFpJiLPe7vCR/C4Clpb3Rd+7DH+UEod9/6ZEuKxHYEDlm0AO5wEdinjHsvfxy0ydbReWyl1DCh1uhce6/0KEUkGrgC+Ukpt88qR5XVn7PHK8b94rPtg+MgAbPN7viEistzrMjkM3OTyusa1t/lt24bHmjVwKhsfgpTzWXje2UGbU88CtrqU1w6zbEQkUUQe9rp/jnC6Z9DW+6+J3b28dfpfwHUikgBMxNMD0YSIVvTxgX/o1K+AHsAQpVRLTrsKnNwx0WA30EZEmlm2nRXg+Ehk3G29tveeqU4HK6W+x6MoL8HXbQMeF9AmPFZjS+B34ciAp0dj5Q1gMXCWUqoV8JzlusFC3XbhcbVY6QzsdCGXP4HKeQeed9ba5rwdQHeHax7D05sz6GBzjPUZrwXG4XFvtcJj9Rsy7AdOBrjXa8AkPC6148rPzaVxh1b08UkLPN3hQ15/7wOxvqHXQl4H/FFEGovIMOD/xUjGBcDlInKud+D0QYLX5TeAO/Aoun/7yXEEOCoiPYGbXcrwJjBNRHp5Gxp/+VvgsZZPev3d11r27cPjMunmcO0lQJaIXCsiSSJyNdAL+I9L2fzlsC1npdRuPL7zZ72Dto1ExGgIXgKuF5GLRCRBRDp5ywdgPXCN9/gcYIILGcrx9Lqa4ek1GTJU43GDPS4iHb3W/zBv7wuvYq8G/oq25sNGK/r4ZDbQFI+1tBp4r5buOwnPgGYpHr/4v/B84HaELaNSaiNwKx7lvRuPH7c4yGn/xDNA+LFSar9l+z14lHAZ8IJXZjcyLPU+w8fAFu//Vm4BHhSRMjxjCm9azj0OzAI+F0+0z1C/a5cCl+OxxkvxDE5e7ie3W4KV82TgFJ5ezV48YxQopb7AM9j7BHAY+ITTvYzf47HADwL/g28PyY7X8fSodgLfe+Wwcg/wLbAWOAD8BV/d9DrQB8+YjyYM9IQpTcwQkX8Bm5RSMe9RaOIXEZkCzFBKnVvXsjRUtEWviRoiMkhEunu7+mPw+GUXBTtPo3HC6xa7BZhT17I0ZLSi10STDnhC/47iiQG/WSn1dZ1KpGmwiMhP8IxnlBDcPaQJgHbdaDQaTZyjLXqNRqOJc+pdUrO2bduqjIyMuhZDo9FoGhRffvnlfqVUO7t99U7RZ2RksG7duroWQ6PRaBoUIuI/m9pEu240Go0mztGKXqPRaOIcV4peRMaIyGYR2SIiM2323yQi33pzV3/mTSNr7LvXe95mb7iURqPRaGqRoIrem+XuGTwJoXoBE62K3MsbSqk+Sql+eHKUP+49txdwDZ5c12Pw5NRwyqCo0Wg0mhjgxqIfjCcHeaFSqgKYj2fGo4lS6ojlZ3NOZ64bhydveLlS6gc8OUEGRy62RqPRaNziRtF3wjfvdjG+ebEBEJFbRWQrHov+9hDPnSEi60Rk3b59+9zKrtHEHfNKSsjIzSVhxQoycnOZV1JS1yJp4oCoDcYqpZ5RSnUHfgvcH+K5c5RSOUqpnHbtbMNANZq4Z15JCTM2b2ZbeTkK2FZezozNm7Wy10SMG0W/E98FFtIJvADCfMBYGzPUczWaHy33FRZyvLraZ9vx6mruKyysI4k08YIbRb8WyBSRrt5FHq7Bs3KOiYhkWn5eBhR4/16MZ4GCZBHpimdx4C8iF1ujiT+2l9un7nfartG4JejMWKVUpYjcBrwPJOJZZHmjiDwIrFNKLQZuE5HReBYwOAhM9Z67UUTexLPYQCVwq1KqKkbPotE0aDonJ7PNRql3Tk6uA2liz7ySEu4rLGR7eTmdk5OZ1a0bk9LS6lqsuKTeZa/MyclROgWC5seI4aO3um+aJSQwp0ePuFOAP6ZnrS1E5EulVI7dPj0zVqOpJ0xKS2NOjx50SU5GgC7JyfVe8YUbJaTHI2qXepfUTKP5MTMpLa1eK3Yr/la5ESUEBH0GPR5Ru2iLXqPRhEUkVrnTuEO8jkfUNVrRa+IePQkpNkRilc/q1o1mCb7qp1lCArO6dYuKbG6JtG40lLqlXTeauCYS94ImMJFECRllX5dRN4HqhhvZGlLd0lE3mrgmIzfXVhl1SU6maNiwOpAofmjokTNOdSM1MZETStV4rqkdOrCktNRU/kerqiitrKxxfl3VrUBRN9qi18Q1etAvdtQHqzwSnOpAaVXNqT7Hq6t5btcuM1ujXQMR7Lp1iVb0mrimoU9Cqu+TiupjlJDbMnOqG0649X3Ux7qlB2M1cU19GfQLB53kLHRCKTOnupGaFL79W1/rllb0mrimIU9Cui4vT08qCpFQQj6d6saTmZk1GgBxuF9qYmKDqFvadaOJe+qje8EJuwFOf0LxAdd310+0cSqbbeXlZOTm1iiHQHXDWm6Xpqby2p49NQZon8zKahDlqRW9RlOPsLNI/XHrA25I4X92hNNIOfndhdMDqG7Kwa4BGNGqVYNtNHV4pSam/NgsykhJWLEi4KBfKOGLDTm01K5n0whomZTEgcpK17Ht4FHydmWampjI/pEjY/MAdYBOaqapEyIZTGwoMw6jTSBrPVQfcEMOLbXr2ZwCSisrA9YlO7+7U8NZWlX1o6lXWtFrYka4uVDiLdoklEbLKRLkH9nZFA0bFlJvqL7kkwmn0XbTGFnrkvUe9xUWMqtbN6pHjaJo2DC6BHjeH8vAtlb0mqhjfHROMcrBPuJ4SmEbaqMVKEooVIVZl6GlhqyyYgWT8/JCbrTdNkbby8uDlnGg5w21d+P0Dup7D1T76DW2hOtbdxM1EsxH7OSnFqB61KjgwtcjouUnDzfdQG2Mkfjfwy5CxZ9gz++mHhnXAfuZqonAa9nZTEpLo+1nn0WcrsDpHUzt0ME2Iqe2Qy0j9tGLyBgR2SwiW0Rkps3+u0XkexH5RkSWiUgXy75HRGSjiOSJyFMi4hSSqqknROI6CRY14saijLXLoTatr2j5ycPt5UxKS6No2DDTjRELJe9fV/6+a1dQBR3s+f17NqmJiTS2UR1Hq6oce45VYNZbu9j4UHs3Tu9gjs3z1rceaFBFLyKJwDPAJUAvYKKI9PI77GsgRyl1DrAAeMR77nBgBHAOcDYwCDg/atJrYkIgpRJMSQb6gN0OJsbS5RBuIxZu4xCtRitYg2GVr+3KlbT97LNaacjchIPa4TbDpdFI7R85kpd79iQ1MdHnmNLKSsfJTHC63tq5xKZ26MB9hYWuy8npHTgtgm13fF25eNxY9IOBLUqpQqVUBTAfGGc9QCm1XCl13PtzNZBu7AKaAI2BZDwRUvXLeaWpQaBJJ8GUpNMHbHSR3ViUsZzNGo5lHEkPJ1qNVqAGw1++Um9WxdoYyA43gseYwBSKXJPS0kixSU+gcJ65CqdltDYcs7p147U9e0J6p07vINF2a83j6zLIwI2i7wTssPwu9m5z4gZgKYBSKhdYDuz2/ntfKZXnf4KIzBCRdSKybt++fW5l18SIQBU6mJKMlmKLlcshHFfKHQUFts99R35+UOssWo1WoHINZlUbssaCSNxp4Sg6p/ekcK9wIbwG3+kdzOjY0VWdj6SnHClRjboRkeuAHOBR7+//ArLxWPidgAtFpMYMBaXUHKVUjlIqp127dtEUSRMGThXaTRe1vueWCdWVMq+kxHYQDzyWsxvrLBqNVqBydWNVRztm3BpZFcmg2/Hqaqbm5blWcIGMkCrsLfujNs8eToPv9A6ezcqqMZ7QNCGByXl5ZOTmcovXIHAaS3DTU44UN4p+J3CW5Xe6d5sPIjIauA8Yq5Qynmg8sFopdVQpdRSPpV+/p+RpHCu0Uzyy/8cX6wHASAi1xxHKgFqsB+CcytWtVX2dV/FEqkCsLgjwdZ04DZoGosp7DTcKzu79GdcwZPGntLLStYvRzt1itbQNGTonJ7O9vNy0xo13Mzc7mxNK+bjO/r5rV9B0yLEezA0aXikiSUA+cBEeBb8WuFYptdFyTH88g7BjlFIFlu1XAzcCY/DUhfeA2Uqpd5zup8Mr6y/BQvwaSrqDUOQMlpLAn7oIAXUbimgQaehfsJBR//J1WonJCTehl8b1E3AeDA10XTcpFuzCRBsBIkKFRW9azwtFnmCEWpcChVe6iqMXkUuB2Xh6SC8rpWaJyIPAOqXUYhH5COiDxw8PsF0pNdYbsfMscB6exvY9pdTdge6lFX39xklJ1uWycoZM28rLzS58lwgbGus17UgA7NRqXeWRsb4XwV42K5HIGeo8h1AbIrcKbl5JCdfl1Rjyc31da5m1SUykrLraR4E75ciJFkZddSLUdxSxoq9NtKJvmLiZGGTXSEBkS9EFUiLGhxqq0g+mmJwmybhJuhUtAvVK3CjWSHoegd61MThsZwjckZ/vs0xfOI2ltQEOVREHum4gH3os6OJ1/QSS/x/eyV5u0UnNNDHHTZy3/4DT9Xl5TN+0yWfb5Lw8brFEiASLRggUcWJd3zOUWHm7BT8MAg3AiUithDUGC9OzjrE4EUm0jNM4x6WpqQHlOuFnVCZCDX++AJemptre125swI5GNtcNFvlVm4neDFkCvYPUxMSoGgla0WuiQrDBLadshBV+H78Cntu1i3klJa7ijt1aYaHEyjshYFqEGbm5TPa6DeZmZ4Of39bNPcPFTWigMTj4j+xs28HL0srKsEP5nAbrl5SWOsrl9P4b4Rspo4DX9uyxlcnt5KxXsrN5uWdPs6EzwoKNgVM73DZ8do1IKCSC6c6c1a0bjWyOaSzCk1lZYd/DDr3wiCYqzOrWzdZHb1hRoVhMitPRLk6Kw3AHhNJ995ch1EE96+Qk62Ie1+flccrlPaNBKMniJqWl8fnhwzy3a5dPOR31ulDCXYzEbmGOyQ7+8kBlcMzGdWx9x26vY9AlOdnnPLcLr9jVX38E+HnHjj4LkNj59pslJDhep9pyb+N/q0srNSmJJzMzo+7y0xa9xpFQJnEEi58PZ8p/MHfQfYWFIflorTL49xaCKflAk5OclLz/PY37RjIxxmjc7GiTaD9laElpacByCjWW3YlAvbpopHwIdg1/90wk68falaTCU5Z2qRkiCUXeP3IkatQo1KhR7D/33JiM68S9Rd9QQv7qG3aWazjLrxnM6tYtoOXrj/FB2Fmvxr5AFp6/pe9GCThhHcx1slqdsN4znDL1J1DjVlZdbcZ0W3FjCRsNXSCZgn1LwXp1dvuaJiTYhl7aKXW76wcacA91UpS1/iasWOH6XKd6H6gsapu4tugb+gIW0Z4WHcr1op0TflJaGi1t8pQ4cbSqiktTUwNObgqUV2dudnbA2blulJ/dgh+hWKb+A2rRKNNAclcoZXutUK3p49XVXJeXh6xYQdvPPnM9XhKoV+e0L5SsknbXmJudjXKYmBdJQrlIk9HVtxnicWfRB/O7Ovn/wr1HLHN8u7H+3MoSqjUZKLFZuBwIMGmmuYiPv7a0spLX9uxhaocOLCkttX2+QBZkoN4FOC8ibWVqhw6ufLl2k2gAEPGxsKNRpsHktruHG/+zE6WVlUzftIkWiYkBx0sMApV7oH2B6nC431uwHka0z7WT0y6csy68DHGl6P2VWSjpQ8O9R7iDWdbrWQd2EHGcYef/YYUiSyBr0k5uJ4Ui3vuG86yBlNRxh0G5JaWljrHPhgzRUgL+LCktdX1PoEacuDH13jgv1DK1UwjB5LazOP1lDnXmTIV3Sr8d0RhsDtQARPK9BXpXGbm5AetMqHUrFMMsmvrDLXE1YcrtpIdIZgVGa8UgCH3GIPhOdAlFlnBmM07Oy7M9x2mqezAlG+nzRtsSmldSwtS8PEeDINRJRW5SAwQrU6tsTjONoWajYt0frEyiOTko1jOBI/nenCboxWIGt1s5o6k//PnRTJhy63eNZEAkWisGQXiLNlgttlBkcfItJoBjxkUnE8DNOp12GH7LUEgAczEN/8lVoY63zCspoe3KlciKFciKFdxRUMCMjh0do1iivThIsDK1EqwHtn/kSP4RZBzCCaf47VBpLBLzwcVwvzen+umUcjrS+Q5u5YyFS9QNcaXoA6UwjWRAxDqI6VRg4cw0DLVx8G+kQsnAd9Sh612FJ6uhMehmxSlETAFTbGaPul3aLtVhUNZO4RqZDUurqmwnJE3Jy3Ol7OeVlHB9Xl4N18pLu3dzYevWNe4d7cVBDJzKtJmIz0C5m1j5cLOETkpL45XsbJ/VmlKTkri5Y8eQGoAWCQlBe3CRBhOEOyjq1FDGygXlVk6n4wz3XayIK0XvNDX7tezssFPmuom3DreX4KZxCNRIuUm5a8jv3833p7SykslGpIV3KbpAucad+iFuLK0jNh9bYxFu6tgxYByzkxzTN20yc34HSpVgF9pZoRRbTpwIGqXjBjfvw8maPqaUj/UZbi/DrXK1i99+NivLtgFw4kCAOhWtiLdwF7IJVXFHuh6xWzlndetm+26tkwRjQVz56CH6flwn6yoRj5KJ5B5ukmcFUzj+z3tpaqpPlEqoKWIjJVgSM6eMkKmJiewfeXpNmnDSA/vHzVvLLtD1opla2E39a/vZZ67eSbBnsrt3bfqfUxMTSUlKsn3WaI9lBUrgZrcvkMwnlIpJltVg7z5YRtRI6+GPNnul24J3UpKzunVzHDwL9lJCCXu0i7qJdibH2sA/N72d0nGSzb88ozFgaFUqga4XrHGKRqiflVAaMSPLoZt7xWqgzyl3u39IqfX9hzr470aGUAZWnfZN7dCBN0tKQk45EOl7d/NtRvqeAin6uAqvtBIsjMlu/9937TLPN45vk5Rka305TTd3c28rweK93RDMUoglTj0bJx+pUw5u/65zJLHfBtvKy2m7cmVAt5V1QDGcOjNj82Y+P3zYx0CwMxis79hNDD+E/uFHM1DAil2ooV1P0TpY7PSM4bhInMq9qY3hYMhglJu/IeefWvqEi/oVrRnNgepyrGfNxq1FH8y6idRibCzCyz172r7oWIZQ+ROOFW9k4LNLKBUKgcogkNXqb9k7dZ3tcphHE39rLtw6Eyyxmv80fahpbfoTjjuhNutdMIs9mBspFAs51G/VqdcQbvlEo1wDfQ+RLpJjEHF4pYiMEZHNIrJFRGba7L9bRL4XkW9EZJmIdLHs6ywiH4hInveYjHAfJBSCWTeRWjlO080DXXubNywxmrgJ0UxNTPQZaHwlO5uj559vhueBfcSLQbOEBG7u2LHGIJ2TkofAlltTEVKTkoIOfE5KSyMlSNoEI1rEfyAs0PN0SU62TSAVbp0J1lz658UHT6raVIdeYWpSUswGg6NFsCiTQCkAQh2ojdbAarg9nmj0lAKl66iNdZWDum68ywE+A1wMFANrRWSxUup7y2FfAzlKqeMicjPwCHC1d9/rwCyl1IcikkLwVc6iQrCuo9vucyCcXnSga0d7FlywytYsIYEns7IcFan/oJb/yj1Wq/fZEHJkB3K9lFZV0SwhgbmWFXScLDyn5/O32qypY8NJEwC1U2esroX7CgtteyspESw60VSE496//Xss0QxUcJMiwMktGa1Z2k4Dq04NW7jupGi4oSJJxxAN3Fj0g4EtSqlCpVQFMB8YZz1AKbVcKWXUr9VAOoCI9AKSlFIfeo87ajkupgSzbpxWkw8Fpxcd6NpuJ2e4DZMLVtncWIZOSh7c+TDtsFp0dljLIZCF5zY+2T+mPJzVlcKpM+EsQRGshxBOb9MujNb67iIJd7Sri5Ek7Qr1uZ3ey5N+q3wFkyHcHk80ekp1neTMzWBsJ2CH5XcxMCTA8TcAS71/ZwGHRGQh0BX4CJiplIqN09VCsFwVdvsvTU31GZEPRKAXbVzbaeFit7P6Ag3+uBmAtS7C4GTN+d/L3w0RSRI4w6Jz8k9a88rbWXjX5eWRmphIY5voDjcfp11a5ECzOcOtM/4DfMEI1kMIZ8AymJUcqhVtEKwuRjPnkf96AdZyDpTcLpSJYmD/fgP1diLJqeR//9pS7P5ENepGRK4DcoDzLdcfCfQHtgP/AqYBL/mdNwOYAdC5c+eoyROsYO32LyktdVT0xmLGbgZPjI8rnA852EfpZgDWqgwDfaxufPzRmDUYbl750qoqGuFxQ4QSdmrsD3X1nnDqjL/byIi6sesh+fcQotWdD3d8Idi7DbeBCESw57arr6/t2RMVC9ju/d2Sn++zApedYeV/ntHLaSjrXLhR9DuBsyy/073bfBCR0cB9wPlKKaP2FAPrlVKF3mMWAUPxU/RKqTnAHPBE3YT4DFElUMWvxtNV31ZebrodAr1cp4USnBY/DiZDIAsYQg91dBuS6WY2ZiQLUgTzfZ/C47fef+65QWW1Es3Q1VAsQDfnG/JB5JYihD++0CYxMaDCikXIZrDnjkXj4sS8kpIayywa97suL4/7Cgtt51LURQbKSHDjpF4LZIpIVxFpDFwDLLYeICL9geeBsUqpvX7nthaRdt7fFwLWQdyoEsvcGgb+rX6wJF5TO3RwvfhxMBmCWcDVYJvqIVAUUDAfs5sc3JEsSAHuxkuikQ43VJye7Zb8fNf+bmPsYG52NuBZV9VaN/3HFiKxkkMdX2iEZ1WqQM8Rbq6ZYDg997ySkpDWxI2UYMtR2pVJtBflqQ2CKnqlVCVwG/A+kAe8qZTaKCIPishY72GPAinAv0VkvYgs9p5bBdwDLBORb/EYtC/E4DmCKhy3jUAog7T+L9fuHnbrdQY7L9yVleySmWXk5jpW5EQChwa6GTByW+kDKbRgA7fgXrFEo7E3cHq2Obt2hfShR5r3xc0zBWtM7fa3TEqyTRRnfY5QBiIjLXujnJyItHGxw03j4V8msZqYFkviZsJUoEkNTq4DJyUWykzTYBNEgk35dzov0OCT3TkC3NSxoxkCGWk6BOVymro4rK0ZyVT3cPO1RDvXSzj5dqI5UQdil78G3K9R4MZNFQ05A02MitYzh3JPK+GuA1Gb/Cjy0QdqZUPtahnW5z+ys4Na90a+9KkOaXudEiUY1omTbEY6hrl+a5Ya8gVzCYWT694gkGVtZV5JSdRyuRtEEoYW7S51oLTXoRwfiQXo9Ex35OcHPTcY4Yauhhob75ZA5RGrUES3PXhrmdTmxLRoETeKPlClDeSjDpbK1epSCJQv3SkgswpsK9LRqirmlZQErNyBuvjBXELhdiNDqbBO/k2BiCp9uH7raHepnT7oGTYzcYNN1AlluxUn2Uu99ScSoqmwYjl7NJy5Cm7xNyyMcF4rdhPB6tPC326IG0UfqNIG+qC2lZdj5GG3U/qG0lGjRvnkLHebL13wLDLtP93dWE+0TZAp/k5WUbAPK1SLOpwKG25KgFgRikKNxO/9bC1N1An0TBB5/vJwFJZTuUVj0LaucrVbDYv9I0fycs+eQcskWoPotUXc+OjB/aSgQLj1BYbivzXydrudxm2H8vrzjeezWzwcTvsJ/WODwTn5Vri+xbrwqQbCrZ84ln7vQLKFE0Y5r6TEceKd4HHtRSutgZsUzaGmBQ61TKM95vNj4kebj95KKAOsbhRfNBdYTvXmoXdajMIYaA02AzPQRyfAha1bk3vkSNQUXLAGNJaDU5HEt9fXwTQnnBYqieYiGm4aPzeLn0fa6DS0d1Of0IreghsF7cZ6mFdSgtOiJHY45WE3MCJt7CZvwOlZuXbX9cTwFGEAACAASURBVJ8kFSwCKZorcAWzOGNhhUVqkUd7UYxY4/S8TRMSbBuAcJSim1WkamuFrtrubcULP4qoG7e4GWV341eclJYWki+6isCDSserq20HWA2c7Hi7SVKB/PfR9i1OSktzjNKJRdwzRB7hEatJQJHi5P928qUfiOJC14EGfbcFUPIQ3XJriAOdDYG4XWHKCes062C5SILRJcjU/VCP3V5eHtI1wf4jc1oVK1aKrLZTsEYa4eFW3mim9bXDfxnJsupqcwKTXfIw/3uHm0vJjnBTMEfrPce6rH/s/OgsenCOpAnVepjVrRuNXBzXLCGBS1NTg0bqGBU8lPTJdsrpiI2SD5S1MVLsrLCpHTpwX2FhVGao+hOpRe7Gaox0Nmsw/K9fWlUVdJaqP9EMjwy13kXT2o51WWviyEcfqUUQ7vlOA2VW37mbVLaBllkrrazkqE1GzdTERPaPHOmzLZCv1f/YWBFrP2tt+HFjPSgYzoxMO6JpCftfy25dWIj+wKgegI0Ocb84eKTZ5CI538lPavjOwVORg63+7p/V0Jru4Hqbwc7GIjxps+KTk/viQBTXXQ2mXGKdfTCaWR+diHU+E7fXCdZLiUaGTqdrOTWo0e4ZNsTcMW6pLy6puFD0kSqWSM53s4iC2+XwnGTzXzwDoEVCgq1s0VzMwg43jWJtfLjRVHB2xLoc3fjE63JavaGgjDQeVURvEWt/Yl3WdUV9SmccFz76cFMcBDvfjWJy4yeNxRR4Jws91nk43ES81NeollCIdTk6pQ12s2h6rLH6zOF0Go9YWaMNMXeMG+pTOuO4UPTBUhwYAzuxmL7tZmAvFlPgFTimbIhleJqbRjEePtxYl6Pd9V/Jzmb/uefW+bT62lZQ8RpSWZ9cUnExGOsmxYHd9P9oT98OJmO4U+ADPVttTyZxO3BWX3yTmtBpaBPK6iu1Pcgc94Ox/rHxdthVXMNKMQo9loopXJ9ysGeL1RJrTriNQY+1D10TO+LVZ17b1Pb8kkDEhUVvJdQcNA3JSqkvlpa21uMbnYYgetTmtxJxrhsRGQM8iSc8/EWl1MN+++8Gfg5UAvuA6UqpbZb9LfGsFbtIKXVboHtFqujDWVkpVtEE0UbHG2tqC92YNzwict2ISCLwDHAxUAysFZHFSinrIt9fAzlKqeMicjPwCHC1Zf+fgE/DfYBQ8I+xdkrna6UhrOIO9asrqIlvtOstvnATdTMY2KKUKlRKVQDzgXHWA5RSy5VSx70/VwPpxj4RGQikAR9ER+TgWBN3veZiOUCo/6u4Q/xGJ2g0mtjiZjC2E7DD8rsYGBLg+BuApQAikgD8FbgOGO10gojMAGYAdO7c2YVI7rGbRenkw99eXu66y1pXXVttaWk0mlCJatSNiFwH5ADnezfdAixRShWLOCfpVUrNAeaAx0cfTZmgpnJ08nW3SUx0NZOtPs1402g0mmC4cd3sBM6y/E73bvNBREYD9wFjlVKGFh0G3CYiRcBjwBQRedj/3NrGaUIPIq4mitSnGW8ajUYTDDeKfi2QKSJdRaQxcA2w2HqAiPQHnsej5Pca25VSk5RSnZVSGcA9wOtKqZlRkz5MIl3IoT7NeNNoNJpgBHXdKKUqReQ24H084ZUvK6U2isiDwDql1GLgUSAF+LfXRbNdKTU2hnJHTCQLOegJJRqNpiHhykevlFoCLPHb9gfL344DrZZjXgVeDU282sVt+KIOc9S4Qceia+oLcZHULFq4DV/UYY6aYOhVkzT1ibhLgaDR1Af0LGZNbRNoZqy26DWaGKAH7DX1ibjIXqnR1Dca6oD9qVOnKC4u5uTJk3UtisaBJk2akJ6eTqNGjVyfoxW9RhMDGuqAfXFxMS1atCAjI4NAkxw1dYNSitLSUoqLi+natavr87TrRqOJAQ11wP7kyZOkpqZqJV9PERFSU1ND7nFpi16jiRENNS+RVvL1m3Dej7boNRpNvaG0tJR+/frRr18/OnToQKdOnczfFRUVAc9dt24dt99+e9B7DB8+PFriNhi0Ra/RaMIm2pPCUlNTWb9+PQB//OMfSUlJ4Z577jH3V1ZWkpRkr7ZycnLIybGNLvRh1apVYcvXUNEWvUajCYvamhQ2bdo0brrpJoYMGcJvfvMbvvjiC4YNG0b//v0ZPnw4m72ZY1esWMHll18OeBqJ6dOnM2rUKLp168ZTTz1lXi8lJcU8ftSoUUyYMIGePXsyadIkjHlFS5YsoWfPngwcOJDbb7/dvK6VoqIiRo4cyYABAxgwYIBPA/KXv/yFPn360LdvX2bO9KT32rJlC6NHj6Zv374MGDCArVu3RrWcAqEteo1GExaBsrhGe2yiuLiYVatWkZiYyJEjR1i5ciVJSUl89NFH/O53v+Ott96qcc6mTZtYvnw5ZWVl9OjRg5tvvrlGSOLXX3/Nxo0b6dixIyNGjODzzz8nJyeHX/ziF3z66ad07dqViRMn2srUvn17PvzwQ5o0aUJBQQETJ05k3bp1LF26lLfffps1a9bQrFkzDhw4AMCkSZOYOXMm48eP5+TJk1SHsNxppGhFr9FowqI2J4VdddVVJCYmAnD48GGmTp1KQUEBIsKpU6dsz7nssstITk4mOTmZ9u3bU1JSQnp6us8xgwcPNrf169ePoqIiUlJS6Natmxm+OHHiRObMmVPj+qdOneK2225j/fr1JCYmkp+fD8BHH33E9ddfT7NmzQBo06YNZWVl7Ny5k/HjxwOeWPjaRLtu6pB5JSVk5OaSsGIFGbm5Og+KpkHhNPkrFpPCmjdvbv79+9//ngsuuIDvvvuOd955xzHUMNkiR2JiIpU2acjdHOPEE088QVpaGhs2bGDdunVBB4vrEq3o6wid9ErT0HFawCfWk8IOHz5Mp06dAHj11Vejfv0ePXpQWFhIUVERAP/6178c5TjzzDNJSEhg7ty5VFVVAXDxxRfzyiuvcPy4ZxntAwcO0KJFC9LT01m0aBEA5eXl5v7aQCv6OkKvUqVp6NTVpLDf/OY33HvvvfTv3z8kC9wtTZs25dlnn2XMmDEMHDiQFi1a0KpVqxrH3XLLLbz22mv07duXTZs2mb2OMWPGMHbsWHJycujXrx+PPfYYAHPnzuWpp57inHPOYfjw4ezZsyfqsjuhs1fWEQkrVmBX8gJUjxpVy9JoNB7y8vLIzs6uazHqnKNHj5KSkoJSiltvvZXMzEzuuuuuuhbLxO496eyV9ZDa9G9qNJrQeOGFF+jXrx+9e/fm8OHD/OIXv6hrkSLClaIXkTEisllEtohIjTVfReRuEfleRL4RkWUi0sW7vZ+I5IrIRu++q6P9AA2VuvJvajSa4Nx1112sX7+e77//nnnz5pkRNA2VoIpeRBKBZ4BLgF7ARBHp5XfY10COUuocYAHwiHf7cWCKUqo3MAaYLSKtoyV8Q6ahJr3SaDQNDzdx9IOBLUqpQgARmQ+MA743DlBKLbccvxq4zrs933LMLhHZC7QDDkUuesOnoSa90mg0DQs3rptOwA7L72LvNiduAJb6bxSRwUBjoMa8XxGZISLrRGTdvn37XIik0Wg0GrdEdTBWRK4DcoBH/bafCcwFrldK1Zj3q5Sao5TKUUrltGvXLpoiaTQazY8eN4p+J3CW5Xe6d5sPIjIauA8Yq5Qqt2xvCbwL3KeUWh2ZuBqNJp654IILeP/99322zZ49m5tvvtnxnFGjRmGEZF966aUcOlTTM/zHP/7RjGd3YtGiRXz/vemR5g9/+AMfffRRKOLXW9wo+rVApoh0FZHGwDXAYusBItIfeB6Pkt9r2d4Y+D/gdaXUguiJrdFo4pGJEycyf/58n23z5893TCzmz5IlS2jdOrx4D39F/+CDDzJ69OiwrlXfCKrolVKVwG3A+0Ae8KZSaqOIPCgiY72HPQqkAP8WkfUiYjQEPwPOA6Z5t68XkX7RfwyNRhMPTJgwgXfffdfMG1NUVMSuXbsYOXIkN998Mzk5OfTu3ZsHHnjA9vyMjAz2798PwKxZs8jKyuLcc881UxmDJ0Z+0KBB9O3blyuvvJLjx4+zatUqFi9ezK9//Wv69evH1q1bmTZtGgsWeOzTZcuW0b9/f/r06cP06dMp9yZuy8jI4IEHHmDAgAH06dOHTZs21ZCpPqQzdpW9Uim1BFjit+0Plr9tmz2l1D+Af0QioEajqRvuvPNOcxGQaNGvXz9mz57tuL9NmzYMHjyYpUuXMm7cOObPn8/PfvYzRIRZs2bRpk0bqqqquOiii/jmm28455xzbK/z5ZdfMn/+fNavX09lZSUDBgxg4MCBAFxxxRXceOONANx///289NJL/PKXv2Ts2LFcfvnlTJgwwedaJ0+eZNq0aSxbtoysrCymTJnC3//+d+68804A2rZty1dffcWzzz7LY489xosvvuhzfn1IZ6xnxmo0mnqF1X1jddu8+eabDBgwgP79+7Nx40YfN4s/K1euZPz48TRr1oyWLVsyduxYc993333HyJEj6dOnD/PmzWPjxo0B5dm8eTNdu3YlKysLgKlTp/Lpp5+a+6+44goABg4caCZCs3Lq1CluvPFG+vTpw1VXXWXK7TadcTQma+l89BqNxpZAlncsGTduHHfddRdfffUVx48fZ+DAgfzwww889thjrF27ljPOOINp06Y5picOxrRp01i0aBF9+/bl1VdfZcWKFRHJa6Q6dkpzbE1nXF1dXeu56EFb9BqNpp6RkpLCBRdcwPTp001r/siRIzRv3pxWrVpRUlLC0qU1pur4cN5557Fo0SJOnDhBWVkZ77zzjrmvrKyMM888k1OnTjFv3jxze4sWLSgrK6txrR49elBUVMSWLVsATxbK888/3/Xz1Id0xlrRazSaesfEiRPZsGGDqej79u1L//796dmzJ9deey0jRowIeP6AAQO4+uqr6du3L5dccgmDBg0y9/3pT39iyJAhjBgxgp49e5rbr7nmGh599FH69+/vMwDapEkTXnnlFa666ir69OlDQkICN910k+tnqQ/pjHWaYo1GY6LTFDcMdJpijUaj0figFb1Go9HEOVrRazQaTZyjFb1Go/Ghvo3baXwJ5/1oRa/RaEyaNGlCaWmpVvb1FKUUpaWlIcfi6wlTGo3GJD09neLiYvS6EPWXJk2akJ6eHtI5WtFrNBqTRo0a0bVr17oWQxNltOtGo9Fo4hyt6DUajSbO0Ypeo9Fo4hyt6DUajSbO0Ypeo9Fo4hxXil5ExojIZhHZIiIzbfbfLSLfi8g3IrJMRLpY9k0VkQLvv6nRFF6j0Wg0wQmq6EUkEXgGuAToBUwUkV5+h30N5CilzgEWAI94z20DPAAMAQYDD4jIGdETX6PRaDTBcGPRDwa2KKUKlVIVwHxgnPUApdRypZSRHX81YETz/wT4UCl1QCl1EPgQGBMd0TUajUbjBjeKvhOww/K72LvNiRsAY/kXV+eKyAwRWSci6/SMPI1Go4kuUR2MFZHrgBzg0VDOU0rNUUrlKKVy2rVrF02RNBqN5kePG0W/EzjL8jvdu80HERkN3AeMVUqVh3KuRqPRaGKHG0W/FsgUka4i0hi4BlhsPUBE+gPP41Hyey273gf+W0TO8A7C/rd3m0aj0WhqiaBJzZRSlSJyGx4FnQi8rJTaKCIPAuuUUovxuGpSgH+LCMB2pdRYpdQBEfkTnsYC4EGl1IGYPIlGo9FobNGLg2s0Gk0coBcH12g0mh8xWtFrNBpNnKMVvUaj0cQ5WtFrNBpNnKMVvUaj0cQ5WtFrNBpNnKMVvUaj0cQ5WtFrNBpNnKMVvUaj0cQ5WtFrNBpNnKMVvUaj0cQ5WtFrNBpNnKMVvUaj0cQ5WtFrNBpNnKMVvUaj0cQ5WtFrNBpNnKMVvUaj0cQ5rhS9iIwRkc0iskVEZtrsP09EvhKRShGZ4LfvERHZKCJ5IvKUeNca1Gg0Gk3tEFTRi0gi8AxwCdALmCgivfwO2w5MA97wO3c4MAI4BzgbGAScH7HUGo1Go3FN0MXBgcHAFqVUIYCIzAfGAd8bByilirz7qv3OVUAToDEgQCOgJGKpNRqNRuMaN66bTsAOy+9i77agKKVygeXAbu+/95VSef7HicgMEVknIuv27dvn5tIajUajcUlMB2NF5L+AbCAdT+NwoYiM9D9OKTVHKZWjlMpp165dLEXSaDSaHx1uFP1O4CzL73TvNjeMB1YrpY4qpY4CS4FhoYmo0Wg0mkhwo+jXApki0lVEGgPXAItdXn87cL6IJIlIIzwDsTVcNxqNRqOJHUEVvVKqErgNeB+Pkn5TKbVRRB4UkbEAIjJIRIqBq4DnRWSj9/QFwFbgW2ADsEEp9U4MnkOj0Wg0DohSqq5l8CEnJ0etW7eursXQaDSaBoWIfKmUyrHbp2fGajSauGDjxo1MmDCBioqKuhal3qEVvUajiQuWL1/OW2+9RWFhYV2LUu/Qil6j0cQFR44cAeDAgQN1LEn9Qyt6TYPgu+++o3379hQXF/PTn/6UBx54oK5F0gTg1ltvZdq0abV6T0PRl5aW1up9rSxbtoyOHTvWqQx2uEmBoNHUORs2bGDfvn3k5eWRm5vLiRMn6lokTQBWrlzJsWPHavWe9UHRr169mt27d/P5558zduzYOpPDH23Ra6LC/v37WbFiBVu2bInJ9Y3ueGlpKQcOHGDv3r1hXSc/P5/6Fmlm8MMPP3Dq1CnKysrYvXt3jf3l5eXs3OmZq1hYWEhVVRVlZWXs2rWrxrEnT55k+/btQe958ODBiBTj3r17TQVrpbi4mOLi4lot6/rguikuLgY8Cr8+oRW9JipMmTKFCy64gH79+nHy5MmoX99QRkVFRVRWVlJSEnpuvE8++YQePXrwyiuvRFu8iCkoKCArK4uXXnqJX//61/Tv379Gr+Vvf/sbffr0oaysjO7du/Ozn/2MqVOnMmLEiBoK9eGHH6Znz57s2bMn4H2nT5/OtddeG7bcY8aM4aabbvLZduzYMQ4ePEhFRQX79+8P+9qhUh8seq3oNXFNQUEBKSkpHDt2jPXr10f9+sbHW1BQAMC+ffuorvZPlhqYxx9/3Py/vln1Tz31FJWVlWzYsIENGzZQUlLCG2/4ZP1m27ZtHDx40LTqFy5cyKJFiygqKmLHjh0+x37yySecOHGC5557LuB98/Lywu6FVVZW8u2337J8+XKf8jTkg9OKrzY4fPgwUD8U/RdffEFVVVWdyeGPVvRhoJTin//8Z63H63722Wds2rTJcf/JkyeZN29eyAowUpRSFBcXmz7JSKyZI0eO8NZbb9XY7q/oKysrOXjwoM8x33zzjW0js2nTJh588EHeeecdzj77bDZu3Mjdd9/NmjVrwpYzmhw6dMjsZRQUFJCfnw/AE0884aNADx06BODj1jH2W8u8srKStWvXAvDss8869rCM9+bvBlu9ejWbN28OKrfRu9qzZw87duxAKcX8+fN9Gg5rA7RmzRrz2ULBuK7/cyilWLhwoVk3rBb9smXLajQy//nPf2rUmWhTXFzMGWecwbFjx9i4cWPwE2oLpVS9+jdw4EBV31m7dq0C1Pz582v1vnjy+6vq6mrb/Q8//LAC1KpVq2pVrv379ytAzZ49W3Xu3Fn97Gc/C/taDz30kALU999/77P9Jz/5iQJUWlqaWQ7+x4wYMUKNHDmyxjXHjRunANW6dWv1ww8/qG7duilADRo0KGw5o8miRYsUoLp3765atWqlAJWVlaUAVVBQYB53+eWXK0DNmzfPLIMZM2aopk2bqjvvvNM8bv369QpQkydPVoBaunSp7X0PHjxoXufYsWPm9oyMDDV27Nigci9ZssQ8f/78+eqLL75QgBo5cqS5/ZlnnjGP79Gjh7ryyitDLp+VK1eaz21l1apVClD/+7//q5RS5ns977zzVJMmTdTNN99sHltaWqoA9dhjj4V8f7ecOHFCAWrKlCkKUK+88krM7mUHsE456FVt0YeBYVG5sXpiwaefflpj26lTp3j66acBXA3CRRPDckpPT2fo0KERWfS5ublAzV6BYbVZffP+fvpNmzbVGBhUSpGbm8t1113Hvn37yMjIID8/n+uvv76Gu6OuMPzoF110kel+uOKKK4DTPRioadF/8sknPP/88+Tk5PiUl1GG99xzDwkJCY7vw2rxGlb9iRMnKCoqclW3Des8KSnJpxfw2WefAZCYmOhzj5KSEttB5mAYz+Nfr5944gng9HdovPsNGzZw8uRJn2cw1rkIdxDfDYbLauTIkSQlJfm8u7om7hT9c889x4cffsjWrVu59957g/rJli1bxgsvvBDSPQwFE043NFys7pjZs2dTXl7OnXfeaVbct956y/yoasMvWlRUxL333kt1dbWPoh82bBjbt2+3jQQJxHPPPcc777xjKiUnRW/F+tEeOHCA0tJSjh8/DnjK67e//S1Lly5l7969jBgxgqQkTzRxYmIiXbp0oaSkxMf99sILL7B06VJb+b766iseeOCBsHz7L730Eu+//z7gUaS33367jx/beI4RI0aY2y699FLAU8ceeeQRvvjiixqKPiUlBYChQ4fy1VdfUV5ezgMPPMBjjz1G+/bt6dOnD2effbYrRW/UacPtsnXrVrZs2cJvfvObGt/QgQMHuP3221m7di2tWrViyJAhrF692vwelFKkpqbSqVMnvvrqK26//XbKyso4dOhQjcb5kUcecZRv2bJlPPHEE+b+4uJi5s+fz/jx4/npT3/KwoULzTKC04reaCyt36cRiRPLiByjPLt27UrXrl1rVT8ExcnUr6t/kbhuKioqVNOmTdXYsWNNF8CXX34Z8Jwrr7xSdejQIaT7zJo1SwFq8ODBYcsaKocOHTK7wx06dDC7rU899ZRSSqkhQ4aozMxM1bx5c59ufKz485//rAD1ww8/qOeee04Bqri4WH3yyScKUO+9915I10tNTTXdFiKizjnnHJ/9xj7rP+PZlVJq9erVClAdO3ZUSilVVFSkAPO8r7/+2ud6L774ogJUUVGRua1t27ZqxIgRtvL96le/UoBasWJFSM+llFLp6enq4osvVkop9Z///EcB6pZbbjH333bbbap169Zq3bp1ClAJCQmqvLxctWrVSl1zzTUKUDfffLNKT09XgLr22msVoPLz85VSSr311lsKUO+++64CVHp6uvrTn/6klFJqxowZqnXr1qqqqqqGXHPmzDHLcvHixT7XAtTEiRMVoPLy8nzO+9e//mUek5OTo+655x7VuHFjNX78eHN737591fDhw83fxjktWrQwr2O4U6ZOnWpbbobLrUWLFgpQ48aNUwMHDlQtW7ZU55xzjho+fLi67LLLVNu2bdXJkydr1A8sLql33nlHAWr8+PEhvz+3zJ07VwFq06ZN6rLLLlN9+/aN2b3s4Mfiuvn22285ceKEGcMLwQcGS0tLQ47gsFr0qpaiNwxrrl27dpSWlpoW7urVq8nNzWXNmjXccccdpKen14pFb3RLDx8+THFxMYmJiXTo0IGsrCyf/W4wrHHDEhs3bhzfffcdZWVlgGdw0dgH0KJFCxISEnwsesN6Mix6owwOHz5M8+bNOfvss33umZ6e7nPcwYMH2b9/P19++aXtILtR3oa7wC1KKfbu3WuWh1EfX331VdO6LCkpIS0tjczMTMBjETZu3JjMzEzefvtt85hAFj3Ak08+CcDcuXO5//77zX2HDh2ydcXYWfRWK3TRokU1jvP/nZWVxbBhw6ioqOC9994zZUpPTzfLGDzRPQBlZWVm2OgXX3wBONcVY7tRD3bs2EF+fj5Tpkxhw4YNfP7554waNYr9+/ezbds2ADp27OhzDaOHYry/WEbkGOXSqVMnMjMzKSgoqDfRXXGl6K1dvFAUfVVVFQUFBQwbNoxNmzZx//338+tf/9rxHEPBHDp0iJ///Of84Q9/ADwTWkaPHs2qVaui8Tg+GB959+7dOXXqlFmxV69ezezZs2nVqhVTp06tNUVvKIRDhw6xY8cOzjzzTBITE0lLSyMlJSWkbqvxQScmJtK8eXN+/vOfU11dbUaOGAqxTZs2gKexa9eunY+iN67hr+gBBg0aZLptDPwVvXH+yZMn2bBhQw0ZDQWxePFitm7d6vrZDh8+TEVFBdu2bePkyZOsXr2adu3acfz4cV588UXAU5/at29Py5YtfRR+VlaWqRR37tzJ0aNHgdOKvkWLFoBHuZ111ll88MEHJCQkkJNzOlPtsGGeBd1WrlxZQzYjQsSQwSiHpk2bApj3DqToMzMzzYbmxIkTXHnllYiIo6K33sv4NvPz81m8eDGXXXaZaXBVVVWxZcsWEhMTAejfvz8bN26krKzMLB+jjAC+/PJLADIyMgDMZ3jooYe45JJLXCn6N998k4suusinoX/55Ze5/vrraxz77rvv8v/+3/8zFfmNN97In//8Z1q3bk1KSgpZWVkcP348ZBdmrIhLRb93717zYzQGcpwwlMh7773H6tWr+b//+z9eeOEFHn/8cVOZ+mP1M7788sumr3DTpk0sW7bMdrA0UqyKHk4rpsLCQhYsWMCNN95ISkoKZ511Vq1a9IcOHaK4uNj8qEWErKyskCx649jnn3+e559/nj59+gCYWQiNj9P4wFNTU2nfvr3PezAaloqKCiorK82B1meffZYHH3ywxj2dFD3YGwcHDhygV69eJCUl8be//c31sxlKTSlFQUEBa9asYcKECVxwwQX87W9/49SpU6ZFD/DMM8/w+9//3ud5rc8HpwdvmzVrZm4zlG2fPn1MqxqgR48e9OjRgxdeeKGGdVlcXExmZiYtWrQwy7KgoICcnBxatmzpc5zdeY8++ijTpk0zGxqAgQMH8uKLL3LbbbcxY8YMnnzySZKSknwUvXEv49vcv38/Tz/9NEuWLDGfc8eOHVRUVPD73/+eWbNmMXbsWMrLy4HTyt1aRsYaFl27dgU8A9sA8+fP57333jPfr5OPvrq6e9tenAAAIABJREFUmvvvv5+PP/6YBQsWmNsXL17Ma6+95tOjBHj77bf5z3/+w+7duykvL2fu3LlkZ2fz17/+1Ueu+uKnjytFn5uba1oA33//PYmJiWzZsiXg7DxDiRgWwfz589m7dy/V1dWOH/TevXt9XAH+yiLU7mF1dTWVlZU1tiulzNhhf0VvrUAiwi9/+UvAo8B2797NiRMnfD5s4yMxrmvcz7rdwM51YY1hNtwchlxWRQ+eSm5XwQ8ePMiOHTvMf4aFmp+fT0JCApMnT2bSpEmceeaZiAjFxcVUVVWZisH4wNu0aUNaWpqtRQ+Y7ruUlBRuuukmRo6ssR49LVu2JCUlxXx3hgxpaWm2ir60tJTevXtz9dVX89JLL9X48J2wNkaLFy+mrKyMoUOHcuedd1JcXMzChQtNix7gyiuvZPjw4T7Pa5SdwaFDh0hJSSEh4fTna1juhsI3EBHuuOMO1q1bV6OnWVxcTKdOnXzKMj8/n8zMTPPe/pEzxnmdO3fmnnvuMS1o475ZWVlMnz6ds88+mx49enD77bfTrl07H9eR8X2tWbPGdLUsW7YM8LXyAUaNGsXvfvc7OnfubJ5vbQC7detGQkKC+f0ain7AgAGceeaZ5nHffPMN4HmP1dXVPnX82LFjzJ8/n4KCApKTk33mLxhpHIzeZUVFBdXV1aZ8+fn5bNiwgfLycmbOnMn06dPNcgBYu3at7TdmYPRAY40rRS8iY0Rks4hsEZGZNvvPE5GvRKRSRCb47essIh+ISJ6IfC8iGdER3Zf9+/ezZcsWRo0aBXiU53nnnQecVuL+HD9+3FRgX331FXC6QvTu3ZuXX37Z9rySkhKGDBlCkyZNSEpK4vDhw5SVlZkvP1RF/9vf/tZWGf31r3+la9euZsQC+Fr0LVu2JDk5mSuuuML8ENLT06mqqiI7O5u77roL8HTbmzRpYvY0nnnmGbp3705ZWRnt27dnzpw55j23bt1Ky5YtfXpC77//Pi1btjQ/Vv+Qv507d/oo+qysLIqKinw+pm3bttGuXTs6d+5s/jPcUAUFBWRkZNC4cWMAGjVqRIcOHdixYweTJk3iggsuAHwt+jPPPNPM93Ls2DE2b95MkyZNAM+HazQ+ImJb5oZ7wbD8CwoK6NKlCyNGjLCdSFVaWkqbNm248847OXr0KP/85z9tr+uPtTEy6tPQoUO5/PLL6d69O8888wwHDhwwLXorvXr1AqBnz5419lmtdjgdsWON3DGYMmUKrVu35vnnnze3VVdXs337ds466yyzd3TkyBFKSkrIysqiV69etG3blj59+tQIQ92xY4fP+wY499xzHWVt3769j7IrKSnh66+/5vDhw0yaNMmUB05b+UYdMxSmcb9GjRrRpUsX81rJyclkZGSY37hx/169epGdnW267IzvuqKigjvuuINzzjmHyspKlFL07t2bSZMm0alTJx555BHWrVvHt99+C5w24nJzc6muriY7O5uHHnrIlK+goMCU2drIpqen07x5c377299y4YUX2vrq586dS9u2bWslf35QRS8iicAzwCVAL2CiiPTyO2w7MA14g5q8DjyqlMoGBgMxCWRNTk7mtdde47bbbjO3GQVvxND6Y1XI1q5ls2bNmDhxIgcPHqzR4lZWVlJaWkqnTp1Yvny5Oa1+586dQbuHTqxatYq1a9dy6tQpn+3vv/8+e/bs4dVXXzUVfbdu3QBPAqwzzzyTFStW8Pe//908x/ggtm3bZvqaZ870tM1GZf/mm2/Yvn0769at48iRI/zlL38xQ+g+/vhjysvL+e6778xrPvzww5w6dYqPP/4Y8O1NGL7jDh06mNsyMzOprq72qcAFBQVUVVUxc+ZMs2u/d+9evvvuO9OKtGK4oKzWtdWiHz9+PCUlJbz99tu8/vrrHDt2jMmTJwOeBty/l2GHdTzDkKF379788MMPPo2UUooDBw6QmprKgAED6NixoxkrHgzDom/UqBGFhYUMGjSIzMxMEhISuPzyy83rGBa9lX79+vHBBx9wxx131Nhn+OcNBg8ezAcffMDEiRNrHNu8eXNGjx7tI/PmzZs5evQo/fv3Ny16o/5mZmby0EMP8dFHH9VwBVZWVrJ79+4aZTtjxgyWL1/uo4QNjEbMaHT37t3L008/TfPmzbn77rvN7e3bt/ex6FNSUsx6ZdyvW7duNcZbBgwYYPYOBw8ezEcffcSVV17JnDlzzHBZYz/AkiVL2Lx5MwsXLjQHcidNmsTSpUtN43DLli1UVFSY72/16tUUFBSYrlLD956fn8/q1atJT0+nU6dO5j0SEhJ47733uOmmm1i1alUNF7JSiocffpgTJ07w1FNP1SizaOPGoh8MbFFKFSqlKoD5wDjrAUqpIqXUN4BP6Iq3QUhSSn3oPe6oUiomfZUWLVowZcoU0zcHmO4Vw+q0xi6Dr0Kurq42fZ6DBg0yK2dpaakZibF3715WrVqFUoq0tDSGDh1K3759gdMRAcY5oZCfn09VVRU//PADa9asobq6mqqqKtOyfPLJJ81rGl3TqqoqUlNTGTp0KKmpqea1rB9gcXExu3btMrvshtXkPxhWWFjIO++847PNOGb9+vWsWLHCZ19BQQEiQtOmTc1ntioqu8gb43pTp07lhhtu4Fe/+hXgsZSMhF5W0tPT2bJli88kGeOY1NRUxo4dS0ZGBg899BBPPPEEOTk5jB49GghN0W/dupUFCxaQn59PVlYWWVlZNRqpI0eOmOUtIkEnhR05coSFCxfy/vvvU1JSgogwYMAAAO68805TsQ0dOtS09OwseoCLL764RiQJ1LTojWP9laDB0KFD+eGHH3wUl7HdsOitVnTHjh3p27dvjcH9kpISqqqqapRtkyZNzN60P0bdSE1NpUWLFnzzzTe88cYbTJs2jQ4dOtClSxeSk5OZPn26GW1VUFBAZmamWVbG/fzrCZx2W4HHJXfRRReRlJRE9+7dGTVqlOniMv433u3s2bPNZ7722mvp06ePz9iNoS+aNWtmRrcBPmk2DEVvlcHg3HPP5dFHH6V169Y+0VqbNm3ikUce4fvvv6djx4689NJLvPnmmyxYsMA0pqKNG0XfCbD23Yq929yQBRwSkYUi8rWIPOrtIfggIjNEZJ2IrHOyvt3SokULcyCpd+/egEfR33DDDTUWQvBXyKNGjaJ9+/ZcfPHFZoRHfn4+gwcP5n/+53+49tprufDCC4HTlddaMcLx0Vv93W+88QZDhw5l4cKF5OXlUVZWxn//93+zdetWPvzwQ1q2bEm7du3Mc60K3qBr1640bdrUXKTDGCg2ygGo8bG3bt2a2bNnA6e7zoZifvLJJ2nevDnnn3++uW/lypVkZmb6+F6tiqpHjx4kJCT4RHoY1zOO69KlC2lpabz88suUlZWZbgqD9PR0CgsLfbq8xsBhVlYWiYmJ3H333axbt46CggLuuecemjdvDngU7e7du80BQieys7PZv38/V111FWVlZfTr1892EM14n0adGDp0KFu3bnXsKT7++ONceeWVjBkzhoULF5KamsqQIUPo2rUrEyac9mxau/p2Fr3dPqNu+1v0wTDuZRgPubm5tG7d2lTqpaWlfP3118Bp9yB43sOBAwdqRDMFa0StGO/cGER/8803qaio4Pbbbwc8htV5553HhRdeSHV1NYsXL2bt2rU+daJly5Z06dKFQYMGOT6bcZyVpKQks6E0xhPA02PMzc1lyZIlgK9bMDk52Sdyb+zYsRw4cMCceW7QtWtXVq5cSVFRka3LDDwN8owZM1i4cCHbtm2jvLycUaNGMXPmTNLT01mwYAHHjh3j6quv5qqrruJ3v/td8AINB6cAe+MfMAF40fJ7MvC0w7GvAhP8zj0MdMOzyMlbwA2B7heNXDe9evVSgDp8+LBq3ry5+tWvfqV69eqlMjIyfI578803FaAaNWpkTmI5dOiQOnXqlFqxYoUC1BNPPKEA1bx5c5+JGJ9++qlS6nR+i7vvvtvc1759e9eyrlmzxjyvc+fOClB33HGHeuGFF8yJLIBKTk5WnTt3VkopcwKJ00ST0tJSU+6JEyeqli1bqpSUFHXXXXcppU7nBGnfvr0SEXNy2ccff2zKcvXVV6vdu3erxo0bq1tvvdU8Zvny5QpQDz/8sDrnnHPMslu7dq2PDBMmTFBnnHGGOnr0qFJKqZkzZ6pGjRr55OkxJsQ0a9ZMlZaW+pz/yCOPmLKsWbNGHTx4UCnlmThmTP6pqqpSeXl5Kj8/X1VXV5uyGRNXnn/++YBlX1lZqTZu3Ki+/fZblZeXp6qrq21zohg5XIxJRZ9++qkC1DvvvGN73cmTJ/tM8OrVq5cqLy9Xhw8f9jmuurrazN1jTH6yo7Cw0OdagLr00ksDPps/x48fV0lJSeree+9VSinVp08f9ZOf/EQppcyJVp07dzbrmMFrr73mI9+CBQtsJ6AFwniXw4cPNydRXXbZZeb+EydOqGPHjqnKykqVkZGhUlJSFKCWLVvmc50jR46oioqKGtc/ceKEatSokUpKSrLNAzV06FAFmPmSAPWHP/zBfOakpCSf63bv3l1dc8016o033jDrn/E+e/bsaV7j1ltvVYBq0qSJ2rdvn+Pzb9++XSUmJqp77rlHvfLKKwpQr7/+utq/f79SyjO579tvv1Xffvut2rJli+ty9YcIJ0ztBKymUbp3mxuKgfXK4/apBBYBA1yeGzbp6emmZd+6dWsOHTpEaWkpO3fupKysjKeeeoqKigrTUrMO+LRq1YqkpCTTWjZ898eOHaNZs2amO8iwspo0aUK7du1Yvvz/t3fuwVFWWQL/nbxJCOmkISSYjBCleeRBmohkLTcKlCAUGrUIT1HKx6gTeYhB3EJWSrRKh1of606J2dpRWddFKd3SUtZxdpxyLIuwwKAIAaKz8ghiCKC8LCWYu39038/uTne6O+lOy5f7q+pK53v1Od/9+vS555577p8Bj5d48uTJiCdK+IY3dJhiy5YtNDU1kZeXx9SpU0lKSuLHH3/E4XAAP3uWwTx6vV97sx9++CEjR44kNze3i0d/7NgxCgsLuffee8nKyrLyhVNTUzl27Bjr16+3Bq9013TRokUMGDCAu+++G4fDYY0rBIYeli1bxrfffsuGDRusz8rPz/cbHNWe2O23327ppPH1GEeNGmXpnpOT49cVHz16tNXF16E33csI53UmJyczduxYysrKGD16NCJCXl4eTqfTapc33njD8oL1/a6qqiI5OdnqEV24cIEnnniChx56iH379nH48GHKysosLzE/P5+0tLQu3qaIWPc1VOhGn6/11Zkk0Xr0AwYMoLKykk2bNtHQ0MDu3butz544cSLgef4Cx0oC01B74tH7hm60nsuWLbP2Z2RkkJmZSXJyMkuWLOHs2bOUl5dbg/Ca7OxsUlNTu1w/IyMDt9vNoEGDgg6+Bwv71NbWkp2dzaFDhxgxYoTfdXW4Sus6evRo7rrrLgDq6uoYNmwYl1xyCZWVlQAsXLiQwYMHh9S/uLiYWbNm0djYyNq1aykrK+PWW2+1nqdLL72UsrIyysrK/HpTsSQSQ78NGCkiI0QkDZgLvBPh9bcBDhHR8YbJQHP0YkbHtGnTrJK5DofDWkWno6ODxsZGli5dyiuvvGLF6MeMGQP4P7za8DQ3e8R1u92sWLGCp556ioqKCr90r6KiIqvbO2XKFC5cuGDN5guHjnfrWD/Azp07efvtt7n22mtJT0+34vLa2OkHJJSh99VFZ1HoH7xz5875LfFWVFSEw+GgoaGB9vZ2LrvsMiZNmkRbWxvvvfceNTU1jBw50hpEbG9vZ/ny5eTl5VnyAH4hJYCrrrqK0tJSq+RwW1tbl/DEzJkzcblcLF++PKT8+fn55OTkhLmLHrSh17MhfdProkGnh54/f5758+dbg9n6mcjMzGTcuHFWKOujjz7ikUceYd26dTzzzDPW+ID+IevOiM+ZM4eamppuDXdWVhZZWVk4HA7ruGAx+nDMnj2br7/+mhdeeIHc3Fyrno7T6fSbpOXLmDFjSEpK4oMPPgA88eVBgwZ1++wFovXPy8tj0qRJTJ8+3W8szZc77riD8vJy1qxZEzJjKhjz58/nuuuuC7pPP0uBE62uvPJK633g8drQa4dxyZIljBo1itraWhYuXMjNN99MTU0NLpfLGm/qjpUrV5Kamkp7ezurV6+OSrdYENbQez3x+4E/AHuBN5RSe0TkMRG5EUBEJohIK1AHvCgie7zn/gQ0AH8Skc8BAaKrINYDli9fzquvvgp4jGNra6uVN64HO5599lmOHz9OZmamX2qiJtCj//DDD1mzZg0zZszgs88+s2be+Z43c+ZMa9At0jh9S0uL9YsOnnGCjo4Ojh8/Tn19PfDzAxpo6AO9YF8C89q1oQ+s3qePW7NmDefOnePLL7+kpKSEtrY2WlparMlLmZmZtLS0cO7cOR5//HE/eXJycqzURo2IUFNTYy3A4JsrrikrK2P//v1cfvnlIeUP9DC7Qxt67YlFY4x80dPXfdM3A69XXV1t6aY9+zFjxvDFF190MfTdxd/nzp3LRx99FPaLn5+f72foo/XoAVasWGH90J84ccIv3q29+8D7XVhYyE033cSLL77I999/T1NTExMnTozKUPl69IsXL2bz5s0hz8/JyWHXrl1W9c5IWbp0KRs3bgy6Tz9LBQUFDBw4kGHDhjFw4ECrfYL1Yo4cOcKhQ4esc3/1q1+xb98+qqqqePLJJ3n++edxuVzs37+fUaNGhZXP7XZz/PhxTp8+zezZs6PSLRZElEevlNqslHIppS5TSj3h3faPSql3vO+3KaWKlFJZSimnUqrU59w/KqUqlFLlSqlFypO502c4HA6/Ket6gLC5udkaKNMeh69xTE9PJysrixMnTpCWltatV6nPW7ZsmWUMGhsbefTRR8PKpzNOtFehu7QVFRVd8sej8egLCgqsyWPBDL1vTZJAhg4dyokTJzh9+nS3hlbLE8qQVVdXc+bMGfbu3es3+zMS9ABasCyLUGhDr/O+e2roXS4Xra2tXRYx0eUCwGMYz549S3NzM1u2bGHMmDFMmDCB7du388MPP1iVPKF7jz5Shg4dak2vh5559N3hO+EpEB2GW79+Pbt27eoyKSscvoOxiUA/406nE6fTaemo2yeYR9/R0cGOHTuiClH9kgmei2UjHA6Hn3d95swZrrnmGvbt28fBgwcZN24ctbW1HDx40MpR1+Tl5XHu3LkuseVA5s2bR0ZGBpMnT+aTTz4BYN26dfz000/MmTOnS0aJRilFS0sLCxcupK6ujq+//poZM2bQ0NDA9OnTrc/UD2KkMXrwxJ8LCwtpbW21Qje7d++2DL3b7ebjjz8O+iAHS5UMhpYnlCHTBmHLli1BPfruSE9PZ9WqVUydOjXic3TWzZEjR0hPT/crERANuhezadMma5vD4fBLXfTVrampiRtvvJGSkhIrZFdcXExFRQX19fXU1vplI/eI+vp6zp8/b40/9MSj745bbrmFpqamoBP3rr76aqqqqli9ejWdnZ1RG/rCwkKWLFlihVP7milTprBo0SImTJjAgw8+aDkRkyZNYtGiRdxwww1+x+vvxOHDh7tk6l20hBqlTdQr1itM6ZFx31d9fb167LHHFKAmT54c8tzKykoFqPHjx0f8ec3NzX6fdc8994Q8tq2tTQHqueee6/aa77//vpUpoJRSq1evjijzQWcbnDx5Ui1evFjl5uZa2TxLly5VgHrttde6nKczK8B/haNAnn76aQWoW265Jej+zs5OlZeXp+rq6hSg1q1b1628vaWjo8OSu7CwsMfXOXr0qAJUWlqays7OVklJSaqkpMTvmM7OTuV0OlVNTY0CVGNjo1/53qampt6qExT93Pqu3NQX6EwmwMoWsSt6BbnU1FR15MiRRIsTMfSXMsXB8B0w9PWQ77nnHtLT07sdLdceczRdb18vu7i4mA0bNvjNyvNF52qHi0PrGKBv9Ubfv6EoLi5m8ODB5Obm4nA4OHXqlFUQS1c4DJZrrj3vlJQUv9zjQMJ59Hpy0fvvv+933XiRkpJilVHoTZigoKCA4cOHc/78eUpLSykvL+9yr7VuuqzExIkT/doxXl3+3sToe8Ps2bMpLCzE5XIlLATTV+jvxJw5c4JOVrsY6RehG43OpnC5XOTn5/PWW291+4XUD3Q0Bsp3gHTJkiWsWLGCAwcOdKmHDl3reYRi+PDhbNiwgeuvvx6ABQsWkJOT4zflOhiPPvood955J+C5D52dnVYtm1mzZnH27FmrgJYvWt9g0819CRejB5g1a5Y1KSUWsepwZGZmcv78+V4bo+rqag4cOIDL5eK+++4LulLZ448/Tnl5OQUFBZSXl1uDtro2fzyIV4w+HGlpaWzatClo8T27MXToUF566SWmTZuWaFFiRr8y9BUVFX51VXR6WSi00Y7G0KekpFiVEXUss7W1lSFDhnD06FFKSkoYNGgQ33zzDS0tLaSkpAStDxKIruOi5brtttvCnlNaWmrNDtb3Yf/+/eTn55ORkcG9994b9DxtkMP1NMJ59OAZv1i5ciXt7e1x9+jBE6f/7rvvYmLoN27c6FdvPZDKykorlxo8xlfX5dcD4bEmUR49BC+YZldsE5v30m9CN9nZ2YwdO5bs7OyIDCv0LHQDnq5fTU2N1QU8dOgQpaWluN1upk6dyptvvsmwYcN4/fXXw3rNsULfh+bm5rDeZk5ODg6HwxqUDEWwqeWBZGRkUF9fT1JSUtgeSCzQA7DdpZ5Ggi5uFe4eBFJRURFVSmi06Lbri96RwT70G4/e6XSyYsUKFixYELFh7UnoBuDdd9+1JlqICFu3buXEiRO43W62bt3K4sWLUUrx1VdfMXPmzOgU6iH6Ppw6dQq3293tsVrmcBOORo0axc6dO/0mewVj1apV1NbW9olHrw19bz16t9vNjh07/Dz2SHj55ZejWpYyWmpqati5c2fUP0CG/k2/8eidTqe1xFekaK8wWu9p+PDhOJ1Oq666nqS1du1acnNzOXr0qDXVOZ7eny++IaxI0uNcLldE4YHKysqwk2dSUlKiNpg9JVaGHjzlb30X94iEgoKCuA7giUif3UuDfehXhj5aysrKSE9PD7qYQqQUFRVx4MABAMaNG8cDDzxAYWEhmzdvJicnJ+qc5J4SraG/WNG59HbPDDEYosH2oRs9m7EnMduqqiq+//77qL06X4qKiti2bRsDBgxg2LBhPPLII6xcuZK0tDTa29uDFmmKB/o+5OfnW7Vz7EisYvQGg52wvaHXpQt66uH1xsiDf80WfS3fJfP6Cl05sbq6us8LKvUlsQzdGAx2wfaGPiUlhXnz5iUsJ7YnxbniQXJyMnPnzqWuri6hcsQbY+gNhq7Y3tCDZ+WmRPFLMfRAxAtaX8yYGL3B0BXbD8Ymmu7WujTEHu3R+1aaNBj6O/3Co08kEydOpKGhISYVDA3hWbBgAUOGDLHGQQwGA4iKcMm7vuKKK65Q27dvT7QYBoPBcFEhIjuUUlcE2xdR6EZErheR/SLypYg8HGR/jYj8VUQuiMisIPsHiUiriPxL4D6DwWAwxJewhl5EkoHfAdOBscA8EQlcSeMQsAgINeq5FvhLz8U0GAwGQ0+JxKO/EvhSKfV/yrMM4EbAL+CslDqglNoFdCnyISJVwFDggxjIazAYDIYoicTQXwIc9vm/1bstLCKSBPwTngXCDQaDwZAA4p1e+Rtgs1KqtbuDROTXIrJdRLa3t7fHWSSDwWDoX0SSXnkE8F1vrsi7LRL+Dvh7EfkNMBBIE5GzSim/AV2lVCPQCJ6smwivbTAYDIYIiMTQbwNGisgIPAZ+LjA/kosrpRbo9yKyCLgi0MgbDAaDIb6EDd0opS4A9wN/APYCbyil9ojIYyJyI4CITBCRVqAOeFFE9sRTaIPBYDBEzi9uwpSItAMHe3GJwcDxGIlzsWB07h8YnfsHPdX5UqXUkGA7fnGGvreIyPZQs8PsitG5f2B07h/EQ2dT1MxgMBhsjjH0BoPBYHPsaOgbEy1AAjA69w+Mzv2DmOtsuxi9wWAwGPyxo0dvMBgMBh+MoTcYDAabYxtDH65mvl0QkQMi8rmIfCoi273b8kTkjyLyhffvRb+Onoj8XkSOichun21B9RQP/+xt+10iMj5xkvecEDqvEZEj3vb+VERm+Oz7B6/O+0VkWmKk7jkiUiwifxaRZhHZIyJLvdvt3s6h9I5fWyulLvoXkAz8DSgB0oDPgLGJlitOuh4ABgds+y3wsPf9w8BTiZYzBnrWAOOB3eH0BGYA/w0IUA1sTbT8MdR5DdAQ5Nix3uc8HRjhff6TE61DlPoWAuO977OBFq9edm/nUHrHra3t4tGHrZlvc2qBV7zvXwFuSqAsMUEp9RfgZMDmUHrWAhuUhybAISKFfSNp7AihcyhqgY1KqR+VUl8BX+L5Hlw0KKWOKqX+6n1/Bk+JlUuwfzuH0jsUvW5ruxj6HtfMvwhRwAciskNEfu3dNlQpddT7/hs8C73YkVB62r397/eGKn7vE5azlc4iMhxwA1vpR+0coDfEqa3tYuj7E1crpcbjWdqxXkRqfHcqT1/P9jmz/UVP4AXgMqASOIpnIR9bISIDgTeBZUqp07777NzOQfSOW1vbxdD3pmb+RYVS6oj37zHgv/B04dp0F9b791jiJIwrofS0bfsrpdqUUj8ppTqBf+XnLrstdBaRVDzG7j+UUm95N9u+nYPpHc+2touht2rmi0ganpr57yRYppgjIlkikq3fA1OB3Xh0vd172O3A24mRMO6E0vMd4DZvVkY1cMqn639RExCDvhlPe4NH57kiku5dK2Ik8L99LV9vEBEB/g3Yq5R62meXrds5lN5xbetEj0DHcCR7Bp7R678BqxItT5x0LMEz+v4ZsEfrCTiBPwFfAP8D5CVa1hjo+p/JbHvDAAAAh0lEQVR4uq8deGKSd4bSE08Wxu+8bf85ngVuEq5DjHT+d69Ou7xf+EKf41d5dd4PTE+0/D3Q92o8YZldwKfe14x+0M6h9I5bW5sSCAaDwWBz7BK6MRgMBkMIjKE3GAwGm2MMvcFgMNgcY+gNBoPB5hhDbzAYDDbHGHqDwWCwOcbQGwwGg835f3KpxpGdGNWzAAAAAElFTkSuQmCC\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Download the model"
      ],
      "metadata": {
        "id": "lD-vKaoHQAFd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "os.makedirs('/content/drive/My Drive/cut_panoramic/Model/Classification', exist_ok=True)\n",
        "model.save('/content/drive/My Drive/cut_panoramic/Model/Classification/44_รอบที่4_Flimpano_Male125_250_Unfreez.h5')"
      ],
      "metadata": {
        "id": "74dL7-HLP_Sh"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from google.colab import files\n",
        "# files.download('/content/drive/My Drive/cut_panoramic/Model/33_รอบที่3_Flimpano_Male125_250.h5')"
      ],
      "metadata": {
        "id": "qcPW-brHQDpc"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "P4pe9URV1vBB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}