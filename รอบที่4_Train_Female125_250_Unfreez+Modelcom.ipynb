{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Wanita-8943/Project_2023/blob/main/%E0%B8%A3%E0%B8%AD%E0%B8%9A%E0%B8%97%E0%B8%B5%E0%B9%884_Train_Female125_250_Unfreez%2BModelcom.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "KKSs7cyoPHcD"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import shutil"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7LoeZxmVPMxp",
        "outputId": "8b1d99a1-7b99-41f7-a89c-720559987972"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import models\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import optimizers\n",
        "import os\n",
        "import glob\n",
        "import shutil\n",
        "import sys\n",
        "import numpy as np\n",
        "from skimage.io import imread\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import Image\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "1pX9g1HxPM2f"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 16\n",
        "width = 150\n",
        "height = 150\n",
        "epochs = 250\n",
        "NUM_TRAIN = 1425\n",
        "NUM_TEST = 475\n",
        "dropout_rate = 0.2\n",
        "input_shape = (height, width, 3)"
      ],
      "metadata": {
        "id": "eSFtvGyvPM6O"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#ดึงข้อมูลใน Github มาใช้\n",
        "import os\n",
        "%cd /content\n",
        "if not os.path.isdir(\"efficientnet_keras_transfer_learning\"):\n",
        " !git clone https://github.com/Wanita-8943/efficientnet_keras_transfer_learning\n",
        "%cd efficientnet_keras_transfer_learning/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lb4K4CsMPNAW",
        "outputId": "c2575a46-c7e6-4d3a-b5fe-0d55b718f434"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "Cloning into 'efficientnet_keras_transfer_learning'...\n",
            "remote: Enumerating objects: 837, done.\u001b[K\n",
            "remote: Counting objects: 100% (359/359), done.\u001b[K\n",
            "remote: Compressing objects: 100% (124/124), done.\u001b[K\n",
            "remote: Total 837 (delta 255), reused 328 (delta 235), pack-reused 478\u001b[K\n",
            "Receiving objects: 100% (837/837), 13.82 MiB | 19.09 MiB/s, done.\n",
            "Resolving deltas: 100% (495/495), done.\n",
            "/content/efficientnet_keras_transfer_learning\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Options: EfficientNetB0, EfficientNetB1, EfficientNetB2, EfficientNetB3\n",
        "# Higher the number, the more complex the model is.\n",
        "from efficientnet import EfficientNetB0 as Net\n",
        "from efficientnet import center_crop_and_resize, preprocess_input"
      ],
      "metadata": {
        "id": "eyBg0dLKPND3"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# loading pretrained conv base model\n",
        "# โหลดโมเดล มาโดยตัด output ของโมเดลออก เเต่ยังใช้ input อันเดิม\n",
        "# เเละโหลด weight ของโมเดล มาด้วยที่ชื่อว่า imagenet\n",
        "conv_base = Net(weights='imagenet', include_top=False, input_shape=input_shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gDL19Uuf1joi",
        "outputId": "5d4ae615-b3ef-4b22-fbdc-af1ef8dfc86f"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
            "Instructions for updating:\n",
            "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://github.com/qubvel/efficientnet/releases/download/v0.0.1/efficientnet-b0_imagenet_1000_notop.h5\n",
            "16717576/16717576 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "conv_base.summary() #ดู Summary"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o1n_e8lG1l4p",
        "outputId": "e171733c-6295-4bc3-bfaa-7d174d304088"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"efficientnet-b0\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 150, 150, 3  0           []                               \n",
            "                                )]                                                                \n",
            "                                                                                                  \n",
            " conv2d (Conv2D)                (None, 75, 75, 32)   864         ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " batch_normalization (BatchNorm  (None, 75, 75, 32)  128         ['conv2d[0][0]']                 \n",
            " alization)                                                                                       \n",
            "                                                                                                  \n",
            " swish (Swish)                  (None, 75, 75, 32)   0           ['batch_normalization[0][0]']    \n",
            "                                                                                                  \n",
            " depthwise_conv2d (DepthwiseCon  (None, 75, 75, 32)  288         ['swish[0][0]']                  \n",
            " v2D)                                                                                             \n",
            "                                                                                                  \n",
            " batch_normalization_1 (BatchNo  (None, 75, 75, 32)  128         ['depthwise_conv2d[0][0]']       \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " swish_1 (Swish)                (None, 75, 75, 32)   0           ['batch_normalization_1[0][0]']  \n",
            "                                                                                                  \n",
            " lambda (Lambda)                (None, 1, 1, 32)     0           ['swish_1[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d_1 (Conv2D)              (None, 1, 1, 8)      264         ['lambda[0][0]']                 \n",
            "                                                                                                  \n",
            " swish_2 (Swish)                (None, 1, 1, 8)      0           ['conv2d_1[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_2 (Conv2D)              (None, 1, 1, 32)     288         ['swish_2[0][0]']                \n",
            "                                                                                                  \n",
            " activation (Activation)        (None, 1, 1, 32)     0           ['conv2d_2[0][0]']               \n",
            "                                                                                                  \n",
            " multiply (Multiply)            (None, 75, 75, 32)   0           ['activation[0][0]',             \n",
            "                                                                  'swish_1[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d_3 (Conv2D)              (None, 75, 75, 16)   512         ['multiply[0][0]']               \n",
            "                                                                                                  \n",
            " batch_normalization_2 (BatchNo  (None, 75, 75, 16)  64          ['conv2d_3[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv2d_4 (Conv2D)              (None, 75, 75, 96)   1536        ['batch_normalization_2[0][0]']  \n",
            "                                                                                                  \n",
            " batch_normalization_3 (BatchNo  (None, 75, 75, 96)  384         ['conv2d_4[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " swish_3 (Swish)                (None, 75, 75, 96)   0           ['batch_normalization_3[0][0]']  \n",
            "                                                                                                  \n",
            " depthwise_conv2d_1 (DepthwiseC  (None, 38, 38, 96)  864         ['swish_3[0][0]']                \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_4 (BatchNo  (None, 38, 38, 96)  384         ['depthwise_conv2d_1[0][0]']     \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " swish_4 (Swish)                (None, 38, 38, 96)   0           ['batch_normalization_4[0][0]']  \n",
            "                                                                                                  \n",
            " lambda_1 (Lambda)              (None, 1, 1, 96)     0           ['swish_4[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d_5 (Conv2D)              (None, 1, 1, 4)      388         ['lambda_1[0][0]']               \n",
            "                                                                                                  \n",
            " swish_5 (Swish)                (None, 1, 1, 4)      0           ['conv2d_5[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_6 (Conv2D)              (None, 1, 1, 96)     480         ['swish_5[0][0]']                \n",
            "                                                                                                  \n",
            " activation_1 (Activation)      (None, 1, 1, 96)     0           ['conv2d_6[0][0]']               \n",
            "                                                                                                  \n",
            " multiply_1 (Multiply)          (None, 38, 38, 96)   0           ['activation_1[0][0]',           \n",
            "                                                                  'swish_4[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d_7 (Conv2D)              (None, 38, 38, 24)   2304        ['multiply_1[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_5 (BatchNo  (None, 38, 38, 24)  96          ['conv2d_7[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv2d_8 (Conv2D)              (None, 38, 38, 144)  3456        ['batch_normalization_5[0][0]']  \n",
            "                                                                                                  \n",
            " batch_normalization_6 (BatchNo  (None, 38, 38, 144)  576        ['conv2d_8[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " swish_6 (Swish)                (None, 38, 38, 144)  0           ['batch_normalization_6[0][0]']  \n",
            "                                                                                                  \n",
            " depthwise_conv2d_2 (DepthwiseC  (None, 38, 38, 144)  1296       ['swish_6[0][0]']                \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_7 (BatchNo  (None, 38, 38, 144)  576        ['depthwise_conv2d_2[0][0]']     \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " swish_7 (Swish)                (None, 38, 38, 144)  0           ['batch_normalization_7[0][0]']  \n",
            "                                                                                                  \n",
            " lambda_2 (Lambda)              (None, 1, 1, 144)    0           ['swish_7[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d_9 (Conv2D)              (None, 1, 1, 6)      870         ['lambda_2[0][0]']               \n",
            "                                                                                                  \n",
            " swish_8 (Swish)                (None, 1, 1, 6)      0           ['conv2d_9[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_10 (Conv2D)             (None, 1, 1, 144)    1008        ['swish_8[0][0]']                \n",
            "                                                                                                  \n",
            " activation_2 (Activation)      (None, 1, 1, 144)    0           ['conv2d_10[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_2 (Multiply)          (None, 38, 38, 144)  0           ['activation_2[0][0]',           \n",
            "                                                                  'swish_7[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d_11 (Conv2D)             (None, 38, 38, 24)   3456        ['multiply_2[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_8 (BatchNo  (None, 38, 38, 24)  96          ['conv2d_11[0][0]']              \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " drop_connect (DropConnect)     (None, 38, 38, 24)   0           ['batch_normalization_8[0][0]']  \n",
            "                                                                                                  \n",
            " add (Add)                      (None, 38, 38, 24)   0           ['drop_connect[0][0]',           \n",
            "                                                                  'batch_normalization_5[0][0]']  \n",
            "                                                                                                  \n",
            " conv2d_12 (Conv2D)             (None, 38, 38, 144)  3456        ['add[0][0]']                    \n",
            "                                                                                                  \n",
            " batch_normalization_9 (BatchNo  (None, 38, 38, 144)  576        ['conv2d_12[0][0]']              \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " swish_9 (Swish)                (None, 38, 38, 144)  0           ['batch_normalization_9[0][0]']  \n",
            "                                                                                                  \n",
            " depthwise_conv2d_3 (DepthwiseC  (None, 19, 19, 144)  3600       ['swish_9[0][0]']                \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_10 (BatchN  (None, 19, 19, 144)  576        ['depthwise_conv2d_3[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_10 (Swish)               (None, 19, 19, 144)  0           ['batch_normalization_10[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_3 (Lambda)              (None, 1, 1, 144)    0           ['swish_10[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_13 (Conv2D)             (None, 1, 1, 6)      870         ['lambda_3[0][0]']               \n",
            "                                                                                                  \n",
            " swish_11 (Swish)               (None, 1, 1, 6)      0           ['conv2d_13[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_14 (Conv2D)             (None, 1, 1, 144)    1008        ['swish_11[0][0]']               \n",
            "                                                                                                  \n",
            " activation_3 (Activation)      (None, 1, 1, 144)    0           ['conv2d_14[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_3 (Multiply)          (None, 19, 19, 144)  0           ['activation_3[0][0]',           \n",
            "                                                                  'swish_10[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_15 (Conv2D)             (None, 19, 19, 40)   5760        ['multiply_3[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_11 (BatchN  (None, 19, 19, 40)  160         ['conv2d_15[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_16 (Conv2D)             (None, 19, 19, 240)  9600        ['batch_normalization_11[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_12 (BatchN  (None, 19, 19, 240)  960        ['conv2d_16[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_12 (Swish)               (None, 19, 19, 240)  0           ['batch_normalization_12[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_4 (DepthwiseC  (None, 19, 19, 240)  6000       ['swish_12[0][0]']               \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_13 (BatchN  (None, 19, 19, 240)  960        ['depthwise_conv2d_4[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_13 (Swish)               (None, 19, 19, 240)  0           ['batch_normalization_13[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_4 (Lambda)              (None, 1, 1, 240)    0           ['swish_13[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_17 (Conv2D)             (None, 1, 1, 10)     2410        ['lambda_4[0][0]']               \n",
            "                                                                                                  \n",
            " swish_14 (Swish)               (None, 1, 1, 10)     0           ['conv2d_17[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_18 (Conv2D)             (None, 1, 1, 240)    2640        ['swish_14[0][0]']               \n",
            "                                                                                                  \n",
            " activation_4 (Activation)      (None, 1, 1, 240)    0           ['conv2d_18[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_4 (Multiply)          (None, 19, 19, 240)  0           ['activation_4[0][0]',           \n",
            "                                                                  'swish_13[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_19 (Conv2D)             (None, 19, 19, 40)   9600        ['multiply_4[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_14 (BatchN  (None, 19, 19, 40)  160         ['conv2d_19[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_1 (DropConnect)   (None, 19, 19, 40)   0           ['batch_normalization_14[0][0]'] \n",
            "                                                                                                  \n",
            " add_1 (Add)                    (None, 19, 19, 40)   0           ['drop_connect_1[0][0]',         \n",
            "                                                                  'batch_normalization_11[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_20 (Conv2D)             (None, 19, 19, 240)  9600        ['add_1[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_15 (BatchN  (None, 19, 19, 240)  960        ['conv2d_20[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_15 (Swish)               (None, 19, 19, 240)  0           ['batch_normalization_15[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_5 (DepthwiseC  (None, 10, 10, 240)  2160       ['swish_15[0][0]']               \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_16 (BatchN  (None, 10, 10, 240)  960        ['depthwise_conv2d_5[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_16 (Swish)               (None, 10, 10, 240)  0           ['batch_normalization_16[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_5 (Lambda)              (None, 1, 1, 240)    0           ['swish_16[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_21 (Conv2D)             (None, 1, 1, 10)     2410        ['lambda_5[0][0]']               \n",
            "                                                                                                  \n",
            " swish_17 (Swish)               (None, 1, 1, 10)     0           ['conv2d_21[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_22 (Conv2D)             (None, 1, 1, 240)    2640        ['swish_17[0][0]']               \n",
            "                                                                                                  \n",
            " activation_5 (Activation)      (None, 1, 1, 240)    0           ['conv2d_22[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_5 (Multiply)          (None, 10, 10, 240)  0           ['activation_5[0][0]',           \n",
            "                                                                  'swish_16[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_23 (Conv2D)             (None, 10, 10, 80)   19200       ['multiply_5[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_17 (BatchN  (None, 10, 10, 80)  320         ['conv2d_23[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_24 (Conv2D)             (None, 10, 10, 480)  38400       ['batch_normalization_17[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_18 (BatchN  (None, 10, 10, 480)  1920       ['conv2d_24[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_18 (Swish)               (None, 10, 10, 480)  0           ['batch_normalization_18[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_6 (DepthwiseC  (None, 10, 10, 480)  4320       ['swish_18[0][0]']               \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_19 (BatchN  (None, 10, 10, 480)  1920       ['depthwise_conv2d_6[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_19 (Swish)               (None, 10, 10, 480)  0           ['batch_normalization_19[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_6 (Lambda)              (None, 1, 1, 480)    0           ['swish_19[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_25 (Conv2D)             (None, 1, 1, 20)     9620        ['lambda_6[0][0]']               \n",
            "                                                                                                  \n",
            " swish_20 (Swish)               (None, 1, 1, 20)     0           ['conv2d_25[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_26 (Conv2D)             (None, 1, 1, 480)    10080       ['swish_20[0][0]']               \n",
            "                                                                                                  \n",
            " activation_6 (Activation)      (None, 1, 1, 480)    0           ['conv2d_26[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_6 (Multiply)          (None, 10, 10, 480)  0           ['activation_6[0][0]',           \n",
            "                                                                  'swish_19[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_27 (Conv2D)             (None, 10, 10, 80)   38400       ['multiply_6[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_20 (BatchN  (None, 10, 10, 80)  320         ['conv2d_27[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_2 (DropConnect)   (None, 10, 10, 80)   0           ['batch_normalization_20[0][0]'] \n",
            "                                                                                                  \n",
            " add_2 (Add)                    (None, 10, 10, 80)   0           ['drop_connect_2[0][0]',         \n",
            "                                                                  'batch_normalization_17[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_28 (Conv2D)             (None, 10, 10, 480)  38400       ['add_2[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_21 (BatchN  (None, 10, 10, 480)  1920       ['conv2d_28[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_21 (Swish)               (None, 10, 10, 480)  0           ['batch_normalization_21[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_7 (DepthwiseC  (None, 10, 10, 480)  4320       ['swish_21[0][0]']               \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_22 (BatchN  (None, 10, 10, 480)  1920       ['depthwise_conv2d_7[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_22 (Swish)               (None, 10, 10, 480)  0           ['batch_normalization_22[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_7 (Lambda)              (None, 1, 1, 480)    0           ['swish_22[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_29 (Conv2D)             (None, 1, 1, 20)     9620        ['lambda_7[0][0]']               \n",
            "                                                                                                  \n",
            " swish_23 (Swish)               (None, 1, 1, 20)     0           ['conv2d_29[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_30 (Conv2D)             (None, 1, 1, 480)    10080       ['swish_23[0][0]']               \n",
            "                                                                                                  \n",
            " activation_7 (Activation)      (None, 1, 1, 480)    0           ['conv2d_30[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_7 (Multiply)          (None, 10, 10, 480)  0           ['activation_7[0][0]',           \n",
            "                                                                  'swish_22[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_31 (Conv2D)             (None, 10, 10, 80)   38400       ['multiply_7[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_23 (BatchN  (None, 10, 10, 80)  320         ['conv2d_31[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_3 (DropConnect)   (None, 10, 10, 80)   0           ['batch_normalization_23[0][0]'] \n",
            "                                                                                                  \n",
            " add_3 (Add)                    (None, 10, 10, 80)   0           ['drop_connect_3[0][0]',         \n",
            "                                                                  'add_2[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_32 (Conv2D)             (None, 10, 10, 480)  38400       ['add_3[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_24 (BatchN  (None, 10, 10, 480)  1920       ['conv2d_32[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_24 (Swish)               (None, 10, 10, 480)  0           ['batch_normalization_24[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_8 (DepthwiseC  (None, 10, 10, 480)  12000      ['swish_24[0][0]']               \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_25 (BatchN  (None, 10, 10, 480)  1920       ['depthwise_conv2d_8[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_25 (Swish)               (None, 10, 10, 480)  0           ['batch_normalization_25[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_8 (Lambda)              (None, 1, 1, 480)    0           ['swish_25[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_33 (Conv2D)             (None, 1, 1, 20)     9620        ['lambda_8[0][0]']               \n",
            "                                                                                                  \n",
            " swish_26 (Swish)               (None, 1, 1, 20)     0           ['conv2d_33[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_34 (Conv2D)             (None, 1, 1, 480)    10080       ['swish_26[0][0]']               \n",
            "                                                                                                  \n",
            " activation_8 (Activation)      (None, 1, 1, 480)    0           ['conv2d_34[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_8 (Multiply)          (None, 10, 10, 480)  0           ['activation_8[0][0]',           \n",
            "                                                                  'swish_25[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_35 (Conv2D)             (None, 10, 10, 112)  53760       ['multiply_8[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_26 (BatchN  (None, 10, 10, 112)  448        ['conv2d_35[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_36 (Conv2D)             (None, 10, 10, 672)  75264       ['batch_normalization_26[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_27 (BatchN  (None, 10, 10, 672)  2688       ['conv2d_36[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_27 (Swish)               (None, 10, 10, 672)  0           ['batch_normalization_27[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_9 (DepthwiseC  (None, 10, 10, 672)  16800      ['swish_27[0][0]']               \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_28 (BatchN  (None, 10, 10, 672)  2688       ['depthwise_conv2d_9[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_28 (Swish)               (None, 10, 10, 672)  0           ['batch_normalization_28[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_9 (Lambda)              (None, 1, 1, 672)    0           ['swish_28[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_37 (Conv2D)             (None, 1, 1, 28)     18844       ['lambda_9[0][0]']               \n",
            "                                                                                                  \n",
            " swish_29 (Swish)               (None, 1, 1, 28)     0           ['conv2d_37[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_38 (Conv2D)             (None, 1, 1, 672)    19488       ['swish_29[0][0]']               \n",
            "                                                                                                  \n",
            " activation_9 (Activation)      (None, 1, 1, 672)    0           ['conv2d_38[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_9 (Multiply)          (None, 10, 10, 672)  0           ['activation_9[0][0]',           \n",
            "                                                                  'swish_28[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_39 (Conv2D)             (None, 10, 10, 112)  75264       ['multiply_9[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_29 (BatchN  (None, 10, 10, 112)  448        ['conv2d_39[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_4 (DropConnect)   (None, 10, 10, 112)  0           ['batch_normalization_29[0][0]'] \n",
            "                                                                                                  \n",
            " add_4 (Add)                    (None, 10, 10, 112)  0           ['drop_connect_4[0][0]',         \n",
            "                                                                  'batch_normalization_26[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_40 (Conv2D)             (None, 10, 10, 672)  75264       ['add_4[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_30 (BatchN  (None, 10, 10, 672)  2688       ['conv2d_40[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_30 (Swish)               (None, 10, 10, 672)  0           ['batch_normalization_30[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_10 (Depthwise  (None, 10, 10, 672)  16800      ['swish_30[0][0]']               \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_31 (BatchN  (None, 10, 10, 672)  2688       ['depthwise_conv2d_10[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_31 (Swish)               (None, 10, 10, 672)  0           ['batch_normalization_31[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_10 (Lambda)             (None, 1, 1, 672)    0           ['swish_31[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_41 (Conv2D)             (None, 1, 1, 28)     18844       ['lambda_10[0][0]']              \n",
            "                                                                                                  \n",
            " swish_32 (Swish)               (None, 1, 1, 28)     0           ['conv2d_41[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_42 (Conv2D)             (None, 1, 1, 672)    19488       ['swish_32[0][0]']               \n",
            "                                                                                                  \n",
            " activation_10 (Activation)     (None, 1, 1, 672)    0           ['conv2d_42[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_10 (Multiply)         (None, 10, 10, 672)  0           ['activation_10[0][0]',          \n",
            "                                                                  'swish_31[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_43 (Conv2D)             (None, 10, 10, 112)  75264       ['multiply_10[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_32 (BatchN  (None, 10, 10, 112)  448        ['conv2d_43[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_5 (DropConnect)   (None, 10, 10, 112)  0           ['batch_normalization_32[0][0]'] \n",
            "                                                                                                  \n",
            " add_5 (Add)                    (None, 10, 10, 112)  0           ['drop_connect_5[0][0]',         \n",
            "                                                                  'add_4[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_44 (Conv2D)             (None, 10, 10, 672)  75264       ['add_5[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_33 (BatchN  (None, 10, 10, 672)  2688       ['conv2d_44[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_33 (Swish)               (None, 10, 10, 672)  0           ['batch_normalization_33[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_11 (Depthwise  (None, 5, 5, 672)   16800       ['swish_33[0][0]']               \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_34 (BatchN  (None, 5, 5, 672)   2688        ['depthwise_conv2d_11[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_34 (Swish)               (None, 5, 5, 672)    0           ['batch_normalization_34[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_11 (Lambda)             (None, 1, 1, 672)    0           ['swish_34[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_45 (Conv2D)             (None, 1, 1, 28)     18844       ['lambda_11[0][0]']              \n",
            "                                                                                                  \n",
            " swish_35 (Swish)               (None, 1, 1, 28)     0           ['conv2d_45[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_46 (Conv2D)             (None, 1, 1, 672)    19488       ['swish_35[0][0]']               \n",
            "                                                                                                  \n",
            " activation_11 (Activation)     (None, 1, 1, 672)    0           ['conv2d_46[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_11 (Multiply)         (None, 5, 5, 672)    0           ['activation_11[0][0]',          \n",
            "                                                                  'swish_34[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_47 (Conv2D)             (None, 5, 5, 192)    129024      ['multiply_11[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_35 (BatchN  (None, 5, 5, 192)   768         ['conv2d_47[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_48 (Conv2D)             (None, 5, 5, 1152)   221184      ['batch_normalization_35[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_36 (BatchN  (None, 5, 5, 1152)  4608        ['conv2d_48[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_36 (Swish)               (None, 5, 5, 1152)   0           ['batch_normalization_36[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_12 (Depthwise  (None, 5, 5, 1152)  28800       ['swish_36[0][0]']               \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_37 (BatchN  (None, 5, 5, 1152)  4608        ['depthwise_conv2d_12[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_37 (Swish)               (None, 5, 5, 1152)   0           ['batch_normalization_37[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_12 (Lambda)             (None, 1, 1, 1152)   0           ['swish_37[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_49 (Conv2D)             (None, 1, 1, 48)     55344       ['lambda_12[0][0]']              \n",
            "                                                                                                  \n",
            " swish_38 (Swish)               (None, 1, 1, 48)     0           ['conv2d_49[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_50 (Conv2D)             (None, 1, 1, 1152)   56448       ['swish_38[0][0]']               \n",
            "                                                                                                  \n",
            " activation_12 (Activation)     (None, 1, 1, 1152)   0           ['conv2d_50[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_12 (Multiply)         (None, 5, 5, 1152)   0           ['activation_12[0][0]',          \n",
            "                                                                  'swish_37[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_51 (Conv2D)             (None, 5, 5, 192)    221184      ['multiply_12[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_38 (BatchN  (None, 5, 5, 192)   768         ['conv2d_51[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_6 (DropConnect)   (None, 5, 5, 192)    0           ['batch_normalization_38[0][0]'] \n",
            "                                                                                                  \n",
            " add_6 (Add)                    (None, 5, 5, 192)    0           ['drop_connect_6[0][0]',         \n",
            "                                                                  'batch_normalization_35[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_52 (Conv2D)             (None, 5, 5, 1152)   221184      ['add_6[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_39 (BatchN  (None, 5, 5, 1152)  4608        ['conv2d_52[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_39 (Swish)               (None, 5, 5, 1152)   0           ['batch_normalization_39[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_13 (Depthwise  (None, 5, 5, 1152)  28800       ['swish_39[0][0]']               \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_40 (BatchN  (None, 5, 5, 1152)  4608        ['depthwise_conv2d_13[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_40 (Swish)               (None, 5, 5, 1152)   0           ['batch_normalization_40[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_13 (Lambda)             (None, 1, 1, 1152)   0           ['swish_40[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_53 (Conv2D)             (None, 1, 1, 48)     55344       ['lambda_13[0][0]']              \n",
            "                                                                                                  \n",
            " swish_41 (Swish)               (None, 1, 1, 48)     0           ['conv2d_53[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_54 (Conv2D)             (None, 1, 1, 1152)   56448       ['swish_41[0][0]']               \n",
            "                                                                                                  \n",
            " activation_13 (Activation)     (None, 1, 1, 1152)   0           ['conv2d_54[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_13 (Multiply)         (None, 5, 5, 1152)   0           ['activation_13[0][0]',          \n",
            "                                                                  'swish_40[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_55 (Conv2D)             (None, 5, 5, 192)    221184      ['multiply_13[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_41 (BatchN  (None, 5, 5, 192)   768         ['conv2d_55[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_7 (DropConnect)   (None, 5, 5, 192)    0           ['batch_normalization_41[0][0]'] \n",
            "                                                                                                  \n",
            " add_7 (Add)                    (None, 5, 5, 192)    0           ['drop_connect_7[0][0]',         \n",
            "                                                                  'add_6[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_56 (Conv2D)             (None, 5, 5, 1152)   221184      ['add_7[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_42 (BatchN  (None, 5, 5, 1152)  4608        ['conv2d_56[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_42 (Swish)               (None, 5, 5, 1152)   0           ['batch_normalization_42[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_14 (Depthwise  (None, 5, 5, 1152)  28800       ['swish_42[0][0]']               \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_43 (BatchN  (None, 5, 5, 1152)  4608        ['depthwise_conv2d_14[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_43 (Swish)               (None, 5, 5, 1152)   0           ['batch_normalization_43[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_14 (Lambda)             (None, 1, 1, 1152)   0           ['swish_43[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_57 (Conv2D)             (None, 1, 1, 48)     55344       ['lambda_14[0][0]']              \n",
            "                                                                                                  \n",
            " swish_44 (Swish)               (None, 1, 1, 48)     0           ['conv2d_57[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_58 (Conv2D)             (None, 1, 1, 1152)   56448       ['swish_44[0][0]']               \n",
            "                                                                                                  \n",
            " activation_14 (Activation)     (None, 1, 1, 1152)   0           ['conv2d_58[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_14 (Multiply)         (None, 5, 5, 1152)   0           ['activation_14[0][0]',          \n",
            "                                                                  'swish_43[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_59 (Conv2D)             (None, 5, 5, 192)    221184      ['multiply_14[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_44 (BatchN  (None, 5, 5, 192)   768         ['conv2d_59[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_8 (DropConnect)   (None, 5, 5, 192)    0           ['batch_normalization_44[0][0]'] \n",
            "                                                                                                  \n",
            " add_8 (Add)                    (None, 5, 5, 192)    0           ['drop_connect_8[0][0]',         \n",
            "                                                                  'add_7[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_60 (Conv2D)             (None, 5, 5, 1152)   221184      ['add_8[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_45 (BatchN  (None, 5, 5, 1152)  4608        ['conv2d_60[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_45 (Swish)               (None, 5, 5, 1152)   0           ['batch_normalization_45[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_15 (Depthwise  (None, 5, 5, 1152)  10368       ['swish_45[0][0]']               \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_46 (BatchN  (None, 5, 5, 1152)  4608        ['depthwise_conv2d_15[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_46 (Swish)               (None, 5, 5, 1152)   0           ['batch_normalization_46[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_15 (Lambda)             (None, 1, 1, 1152)   0           ['swish_46[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_61 (Conv2D)             (None, 1, 1, 48)     55344       ['lambda_15[0][0]']              \n",
            "                                                                                                  \n",
            " swish_47 (Swish)               (None, 1, 1, 48)     0           ['conv2d_61[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_62 (Conv2D)             (None, 1, 1, 1152)   56448       ['swish_47[0][0]']               \n",
            "                                                                                                  \n",
            " activation_15 (Activation)     (None, 1, 1, 1152)   0           ['conv2d_62[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_15 (Multiply)         (None, 5, 5, 1152)   0           ['activation_15[0][0]',          \n",
            "                                                                  'swish_46[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_63 (Conv2D)             (None, 5, 5, 320)    368640      ['multiply_15[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_47 (BatchN  (None, 5, 5, 320)   1280        ['conv2d_63[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_64 (Conv2D)             (None, 5, 5, 1280)   409600      ['batch_normalization_47[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_48 (BatchN  (None, 5, 5, 1280)  5120        ['conv2d_64[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_48 (Swish)               (None, 5, 5, 1280)   0           ['batch_normalization_48[0][0]'] \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 4,049,564\n",
            "Trainable params: 4,007,548\n",
            "Non-trainable params: 42,016\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "base_dir = '/content/drive/MyDrive/TVT_Female125'\n",
        "os.makedirs(base_dir, exist_ok=True)\n",
        "\n",
        "# Directories for our training,\n",
        "# validation and test splits\n",
        "train_dir = os.path.join(base_dir, 'train')\n",
        "os.makedirs(train_dir, exist_ok=True)\n",
        "validation_dir = os.path.join(base_dir, 'validation')\n",
        "os.makedirs(validation_dir, exist_ok=True)\n",
        "test_dir = os.path.join(base_dir, 'test')\n",
        "os.makedirs(test_dir, exist_ok=True)"
      ],
      "metadata": {
        "id": "Jwpq_-KvPef8"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#load model"
      ],
      "metadata": {
        "id": "od-ZSNm5PoGy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.append('/content/drive/MyDrive/cut_panoramic/Model/Classification/33_รอบที่3_Flimpano_Female125_250.h5')\n",
        "\n",
        "from efficientnet.layers import Swish, DropConnect\n",
        "from efficientnet.model import ConvKernalInitializer\n",
        "from tensorflow.keras.utils import get_custom_objects\n",
        "\n",
        "get_custom_objects().update({\n",
        "    'ConvKernalInitializer': ConvKernalInitializer,\n",
        "    'Swish': Swish,\n",
        "    'DropConnect':DropConnect\n",
        "})"
      ],
      "metadata": {
        "id": "n5iPL5MNPkhE"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#load model \n",
        "from tensorflow.keras.models import load_model\n",
        "model = load_model('/content/drive/MyDrive/cut_panoramic/Model/Classification/33_รอบที่3_Flimpano_Female125_250.h5')\n",
        "height = width = model.input_shape[1]"
      ],
      "metadata": {
        "id": "plYz49xMPkly"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z6IOPBflFbvc",
        "outputId": "14cf679d-8ec5-49e4-cec1-69bfe98ea20b"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " efficientnet-b0 (Functional  (None, 5, 5, 1280)       4049564   \n",
            " )                                                               \n",
            "                                                                 \n",
            " gap (GlobalMaxPooling2D)    (None, 1280)              0         \n",
            "                                                                 \n",
            " dropout_out (Dropout)       (None, 1280)              0         \n",
            "                                                                 \n",
            " fc_out (Dense)              (None, 19)                24339     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4,073,903\n",
            "Trainable params: 24,339\n",
            "Non-trainable params: 4,049,564\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train ด้วย ImageDataGenerator ของ Keras ซึ่งจะเพิ่มข้อมูลเสริมระหว่างการฝึกเพื่อลดโอกาสเกิด overfitting\n",
        "#overfitting เกิดจากข้อมูลที่ซับซ้อนกันเกินไป\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "train_datagen = ImageDataGenerator(\n",
        "      rescale=1./255, #โมเดลส่วนใหญ่ต้องใช้ RGB ในช่วง 0–1\n",
        "      rotation_range=40,\n",
        "      width_shift_range=0.2,\n",
        "      height_shift_range=0.2,\n",
        "      shear_range=0.2,\n",
        "      zoom_range=0.2,\n",
        "      horizontal_flip=True,\n",
        "      fill_mode='nearest')\n",
        "\n",
        "# Note that the validation data should not be augmented!\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "        # This is the target directory #ไดเรกเป้าหมาย\n",
        "        train_dir,\n",
        "        # รูปภาพทั้งหมดจะถูกปรับขนาดตามความสูงและความกว้างของเป้าหมาย\n",
        "        target_size=(height, width),\n",
        "        batch_size=batch_size,\n",
        "        # Since we use categorical_crossentropy loss, we need categorical labels\n",
        "        #เนื่องจากเราใช้ categorical_crossentropy loss เราจึงต้องมีป้ายกำกับตามหมวดหมู่\n",
        "        class_mode='categorical')\n",
        "\n",
        "validation_generator = test_datagen.flow_from_directory( #การดึงภาพจาก Directory มาเข้าโมเดล \n",
        "        validation_dir,\n",
        "        target_size=(height, width),\n",
        "        batch_size=batch_size,\n",
        "        class_mode='categorical')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KBMZbdr2Pgw4",
        "outputId": "05bbf409-ec91-4171-a58c-607b7fd1c5c3"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1425 images belonging to 19 classes.\n",
            "Found 475 images belonging to 19 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# multiply_16\n",
        "# set 'multiply_16' and following layers trainable\n",
        "conv_base.trainable = True\n",
        "\n",
        "set_trainable = False\n",
        "for layer in conv_base.layers:\n",
        "    if layer.name == 'multiply_16':\n",
        "        set_trainable = True\n",
        "    if set_trainable:\n",
        "        layer.trainable = True\n",
        "    else:\n",
        "        layer.trainable = False"
      ],
      "metadata": {
        "id": "wSz_e8hR0Fiv"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=optimizers.RMSprop(learning_rate=2e-5),\n",
        "              metrics=['acc'])\n",
        "history = model.fit_generator(\n",
        "      train_generator,\n",
        "      steps_per_epoch= NUM_TRAIN //batch_size,\n",
        "      epochs=epochs,\n",
        "      validation_data=validation_generator,\n",
        "      validation_steps= NUM_TEST //batch_size,\n",
        "      verbose=1,\n",
        "      use_multiprocessing=True,\n",
        "      workers=4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C9Cf1dwyP1PD",
        "outputId": "8f147975-3ffe-4b84-aacf-d686fb6380ad"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-16-95ae5648fc7b>:4: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  history = model.fit_generator(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/250\n",
            "89/89 [==============================] - 34s 283ms/step - loss: 2.4352 - acc: 0.2392 - val_loss: 3.0012 - val_acc: 0.1832\n",
            "Epoch 2/250\n",
            "89/89 [==============================] - 26s 280ms/step - loss: 2.3037 - acc: 0.2598 - val_loss: 2.9632 - val_acc: 0.1875\n",
            "Epoch 3/250\n",
            "89/89 [==============================] - 26s 286ms/step - loss: 2.3042 - acc: 0.2811 - val_loss: 2.9821 - val_acc: 0.1810\n",
            "Epoch 4/250\n",
            "89/89 [==============================] - 25s 280ms/step - loss: 2.3379 - acc: 0.2548 - val_loss: 2.9939 - val_acc: 0.1810\n",
            "Epoch 5/250\n",
            "89/89 [==============================] - 25s 280ms/step - loss: 2.2533 - acc: 0.2782 - val_loss: 2.9909 - val_acc: 0.1789\n",
            "Epoch 6/250\n",
            "89/89 [==============================] - 26s 281ms/step - loss: 2.2260 - acc: 0.2732 - val_loss: 3.0099 - val_acc: 0.1789\n",
            "Epoch 7/250\n",
            "89/89 [==============================] - 27s 299ms/step - loss: 2.2564 - acc: 0.2669 - val_loss: 3.0008 - val_acc: 0.1832\n",
            "Epoch 8/250\n",
            "89/89 [==============================] - 26s 281ms/step - loss: 2.2947 - acc: 0.2548 - val_loss: 3.0208 - val_acc: 0.1767\n",
            "Epoch 9/250\n",
            "89/89 [==============================] - 27s 289ms/step - loss: 2.2646 - acc: 0.2846 - val_loss: 2.9965 - val_acc: 0.1789\n",
            "Epoch 10/250\n",
            "89/89 [==============================] - 27s 296ms/step - loss: 2.3130 - acc: 0.2427 - val_loss: 2.9745 - val_acc: 0.1789\n",
            "Epoch 11/250\n",
            "89/89 [==============================] - 27s 301ms/step - loss: 2.2641 - acc: 0.2626 - val_loss: 2.9765 - val_acc: 0.1789\n",
            "Epoch 12/250\n",
            "89/89 [==============================] - 27s 302ms/step - loss: 2.2525 - acc: 0.2754 - val_loss: 3.0195 - val_acc: 0.1767\n",
            "Epoch 13/250\n",
            "89/89 [==============================] - 28s 306ms/step - loss: 2.2715 - acc: 0.2697 - val_loss: 2.9905 - val_acc: 0.1746\n",
            "Epoch 14/250\n",
            "89/89 [==============================] - 28s 305ms/step - loss: 2.3221 - acc: 0.2441 - val_loss: 3.0100 - val_acc: 0.1724\n",
            "Epoch 15/250\n",
            "89/89 [==============================] - 28s 307ms/step - loss: 2.2946 - acc: 0.2569 - val_loss: 3.0165 - val_acc: 0.1681\n",
            "Epoch 16/250\n",
            "89/89 [==============================] - 28s 304ms/step - loss: 2.3305 - acc: 0.2590 - val_loss: 2.9928 - val_acc: 0.1832\n",
            "Epoch 17/250\n",
            "89/89 [==============================] - 28s 304ms/step - loss: 2.2848 - acc: 0.2718 - val_loss: 2.9783 - val_acc: 0.1853\n",
            "Epoch 18/250\n",
            "89/89 [==============================] - 27s 301ms/step - loss: 2.2636 - acc: 0.2725 - val_loss: 2.9930 - val_acc: 0.1832\n",
            "Epoch 19/250\n",
            "89/89 [==============================] - 28s 303ms/step - loss: 2.2552 - acc: 0.2803 - val_loss: 3.0282 - val_acc: 0.1659\n",
            "Epoch 20/250\n",
            "89/89 [==============================] - 27s 297ms/step - loss: 2.2701 - acc: 0.2661 - val_loss: 3.0198 - val_acc: 0.1659\n",
            "Epoch 21/250\n",
            "89/89 [==============================] - 26s 285ms/step - loss: 2.2365 - acc: 0.2598 - val_loss: 3.0004 - val_acc: 0.1767\n",
            "Epoch 22/250\n",
            "89/89 [==============================] - 27s 298ms/step - loss: 2.2560 - acc: 0.2896 - val_loss: 3.0297 - val_acc: 0.1746\n",
            "Epoch 23/250\n",
            "89/89 [==============================] - 27s 299ms/step - loss: 2.2264 - acc: 0.2768 - val_loss: 3.0251 - val_acc: 0.1724\n",
            "Epoch 24/250\n",
            "89/89 [==============================] - 27s 292ms/step - loss: 2.2501 - acc: 0.2718 - val_loss: 3.0339 - val_acc: 0.1746\n",
            "Epoch 25/250\n",
            "89/89 [==============================] - 25s 278ms/step - loss: 2.3032 - acc: 0.2463 - val_loss: 3.0487 - val_acc: 0.1746\n",
            "Epoch 26/250\n",
            "89/89 [==============================] - 27s 295ms/step - loss: 2.2943 - acc: 0.2520 - val_loss: 3.0374 - val_acc: 0.1746\n",
            "Epoch 27/250\n",
            "89/89 [==============================] - 27s 293ms/step - loss: 2.2704 - acc: 0.2704 - val_loss: 3.0025 - val_acc: 0.1767\n",
            "Epoch 28/250\n",
            "89/89 [==============================] - 27s 296ms/step - loss: 2.2788 - acc: 0.2583 - val_loss: 2.9966 - val_acc: 0.1767\n",
            "Epoch 29/250\n",
            "89/89 [==============================] - 26s 281ms/step - loss: 2.2925 - acc: 0.2683 - val_loss: 2.9963 - val_acc: 0.1789\n",
            "Epoch 30/250\n",
            "89/89 [==============================] - 26s 282ms/step - loss: 2.2507 - acc: 0.2860 - val_loss: 2.9972 - val_acc: 0.1810\n",
            "Epoch 31/250\n",
            "89/89 [==============================] - 25s 276ms/step - loss: 2.2953 - acc: 0.2683 - val_loss: 2.9930 - val_acc: 0.1767\n",
            "Epoch 32/250\n",
            "89/89 [==============================] - 21s 225ms/step - loss: 2.2471 - acc: 0.2534 - val_loss: 2.9941 - val_acc: 0.1767\n",
            "Epoch 33/250\n",
            "89/89 [==============================] - 27s 298ms/step - loss: 2.2732 - acc: 0.2796 - val_loss: 2.9884 - val_acc: 0.1789\n",
            "Epoch 34/250\n",
            "89/89 [==============================] - 27s 293ms/step - loss: 2.3081 - acc: 0.2576 - val_loss: 3.0160 - val_acc: 0.1789\n",
            "Epoch 35/250\n",
            "89/89 [==============================] - 20s 222ms/step - loss: 2.2620 - acc: 0.2640 - val_loss: 2.9900 - val_acc: 0.1875\n",
            "Epoch 36/250\n",
            "89/89 [==============================] - 27s 285ms/step - loss: 2.3010 - acc: 0.2761 - val_loss: 3.0185 - val_acc: 0.1746\n",
            "Epoch 37/250\n",
            "89/89 [==============================] - 21s 233ms/step - loss: 2.2575 - acc: 0.2697 - val_loss: 3.0082 - val_acc: 0.1724\n",
            "Epoch 38/250\n",
            "89/89 [==============================] - 25s 274ms/step - loss: 2.2312 - acc: 0.2761 - val_loss: 3.0237 - val_acc: 0.1703\n",
            "Epoch 39/250\n",
            "89/89 [==============================] - 20s 220ms/step - loss: 2.2121 - acc: 0.2697 - val_loss: 2.9980 - val_acc: 0.1853\n",
            "Epoch 40/250\n",
            "89/89 [==============================] - 26s 284ms/step - loss: 2.2075 - acc: 0.2782 - val_loss: 2.9641 - val_acc: 0.1789\n",
            "Epoch 41/250\n",
            "89/89 [==============================] - 25s 277ms/step - loss: 2.2524 - acc: 0.2711 - val_loss: 3.0284 - val_acc: 0.1767\n",
            "Epoch 42/250\n",
            "89/89 [==============================] - 26s 282ms/step - loss: 2.2028 - acc: 0.2796 - val_loss: 3.0145 - val_acc: 0.1746\n",
            "Epoch 43/250\n",
            "89/89 [==============================] - 27s 298ms/step - loss: 2.2770 - acc: 0.2711 - val_loss: 3.0122 - val_acc: 0.1746\n",
            "Epoch 44/250\n",
            "89/89 [==============================] - 26s 285ms/step - loss: 2.2427 - acc: 0.2605 - val_loss: 3.0058 - val_acc: 0.1810\n",
            "Epoch 45/250\n",
            "89/89 [==============================] - 25s 278ms/step - loss: 2.2130 - acc: 0.2839 - val_loss: 3.0025 - val_acc: 0.1789\n",
            "Epoch 46/250\n",
            "89/89 [==============================] - 25s 280ms/step - loss: 2.1910 - acc: 0.2803 - val_loss: 2.9964 - val_acc: 0.1853\n",
            "Epoch 47/250\n",
            "89/89 [==============================] - 20s 221ms/step - loss: 2.2433 - acc: 0.2711 - val_loss: 3.0134 - val_acc: 0.1789\n",
            "Epoch 48/250\n",
            "89/89 [==============================] - 27s 288ms/step - loss: 2.2430 - acc: 0.2527 - val_loss: 2.9632 - val_acc: 0.1810\n",
            "Epoch 49/250\n",
            "89/89 [==============================] - 22s 243ms/step - loss: 2.2481 - acc: 0.2477 - val_loss: 3.0072 - val_acc: 0.1767\n",
            "Epoch 50/250\n",
            "89/89 [==============================] - 22s 244ms/step - loss: 2.2707 - acc: 0.2725 - val_loss: 3.0428 - val_acc: 0.1703\n",
            "Epoch 51/250\n",
            "89/89 [==============================] - 27s 298ms/step - loss: 2.1996 - acc: 0.2818 - val_loss: 2.9891 - val_acc: 0.1789\n",
            "Epoch 52/250\n",
            "89/89 [==============================] - 27s 301ms/step - loss: 2.2613 - acc: 0.2796 - val_loss: 2.9804 - val_acc: 0.1832\n",
            "Epoch 53/250\n",
            "89/89 [==============================] - 27s 300ms/step - loss: 2.2469 - acc: 0.2576 - val_loss: 2.9915 - val_acc: 0.1810\n",
            "Epoch 54/250\n",
            "89/89 [==============================] - 27s 291ms/step - loss: 2.2078 - acc: 0.2661 - val_loss: 2.9997 - val_acc: 0.1789\n",
            "Epoch 55/250\n",
            "89/89 [==============================] - 27s 296ms/step - loss: 2.2135 - acc: 0.2938 - val_loss: 2.9849 - val_acc: 0.1853\n",
            "Epoch 56/250\n",
            "89/89 [==============================] - 26s 282ms/step - loss: 2.2222 - acc: 0.2590 - val_loss: 2.9773 - val_acc: 0.1810\n",
            "Epoch 57/250\n",
            "89/89 [==============================] - 27s 294ms/step - loss: 2.2585 - acc: 0.2754 - val_loss: 2.9861 - val_acc: 0.1767\n",
            "Epoch 58/250\n",
            "89/89 [==============================] - 26s 282ms/step - loss: 2.2262 - acc: 0.2839 - val_loss: 2.9958 - val_acc: 0.1767\n",
            "Epoch 59/250\n",
            "89/89 [==============================] - 25s 279ms/step - loss: 2.2683 - acc: 0.2811 - val_loss: 2.9911 - val_acc: 0.1746\n",
            "Epoch 60/250\n",
            "89/89 [==============================] - 21s 225ms/step - loss: 2.2209 - acc: 0.2889 - val_loss: 2.9904 - val_acc: 0.1789\n",
            "Epoch 61/250\n",
            "89/89 [==============================] - 22s 241ms/step - loss: 2.2497 - acc: 0.2669 - val_loss: 2.9915 - val_acc: 0.1767\n",
            "Epoch 62/250\n",
            "89/89 [==============================] - 26s 279ms/step - loss: 2.1929 - acc: 0.2818 - val_loss: 2.9698 - val_acc: 0.1810\n",
            "Epoch 63/250\n",
            "89/89 [==============================] - 21s 227ms/step - loss: 2.2564 - acc: 0.2576 - val_loss: 2.9988 - val_acc: 0.1767\n",
            "Epoch 64/250\n",
            "89/89 [==============================] - 25s 279ms/step - loss: 2.2476 - acc: 0.2598 - val_loss: 2.9870 - val_acc: 0.1810\n",
            "Epoch 65/250\n",
            "89/89 [==============================] - 25s 276ms/step - loss: 2.2515 - acc: 0.2583 - val_loss: 2.9563 - val_acc: 0.1875\n",
            "Epoch 66/250\n",
            "89/89 [==============================] - 25s 278ms/step - loss: 2.2342 - acc: 0.2732 - val_loss: 2.9633 - val_acc: 0.1832\n",
            "Epoch 67/250\n",
            "89/89 [==============================] - 25s 279ms/step - loss: 2.2706 - acc: 0.2669 - val_loss: 2.9680 - val_acc: 0.1767\n",
            "Epoch 68/250\n",
            "89/89 [==============================] - 27s 294ms/step - loss: 2.1828 - acc: 0.2881 - val_loss: 2.9679 - val_acc: 0.1767\n",
            "Epoch 69/250\n",
            "89/89 [==============================] - 20s 223ms/step - loss: 2.2588 - acc: 0.2754 - val_loss: 2.9858 - val_acc: 0.1767\n",
            "Epoch 70/250\n",
            "89/89 [==============================] - 27s 297ms/step - loss: 2.2110 - acc: 0.2732 - val_loss: 2.9688 - val_acc: 0.1810\n",
            "Epoch 71/250\n",
            "89/89 [==============================] - 22s 244ms/step - loss: 2.2565 - acc: 0.2676 - val_loss: 2.9719 - val_acc: 0.1832\n",
            "Epoch 72/250\n",
            "89/89 [==============================] - 27s 297ms/step - loss: 2.2541 - acc: 0.2676 - val_loss: 2.9710 - val_acc: 0.1853\n",
            "Epoch 73/250\n",
            "89/89 [==============================] - 27s 298ms/step - loss: 2.2162 - acc: 0.2775 - val_loss: 2.9820 - val_acc: 0.1810\n",
            "Epoch 74/250\n",
            "89/89 [==============================] - 27s 297ms/step - loss: 2.2478 - acc: 0.2718 - val_loss: 2.9686 - val_acc: 0.1832\n",
            "Epoch 75/250\n",
            "89/89 [==============================] - 27s 292ms/step - loss: 2.2468 - acc: 0.2697 - val_loss: 2.9814 - val_acc: 0.1789\n",
            "Epoch 76/250\n",
            "89/89 [==============================] - 26s 281ms/step - loss: 2.1834 - acc: 0.2846 - val_loss: 3.0043 - val_acc: 0.1789\n",
            "Epoch 77/250\n",
            "89/89 [==============================] - 21s 223ms/step - loss: 2.2134 - acc: 0.2775 - val_loss: 3.0076 - val_acc: 0.1703\n",
            "Epoch 78/250\n",
            "89/89 [==============================] - 26s 285ms/step - loss: 2.1897 - acc: 0.2811 - val_loss: 2.9857 - val_acc: 0.1767\n",
            "Epoch 79/250\n",
            "89/89 [==============================] - 27s 302ms/step - loss: 2.2583 - acc: 0.2477 - val_loss: 2.9984 - val_acc: 0.1746\n",
            "Epoch 80/250\n",
            "89/89 [==============================] - 26s 282ms/step - loss: 2.2173 - acc: 0.2825 - val_loss: 3.0010 - val_acc: 0.1767\n",
            "Epoch 81/250\n",
            "89/89 [==============================] - 25s 276ms/step - loss: 2.2317 - acc: 0.2846 - val_loss: 2.9874 - val_acc: 0.1853\n",
            "Epoch 82/250\n",
            "89/89 [==============================] - 25s 276ms/step - loss: 2.2462 - acc: 0.2676 - val_loss: 2.9935 - val_acc: 0.1789\n",
            "Epoch 83/250\n",
            "89/89 [==============================] - 25s 282ms/step - loss: 2.2385 - acc: 0.2796 - val_loss: 2.9676 - val_acc: 0.1875\n",
            "Epoch 84/250\n",
            "89/89 [==============================] - 26s 281ms/step - loss: 2.2713 - acc: 0.2640 - val_loss: 2.9813 - val_acc: 0.1810\n",
            "Epoch 85/250\n",
            "89/89 [==============================] - 25s 279ms/step - loss: 2.2703 - acc: 0.2718 - val_loss: 2.9627 - val_acc: 0.1810\n",
            "Epoch 86/250\n",
            "89/89 [==============================] - 26s 280ms/step - loss: 2.2474 - acc: 0.2640 - val_loss: 2.9608 - val_acc: 0.1789\n",
            "Epoch 87/250\n",
            "89/89 [==============================] - 25s 278ms/step - loss: 2.2626 - acc: 0.2782 - val_loss: 2.9898 - val_acc: 0.1832\n",
            "Epoch 88/250\n",
            "89/89 [==============================] - 21s 224ms/step - loss: 2.2097 - acc: 0.2796 - val_loss: 2.9887 - val_acc: 0.1853\n",
            "Epoch 89/250\n",
            "89/89 [==============================] - 27s 291ms/step - loss: 2.2462 - acc: 0.2654 - val_loss: 2.9863 - val_acc: 0.1810\n",
            "Epoch 90/250\n",
            "89/89 [==============================] - 27s 292ms/step - loss: 2.2172 - acc: 0.2718 - val_loss: 2.9694 - val_acc: 0.1832\n",
            "Epoch 91/250\n",
            "89/89 [==============================] - 27s 300ms/step - loss: 2.2697 - acc: 0.2725 - val_loss: 2.9675 - val_acc: 0.1875\n",
            "Epoch 92/250\n",
            "89/89 [==============================] - 27s 298ms/step - loss: 2.2407 - acc: 0.2690 - val_loss: 2.9476 - val_acc: 0.1897\n",
            "Epoch 93/250\n",
            "89/89 [==============================] - 27s 298ms/step - loss: 2.2119 - acc: 0.2768 - val_loss: 2.9541 - val_acc: 0.1832\n",
            "Epoch 94/250\n",
            "89/89 [==============================] - 25s 279ms/step - loss: 2.2264 - acc: 0.2704 - val_loss: 2.9372 - val_acc: 0.1875\n",
            "Epoch 95/250\n",
            "89/89 [==============================] - 25s 275ms/step - loss: 2.2485 - acc: 0.2654 - val_loss: 2.9561 - val_acc: 0.1832\n",
            "Epoch 96/250\n",
            "89/89 [==============================] - 26s 287ms/step - loss: 2.2319 - acc: 0.2839 - val_loss: 2.9777 - val_acc: 0.1853\n",
            "Epoch 97/250\n",
            "89/89 [==============================] - 27s 293ms/step - loss: 2.2266 - acc: 0.2683 - val_loss: 2.9785 - val_acc: 0.1832\n",
            "Epoch 98/250\n",
            "89/89 [==============================] - 25s 279ms/step - loss: 2.2084 - acc: 0.2860 - val_loss: 2.9846 - val_acc: 0.1789\n",
            "Epoch 99/250\n",
            "89/89 [==============================] - 22s 243ms/step - loss: 2.2365 - acc: 0.2633 - val_loss: 2.9889 - val_acc: 0.1767\n",
            "Epoch 100/250\n",
            "89/89 [==============================] - 21s 233ms/step - loss: 2.1954 - acc: 0.2789 - val_loss: 2.9668 - val_acc: 0.1789\n",
            "Epoch 101/250\n",
            "89/89 [==============================] - 25s 273ms/step - loss: 2.2515 - acc: 0.2661 - val_loss: 2.9837 - val_acc: 0.1767\n",
            "Epoch 102/250\n",
            "89/89 [==============================] - 25s 275ms/step - loss: 2.2010 - acc: 0.2931 - val_loss: 2.9538 - val_acc: 0.1789\n",
            "Epoch 103/250\n",
            "89/89 [==============================] - 20s 219ms/step - loss: 2.1819 - acc: 0.2725 - val_loss: 2.9675 - val_acc: 0.1832\n",
            "Epoch 104/250\n",
            "89/89 [==============================] - 26s 288ms/step - loss: 2.2326 - acc: 0.2775 - val_loss: 2.9778 - val_acc: 0.1789\n",
            "Epoch 105/250\n",
            "89/89 [==============================] - 25s 272ms/step - loss: 2.2117 - acc: 0.2683 - val_loss: 3.0083 - val_acc: 0.1789\n",
            "Epoch 106/250\n",
            "89/89 [==============================] - 25s 276ms/step - loss: 2.2061 - acc: 0.2867 - val_loss: 2.9779 - val_acc: 0.1724\n",
            "Epoch 107/250\n",
            "89/89 [==============================] - 25s 273ms/step - loss: 2.2032 - acc: 0.2860 - val_loss: 2.9807 - val_acc: 0.1810\n",
            "Epoch 108/250\n",
            "89/89 [==============================] - 26s 279ms/step - loss: 2.2234 - acc: 0.2633 - val_loss: 2.9689 - val_acc: 0.1810\n",
            "Epoch 109/250\n",
            "89/89 [==============================] - 27s 288ms/step - loss: 2.2299 - acc: 0.2690 - val_loss: 2.9803 - val_acc: 0.1746\n",
            "Epoch 110/250\n",
            "89/89 [==============================] - 27s 285ms/step - loss: 2.1995 - acc: 0.2647 - val_loss: 3.0199 - val_acc: 0.1681\n",
            "Epoch 111/250\n",
            "89/89 [==============================] - 26s 278ms/step - loss: 2.2673 - acc: 0.2661 - val_loss: 2.9959 - val_acc: 0.1703\n",
            "Epoch 112/250\n",
            "89/89 [==============================] - 27s 296ms/step - loss: 2.2507 - acc: 0.2576 - val_loss: 2.9973 - val_acc: 0.1810\n",
            "Epoch 113/250\n",
            "89/89 [==============================] - 26s 281ms/step - loss: 2.2629 - acc: 0.2690 - val_loss: 2.9895 - val_acc: 0.1789\n",
            "Epoch 114/250\n",
            "89/89 [==============================] - 25s 275ms/step - loss: 2.2370 - acc: 0.2711 - val_loss: 2.9787 - val_acc: 0.1746\n",
            "Epoch 115/250\n",
            "89/89 [==============================] - 27s 295ms/step - loss: 2.2016 - acc: 0.2754 - val_loss: 2.9510 - val_acc: 0.1789\n",
            "Epoch 116/250\n",
            "89/89 [==============================] - 26s 281ms/step - loss: 2.2370 - acc: 0.2768 - val_loss: 2.9499 - val_acc: 0.1789\n",
            "Epoch 117/250\n",
            "89/89 [==============================] - 25s 274ms/step - loss: 2.1891 - acc: 0.2917 - val_loss: 2.9597 - val_acc: 0.1703\n",
            "Epoch 118/250\n",
            "89/89 [==============================] - 26s 282ms/step - loss: 2.1485 - acc: 0.2945 - val_loss: 2.9923 - val_acc: 0.1681\n",
            "Epoch 119/250\n",
            "89/89 [==============================] - 27s 300ms/step - loss: 2.1851 - acc: 0.2867 - val_loss: 2.9517 - val_acc: 0.1832\n",
            "Epoch 120/250\n",
            "89/89 [==============================] - 26s 280ms/step - loss: 2.2396 - acc: 0.2761 - val_loss: 2.9888 - val_acc: 0.1681\n",
            "Epoch 121/250\n",
            "89/89 [==============================] - 22s 246ms/step - loss: 2.2090 - acc: 0.2683 - val_loss: 2.9768 - val_acc: 0.1724\n",
            "Epoch 122/250\n",
            "89/89 [==============================] - 25s 275ms/step - loss: 2.1996 - acc: 0.2718 - val_loss: 2.9597 - val_acc: 0.1724\n",
            "Epoch 123/250\n",
            "89/89 [==============================] - 26s 282ms/step - loss: 2.2229 - acc: 0.2768 - val_loss: 2.9820 - val_acc: 0.1746\n",
            "Epoch 124/250\n",
            "89/89 [==============================] - 25s 276ms/step - loss: 2.2251 - acc: 0.2661 - val_loss: 2.9541 - val_acc: 0.1789\n",
            "Epoch 125/250\n",
            "89/89 [==============================] - 26s 282ms/step - loss: 2.2128 - acc: 0.2775 - val_loss: 2.9826 - val_acc: 0.1767\n",
            "Epoch 126/250\n",
            "89/89 [==============================] - 27s 299ms/step - loss: 2.2094 - acc: 0.2640 - val_loss: 2.9715 - val_acc: 0.1853\n",
            "Epoch 127/250\n",
            "89/89 [==============================] - 27s 296ms/step - loss: 2.2214 - acc: 0.2661 - val_loss: 2.9824 - val_acc: 0.1746\n",
            "Epoch 128/250\n",
            "89/89 [==============================] - 27s 297ms/step - loss: 2.2230 - acc: 0.2931 - val_loss: 2.9855 - val_acc: 0.1746\n",
            "Epoch 129/250\n",
            "89/89 [==============================] - 22s 240ms/step - loss: 2.2351 - acc: 0.2704 - val_loss: 2.9720 - val_acc: 0.1746\n",
            "Epoch 130/250\n",
            "89/89 [==============================] - 20s 219ms/step - loss: 2.2422 - acc: 0.2711 - val_loss: 2.9670 - val_acc: 0.1767\n",
            "Epoch 131/250\n",
            "89/89 [==============================] - 27s 291ms/step - loss: 2.2240 - acc: 0.2740 - val_loss: 2.9643 - val_acc: 0.1724\n",
            "Epoch 132/250\n",
            "89/89 [==============================] - 25s 279ms/step - loss: 2.2021 - acc: 0.2903 - val_loss: 2.9836 - val_acc: 0.1724\n",
            "Epoch 133/250\n",
            "89/89 [==============================] - 25s 278ms/step - loss: 2.2093 - acc: 0.2860 - val_loss: 2.9671 - val_acc: 0.1746\n",
            "Epoch 134/250\n",
            "89/89 [==============================] - 26s 284ms/step - loss: 2.2149 - acc: 0.2740 - val_loss: 2.9630 - val_acc: 0.1724\n",
            "Epoch 135/250\n",
            "89/89 [==============================] - 27s 296ms/step - loss: 2.2030 - acc: 0.2832 - val_loss: 2.9951 - val_acc: 0.1746\n",
            "Epoch 136/250\n",
            "89/89 [==============================] - 27s 299ms/step - loss: 2.1773 - acc: 0.2811 - val_loss: 2.9796 - val_acc: 0.1724\n",
            "Epoch 137/250\n",
            "89/89 [==============================] - 26s 290ms/step - loss: 2.2234 - acc: 0.2605 - val_loss: 2.9812 - val_acc: 0.1767\n",
            "Epoch 138/250\n",
            "89/89 [==============================] - 27s 300ms/step - loss: 2.2103 - acc: 0.2796 - val_loss: 2.9723 - val_acc: 0.1703\n",
            "Epoch 139/250\n",
            "89/89 [==============================] - 22s 237ms/step - loss: 2.2658 - acc: 0.2590 - val_loss: 2.9604 - val_acc: 0.1767\n",
            "Epoch 140/250\n",
            "89/89 [==============================] - 27s 294ms/step - loss: 2.2233 - acc: 0.2711 - val_loss: 2.9837 - val_acc: 0.1789\n",
            "Epoch 141/250\n",
            "89/89 [==============================] - 27s 300ms/step - loss: 2.1916 - acc: 0.2825 - val_loss: 2.9679 - val_acc: 0.1789\n",
            "Epoch 142/250\n",
            "89/89 [==============================] - 26s 283ms/step - loss: 2.1848 - acc: 0.2782 - val_loss: 2.9716 - val_acc: 0.1746\n",
            "Epoch 143/250\n",
            "89/89 [==============================] - 26s 281ms/step - loss: 2.2181 - acc: 0.2562 - val_loss: 2.9753 - val_acc: 0.1832\n",
            "Epoch 144/250\n",
            "89/89 [==============================] - 26s 286ms/step - loss: 2.2149 - acc: 0.2725 - val_loss: 2.9702 - val_acc: 0.1789\n",
            "Epoch 145/250\n",
            "89/89 [==============================] - 22s 242ms/step - loss: 2.1551 - acc: 0.2896 - val_loss: 2.9644 - val_acc: 0.1746\n",
            "Epoch 146/250\n",
            "89/89 [==============================] - 27s 292ms/step - loss: 2.2229 - acc: 0.2803 - val_loss: 2.9922 - val_acc: 0.1767\n",
            "Epoch 147/250\n",
            "89/89 [==============================] - 21s 224ms/step - loss: 2.1179 - acc: 0.2981 - val_loss: 2.9653 - val_acc: 0.1789\n",
            "Epoch 148/250\n",
            "89/89 [==============================] - 22s 231ms/step - loss: 2.1815 - acc: 0.2839 - val_loss: 3.0036 - val_acc: 0.1703\n",
            "Epoch 149/250\n",
            "89/89 [==============================] - 26s 279ms/step - loss: 2.2012 - acc: 0.2740 - val_loss: 2.9691 - val_acc: 0.1746\n",
            "Epoch 150/250\n",
            "89/89 [==============================] - 25s 277ms/step - loss: 2.2057 - acc: 0.2754 - val_loss: 2.9953 - val_acc: 0.1616\n",
            "Epoch 151/250\n",
            "89/89 [==============================] - 25s 276ms/step - loss: 2.1991 - acc: 0.2768 - val_loss: 2.9446 - val_acc: 0.1789\n",
            "Epoch 152/250\n",
            "89/89 [==============================] - 26s 280ms/step - loss: 2.2166 - acc: 0.2825 - val_loss: 2.9587 - val_acc: 0.1767\n",
            "Epoch 153/250\n",
            "89/89 [==============================] - 25s 277ms/step - loss: 2.2143 - acc: 0.2605 - val_loss: 2.9668 - val_acc: 0.1703\n",
            "Epoch 154/250\n",
            "89/89 [==============================] - 27s 291ms/step - loss: 2.2429 - acc: 0.2683 - val_loss: 2.9677 - val_acc: 0.1832\n",
            "Epoch 155/250\n",
            "89/89 [==============================] - 26s 284ms/step - loss: 2.2491 - acc: 0.2740 - val_loss: 2.9736 - val_acc: 0.1724\n",
            "Epoch 156/250\n",
            "89/89 [==============================] - 25s 276ms/step - loss: 2.2416 - acc: 0.2789 - val_loss: 2.9454 - val_acc: 0.1810\n",
            "Epoch 157/250\n",
            "89/89 [==============================] - 26s 288ms/step - loss: 2.1957 - acc: 0.2896 - val_loss: 2.9352 - val_acc: 0.1767\n",
            "Epoch 158/250\n",
            "89/89 [==============================] - 25s 279ms/step - loss: 2.2090 - acc: 0.3016 - val_loss: 2.9563 - val_acc: 0.1746\n",
            "Epoch 159/250\n",
            "89/89 [==============================] - 25s 276ms/step - loss: 2.2105 - acc: 0.2711 - val_loss: 2.9379 - val_acc: 0.1832\n",
            "Epoch 160/250\n",
            "89/89 [==============================] - 25s 275ms/step - loss: 2.2587 - acc: 0.2782 - val_loss: 2.9371 - val_acc: 0.1789\n",
            "Epoch 161/250\n",
            "89/89 [==============================] - 25s 278ms/step - loss: 2.2088 - acc: 0.2747 - val_loss: 2.9398 - val_acc: 0.1746\n",
            "Epoch 162/250\n",
            "89/89 [==============================] - 25s 278ms/step - loss: 2.2328 - acc: 0.2754 - val_loss: 2.9562 - val_acc: 0.1746\n",
            "Epoch 163/250\n",
            "89/89 [==============================] - 25s 280ms/step - loss: 2.1990 - acc: 0.2697 - val_loss: 2.9593 - val_acc: 0.1810\n",
            "Epoch 164/250\n",
            "89/89 [==============================] - 26s 278ms/step - loss: 2.2203 - acc: 0.2818 - val_loss: 2.9427 - val_acc: 0.1724\n",
            "Epoch 165/250\n",
            "89/89 [==============================] - 22s 229ms/step - loss: 2.2100 - acc: 0.2640 - val_loss: 2.9622 - val_acc: 0.1810\n",
            "Epoch 166/250\n",
            "89/89 [==============================] - 25s 275ms/step - loss: 2.2125 - acc: 0.2661 - val_loss: 2.9978 - val_acc: 0.1659\n",
            "Epoch 167/250\n",
            "89/89 [==============================] - 25s 279ms/step - loss: 2.1947 - acc: 0.2484 - val_loss: 3.0032 - val_acc: 0.1724\n",
            "Epoch 168/250\n",
            "89/89 [==============================] - 25s 278ms/step - loss: 2.2393 - acc: 0.2860 - val_loss: 2.9700 - val_acc: 0.1853\n",
            "Epoch 169/250\n",
            "89/89 [==============================] - 21s 226ms/step - loss: 2.2150 - acc: 0.2789 - val_loss: 2.9672 - val_acc: 0.1789\n",
            "Epoch 170/250\n",
            "89/89 [==============================] - 26s 282ms/step - loss: 2.1995 - acc: 0.2619 - val_loss: 2.9776 - val_acc: 0.1724\n",
            "Epoch 171/250\n",
            "89/89 [==============================] - 26s 280ms/step - loss: 2.1805 - acc: 0.2676 - val_loss: 2.9867 - val_acc: 0.1746\n",
            "Epoch 172/250\n",
            "89/89 [==============================] - 27s 292ms/step - loss: 2.1867 - acc: 0.2697 - val_loss: 2.9595 - val_acc: 0.1746\n",
            "Epoch 173/250\n",
            "89/89 [==============================] - 22s 239ms/step - loss: 2.1718 - acc: 0.2914 - val_loss: 2.9439 - val_acc: 0.1789\n",
            "Epoch 174/250\n",
            "89/89 [==============================] - 21s 222ms/step - loss: 2.1927 - acc: 0.2974 - val_loss: 2.9395 - val_acc: 0.1789\n",
            "Epoch 175/250\n",
            "89/89 [==============================] - 26s 286ms/step - loss: 2.1576 - acc: 0.2889 - val_loss: 2.9570 - val_acc: 0.1767\n",
            "Epoch 176/250\n",
            "89/89 [==============================] - 27s 295ms/step - loss: 2.1921 - acc: 0.2867 - val_loss: 2.9325 - val_acc: 0.1810\n",
            "Epoch 177/250\n",
            "89/89 [==============================] - 26s 287ms/step - loss: 2.1726 - acc: 0.2782 - val_loss: 2.9588 - val_acc: 0.1767\n",
            "Epoch 178/250\n",
            "89/89 [==============================] - 27s 297ms/step - loss: 2.1749 - acc: 0.2740 - val_loss: 2.9478 - val_acc: 0.1703\n",
            "Epoch 179/250\n",
            "89/89 [==============================] - 27s 296ms/step - loss: 2.1990 - acc: 0.2505 - val_loss: 2.9375 - val_acc: 0.1746\n",
            "Epoch 180/250\n",
            "89/89 [==============================] - 27s 293ms/step - loss: 2.1812 - acc: 0.2576 - val_loss: 2.9443 - val_acc: 0.1789\n",
            "Epoch 181/250\n",
            "89/89 [==============================] - 27s 301ms/step - loss: 2.2371 - acc: 0.2505 - val_loss: 2.9750 - val_acc: 0.1746\n",
            "Epoch 182/250\n",
            "89/89 [==============================] - 21s 232ms/step - loss: 2.2240 - acc: 0.2612 - val_loss: 2.9940 - val_acc: 0.1746\n",
            "Epoch 183/250\n",
            "89/89 [==============================] - 26s 276ms/step - loss: 2.1680 - acc: 0.2860 - val_loss: 2.9821 - val_acc: 0.1789\n",
            "Epoch 184/250\n",
            "89/89 [==============================] - 25s 278ms/step - loss: 2.1719 - acc: 0.2867 - val_loss: 2.9877 - val_acc: 0.1767\n",
            "Epoch 185/250\n",
            "89/89 [==============================] - 25s 273ms/step - loss: 2.2318 - acc: 0.2803 - val_loss: 2.9868 - val_acc: 0.1703\n",
            "Epoch 186/250\n",
            "89/89 [==============================] - 25s 277ms/step - loss: 2.1948 - acc: 0.2761 - val_loss: 2.9788 - val_acc: 0.1767\n",
            "Epoch 187/250\n",
            "89/89 [==============================] - 26s 280ms/step - loss: 2.2271 - acc: 0.2825 - val_loss: 2.9735 - val_acc: 0.1746\n",
            "Epoch 188/250\n",
            "89/89 [==============================] - 26s 282ms/step - loss: 2.1782 - acc: 0.2768 - val_loss: 2.9511 - val_acc: 0.1832\n",
            "Epoch 189/250\n",
            "89/89 [==============================] - 20s 224ms/step - loss: 2.1812 - acc: 0.2981 - val_loss: 2.9677 - val_acc: 0.1767\n",
            "Epoch 190/250\n",
            "89/89 [==============================] - 27s 296ms/step - loss: 2.1592 - acc: 0.2846 - val_loss: 2.9642 - val_acc: 0.1659\n",
            "Epoch 191/250\n",
            "89/89 [==============================] - 26s 283ms/step - loss: 2.1828 - acc: 0.2988 - val_loss: 2.9683 - val_acc: 0.1703\n",
            "Epoch 192/250\n",
            "89/89 [==============================] - 25s 279ms/step - loss: 2.1435 - acc: 0.2825 - val_loss: 2.9484 - val_acc: 0.1832\n",
            "Epoch 193/250\n",
            "89/89 [==============================] - 27s 293ms/step - loss: 2.2066 - acc: 0.2789 - val_loss: 2.9720 - val_acc: 0.1703\n",
            "Epoch 194/250\n",
            "89/89 [==============================] - 27s 298ms/step - loss: 2.1451 - acc: 0.2917 - val_loss: 3.0012 - val_acc: 0.1724\n",
            "Epoch 195/250\n",
            "89/89 [==============================] - 26s 288ms/step - loss: 2.1792 - acc: 0.2782 - val_loss: 2.9788 - val_acc: 0.1724\n",
            "Epoch 196/250\n",
            "89/89 [==============================] - 27s 295ms/step - loss: 2.2476 - acc: 0.2754 - val_loss: 2.9729 - val_acc: 0.1810\n",
            "Epoch 197/250\n",
            "89/89 [==============================] - 27s 298ms/step - loss: 2.1968 - acc: 0.2761 - val_loss: 2.9970 - val_acc: 0.1767\n",
            "Epoch 198/250\n",
            "89/89 [==============================] - 26s 285ms/step - loss: 2.1721 - acc: 0.2903 - val_loss: 2.9852 - val_acc: 0.1681\n",
            "Epoch 199/250\n",
            "89/89 [==============================] - 27s 296ms/step - loss: 2.1850 - acc: 0.2846 - val_loss: 2.9707 - val_acc: 0.1724\n",
            "Epoch 200/250\n",
            "89/89 [==============================] - 25s 280ms/step - loss: 2.2163 - acc: 0.2796 - val_loss: 2.9565 - val_acc: 0.1767\n",
            "Epoch 201/250\n",
            "89/89 [==============================] - 26s 287ms/step - loss: 2.2021 - acc: 0.2690 - val_loss: 2.9840 - val_acc: 0.1724\n",
            "Epoch 202/250\n",
            "89/89 [==============================] - 26s 288ms/step - loss: 2.2124 - acc: 0.2619 - val_loss: 2.9456 - val_acc: 0.1746\n",
            "Epoch 203/250\n",
            "89/89 [==============================] - 27s 297ms/step - loss: 2.2475 - acc: 0.2853 - val_loss: 2.9656 - val_acc: 0.1789\n",
            "Epoch 204/250\n",
            "89/89 [==============================] - 25s 279ms/step - loss: 2.2047 - acc: 0.2903 - val_loss: 2.9682 - val_acc: 0.1724\n",
            "Epoch 205/250\n",
            "89/89 [==============================] - 27s 294ms/step - loss: 2.2021 - acc: 0.2718 - val_loss: 2.9548 - val_acc: 0.1746\n",
            "Epoch 206/250\n",
            "89/89 [==============================] - 27s 295ms/step - loss: 2.1639 - acc: 0.2967 - val_loss: 2.9542 - val_acc: 0.1810\n",
            "Epoch 207/250\n",
            "89/89 [==============================] - 25s 278ms/step - loss: 2.1620 - acc: 0.2754 - val_loss: 2.9802 - val_acc: 0.1659\n",
            "Epoch 208/250\n",
            "89/89 [==============================] - 25s 281ms/step - loss: 2.1811 - acc: 0.2910 - val_loss: 2.9673 - val_acc: 0.1853\n",
            "Epoch 209/250\n",
            "89/89 [==============================] - 26s 288ms/step - loss: 2.2509 - acc: 0.2583 - val_loss: 2.9537 - val_acc: 0.1789\n",
            "Epoch 210/250\n",
            "89/89 [==============================] - 27s 293ms/step - loss: 2.1359 - acc: 0.2889 - val_loss: 2.9326 - val_acc: 0.1789\n",
            "Epoch 211/250\n",
            "89/89 [==============================] - 27s 294ms/step - loss: 2.1831 - acc: 0.2889 - val_loss: 2.9675 - val_acc: 0.1810\n",
            "Epoch 212/250\n",
            "89/89 [==============================] - 27s 298ms/step - loss: 2.1585 - acc: 0.3038 - val_loss: 2.9906 - val_acc: 0.1810\n",
            "Epoch 213/250\n",
            "89/89 [==============================] - 26s 282ms/step - loss: 2.2504 - acc: 0.2711 - val_loss: 2.9026 - val_acc: 0.1810\n",
            "Epoch 214/250\n",
            "89/89 [==============================] - 25s 277ms/step - loss: 2.2237 - acc: 0.2811 - val_loss: 2.9690 - val_acc: 0.1746\n",
            "Epoch 215/250\n",
            "89/89 [==============================] - 26s 281ms/step - loss: 2.1962 - acc: 0.2775 - val_loss: 2.9698 - val_acc: 0.1767\n",
            "Epoch 216/250\n",
            "89/89 [==============================] - 25s 276ms/step - loss: 2.2026 - acc: 0.2761 - val_loss: 2.9615 - val_acc: 0.1703\n",
            "Epoch 217/250\n",
            "89/89 [==============================] - 27s 293ms/step - loss: 2.1814 - acc: 0.2789 - val_loss: 2.9699 - val_acc: 0.1789\n",
            "Epoch 218/250\n",
            "89/89 [==============================] - 26s 283ms/step - loss: 2.1668 - acc: 0.2747 - val_loss: 2.9894 - val_acc: 0.1746\n",
            "Epoch 219/250\n",
            "89/89 [==============================] - 20s 219ms/step - loss: 2.2053 - acc: 0.2633 - val_loss: 2.9882 - val_acc: 0.1746\n",
            "Epoch 220/250\n",
            "89/89 [==============================] - 23s 247ms/step - loss: 2.2408 - acc: 0.2697 - val_loss: 2.9845 - val_acc: 0.1746\n",
            "Epoch 221/250\n",
            "89/89 [==============================] - 28s 303ms/step - loss: 2.1812 - acc: 0.2874 - val_loss: 2.9973 - val_acc: 0.1746\n",
            "Epoch 222/250\n",
            "89/89 [==============================] - 27s 301ms/step - loss: 2.1567 - acc: 0.2846 - val_loss: 2.9827 - val_acc: 0.1746\n",
            "Epoch 223/250\n",
            "89/89 [==============================] - 27s 301ms/step - loss: 2.1968 - acc: 0.2839 - val_loss: 2.9809 - val_acc: 0.1681\n",
            "Epoch 224/250\n",
            "89/89 [==============================] - 28s 303ms/step - loss: 2.2068 - acc: 0.2782 - val_loss: 2.9707 - val_acc: 0.1789\n",
            "Epoch 225/250\n",
            "89/89 [==============================] - 27s 298ms/step - loss: 2.1900 - acc: 0.2903 - val_loss: 2.9432 - val_acc: 0.1767\n",
            "Epoch 226/250\n",
            "89/89 [==============================] - 26s 284ms/step - loss: 2.1717 - acc: 0.2803 - val_loss: 2.9691 - val_acc: 0.1767\n",
            "Epoch 227/250\n",
            "89/89 [==============================] - 25s 278ms/step - loss: 2.1867 - acc: 0.2981 - val_loss: 2.9563 - val_acc: 0.1810\n",
            "Epoch 228/250\n",
            "89/89 [==============================] - 21s 225ms/step - loss: 2.2073 - acc: 0.2683 - val_loss: 2.9346 - val_acc: 0.1789\n",
            "Epoch 229/250\n",
            "89/89 [==============================] - 26s 285ms/step - loss: 2.1200 - acc: 0.2988 - val_loss: 2.9447 - val_acc: 0.1767\n",
            "Epoch 230/250\n",
            "89/89 [==============================] - 27s 299ms/step - loss: 2.1602 - acc: 0.2889 - val_loss: 2.9614 - val_acc: 0.1832\n",
            "Epoch 231/250\n",
            "89/89 [==============================] - 26s 281ms/step - loss: 2.1700 - acc: 0.2654 - val_loss: 2.9789 - val_acc: 0.1746\n",
            "Epoch 232/250\n",
            "89/89 [==============================] - 26s 290ms/step - loss: 2.1655 - acc: 0.2860 - val_loss: 2.9402 - val_acc: 0.1724\n",
            "Epoch 233/250\n",
            "89/89 [==============================] - 26s 285ms/step - loss: 2.1507 - acc: 0.2839 - val_loss: 2.9704 - val_acc: 0.1724\n",
            "Epoch 234/250\n",
            "89/89 [==============================] - 27s 298ms/step - loss: 2.1791 - acc: 0.2740 - val_loss: 2.9769 - val_acc: 0.1767\n",
            "Epoch 235/250\n",
            "89/89 [==============================] - 21s 230ms/step - loss: 2.1290 - acc: 0.3009 - val_loss: 2.9958 - val_acc: 0.1724\n",
            "Epoch 236/250\n",
            "89/89 [==============================] - 27s 289ms/step - loss: 2.1644 - acc: 0.2903 - val_loss: 2.9567 - val_acc: 0.1703\n",
            "Epoch 237/250\n",
            "89/89 [==============================] - 26s 282ms/step - loss: 2.1998 - acc: 0.2789 - val_loss: 2.9419 - val_acc: 0.1810\n",
            "Epoch 238/250\n",
            "89/89 [==============================] - 22s 232ms/step - loss: 2.1828 - acc: 0.2896 - val_loss: 2.9493 - val_acc: 0.1724\n",
            "Epoch 239/250\n",
            "89/89 [==============================] - 26s 277ms/step - loss: 2.1209 - acc: 0.2839 - val_loss: 2.9529 - val_acc: 0.1767\n",
            "Epoch 240/250\n",
            "89/89 [==============================] - 27s 289ms/step - loss: 2.1844 - acc: 0.2619 - val_loss: 2.9688 - val_acc: 0.1724\n",
            "Epoch 241/250\n",
            "89/89 [==============================] - 27s 299ms/step - loss: 2.1234 - acc: 0.3052 - val_loss: 2.9524 - val_acc: 0.1853\n",
            "Epoch 242/250\n",
            "89/89 [==============================] - 28s 305ms/step - loss: 2.2145 - acc: 0.2605 - val_loss: 2.9909 - val_acc: 0.1767\n",
            "Epoch 243/250\n",
            "89/89 [==============================] - 28s 307ms/step - loss: 2.2318 - acc: 0.2718 - val_loss: 2.9494 - val_acc: 0.1746\n",
            "Epoch 244/250\n",
            "89/89 [==============================] - 26s 289ms/step - loss: 2.1901 - acc: 0.2732 - val_loss: 2.9775 - val_acc: 0.1789\n",
            "Epoch 245/250\n",
            "89/89 [==============================] - 26s 282ms/step - loss: 2.1961 - acc: 0.2910 - val_loss: 2.9577 - val_acc: 0.1832\n",
            "Epoch 246/250\n",
            "89/89 [==============================] - 26s 282ms/step - loss: 2.1465 - acc: 0.2811 - val_loss: 2.9760 - val_acc: 0.1767\n",
            "Epoch 247/250\n",
            "89/89 [==============================] - 26s 283ms/step - loss: 2.1944 - acc: 0.2740 - val_loss: 2.9798 - val_acc: 0.1746\n",
            "Epoch 248/250\n",
            "89/89 [==============================] - 26s 286ms/step - loss: 2.1758 - acc: 0.2881 - val_loss: 2.9559 - val_acc: 0.1810\n",
            "Epoch 249/250\n",
            "89/89 [==============================] - 26s 288ms/step - loss: 2.2123 - acc: 0.2917 - val_loss: 2.9491 - val_acc: 0.1789\n",
            "Epoch 250/250\n",
            "89/89 [==============================] - 26s 279ms/step - loss: 2.1593 - acc: 0.2924 - val_loss: 2.9921 - val_acc: 0.1746\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "acc = history.history['acc']\n",
        "val_acc = history.history['val_acc']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs_x = range(len(acc))\n",
        "\n",
        "plt.plot(epochs_x, acc, 'mo', label='Training acc')\n",
        "plt.plot(epochs_x, val_acc, 'k', label='Validation acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.figure()\n",
        "\n",
        "plt.plot(epochs_x, loss, 'mo', label='Training loss')\n",
        "plt.plot(epochs_x, val_loss, 'k', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "kwylTJpTP5XI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545
        },
        "outputId": "1e2c2e7e-06cb-41ba-8008-f87bb726563f"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Download the model"
      ],
      "metadata": {
        "id": "lD-vKaoHQAFd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "os.makedirs('/content/drive/My Drive/cut_panoramic/Model/Classification', exist_ok=True)\n",
        "model.save('/content/drive/My Drive/cut_panoramic/Model/Classification/44_รอบที่4_Flimpano_Female125_250_Unfreez+Modelcom.h5')"
      ],
      "metadata": {
        "id": "74dL7-HLP_Sh"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from google.colab import files\n",
        "# files.download('/content/drive/My Drive/cut_panoramic/Model/33_รอบที่3_Flimpano_Female125_250.h5')"
      ],
      "metadata": {
        "id": "qcPW-brHQDpc"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "05eOFn2Y1wRs"
      },
      "execution_count": 19,
      "outputs": []
    }
  ]
}